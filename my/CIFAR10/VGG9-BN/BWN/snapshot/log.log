I0125 17:17:20.308210 12648 upgrade_proto.cpp:1113] snapshot_prefix was a directory and is replaced to my/CIFAR10/VGG9-BN/BWN/snapshot/solver
I0125 17:17:20.309413 12648 caffe.cpp:204] Using GPUs 0
I0125 17:17:24.720511 12648 caffe.cpp:209] GPU 0: GeForce GTX 1080 Ti
I0125 17:17:25.197206 12648 solver.cpp:45] Initializing solver from parameters: 
test_iter: 100
test_interval: 100
base_lr: 0.1
display: 200
max_iter: 100000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
stepsize: 15000
snapshot: 10000
snapshot_prefix: "my/CIFAR10/VGG9-BN/BWN/snapshot/solver"
solver_mode: GPU
device_id: 0
net: "my/CIFAR10/VGG9-BN/BWN/train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
I0125 17:17:25.197782 12648 solver.cpp:105] Creating training net from net file: my/CIFAR10/VGG9-BN/BWN/train_test.prototxt
I0125 17:17:25.199102 12648 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0125 17:17:25.199157 12648 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0125 17:17:25.199374 12648 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_vgg"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
    mean_file: "/home/zhengzhe/Data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/zhengzhe/Data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "BinaryConvolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
  debug_param {
    binary_relax: true
    update_lamda: 10
  }
}
layer {
  name: "bn1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1_bn"
}
layer {
  name: "bn1_scal"
  type: "Scale"
  bottom: "conv1_bn"
  top: "conv1_sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1_sc"
  top: "conv1_sc"
}
layer {
  name: "conv2"
  type: "BinaryConvolution"
  bottom: "conv1_sc"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
  debug_param {
    binary_relax: true
    update_lamda: 10
    phase1_iter: 50000
  }
}
layer {
  name: "bn2_bn"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2_bn"
}
layer {
  name: "bn2_scal"
  type: "Scale"
  bottom: "conv2_bn"
  top: "conv2_sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2_sc"
  top: "conv2_sc"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv2_sc"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "pool1"
  top: "pool1"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "conv3"
  type: "BinaryConvolution"
  bottom: "pool1"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
  debug_param {
    binary_relax: true
    update_lamda: 10
  }
}
layer {
  name: "bn3_bn"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3_bn"
}
layer {
  name: "bn3_scal"
  type: "Scale"
  bottom: "conv3_bn"
  top: "conv3_sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3_sc"
  top: "conv3_sc"
}
layer {
  name: "conv4"
  type: "BinaryConvolution"
  bottom: "conv3_sc"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
  debug_param {
    binary_relax: true
    update_lamda: 10
  }
}
layer {
  name: "bn4_bn"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4_bn"
}
layer {
  name: "bn4_scal"
  type: "Scale"
  bottom: "conv4_bn"
  top: "conv4_sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4_sc"
  top: "conv4_sc"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv4_sc"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "pool2"
  top: "pool2"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "conv5"
  type: "BinaryConvolution"
  bottom: "pool2"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
  debug_param {
    binary_relax: true
    update_lamda: 10
  }
}
layer {
  name: "bn5_bn"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5_bn"
}
layer {
  name: "bn5_scal"
  type: "Scale"
  bottom: "conv5_bn"
  top: "conv5_sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5_sc"
  top: "conv5_sc"
}
layer {
  name: "conv6"
  type: "BinaryConvolution"
  bottom: "conv5_sc"
  top: "conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
  debug_param {
    binary_relax: true
    update_lamda: 10
  }
}
layer {
  name: "bn6_bn"
  type: "BatchNorm"
  bottom: "conv6"
  top: "conv6_bn"
}
layer {
  name: "bn6_scal"
  type: "Scale"
  bottom: "conv6_bn"
  top: "conv6_sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "conv6_sc"
  top: "conv6_sc"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv6_sc"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "pool3"
  top: "pool3"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "fc7"
  type: "BinaryInnerProduct"
  bottom: "pool3"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 512
    bias_term: false
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
  debug_param {
    binary_relax: true
    update_lamda: 10
  }
}
layer {
  name: "bn7_bn"
  type: "BatchNorm"
  bottom: "fc7"
  top: "fc7_bn"
}
layer {
  name: "bn7_scal"
  type: "Scale"
  bottom: "fc7_bn"
  top: "fc7_sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7_sc"
  top: "fc7_sc"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7_sc"
  top: "fc7_sc"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "BinaryInnerProduct"
  bottom: "fc7_sc"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 512
    bias_term: false
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
  debug_param {
    binary_relax: true
    update_lamda: 10
  }
}
layer {
  name: "bn8_bn"
  type: "BatchNorm"
  bottom: "fc8"
  top: "fc8_bn"
}
layer {
  name: "bn8_scal"
  type: "Scale"
  bottom: "fc8_bn"
  top: "fc8_sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu8"
  type: "ReLU"
  bottom: "fc8_sc"
  top: "fc8_sc"
}
layer {
  name: "drop8"
  type: "Dropout"
  bottom: "fc8_sc"
  top: "fc8_sc"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc9"
  type: "BinaryInnerProduct"
  bottom: "fc8_sc"
  top: "fc9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.01
    }
  }
  debug_param {
    binary_relax: true
    update_lamda: 10
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc9"
  bottom: "label"
  top: "loss"
}
I0125 17:17:25.200017 12648 layer_factory.hpp:78] Creating layer cifar
I0125 17:17:25.200239 12648 db_lmdb.cpp:35] Opened lmdb /home/zhengzhe/Data/cifar10/cifar10_train_lmdb
I0125 17:17:25.200310 12648 net.cpp:84] Creating Layer cifar
I0125 17:17:25.200357 12648 net.cpp:380] cifar -> data
I0125 17:17:25.200510 12648 net.cpp:380] cifar -> label
I0125 17:17:25.200575 12648 data_transformer.cpp:25] Loading mean file from: /home/zhengzhe/Data/cifar10/mean.binaryproto
I0125 17:17:25.203670 12648 data_layer.cpp:45] output data size: 100,3,32,32
I0125 17:17:25.210300 12648 base_data_layer.cpp:72] Initializing prefetch
I0125 17:17:25.210947 12648 base_data_layer.cpp:75] Prefetch initialized.
I0125 17:17:25.210970 12648 net.cpp:122] Setting up cifar
I0125 17:17:25.211014 12648 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0125 17:17:25.211021 12648 net.cpp:129] Top shape: 100 (100)
I0125 17:17:25.211024 12648 net.cpp:137] Memory required for data: 1229200
I0125 17:17:25.211038 12648 layer_factory.hpp:78] Creating layer conv1
I0125 17:17:25.211113 12648 net.cpp:84] Creating Layer conv1
I0125 17:17:25.211130 12648 net.cpp:406] conv1 <- data
I0125 17:17:25.211190 12648 net.cpp:380] conv1 -> conv1
I0125 17:17:25.850188 12648 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 393216
I0125 17:17:25.850265 12648 net.cpp:122] Setting up conv1
I0125 17:17:25.850294 12648 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0125 17:17:25.850303 12648 net.cpp:137] Memory required for data: 27443600
I0125 17:17:25.850464 12648 layer_factory.hpp:78] Creating layer bn1_bn
I0125 17:17:25.850543 12648 net.cpp:84] Creating Layer bn1_bn
I0125 17:17:25.850562 12648 net.cpp:406] bn1_bn <- conv1
I0125 17:17:25.850622 12648 net.cpp:380] bn1_bn -> conv1_bn
I0125 17:17:25.852749 12648 net.cpp:122] Setting up bn1_bn
I0125 17:17:25.852795 12648 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0125 17:17:25.852802 12648 net.cpp:137] Memory required for data: 53658000
I0125 17:17:25.852874 12648 layer_factory.hpp:78] Creating layer bn1_scal
I0125 17:17:25.852921 12648 net.cpp:84] Creating Layer bn1_scal
I0125 17:17:25.852933 12648 net.cpp:406] bn1_scal <- conv1_bn
I0125 17:17:25.852970 12648 net.cpp:380] bn1_scal -> conv1_sc
I0125 17:17:25.853138 12648 layer_factory.hpp:78] Creating layer bn1_scal
I0125 17:17:25.853458 12648 net.cpp:122] Setting up bn1_scal
I0125 17:17:25.853483 12648 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0125 17:17:25.853493 12648 net.cpp:137] Memory required for data: 79872400
I0125 17:17:25.853529 12648 layer_factory.hpp:78] Creating layer relu1
I0125 17:17:25.853577 12648 net.cpp:84] Creating Layer relu1
I0125 17:17:25.853591 12648 net.cpp:406] relu1 <- conv1_sc
I0125 17:17:25.853612 12648 net.cpp:367] relu1 -> conv1_sc (in-place)
I0125 17:17:25.854511 12648 net.cpp:122] Setting up relu1
I0125 17:17:25.854532 12648 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0125 17:17:25.854547 12648 net.cpp:137] Memory required for data: 106086800
I0125 17:17:25.854557 12648 layer_factory.hpp:78] Creating layer conv2
I0125 17:17:25.854604 12648 net.cpp:84] Creating Layer conv2
I0125 17:17:25.854616 12648 net.cpp:406] conv2 <- conv1_sc
I0125 17:17:25.854652 12648 net.cpp:380] conv2 -> conv2
I0125 17:17:25.864933 12648 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 786432
I0125 17:17:25.864981 12648 net.cpp:122] Setting up conv2
I0125 17:17:25.864995 12648 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0125 17:17:25.865012 12648 net.cpp:137] Memory required for data: 132301200
I0125 17:17:25.865032 12648 layer_factory.hpp:78] Creating layer bn2_bn
I0125 17:17:25.865068 12648 net.cpp:84] Creating Layer bn2_bn
I0125 17:17:25.865079 12648 net.cpp:406] bn2_bn <- conv2
I0125 17:17:25.865103 12648 net.cpp:380] bn2_bn -> conv2_bn
I0125 17:17:25.865504 12648 net.cpp:122] Setting up bn2_bn
I0125 17:17:25.865525 12648 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0125 17:17:25.865530 12648 net.cpp:137] Memory required for data: 158515600
I0125 17:17:25.865576 12648 layer_factory.hpp:78] Creating layer bn2_scal
I0125 17:17:25.865635 12648 net.cpp:84] Creating Layer bn2_scal
I0125 17:17:25.865648 12648 net.cpp:406] bn2_scal <- conv2_bn
I0125 17:17:25.865676 12648 net.cpp:380] bn2_scal -> conv2_sc
I0125 17:17:25.865785 12648 layer_factory.hpp:78] Creating layer bn2_scal
I0125 17:17:25.866029 12648 net.cpp:122] Setting up bn2_scal
I0125 17:17:25.866050 12648 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0125 17:17:25.866057 12648 net.cpp:137] Memory required for data: 184730000
I0125 17:17:25.866091 12648 layer_factory.hpp:78] Creating layer relu2
I0125 17:17:25.866127 12648 net.cpp:84] Creating Layer relu2
I0125 17:17:25.866138 12648 net.cpp:406] relu2 <- conv2_sc
I0125 17:17:25.866165 12648 net.cpp:367] relu2 -> conv2_sc (in-place)
I0125 17:17:25.867028 12648 net.cpp:122] Setting up relu2
I0125 17:17:25.867046 12648 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0125 17:17:25.867051 12648 net.cpp:137] Memory required for data: 210944400
I0125 17:17:25.867060 12648 layer_factory.hpp:78] Creating layer pool1
I0125 17:17:25.867102 12648 net.cpp:84] Creating Layer pool1
I0125 17:17:25.867113 12648 net.cpp:406] pool1 <- conv2_sc
I0125 17:17:25.867154 12648 net.cpp:380] pool1 -> pool1
I0125 17:17:25.867272 12648 net.cpp:122] Setting up pool1
I0125 17:17:25.867296 12648 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0125 17:17:25.867302 12648 net.cpp:137] Memory required for data: 217498000
I0125 17:17:25.867311 12648 layer_factory.hpp:78] Creating layer drop1
I0125 17:17:25.867347 12648 net.cpp:84] Creating Layer drop1
I0125 17:17:25.867359 12648 net.cpp:406] drop1 <- pool1
I0125 17:17:25.867383 12648 net.cpp:367] drop1 -> pool1 (in-place)
I0125 17:17:25.867449 12648 net.cpp:122] Setting up drop1
I0125 17:17:25.867461 12648 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0125 17:17:25.867466 12648 net.cpp:137] Memory required for data: 224051600
I0125 17:17:25.867475 12648 layer_factory.hpp:78] Creating layer conv3
I0125 17:17:25.867511 12648 net.cpp:84] Creating Layer conv3
I0125 17:17:25.867523 12648 net.cpp:406] conv3 <- pool1
I0125 17:17:25.867550 12648 net.cpp:380] conv3 -> conv3
I0125 17:17:25.880136 12648 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 1572864
I0125 17:17:25.880491 12648 net.cpp:122] Setting up conv3
I0125 17:17:25.880512 12648 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0125 17:17:25.880518 12648 net.cpp:137] Memory required for data: 237158800
I0125 17:17:25.880537 12648 layer_factory.hpp:78] Creating layer bn3_bn
I0125 17:17:25.880563 12648 net.cpp:84] Creating Layer bn3_bn
I0125 17:17:25.880574 12648 net.cpp:406] bn3_bn <- conv3
I0125 17:17:25.880597 12648 net.cpp:380] bn3_bn -> conv3_bn
I0125 17:17:25.880924 12648 net.cpp:122] Setting up bn3_bn
I0125 17:17:25.880942 12648 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0125 17:17:25.880949 12648 net.cpp:137] Memory required for data: 250266000
I0125 17:17:25.880977 12648 layer_factory.hpp:78] Creating layer bn3_scal
I0125 17:17:25.881001 12648 net.cpp:84] Creating Layer bn3_scal
I0125 17:17:25.881012 12648 net.cpp:406] bn3_scal <- conv3_bn
I0125 17:17:25.881034 12648 net.cpp:380] bn3_scal -> conv3_sc
I0125 17:17:25.881132 12648 layer_factory.hpp:78] Creating layer bn3_scal
I0125 17:17:25.881340 12648 net.cpp:122] Setting up bn3_scal
I0125 17:17:25.881366 12648 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0125 17:17:25.881371 12648 net.cpp:137] Memory required for data: 263373200
I0125 17:17:25.881405 12648 layer_factory.hpp:78] Creating layer relu3
I0125 17:17:25.881428 12648 net.cpp:84] Creating Layer relu3
I0125 17:17:25.881438 12648 net.cpp:406] relu3 <- conv3_sc
I0125 17:17:25.881458 12648 net.cpp:367] relu3 -> conv3_sc (in-place)
I0125 17:17:25.882560 12648 net.cpp:122] Setting up relu3
I0125 17:17:25.882581 12648 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0125 17:17:25.882586 12648 net.cpp:137] Memory required for data: 276480400
I0125 17:17:25.882596 12648 layer_factory.hpp:78] Creating layer conv4
I0125 17:17:25.882637 12648 net.cpp:84] Creating Layer conv4
I0125 17:17:25.882650 12648 net.cpp:406] conv4 <- conv3_sc
I0125 17:17:25.882699 12648 net.cpp:380] conv4 -> conv4
I0125 17:17:25.902875 12648 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0125 17:17:25.903215 12648 net.cpp:122] Setting up conv4
I0125 17:17:25.903236 12648 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0125 17:17:25.903242 12648 net.cpp:137] Memory required for data: 289587600
I0125 17:17:25.903261 12648 layer_factory.hpp:78] Creating layer bn4_bn
I0125 17:17:25.903295 12648 net.cpp:84] Creating Layer bn4_bn
I0125 17:17:25.903306 12648 net.cpp:406] bn4_bn <- conv4
I0125 17:17:25.903347 12648 net.cpp:380] bn4_bn -> conv4_bn
I0125 17:17:25.903650 12648 net.cpp:122] Setting up bn4_bn
I0125 17:17:25.903676 12648 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0125 17:17:25.903692 12648 net.cpp:137] Memory required for data: 302694800
I0125 17:17:25.903717 12648 layer_factory.hpp:78] Creating layer bn4_scal
I0125 17:17:25.903740 12648 net.cpp:84] Creating Layer bn4_scal
I0125 17:17:25.903751 12648 net.cpp:406] bn4_scal <- conv4_bn
I0125 17:17:25.903771 12648 net.cpp:380] bn4_scal -> conv4_sc
I0125 17:17:25.903865 12648 layer_factory.hpp:78] Creating layer bn4_scal
I0125 17:17:25.904073 12648 net.cpp:122] Setting up bn4_scal
I0125 17:17:25.904090 12648 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0125 17:17:25.904096 12648 net.cpp:137] Memory required for data: 315802000
I0125 17:17:25.904114 12648 layer_factory.hpp:78] Creating layer relu4
I0125 17:17:25.904132 12648 net.cpp:84] Creating Layer relu4
I0125 17:17:25.904141 12648 net.cpp:406] relu4 <- conv4_sc
I0125 17:17:25.904160 12648 net.cpp:367] relu4 -> conv4_sc (in-place)
I0125 17:17:25.905949 12648 net.cpp:122] Setting up relu4
I0125 17:17:25.906018 12648 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0125 17:17:25.906028 12648 net.cpp:137] Memory required for data: 328909200
I0125 17:17:25.906054 12648 layer_factory.hpp:78] Creating layer pool2
I0125 17:17:25.906136 12648 net.cpp:84] Creating Layer pool2
I0125 17:17:25.906170 12648 net.cpp:406] pool2 <- conv4_sc
I0125 17:17:25.906260 12648 net.cpp:380] pool2 -> pool2
I0125 17:17:25.906510 12648 net.cpp:122] Setting up pool2
I0125 17:17:25.906554 12648 net.cpp:129] Top shape: 100 128 8 8 (819200)
I0125 17:17:25.906570 12648 net.cpp:137] Memory required for data: 332186000
I0125 17:17:25.906592 12648 layer_factory.hpp:78] Creating layer drop2
I0125 17:17:25.906641 12648 net.cpp:84] Creating Layer drop2
I0125 17:17:25.906668 12648 net.cpp:406] drop2 <- pool2
I0125 17:17:25.906721 12648 net.cpp:367] drop2 -> pool2 (in-place)
I0125 17:17:25.906852 12648 net.cpp:122] Setting up drop2
I0125 17:17:25.906884 12648 net.cpp:129] Top shape: 100 128 8 8 (819200)
I0125 17:17:25.906900 12648 net.cpp:137] Memory required for data: 335462800
I0125 17:17:25.906921 12648 layer_factory.hpp:78] Creating layer conv5
I0125 17:17:25.907014 12648 net.cpp:84] Creating Layer conv5
I0125 17:17:25.907045 12648 net.cpp:406] conv5 <- pool2
I0125 17:17:25.907115 12648 net.cpp:380] conv5 -> conv5
I0125 17:17:25.967430 12648 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 6291456
I0125 17:17:25.967839 12648 net.cpp:122] Setting up conv5
I0125 17:17:25.967870 12648 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0125 17:17:25.967877 12648 net.cpp:137] Memory required for data: 342016400
I0125 17:17:25.967905 12648 layer_factory.hpp:78] Creating layer bn5_bn
I0125 17:17:25.967936 12648 net.cpp:84] Creating Layer bn5_bn
I0125 17:17:25.967962 12648 net.cpp:406] bn5_bn <- conv5
I0125 17:17:25.968001 12648 net.cpp:380] bn5_bn -> conv5_bn
I0125 17:17:25.968475 12648 net.cpp:122] Setting up bn5_bn
I0125 17:17:25.968499 12648 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0125 17:17:25.968505 12648 net.cpp:137] Memory required for data: 348570000
I0125 17:17:25.968544 12648 layer_factory.hpp:78] Creating layer bn5_scal
I0125 17:17:25.968591 12648 net.cpp:84] Creating Layer bn5_scal
I0125 17:17:25.968611 12648 net.cpp:406] bn5_scal <- conv5_bn
I0125 17:17:25.968645 12648 net.cpp:380] bn5_scal -> conv5_sc
I0125 17:17:25.968808 12648 layer_factory.hpp:78] Creating layer bn5_scal
I0125 17:17:25.969142 12648 net.cpp:122] Setting up bn5_scal
I0125 17:17:25.969172 12648 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0125 17:17:25.969177 12648 net.cpp:137] Memory required for data: 355123600
I0125 17:17:25.969203 12648 layer_factory.hpp:78] Creating layer relu5
I0125 17:17:25.969236 12648 net.cpp:84] Creating Layer relu5
I0125 17:17:25.969255 12648 net.cpp:406] relu5 <- conv5_sc
I0125 17:17:25.969301 12648 net.cpp:367] relu5 -> conv5_sc (in-place)
I0125 17:17:25.970312 12648 net.cpp:122] Setting up relu5
I0125 17:17:25.970335 12648 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0125 17:17:25.970340 12648 net.cpp:137] Memory required for data: 361677200
I0125 17:17:25.970357 12648 layer_factory.hpp:78] Creating layer conv6
I0125 17:17:25.970398 12648 net.cpp:84] Creating Layer conv6
I0125 17:17:25.970418 12648 net.cpp:406] conv6 <- conv5_sc
I0125 17:17:25.970464 12648 net.cpp:380] conv6 -> conv6
I0125 17:17:26.068965 12648 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0125 17:17:26.069314 12648 net.cpp:122] Setting up conv6
I0125 17:17:26.069339 12648 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0125 17:17:26.069351 12648 net.cpp:137] Memory required for data: 368230800
I0125 17:17:26.069371 12648 layer_factory.hpp:78] Creating layer bn6_bn
I0125 17:17:26.069396 12648 net.cpp:84] Creating Layer bn6_bn
I0125 17:17:26.069411 12648 net.cpp:406] bn6_bn <- conv6
I0125 17:17:26.069433 12648 net.cpp:380] bn6_bn -> conv6_bn
I0125 17:17:26.069785 12648 net.cpp:122] Setting up bn6_bn
I0125 17:17:26.069804 12648 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0125 17:17:26.069811 12648 net.cpp:137] Memory required for data: 374784400
I0125 17:17:26.069864 12648 layer_factory.hpp:78] Creating layer bn6_scal
I0125 17:17:26.069890 12648 net.cpp:84] Creating Layer bn6_scal
I0125 17:17:26.069902 12648 net.cpp:406] bn6_scal <- conv6_bn
I0125 17:17:26.069924 12648 net.cpp:380] bn6_scal -> conv6_sc
I0125 17:17:26.070029 12648 layer_factory.hpp:78] Creating layer bn6_scal
I0125 17:17:26.070255 12648 net.cpp:122] Setting up bn6_scal
I0125 17:17:26.070274 12648 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0125 17:17:26.070281 12648 net.cpp:137] Memory required for data: 381338000
I0125 17:17:26.070302 12648 layer_factory.hpp:78] Creating layer relu6
I0125 17:17:26.070319 12648 net.cpp:84] Creating Layer relu6
I0125 17:17:26.070329 12648 net.cpp:406] relu6 <- conv6_sc
I0125 17:17:26.070361 12648 net.cpp:367] relu6 -> conv6_sc (in-place)
I0125 17:17:26.071171 12648 net.cpp:122] Setting up relu6
I0125 17:17:26.071189 12648 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0125 17:17:26.071193 12648 net.cpp:137] Memory required for data: 387891600
I0125 17:17:26.071203 12648 layer_factory.hpp:78] Creating layer pool3
I0125 17:17:26.071225 12648 net.cpp:84] Creating Layer pool3
I0125 17:17:26.071234 12648 net.cpp:406] pool3 <- conv6_sc
I0125 17:17:26.071257 12648 net.cpp:380] pool3 -> pool3
I0125 17:17:26.071358 12648 net.cpp:122] Setting up pool3
I0125 17:17:26.071377 12648 net.cpp:129] Top shape: 100 256 4 4 (409600)
I0125 17:17:26.071382 12648 net.cpp:137] Memory required for data: 389530000
I0125 17:17:26.071388 12648 layer_factory.hpp:78] Creating layer drop3
I0125 17:17:26.071409 12648 net.cpp:84] Creating Layer drop3
I0125 17:17:26.071420 12648 net.cpp:406] drop3 <- pool3
I0125 17:17:26.071444 12648 net.cpp:367] drop3 -> pool3 (in-place)
I0125 17:17:26.071511 12648 net.cpp:122] Setting up drop3
I0125 17:17:26.071523 12648 net.cpp:129] Top shape: 100 256 4 4 (409600)
I0125 17:17:26.071527 12648 net.cpp:137] Memory required for data: 391168400
I0125 17:17:26.071534 12648 layer_factory.hpp:78] Creating layer fc7
I0125 17:17:26.071570 12648 net.cpp:84] Creating Layer fc7
I0125 17:17:26.071580 12648 net.cpp:406] fc7 <- pool3
I0125 17:17:26.071607 12648 net.cpp:380] fc7 -> fc7
I0125 17:17:26.246922 12648 net.cpp:122] Setting up fc7
I0125 17:17:26.246940 12648 net.cpp:129] Top shape: 100 512 (51200)
I0125 17:17:26.246944 12648 net.cpp:137] Memory required for data: 391373200
I0125 17:17:26.246970 12648 layer_factory.hpp:78] Creating layer bn7_bn
I0125 17:17:26.246997 12648 net.cpp:84] Creating Layer bn7_bn
I0125 17:17:26.247005 12648 net.cpp:406] bn7_bn <- fc7
I0125 17:17:26.247022 12648 net.cpp:380] bn7_bn -> fc7_bn
I0125 17:17:26.247303 12648 net.cpp:122] Setting up bn7_bn
I0125 17:17:26.247318 12648 net.cpp:129] Top shape: 100 512 (51200)
I0125 17:17:26.247337 12648 net.cpp:137] Memory required for data: 391578000
I0125 17:17:26.247380 12648 layer_factory.hpp:78] Creating layer bn7_scal
I0125 17:17:26.247400 12648 net.cpp:84] Creating Layer bn7_scal
I0125 17:17:26.247407 12648 net.cpp:406] bn7_scal <- fc7_bn
I0125 17:17:26.247423 12648 net.cpp:380] bn7_scal -> fc7_sc
I0125 17:17:26.247498 12648 layer_factory.hpp:78] Creating layer bn7_scal
I0125 17:17:26.247668 12648 net.cpp:122] Setting up bn7_scal
I0125 17:17:26.247683 12648 net.cpp:129] Top shape: 100 512 (51200)
I0125 17:17:26.247686 12648 net.cpp:137] Memory required for data: 391782800
I0125 17:17:26.247700 12648 layer_factory.hpp:78] Creating layer relu7
I0125 17:17:26.247715 12648 net.cpp:84] Creating Layer relu7
I0125 17:17:26.247723 12648 net.cpp:406] relu7 <- fc7_sc
I0125 17:17:26.247737 12648 net.cpp:367] relu7 -> fc7_sc (in-place)
I0125 17:17:26.248349 12648 net.cpp:122] Setting up relu7
I0125 17:17:26.248363 12648 net.cpp:129] Top shape: 100 512 (51200)
I0125 17:17:26.248365 12648 net.cpp:137] Memory required for data: 391987600
I0125 17:17:26.248371 12648 layer_factory.hpp:78] Creating layer drop7
I0125 17:17:26.248384 12648 net.cpp:84] Creating Layer drop7
I0125 17:17:26.248391 12648 net.cpp:406] drop7 <- fc7_sc
I0125 17:17:26.248405 12648 net.cpp:367] drop7 -> fc7_sc (in-place)
I0125 17:17:26.248464 12648 net.cpp:122] Setting up drop7
I0125 17:17:26.248474 12648 net.cpp:129] Top shape: 100 512 (51200)
I0125 17:17:26.248477 12648 net.cpp:137] Memory required for data: 392192400
I0125 17:17:26.248482 12648 layer_factory.hpp:78] Creating layer fc8
I0125 17:17:26.248502 12648 net.cpp:84] Creating Layer fc8
I0125 17:17:26.248509 12648 net.cpp:406] fc8 <- fc7_sc
I0125 17:17:26.248558 12648 net.cpp:380] fc8 -> fc8
I0125 17:17:26.270439 12648 net.cpp:122] Setting up fc8
I0125 17:17:26.270457 12648 net.cpp:129] Top shape: 100 512 (51200)
I0125 17:17:26.270462 12648 net.cpp:137] Memory required for data: 392397200
I0125 17:17:26.270475 12648 layer_factory.hpp:78] Creating layer bn8_bn
I0125 17:17:26.270490 12648 net.cpp:84] Creating Layer bn8_bn
I0125 17:17:26.270498 12648 net.cpp:406] bn8_bn <- fc8
I0125 17:17:26.270512 12648 net.cpp:380] bn8_bn -> fc8_bn
I0125 17:17:26.270776 12648 net.cpp:122] Setting up bn8_bn
I0125 17:17:26.270792 12648 net.cpp:129] Top shape: 100 512 (51200)
I0125 17:17:26.270795 12648 net.cpp:137] Memory required for data: 392602000
I0125 17:17:26.270817 12648 layer_factory.hpp:78] Creating layer bn8_scal
I0125 17:17:26.270834 12648 net.cpp:84] Creating Layer bn8_scal
I0125 17:17:26.270844 12648 net.cpp:406] bn8_scal <- fc8_bn
I0125 17:17:26.270876 12648 net.cpp:380] bn8_scal -> fc8_sc
I0125 17:17:26.270949 12648 layer_factory.hpp:78] Creating layer bn8_scal
I0125 17:17:26.271132 12648 net.cpp:122] Setting up bn8_scal
I0125 17:17:26.271147 12648 net.cpp:129] Top shape: 100 512 (51200)
I0125 17:17:26.271149 12648 net.cpp:137] Memory required for data: 392806800
I0125 17:17:26.271163 12648 layer_factory.hpp:78] Creating layer relu8
I0125 17:17:26.271194 12648 net.cpp:84] Creating Layer relu8
I0125 17:17:26.271201 12648 net.cpp:406] relu8 <- fc8_sc
I0125 17:17:26.271216 12648 net.cpp:367] relu8 -> fc8_sc (in-place)
I0125 17:17:26.272097 12648 net.cpp:122] Setting up relu8
I0125 17:17:26.272111 12648 net.cpp:129] Top shape: 100 512 (51200)
I0125 17:17:26.272115 12648 net.cpp:137] Memory required for data: 393011600
I0125 17:17:26.272121 12648 layer_factory.hpp:78] Creating layer drop8
I0125 17:17:26.272136 12648 net.cpp:84] Creating Layer drop8
I0125 17:17:26.272145 12648 net.cpp:406] drop8 <- fc8_sc
I0125 17:17:26.272161 12648 net.cpp:367] drop8 -> fc8_sc (in-place)
I0125 17:17:26.272204 12648 net.cpp:122] Setting up drop8
I0125 17:17:26.272241 12648 net.cpp:129] Top shape: 100 512 (51200)
I0125 17:17:26.272245 12648 net.cpp:137] Memory required for data: 393216400
I0125 17:17:26.272251 12648 layer_factory.hpp:78] Creating layer fc9
I0125 17:17:26.272270 12648 net.cpp:84] Creating Layer fc9
I0125 17:17:26.272279 12648 net.cpp:406] fc9 <- fc8_sc
I0125 17:17:26.272317 12648 net.cpp:380] fc9 -> fc9
I0125 17:17:26.274232 12648 net.cpp:122] Setting up fc9
I0125 17:17:26.274250 12648 net.cpp:129] Top shape: 100 10 (1000)
I0125 17:17:26.274253 12648 net.cpp:137] Memory required for data: 393220400
I0125 17:17:26.274268 12648 layer_factory.hpp:78] Creating layer loss
I0125 17:17:26.274294 12648 net.cpp:84] Creating Layer loss
I0125 17:17:26.274302 12648 net.cpp:406] loss <- fc9
I0125 17:17:26.274313 12648 net.cpp:406] loss <- label
I0125 17:17:26.274389 12648 net.cpp:380] loss -> loss
I0125 17:17:26.274420 12648 layer_factory.hpp:78] Creating layer loss
I0125 17:17:26.275166 12648 net.cpp:122] Setting up loss
I0125 17:17:26.275182 12648 net.cpp:129] Top shape: (1)
I0125 17:17:26.275185 12648 net.cpp:132]     with loss weight 1
I0125 17:17:26.275226 12648 net.cpp:137] Memory required for data: 393220404
I0125 17:17:26.275234 12648 net.cpp:198] loss needs backward computation.
I0125 17:17:26.275241 12648 net.cpp:198] fc9 needs backward computation.
I0125 17:17:26.275245 12648 net.cpp:198] drop8 needs backward computation.
I0125 17:17:26.275249 12648 net.cpp:198] relu8 needs backward computation.
I0125 17:17:26.275252 12648 net.cpp:198] bn8_scal needs backward computation.
I0125 17:17:26.275256 12648 net.cpp:198] bn8_bn needs backward computation.
I0125 17:17:26.275259 12648 net.cpp:198] fc8 needs backward computation.
I0125 17:17:26.275264 12648 net.cpp:198] drop7 needs backward computation.
I0125 17:17:26.275266 12648 net.cpp:198] relu7 needs backward computation.
I0125 17:17:26.275269 12648 net.cpp:198] bn7_scal needs backward computation.
I0125 17:17:26.275272 12648 net.cpp:198] bn7_bn needs backward computation.
I0125 17:17:26.275276 12648 net.cpp:198] fc7 needs backward computation.
I0125 17:17:26.275280 12648 net.cpp:198] drop3 needs backward computation.
I0125 17:17:26.275283 12648 net.cpp:198] pool3 needs backward computation.
I0125 17:17:26.275287 12648 net.cpp:198] relu6 needs backward computation.
I0125 17:17:26.275290 12648 net.cpp:198] bn6_scal needs backward computation.
I0125 17:17:26.275295 12648 net.cpp:198] bn6_bn needs backward computation.
I0125 17:17:26.275298 12648 net.cpp:198] conv6 needs backward computation.
I0125 17:17:26.275302 12648 net.cpp:198] relu5 needs backward computation.
I0125 17:17:26.275305 12648 net.cpp:198] bn5_scal needs backward computation.
I0125 17:17:26.275310 12648 net.cpp:198] bn5_bn needs backward computation.
I0125 17:17:26.275313 12648 net.cpp:198] conv5 needs backward computation.
I0125 17:17:26.275318 12648 net.cpp:198] drop2 needs backward computation.
I0125 17:17:26.275321 12648 net.cpp:198] pool2 needs backward computation.
I0125 17:17:26.275326 12648 net.cpp:198] relu4 needs backward computation.
I0125 17:17:26.275331 12648 net.cpp:198] bn4_scal needs backward computation.
I0125 17:17:26.275334 12648 net.cpp:198] bn4_bn needs backward computation.
I0125 17:17:26.275338 12648 net.cpp:198] conv4 needs backward computation.
I0125 17:17:26.275346 12648 net.cpp:198] relu3 needs backward computation.
I0125 17:17:26.275351 12648 net.cpp:198] bn3_scal needs backward computation.
I0125 17:17:26.275354 12648 net.cpp:198] bn3_bn needs backward computation.
I0125 17:17:26.275358 12648 net.cpp:198] conv3 needs backward computation.
I0125 17:17:26.275362 12648 net.cpp:198] drop1 needs backward computation.
I0125 17:17:26.275367 12648 net.cpp:198] pool1 needs backward computation.
I0125 17:17:26.275370 12648 net.cpp:198] relu2 needs backward computation.
I0125 17:17:26.275374 12648 net.cpp:198] bn2_scal needs backward computation.
I0125 17:17:26.275378 12648 net.cpp:198] bn2_bn needs backward computation.
I0125 17:17:26.275382 12648 net.cpp:198] conv2 needs backward computation.
I0125 17:17:26.275388 12648 net.cpp:198] relu1 needs backward computation.
I0125 17:17:26.275408 12648 net.cpp:198] bn1_scal needs backward computation.
I0125 17:17:26.275414 12648 net.cpp:198] bn1_bn needs backward computation.
I0125 17:17:26.275418 12648 net.cpp:198] conv1 needs backward computation.
I0125 17:17:26.275424 12648 net.cpp:200] cifar does not need backward computation.
I0125 17:17:26.275432 12648 net.cpp:242] This network produces output loss
I0125 17:17:26.275507 12648 net.cpp:255] Network initialization done.
I0125 17:17:26.276398 12648 solver.cpp:193] Creating test net (#0) specified by net file: my/CIFAR10/VGG9-BN/BWN/train_test.prototxt
I0125 17:17:26.276531 12648 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0125 17:17:26.276798 12648 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_vgg"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 32
    mean_file: "/home/zhengzhe/Data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/zhengzhe/Data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "BinaryConvolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
  debug_param {
    binary_relax: true
    update_lamda: 10
  }
}
layer {
  name: "bn1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1_bn"
}
layer {
  name: "bn1_scal"
  type: "Scale"
  bottom: "conv1_bn"
  top: "conv1_sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1_sc"
  top: "conv1_sc"
}
layer {
  name: "conv2"
  type: "BinaryConvolution"
  bottom: "conv1_sc"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
  debug_param {
    binary_relax: true
    update_lamda: 10
    phase1_iter: 50000
  }
}
layer {
  name: "bn2_bn"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2_bn"
}
layer {
  name: "bn2_scal"
  type: "Scale"
  bottom: "conv2_bn"
  top: "conv2_sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2_sc"
  top: "conv2_sc"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv2_sc"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "pool1"
  top: "pool1"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "conv3"
  type: "BinaryConvolution"
  bottom: "pool1"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
  debug_param {
    binary_relax: true
    update_lamda: 10
  }
}
layer {
  name: "bn3_bn"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3_bn"
}
layer {
  name: "bn3_scal"
  type: "Scale"
  bottom: "conv3_bn"
  top: "conv3_sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3_sc"
  top: "conv3_sc"
}
layer {
  name: "conv4"
  type: "BinaryConvolution"
  bottom: "conv3_sc"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
  debug_param {
    binary_relax: true
    update_lamda: 10
  }
}
layer {
  name: "bn4_bn"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4_bn"
}
layer {
  name: "bn4_scal"
  type: "Scale"
  bottom: "conv4_bn"
  top: "conv4_sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4_sc"
  top: "conv4_sc"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv4_sc"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "pool2"
  top: "pool2"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "conv5"
  type: "BinaryConvolution"
  bottom: "pool2"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
  debug_param {
    binary_relax: true
    update_lamda: 10
  }
}
layer {
  name: "bn5_bn"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5_bn"
}
layer {
  name: "bn5_scal"
  type: "Scale"
  bottom: "conv5_bn"
  top: "conv5_sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5_sc"
  top: "conv5_sc"
}
layer {
  name: "conv6"
  type: "BinaryConvolution"
  bottom: "conv5_sc"
  top: "conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
  debug_param {
    binary_relax: true
    update_lamda: 10
  }
}
layer {
  name: "bn6_bn"
  type: "BatchNorm"
  bottom: "conv6"
  top: "conv6_bn"
}
layer {
  name: "bn6_scal"
  type: "Scale"
  bottom: "conv6_bn"
  top: "conv6_sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "conv6_sc"
  top: "conv6_sc"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv6_sc"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "pool3"
  top: "pool3"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "fc7"
  type: "BinaryInnerProduct"
  bottom: "pool3"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 512
    bias_term: false
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
  debug_param {
    binary_relax: true
    update_lamda: 10
  }
}
layer {
  name: "bn7_bn"
  type: "BatchNorm"
  bottom: "fc7"
  top: "fc7_bn"
}
layer {
  name: "bn7_scal"
  type: "Scale"
  bottom: "fc7_bn"
  top: "fc7_sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7_sc"
  top: "fc7_sc"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7_sc"
  top: "fc7_sc"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "BinaryInnerProduct"
  bottom: "fc7_sc"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 512
    bias_term: false
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
  debug_param {
    binary_relax: true
    update_lamda: 10
  }
}
layer {
  name: "bn8_bn"
  type: "BatchNorm"
  bottom: "fc8"
  top: "fc8_bn"
}
layer {
  name: "bn8_scal"
  type: "Scale"
  bottom: "fc8_bn"
  top: "fc8_sc"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu8"
  type: "ReLU"
  bottom: "fc8_sc"
  top: "fc8_sc"
}
layer {
  name: "drop8"
  type: "Dropout"
  bottom: "fc8_sc"
  top: "fc8_sc"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc9"
  type: "BinaryInnerProduct"
  bottom: "fc8_sc"
  top: "fc9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.01
    }
  }
  debug_param {
    binary_relax: true
    update_lamda: 10
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc9"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc9"
  bottom: "label"
  top: "loss"
}
I0125 17:17:26.277240 12648 layer_factory.hpp:78] Creating layer cifar
I0125 17:17:26.277359 12648 db_lmdb.cpp:35] Opened lmdb /home/zhengzhe/Data/cifar10/cifar10_test_lmdb
I0125 17:17:26.277382 12648 net.cpp:84] Creating Layer cifar
I0125 17:17:26.277413 12648 net.cpp:380] cifar -> data
I0125 17:17:26.277443 12648 net.cpp:380] cifar -> label
I0125 17:17:26.277465 12648 data_transformer.cpp:25] Loading mean file from: /home/zhengzhe/Data/cifar10/mean.binaryproto
I0125 17:17:26.277814 12648 data_layer.cpp:45] output data size: 100,3,32,32
I0125 17:17:26.284487 12648 base_data_layer.cpp:72] Initializing prefetch
I0125 17:17:26.285018 12648 base_data_layer.cpp:75] Prefetch initialized.
I0125 17:17:26.285025 12648 net.cpp:122] Setting up cifar
I0125 17:17:26.285035 12648 net.cpp:129] Top shape: 100 3 32 32 (307200)
I0125 17:17:26.285042 12648 net.cpp:129] Top shape: 100 (100)
I0125 17:17:26.285044 12648 net.cpp:137] Memory required for data: 1229200
I0125 17:17:26.285053 12648 layer_factory.hpp:78] Creating layer label_cifar_1_split
I0125 17:17:26.285136 12648 net.cpp:84] Creating Layer label_cifar_1_split
I0125 17:17:26.285145 12648 net.cpp:406] label_cifar_1_split <- label
I0125 17:17:26.285164 12648 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I0125 17:17:26.285204 12648 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I0125 17:17:26.285274 12648 net.cpp:122] Setting up label_cifar_1_split
I0125 17:17:26.285291 12648 net.cpp:129] Top shape: 100 (100)
I0125 17:17:26.285300 12648 net.cpp:129] Top shape: 100 (100)
I0125 17:17:26.285318 12648 net.cpp:137] Memory required for data: 1230000
I0125 17:17:26.285324 12648 layer_factory.hpp:78] Creating layer conv1
I0125 17:17:26.285359 12648 net.cpp:84] Creating Layer conv1
I0125 17:17:26.285368 12648 net.cpp:406] conv1 <- data
I0125 17:17:26.285393 12648 net.cpp:380] conv1 -> conv1
I0125 17:17:26.288480 12648 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 393216
I0125 17:17:26.288635 12648 net.cpp:122] Setting up conv1
I0125 17:17:26.288648 12648 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0125 17:17:26.288653 12648 net.cpp:137] Memory required for data: 27444400
I0125 17:17:26.288678 12648 layer_factory.hpp:78] Creating layer bn1_bn
I0125 17:17:26.288697 12648 net.cpp:84] Creating Layer bn1_bn
I0125 17:17:26.288704 12648 net.cpp:406] bn1_bn <- conv1
I0125 17:17:26.288729 12648 net.cpp:380] bn1_bn -> conv1_bn
I0125 17:17:26.289048 12648 net.cpp:122] Setting up bn1_bn
I0125 17:17:26.289063 12648 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0125 17:17:26.289083 12648 net.cpp:137] Memory required for data: 53658800
I0125 17:17:26.289116 12648 layer_factory.hpp:78] Creating layer bn1_scal
I0125 17:17:26.289139 12648 net.cpp:84] Creating Layer bn1_scal
I0125 17:17:26.289149 12648 net.cpp:406] bn1_scal <- conv1_bn
I0125 17:17:26.289165 12648 net.cpp:380] bn1_scal -> conv1_sc
I0125 17:17:26.289243 12648 layer_factory.hpp:78] Creating layer bn1_scal
I0125 17:17:26.289438 12648 net.cpp:122] Setting up bn1_scal
I0125 17:17:26.289453 12648 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0125 17:17:26.289458 12648 net.cpp:137] Memory required for data: 79873200
I0125 17:17:26.289481 12648 layer_factory.hpp:78] Creating layer relu1
I0125 17:17:26.289499 12648 net.cpp:84] Creating Layer relu1
I0125 17:17:26.289506 12648 net.cpp:406] relu1 <- conv1_sc
I0125 17:17:26.289537 12648 net.cpp:367] relu1 -> conv1_sc (in-place)
I0125 17:17:26.290470 12648 net.cpp:122] Setting up relu1
I0125 17:17:26.290503 12648 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0125 17:17:26.290508 12648 net.cpp:137] Memory required for data: 106087600
I0125 17:17:26.290514 12648 layer_factory.hpp:78] Creating layer conv2
I0125 17:17:26.290539 12648 net.cpp:84] Creating Layer conv2
I0125 17:17:26.290549 12648 net.cpp:406] conv2 <- conv1_sc
I0125 17:17:26.290571 12648 net.cpp:380] conv2 -> conv2
I0125 17:17:26.296231 12648 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 786432
I0125 17:17:26.296270 12648 net.cpp:122] Setting up conv2
I0125 17:17:26.296280 12648 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0125 17:17:26.296298 12648 net.cpp:137] Memory required for data: 132302000
I0125 17:17:26.296313 12648 layer_factory.hpp:78] Creating layer bn2_bn
I0125 17:17:26.296350 12648 net.cpp:84] Creating Layer bn2_bn
I0125 17:17:26.296358 12648 net.cpp:406] bn2_bn <- conv2
I0125 17:17:26.296378 12648 net.cpp:380] bn2_bn -> conv2_bn
I0125 17:17:26.296852 12648 net.cpp:122] Setting up bn2_bn
I0125 17:17:26.296877 12648 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0125 17:17:26.296881 12648 net.cpp:137] Memory required for data: 158516400
I0125 17:17:26.296929 12648 layer_factory.hpp:78] Creating layer bn2_scal
I0125 17:17:26.296954 12648 net.cpp:84] Creating Layer bn2_scal
I0125 17:17:26.296962 12648 net.cpp:406] bn2_scal <- conv2_bn
I0125 17:17:26.296983 12648 net.cpp:380] bn2_scal -> conv2_sc
I0125 17:17:26.297065 12648 layer_factory.hpp:78] Creating layer bn2_scal
I0125 17:17:26.297258 12648 net.cpp:122] Setting up bn2_scal
I0125 17:17:26.297273 12648 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0125 17:17:26.297277 12648 net.cpp:137] Memory required for data: 184730800
I0125 17:17:26.297292 12648 layer_factory.hpp:78] Creating layer relu2
I0125 17:17:26.297308 12648 net.cpp:84] Creating Layer relu2
I0125 17:17:26.297315 12648 net.cpp:406] relu2 <- conv2_sc
I0125 17:17:26.297333 12648 net.cpp:367] relu2 -> conv2_sc (in-place)
I0125 17:17:26.298255 12648 net.cpp:122] Setting up relu2
I0125 17:17:26.298269 12648 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0125 17:17:26.298288 12648 net.cpp:137] Memory required for data: 210945200
I0125 17:17:26.298295 12648 layer_factory.hpp:78] Creating layer pool1
I0125 17:17:26.298311 12648 net.cpp:84] Creating Layer pool1
I0125 17:17:26.298319 12648 net.cpp:406] pool1 <- conv2_sc
I0125 17:17:26.298374 12648 net.cpp:380] pool1 -> pool1
I0125 17:17:26.298454 12648 net.cpp:122] Setting up pool1
I0125 17:17:26.298471 12648 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0125 17:17:26.298475 12648 net.cpp:137] Memory required for data: 217498800
I0125 17:17:26.298481 12648 layer_factory.hpp:78] Creating layer drop1
I0125 17:17:26.298496 12648 net.cpp:84] Creating Layer drop1
I0125 17:17:26.298503 12648 net.cpp:406] drop1 <- pool1
I0125 17:17:26.298519 12648 net.cpp:367] drop1 -> pool1 (in-place)
I0125 17:17:26.298568 12648 net.cpp:122] Setting up drop1
I0125 17:17:26.298578 12648 net.cpp:129] Top shape: 100 64 16 16 (1638400)
I0125 17:17:26.298580 12648 net.cpp:137] Memory required for data: 224052400
I0125 17:17:26.298586 12648 layer_factory.hpp:78] Creating layer conv3
I0125 17:17:26.298609 12648 net.cpp:84] Creating Layer conv3
I0125 17:17:26.298617 12648 net.cpp:406] conv3 <- pool1
I0125 17:17:26.298643 12648 net.cpp:380] conv3 -> conv3
I0125 17:17:26.306814 12648 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 1572864
I0125 17:17:26.307140 12648 net.cpp:122] Setting up conv3
I0125 17:17:26.307190 12648 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0125 17:17:26.307196 12648 net.cpp:137] Memory required for data: 237159600
I0125 17:17:26.307211 12648 layer_factory.hpp:78] Creating layer bn3_bn
I0125 17:17:26.307226 12648 net.cpp:84] Creating Layer bn3_bn
I0125 17:17:26.307235 12648 net.cpp:406] bn3_bn <- conv3
I0125 17:17:26.307250 12648 net.cpp:380] bn3_bn -> conv3_bn
I0125 17:17:26.307521 12648 net.cpp:122] Setting up bn3_bn
I0125 17:17:26.307535 12648 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0125 17:17:26.307540 12648 net.cpp:137] Memory required for data: 250266800
I0125 17:17:26.307561 12648 layer_factory.hpp:78] Creating layer bn3_scal
I0125 17:17:26.307579 12648 net.cpp:84] Creating Layer bn3_scal
I0125 17:17:26.307588 12648 net.cpp:406] bn3_scal <- conv3_bn
I0125 17:17:26.307607 12648 net.cpp:380] bn3_scal -> conv3_sc
I0125 17:17:26.307689 12648 layer_factory.hpp:78] Creating layer bn3_scal
I0125 17:17:26.307866 12648 net.cpp:122] Setting up bn3_scal
I0125 17:17:26.307881 12648 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0125 17:17:26.307886 12648 net.cpp:137] Memory required for data: 263374000
I0125 17:17:26.307911 12648 layer_factory.hpp:78] Creating layer relu3
I0125 17:17:26.307945 12648 net.cpp:84] Creating Layer relu3
I0125 17:17:26.307956 12648 net.cpp:406] relu3 <- conv3_sc
I0125 17:17:26.307974 12648 net.cpp:367] relu3 -> conv3_sc (in-place)
I0125 17:17:26.308614 12648 net.cpp:122] Setting up relu3
I0125 17:17:26.308629 12648 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0125 17:17:26.308631 12648 net.cpp:137] Memory required for data: 276481200
I0125 17:17:26.308648 12648 layer_factory.hpp:78] Creating layer conv4
I0125 17:17:26.308681 12648 net.cpp:84] Creating Layer conv4
I0125 17:17:26.308691 12648 net.cpp:406] conv4 <- conv3_sc
I0125 17:17:26.308712 12648 net.cpp:380] conv4 -> conv4
I0125 17:17:26.323590 12648 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0125 17:17:26.323891 12648 net.cpp:122] Setting up conv4
I0125 17:17:26.323911 12648 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0125 17:17:26.323916 12648 net.cpp:137] Memory required for data: 289588400
I0125 17:17:26.323930 12648 layer_factory.hpp:78] Creating layer bn4_bn
I0125 17:17:26.323947 12648 net.cpp:84] Creating Layer bn4_bn
I0125 17:17:26.323956 12648 net.cpp:406] bn4_bn <- conv4
I0125 17:17:26.323971 12648 net.cpp:380] bn4_bn -> conv4_bn
I0125 17:17:26.324239 12648 net.cpp:122] Setting up bn4_bn
I0125 17:17:26.324254 12648 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0125 17:17:26.324261 12648 net.cpp:137] Memory required for data: 302695600
I0125 17:17:26.324283 12648 layer_factory.hpp:78] Creating layer bn4_scal
I0125 17:17:26.324301 12648 net.cpp:84] Creating Layer bn4_scal
I0125 17:17:26.324311 12648 net.cpp:406] bn4_scal <- conv4_bn
I0125 17:17:26.324328 12648 net.cpp:380] bn4_scal -> conv4_sc
I0125 17:17:26.324417 12648 layer_factory.hpp:78] Creating layer bn4_scal
I0125 17:17:26.324589 12648 net.cpp:122] Setting up bn4_scal
I0125 17:17:26.324604 12648 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0125 17:17:26.324609 12648 net.cpp:137] Memory required for data: 315802800
I0125 17:17:26.324625 12648 layer_factory.hpp:78] Creating layer relu4
I0125 17:17:26.324638 12648 net.cpp:84] Creating Layer relu4
I0125 17:17:26.324646 12648 net.cpp:406] relu4 <- conv4_sc
I0125 17:17:26.324664 12648 net.cpp:367] relu4 -> conv4_sc (in-place)
I0125 17:17:26.325260 12648 net.cpp:122] Setting up relu4
I0125 17:17:26.325274 12648 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0125 17:17:26.325278 12648 net.cpp:137] Memory required for data: 328910000
I0125 17:17:26.325284 12648 layer_factory.hpp:78] Creating layer pool2
I0125 17:17:26.325299 12648 net.cpp:84] Creating Layer pool2
I0125 17:17:26.325309 12648 net.cpp:406] pool2 <- conv4_sc
I0125 17:17:26.325325 12648 net.cpp:380] pool2 -> pool2
I0125 17:17:26.325405 12648 net.cpp:122] Setting up pool2
I0125 17:17:26.325419 12648 net.cpp:129] Top shape: 100 128 8 8 (819200)
I0125 17:17:26.325423 12648 net.cpp:137] Memory required for data: 332186800
I0125 17:17:26.325429 12648 layer_factory.hpp:78] Creating layer drop2
I0125 17:17:26.325445 12648 net.cpp:84] Creating Layer drop2
I0125 17:17:26.325453 12648 net.cpp:406] drop2 <- pool2
I0125 17:17:26.325469 12648 net.cpp:367] drop2 -> pool2 (in-place)
I0125 17:17:26.325510 12648 net.cpp:122] Setting up drop2
I0125 17:17:26.325520 12648 net.cpp:129] Top shape: 100 128 8 8 (819200)
I0125 17:17:26.325522 12648 net.cpp:137] Memory required for data: 335463600
I0125 17:17:26.325527 12648 layer_factory.hpp:78] Creating layer conv5
I0125 17:17:26.325552 12648 net.cpp:84] Creating Layer conv5
I0125 17:17:26.325562 12648 net.cpp:406] conv5 <- pool2
I0125 17:17:26.325579 12648 net.cpp:380] conv5 -> conv5
I0125 17:17:26.354632 12648 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 6291456
I0125 17:17:26.354923 12648 net.cpp:122] Setting up conv5
I0125 17:17:26.354938 12648 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0125 17:17:26.354946 12648 net.cpp:137] Memory required for data: 342017200
I0125 17:17:26.354960 12648 layer_factory.hpp:78] Creating layer bn5_bn
I0125 17:17:26.354979 12648 net.cpp:84] Creating Layer bn5_bn
I0125 17:17:26.355000 12648 net.cpp:406] bn5_bn <- conv5
I0125 17:17:26.355018 12648 net.cpp:380] bn5_bn -> conv5_bn
I0125 17:17:26.355290 12648 net.cpp:122] Setting up bn5_bn
I0125 17:17:26.355304 12648 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0125 17:17:26.355312 12648 net.cpp:137] Memory required for data: 348570800
I0125 17:17:26.355334 12648 layer_factory.hpp:78] Creating layer bn5_scal
I0125 17:17:26.355357 12648 net.cpp:84] Creating Layer bn5_scal
I0125 17:17:26.355366 12648 net.cpp:406] bn5_scal <- conv5_bn
I0125 17:17:26.355391 12648 net.cpp:380] bn5_scal -> conv5_sc
I0125 17:17:26.355469 12648 layer_factory.hpp:78] Creating layer bn5_scal
I0125 17:17:26.355648 12648 net.cpp:122] Setting up bn5_scal
I0125 17:17:26.355671 12648 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0125 17:17:26.355675 12648 net.cpp:137] Memory required for data: 355124400
I0125 17:17:26.355690 12648 layer_factory.hpp:78] Creating layer relu5
I0125 17:17:26.355703 12648 net.cpp:84] Creating Layer relu5
I0125 17:17:26.355710 12648 net.cpp:406] relu5 <- conv5_sc
I0125 17:17:26.355727 12648 net.cpp:367] relu5 -> conv5_sc (in-place)
I0125 17:17:26.356624 12648 net.cpp:122] Setting up relu5
I0125 17:17:26.356657 12648 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0125 17:17:26.356662 12648 net.cpp:137] Memory required for data: 361678000
I0125 17:17:26.356668 12648 layer_factory.hpp:78] Creating layer conv6
I0125 17:17:26.356693 12648 net.cpp:84] Creating Layer conv6
I0125 17:17:26.356709 12648 net.cpp:406] conv6 <- conv5_sc
I0125 17:17:26.356732 12648 net.cpp:380] conv6 -> conv6
I0125 17:17:26.406138 12648 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0125 17:17:26.406471 12648 net.cpp:122] Setting up conv6
I0125 17:17:26.406502 12648 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0125 17:17:26.406522 12648 net.cpp:137] Memory required for data: 368231600
I0125 17:17:26.406536 12648 layer_factory.hpp:78] Creating layer bn6_bn
I0125 17:17:26.406553 12648 net.cpp:84] Creating Layer bn6_bn
I0125 17:17:26.406560 12648 net.cpp:406] bn6_bn <- conv6
I0125 17:17:26.406576 12648 net.cpp:380] bn6_bn -> conv6_bn
I0125 17:17:26.406849 12648 net.cpp:122] Setting up bn6_bn
I0125 17:17:26.406864 12648 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0125 17:17:26.406868 12648 net.cpp:137] Memory required for data: 374785200
I0125 17:17:26.406905 12648 layer_factory.hpp:78] Creating layer bn6_scal
I0125 17:17:26.406926 12648 net.cpp:84] Creating Layer bn6_scal
I0125 17:17:26.406940 12648 net.cpp:406] bn6_scal <- conv6_bn
I0125 17:17:26.406956 12648 net.cpp:380] bn6_scal -> conv6_sc
I0125 17:17:26.407038 12648 layer_factory.hpp:78] Creating layer bn6_scal
I0125 17:17:26.407219 12648 net.cpp:122] Setting up bn6_scal
I0125 17:17:26.407235 12648 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0125 17:17:26.407239 12648 net.cpp:137] Memory required for data: 381338800
I0125 17:17:26.407253 12648 layer_factory.hpp:78] Creating layer relu6
I0125 17:17:26.407268 12648 net.cpp:84] Creating Layer relu6
I0125 17:17:26.407274 12648 net.cpp:406] relu6 <- conv6_sc
I0125 17:17:26.407289 12648 net.cpp:367] relu6 -> conv6_sc (in-place)
I0125 17:17:26.407913 12648 net.cpp:122] Setting up relu6
I0125 17:17:26.407927 12648 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0125 17:17:26.407946 12648 net.cpp:137] Memory required for data: 387892400
I0125 17:17:26.407953 12648 layer_factory.hpp:78] Creating layer pool3
I0125 17:17:26.407968 12648 net.cpp:84] Creating Layer pool3
I0125 17:17:26.407975 12648 net.cpp:406] pool3 <- conv6_sc
I0125 17:17:26.407992 12648 net.cpp:380] pool3 -> pool3
I0125 17:17:26.408071 12648 net.cpp:122] Setting up pool3
I0125 17:17:26.408084 12648 net.cpp:129] Top shape: 100 256 4 4 (409600)
I0125 17:17:26.408087 12648 net.cpp:137] Memory required for data: 389530800
I0125 17:17:26.408093 12648 layer_factory.hpp:78] Creating layer drop3
I0125 17:17:26.408109 12648 net.cpp:84] Creating Layer drop3
I0125 17:17:26.408116 12648 net.cpp:406] drop3 <- pool3
I0125 17:17:26.408133 12648 net.cpp:367] drop3 -> pool3 (in-place)
I0125 17:17:26.408190 12648 net.cpp:122] Setting up drop3
I0125 17:17:26.408200 12648 net.cpp:129] Top shape: 100 256 4 4 (409600)
I0125 17:17:26.408203 12648 net.cpp:137] Memory required for data: 391169200
I0125 17:17:26.408210 12648 layer_factory.hpp:78] Creating layer fc7
I0125 17:17:26.408237 12648 net.cpp:84] Creating Layer fc7
I0125 17:17:26.408249 12648 net.cpp:406] fc7 <- pool3
I0125 17:17:26.408269 12648 net.cpp:380] fc7 -> fc7
I0125 17:17:26.585544 12648 net.cpp:122] Setting up fc7
I0125 17:17:26.585579 12648 net.cpp:129] Top shape: 100 512 (51200)
I0125 17:17:26.585583 12648 net.cpp:137] Memory required for data: 391374000
I0125 17:17:26.585598 12648 layer_factory.hpp:78] Creating layer bn7_bn
I0125 17:17:26.585618 12648 net.cpp:84] Creating Layer bn7_bn
I0125 17:17:26.585624 12648 net.cpp:406] bn7_bn <- fc7
I0125 17:17:26.585640 12648 net.cpp:380] bn7_bn -> fc7_bn
I0125 17:17:26.585907 12648 net.cpp:122] Setting up bn7_bn
I0125 17:17:26.585922 12648 net.cpp:129] Top shape: 100 512 (51200)
I0125 17:17:26.585927 12648 net.cpp:137] Memory required for data: 391578800
I0125 17:17:26.585947 12648 layer_factory.hpp:78] Creating layer bn7_scal
I0125 17:17:26.585964 12648 net.cpp:84] Creating Layer bn7_scal
I0125 17:17:26.585971 12648 net.cpp:406] bn7_scal <- fc7_bn
I0125 17:17:26.585990 12648 net.cpp:380] bn7_scal -> fc7_sc
I0125 17:17:26.586063 12648 layer_factory.hpp:78] Creating layer bn7_scal
I0125 17:17:26.586244 12648 net.cpp:122] Setting up bn7_scal
I0125 17:17:26.586259 12648 net.cpp:129] Top shape: 100 512 (51200)
I0125 17:17:26.586263 12648 net.cpp:137] Memory required for data: 391783600
I0125 17:17:26.586277 12648 layer_factory.hpp:78] Creating layer relu7
I0125 17:17:26.586292 12648 net.cpp:84] Creating Layer relu7
I0125 17:17:26.586298 12648 net.cpp:406] relu7 <- fc7_sc
I0125 17:17:26.586315 12648 net.cpp:367] relu7 -> fc7_sc (in-place)
I0125 17:17:26.587216 12648 net.cpp:122] Setting up relu7
I0125 17:17:26.587249 12648 net.cpp:129] Top shape: 100 512 (51200)
I0125 17:17:26.587254 12648 net.cpp:137] Memory required for data: 391988400
I0125 17:17:26.587260 12648 layer_factory.hpp:78] Creating layer drop7
I0125 17:17:26.587290 12648 net.cpp:84] Creating Layer drop7
I0125 17:17:26.587322 12648 net.cpp:406] drop7 <- fc7_sc
I0125 17:17:26.587339 12648 net.cpp:367] drop7 -> fc7_sc (in-place)
I0125 17:17:26.587407 12648 net.cpp:122] Setting up drop7
I0125 17:17:26.587419 12648 net.cpp:129] Top shape: 100 512 (51200)
I0125 17:17:26.587421 12648 net.cpp:137] Memory required for data: 392193200
I0125 17:17:26.587426 12648 layer_factory.hpp:78] Creating layer fc8
I0125 17:17:26.587448 12648 net.cpp:84] Creating Layer fc8
I0125 17:17:26.587456 12648 net.cpp:406] fc8 <- fc7_sc
I0125 17:17:26.587474 12648 net.cpp:380] fc8 -> fc8
I0125 17:17:26.609443 12648 net.cpp:122] Setting up fc8
I0125 17:17:26.609459 12648 net.cpp:129] Top shape: 100 512 (51200)
I0125 17:17:26.609479 12648 net.cpp:137] Memory required for data: 392398000
I0125 17:17:26.609491 12648 layer_factory.hpp:78] Creating layer bn8_bn
I0125 17:17:26.609508 12648 net.cpp:84] Creating Layer bn8_bn
I0125 17:17:26.609514 12648 net.cpp:406] bn8_bn <- fc8
I0125 17:17:26.609529 12648 net.cpp:380] bn8_bn -> fc8_bn
I0125 17:17:26.609802 12648 net.cpp:122] Setting up bn8_bn
I0125 17:17:26.609817 12648 net.cpp:129] Top shape: 100 512 (51200)
I0125 17:17:26.609822 12648 net.cpp:137] Memory required for data: 392602800
I0125 17:17:26.609843 12648 layer_factory.hpp:78] Creating layer bn8_scal
I0125 17:17:26.609860 12648 net.cpp:84] Creating Layer bn8_scal
I0125 17:17:26.609869 12648 net.cpp:406] bn8_scal <- fc8_bn
I0125 17:17:26.609884 12648 net.cpp:380] bn8_scal -> fc8_sc
I0125 17:17:26.609958 12648 layer_factory.hpp:78] Creating layer bn8_scal
I0125 17:17:26.610142 12648 net.cpp:122] Setting up bn8_scal
I0125 17:17:26.610157 12648 net.cpp:129] Top shape: 100 512 (51200)
I0125 17:17:26.610162 12648 net.cpp:137] Memory required for data: 392807600
I0125 17:17:26.610175 12648 layer_factory.hpp:78] Creating layer relu8
I0125 17:17:26.610189 12648 net.cpp:84] Creating Layer relu8
I0125 17:17:26.610210 12648 net.cpp:406] relu8 <- fc8_sc
I0125 17:17:26.610227 12648 net.cpp:367] relu8 -> fc8_sc (in-place)
I0125 17:17:26.610859 12648 net.cpp:122] Setting up relu8
I0125 17:17:26.610875 12648 net.cpp:129] Top shape: 100 512 (51200)
I0125 17:17:26.610894 12648 net.cpp:137] Memory required for data: 393012400
I0125 17:17:26.610900 12648 layer_factory.hpp:78] Creating layer drop8
I0125 17:17:26.610915 12648 net.cpp:84] Creating Layer drop8
I0125 17:17:26.610922 12648 net.cpp:406] drop8 <- fc8_sc
I0125 17:17:26.610937 12648 net.cpp:367] drop8 -> fc8_sc (in-place)
I0125 17:17:26.610982 12648 net.cpp:122] Setting up drop8
I0125 17:17:26.610992 12648 net.cpp:129] Top shape: 100 512 (51200)
I0125 17:17:26.610996 12648 net.cpp:137] Memory required for data: 393217200
I0125 17:17:26.611001 12648 layer_factory.hpp:78] Creating layer fc9
I0125 17:17:26.611021 12648 net.cpp:84] Creating Layer fc9
I0125 17:17:26.611028 12648 net.cpp:406] fc9 <- fc8_sc
I0125 17:17:26.611047 12648 net.cpp:380] fc9 -> fc9
I0125 17:17:26.611771 12648 net.cpp:122] Setting up fc9
I0125 17:17:26.611801 12648 net.cpp:129] Top shape: 100 10 (1000)
I0125 17:17:26.611806 12648 net.cpp:137] Memory required for data: 393221200
I0125 17:17:26.611820 12648 layer_factory.hpp:78] Creating layer fc9_fc9_0_split
I0125 17:17:26.611835 12648 net.cpp:84] Creating Layer fc9_fc9_0_split
I0125 17:17:26.611842 12648 net.cpp:406] fc9_fc9_0_split <- fc9
I0125 17:17:26.611857 12648 net.cpp:380] fc9_fc9_0_split -> fc9_fc9_0_split_0
I0125 17:17:26.611891 12648 net.cpp:380] fc9_fc9_0_split -> fc9_fc9_0_split_1
I0125 17:17:26.611950 12648 net.cpp:122] Setting up fc9_fc9_0_split
I0125 17:17:26.611966 12648 net.cpp:129] Top shape: 100 10 (1000)
I0125 17:17:26.611973 12648 net.cpp:129] Top shape: 100 10 (1000)
I0125 17:17:26.611975 12648 net.cpp:137] Memory required for data: 393229200
I0125 17:17:26.611980 12648 layer_factory.hpp:78] Creating layer accuracy
I0125 17:17:26.612000 12648 net.cpp:84] Creating Layer accuracy
I0125 17:17:26.612007 12648 net.cpp:406] accuracy <- fc9_fc9_0_split_0
I0125 17:17:26.612020 12648 net.cpp:406] accuracy <- label_cifar_1_split_0
I0125 17:17:26.612031 12648 net.cpp:380] accuracy -> accuracy
I0125 17:17:26.612061 12648 net.cpp:122] Setting up accuracy
I0125 17:17:26.612072 12648 net.cpp:129] Top shape: (1)
I0125 17:17:26.612076 12648 net.cpp:137] Memory required for data: 393229204
I0125 17:17:26.612082 12648 layer_factory.hpp:78] Creating layer loss
I0125 17:17:26.612093 12648 net.cpp:84] Creating Layer loss
I0125 17:17:26.612100 12648 net.cpp:406] loss <- fc9_fc9_0_split_1
I0125 17:17:26.612110 12648 net.cpp:406] loss <- label_cifar_1_split_1
I0125 17:17:26.612121 12648 net.cpp:380] loss -> loss
I0125 17:17:26.612138 12648 layer_factory.hpp:78] Creating layer loss
I0125 17:17:26.613159 12648 net.cpp:122] Setting up loss
I0125 17:17:26.613175 12648 net.cpp:129] Top shape: (1)
I0125 17:17:26.613194 12648 net.cpp:132]     with loss weight 1
I0125 17:17:26.613204 12648 net.cpp:137] Memory required for data: 393229208
I0125 17:17:26.613211 12648 net.cpp:198] loss needs backward computation.
I0125 17:17:26.613234 12648 net.cpp:200] accuracy does not need backward computation.
I0125 17:17:26.613238 12648 net.cpp:198] fc9_fc9_0_split needs backward computation.
I0125 17:17:26.613242 12648 net.cpp:198] fc9 needs backward computation.
I0125 17:17:26.613246 12648 net.cpp:198] drop8 needs backward computation.
I0125 17:17:26.613250 12648 net.cpp:198] relu8 needs backward computation.
I0125 17:17:26.613253 12648 net.cpp:198] bn8_scal needs backward computation.
I0125 17:17:26.613257 12648 net.cpp:198] bn8_bn needs backward computation.
I0125 17:17:26.613261 12648 net.cpp:198] fc8 needs backward computation.
I0125 17:17:26.613265 12648 net.cpp:198] drop7 needs backward computation.
I0125 17:17:26.613268 12648 net.cpp:198] relu7 needs backward computation.
I0125 17:17:26.613271 12648 net.cpp:198] bn7_scal needs backward computation.
I0125 17:17:26.613276 12648 net.cpp:198] bn7_bn needs backward computation.
I0125 17:17:26.613279 12648 net.cpp:198] fc7 needs backward computation.
I0125 17:17:26.613302 12648 net.cpp:198] drop3 needs backward computation.
I0125 17:17:26.613307 12648 net.cpp:198] pool3 needs backward computation.
I0125 17:17:26.613312 12648 net.cpp:198] relu6 needs backward computation.
I0125 17:17:26.613315 12648 net.cpp:198] bn6_scal needs backward computation.
I0125 17:17:26.613318 12648 net.cpp:198] bn6_bn needs backward computation.
I0125 17:17:26.613323 12648 net.cpp:198] conv6 needs backward computation.
I0125 17:17:26.613329 12648 net.cpp:198] relu5 needs backward computation.
I0125 17:17:26.613332 12648 net.cpp:198] bn5_scal needs backward computation.
I0125 17:17:26.613337 12648 net.cpp:198] bn5_bn needs backward computation.
I0125 17:17:26.613340 12648 net.cpp:198] conv5 needs backward computation.
I0125 17:17:26.613349 12648 net.cpp:198] drop2 needs backward computation.
I0125 17:17:26.613368 12648 net.cpp:198] pool2 needs backward computation.
I0125 17:17:26.613373 12648 net.cpp:198] relu4 needs backward computation.
I0125 17:17:26.613376 12648 net.cpp:198] bn4_scal needs backward computation.
I0125 17:17:26.613380 12648 net.cpp:198] bn4_bn needs backward computation.
I0125 17:17:26.613384 12648 net.cpp:198] conv4 needs backward computation.
I0125 17:17:26.613389 12648 net.cpp:198] relu3 needs backward computation.
I0125 17:17:26.613392 12648 net.cpp:198] bn3_scal needs backward computation.
I0125 17:17:26.613396 12648 net.cpp:198] bn3_bn needs backward computation.
I0125 17:17:26.613400 12648 net.cpp:198] conv3 needs backward computation.
I0125 17:17:26.613404 12648 net.cpp:198] drop1 needs backward computation.
I0125 17:17:26.613409 12648 net.cpp:198] pool1 needs backward computation.
I0125 17:17:26.613412 12648 net.cpp:198] relu2 needs backward computation.
I0125 17:17:26.613416 12648 net.cpp:198] bn2_scal needs backward computation.
I0125 17:17:26.613420 12648 net.cpp:198] bn2_bn needs backward computation.
I0125 17:17:26.613425 12648 net.cpp:198] conv2 needs backward computation.
I0125 17:17:26.613430 12648 net.cpp:198] relu1 needs backward computation.
I0125 17:17:26.613432 12648 net.cpp:198] bn1_scal needs backward computation.
I0125 17:17:26.613437 12648 net.cpp:198] bn1_bn needs backward computation.
I0125 17:17:26.613441 12648 net.cpp:198] conv1 needs backward computation.
I0125 17:17:26.613446 12648 net.cpp:200] label_cifar_1_split does not need backward computation.
I0125 17:17:26.613451 12648 net.cpp:200] cifar does not need backward computation.
I0125 17:17:26.613456 12648 net.cpp:242] This network produces output accuracy
I0125 17:17:26.613463 12648 net.cpp:242] This network produces output loss
I0125 17:17:26.613526 12648 net.cpp:255] Network initialization done.
I0125 17:17:26.613656 12648 solver.cpp:57] Solver scaffolding done.
I0125 17:17:26.615789 12648 caffe.cpp:239] Starting Optimization
I0125 17:17:26.615801 12648 solver.cpp:300] Solving CIFAR10_vgg
I0125 17:17:26.615819 12648 solver.cpp:301] Learning Rate Policy: step
I0125 17:17:26.617954 12648 solver.cpp:385] Iteration 0, Testing net (#0)
I0125 17:17:26.621134 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.626006 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:26.633127 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.636260 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.640707 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.643803 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.650856 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.651603 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:26.651903 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.652119 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.652361 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.652578 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.670554 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.671293 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:26.671589 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.671835 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.672055 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.672283 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.690320 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.691073 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:26.691336 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.691577 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.691797 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.692013 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.710055 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.710788 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:26.711063 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.711279 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.711516 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.711721 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.729777 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.730520 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:26.730790 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.730995 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.731215 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.731427 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.749506 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.750216 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:26.750496 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.750730 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.750952 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.751160 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.769232 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.769961 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:26.770238 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.770452 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.770674 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.770884 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.789129 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.789402 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:26.789629 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.789837 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.790060 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.790271 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.807518 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.807777 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:26.807999 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.808204 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.808428 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.808634 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.825659 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.826323 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:26.826575 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.826778 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.827006 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.827216 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.844024 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.844264 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:26.844491 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.844700 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.844919 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.845125 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.862277 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.862530 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:26.862749 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.862956 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.863171 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.863384 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.880537 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.880784 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:26.881002 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.881206 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.881433 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.881639 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.898705 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.899354 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:26.899598 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.899802 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.900027 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.900231 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.916890 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.917605 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:26.917863 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.918084 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.918306 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.918535 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.935254 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.935518 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:26.935760 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.935969 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.936204 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.936426 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.953403 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.953665 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:26.953902 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.954111 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.954336 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.954556 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.970896 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.971143 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:26.971365 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.971578 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.971797 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.972004 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.987828 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.988072 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:26.988291 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.988502 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.988723 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:26.988932 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.004748 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.005007 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.005228 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.005442 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.005666 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.005872 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.021735 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.021986 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.022204 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.022416 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.022636 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.022853 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.038724 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.038972 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.039193 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.039405 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.039624 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.039832 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.055654 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.055896 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.056114 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.056331 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.056555 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.056761 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.072562 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.072798 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.073016 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.073222 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.073459 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.073665 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.089562 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.089808 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.090025 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.090235 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.090463 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.090672 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.106511 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.106753 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.106971 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.107174 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.107396 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.107604 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.123519 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.123776 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.124003 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.124217 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.124449 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.124662 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.139931 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.140175 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.140401 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.140607 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.140825 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.141031 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.156298 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.156565 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.156810 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.157018 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.157238 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.157449 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.172626 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.172876 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.173095 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.173300 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.173545 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.173758 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.189020 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.189268 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.189512 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.189721 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.189956 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.190161 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.205332 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.205602 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.205842 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.206048 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.206266 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.206493 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.221637 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.222290 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.222542 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.222744 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.222960 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.223166 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.238062 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.238293 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.238515 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.238724 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.238943 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.239151 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.254422 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.254667 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.254882 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.255086 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.255304 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.255518 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.270627 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.271155 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.271422 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.271630 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.271847 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.272053 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.287093 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.287348 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.287566 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.287770 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.287986 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.288193 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.303500 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.303742 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.303962 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.304167 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.304395 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.304605 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.319762 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.320011 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.320232 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.320441 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.320662 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.320870 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.336099 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.336369 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.336594 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.336815 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.337036 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.337241 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.352363 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.352885 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.353107 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.353327 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.353569 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.353778 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.368845 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.369076 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.369295 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.369523 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.369761 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.369967 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.385123 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.385355 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.385576 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.385777 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.385993 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.386199 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.401463 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.401712 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.401947 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.402150 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.402379 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.402585 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.417824 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.418077 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.418296 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.418507 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.418738 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.418944 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.434187 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.434437 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.434665 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.434875 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.435091 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.435297 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.450580 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.450839 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.451074 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.451277 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.451506 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.451714 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.466897 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.467139 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.467372 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.467576 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.467797 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.468008 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.483194 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.483440 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.483673 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.483877 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.484098 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.484303 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.499487 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.499730 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.499948 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.500154 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.500375 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.500581 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.515856 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.516098 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.516325 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.516554 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.516782 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.517000 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.532136 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.532378 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.532610 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.532816 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.533036 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.533241 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.548462 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.548712 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.548933 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.549139 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.549376 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.549587 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.564790 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.565038 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.565258 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.565470 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.565687 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.565893 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.581029 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.581526 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.581755 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.581959 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.582178 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.582388 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.597339 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.597999 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.598245 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.598453 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.598675 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.598883 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.613793 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.614037 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.614256 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.614467 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.614689 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.614894 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.630100 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.630357 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.630574 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.630782 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.631001 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.631206 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.646513 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.646762 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.646978 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.647181 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.647404 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.647610 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.662889 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.663130 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.663355 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.663563 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.663779 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.663985 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.679180 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.679437 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.679656 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.679859 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.680076 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.680284 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.695585 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.695829 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.696048 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.696254 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.696478 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.696686 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.711858 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.712352 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.712595 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.712800 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.713019 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.713227 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.728322 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.728575 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.728796 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.729001 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.729220 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.729434 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.744603 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.745095 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.745359 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.745566 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.745795 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.746006 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.761101 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.761389 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.761615 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.761840 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.762080 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.762296 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.777508 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.777765 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.777987 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.778192 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.778419 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.778638 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.793841 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.794096 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.794313 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.794528 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.794749 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.794960 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.810088 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.810585 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.810839 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.811046 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.811269 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.811482 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.826488 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.826728 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.826954 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.827157 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.827386 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.827600 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.842797 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.843044 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.843266 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.843477 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.843698 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.843904 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.859066 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.859311 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.859534 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.859738 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.859956 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.860159 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.875351 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.875588 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.875805 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.876011 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.876231 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.876446 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.891683 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.891932 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.892150 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.892372 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.892594 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.892803 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.907951 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.908192 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.908416 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.908627 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.908848 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.909054 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.924242 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.924481 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.924700 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.924906 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.925127 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.925331 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.940524 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.940758 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.940977 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.941195 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.941421 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.941628 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.956790 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.957029 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.957247 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.957466 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.957687 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.957895 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.973070 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.973315 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.973541 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.973744 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.973965 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.974169 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.989389 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.989637 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:27.989874 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.990078 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.990301 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:27.990514 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.005681 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.005929 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:28.006160 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.006377 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.006598 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.006814 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.021970 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.022233 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:28.022464 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.022676 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.022902 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.023113 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.038451 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.038686 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:28.038904 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.039111 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.039330 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.039541 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.054813 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.055038 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:28.055258 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.055469 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.055689 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.055898 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.071188 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.071418 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:28.071635 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.071838 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.072062 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.072266 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.087564 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.087802 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:28.088023 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.088228 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.088455 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.088661 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.103953 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.104193 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:28.104415 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.104619 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.104840 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.105051 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.120319 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.120565 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:28.120792 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.121004 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.121230 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.121448 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.136725 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.136965 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:28.137189 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.137405 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.137635 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.137850 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.153079 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.153321 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:28.153551 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.153760 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.153992 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.154207 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.169440 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.169661 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:28.169883 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.170117 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.170351 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.170564 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.185791 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.186043 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:28.186267 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.186486 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.186712 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.186923 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.202399 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.202626 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:28.202849 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.203061 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.203289 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.203506 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.218797 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.219027 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:28.219250 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.219468 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.219696 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.219907 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.235697 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.235940 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:28.236163 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.236383 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.236608 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.236822 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.252110 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.252353 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:28.252588 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.252797 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.253041 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.253253 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.255581 12764 data_layer.cpp:73] Restarting data prefetching from start.
I0125 17:17:28.268752 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.268999 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:28.269232 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.269448 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.269678 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.269889 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.285261 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.285511 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:28.285733 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.285946 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.286171 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.286391 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.301620 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.301862 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:28.302083 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.302294 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.302528 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.302739 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.317853 12648 solver.cpp:454]     Test net output #0: accuracy = 0.0936
I0125 17:17:28.317879 12648 solver.cpp:454]     Test net output #1: loss = 79.1618 (* 1 = 79.1618 loss)
I0125 17:17:28.317888 12648 solver.cpp:468] snapshoting best accuracy model ...
I0125 17:17:28.317898 12648 net.cpp:929] Serializing 43 layers
I0125 17:17:28.447407 12648 solver.cpp:472] snapshoting best accuracy model done.
I0125 17:17:28.447538 12648 solver.cpp:474] ================================
I0125 17:17:28.447546 12648 solver.cpp:475]     Test net best accuracy1 is: 0.0936
I0125 17:17:28.448004 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.452730 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:28.462389 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.465209 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.470474 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.475201 12648 cudnn_binary_conv_layer.cu:89] 0
I0125 17:17:28.537271 12648 solver.cpp:243] Iteration 0 (2.76785e+37 iter/s, 1.92133s/200 iters), loss = 2.33996
I0125 17:17:28.537325 12648 solver.cpp:262]     Train net output #0: loss = 2.33996 (* 1 = 2.33996 loss)
I0125 17:17:28.537369 12648 sgd_solver.cpp:122] Iteration 0, lr = 0.1
I0125 17:17:28.543421 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:28.610282 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:28.679296 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:28.746099 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:28.815604 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:28.885110 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:28.952005 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:29.018677 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:29.087954 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:29.154551 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:29.223572 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:29.292516 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:29.359468 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:29.426276 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:29.494563 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:29.560854 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:29.629667 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:29.698936 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:29.766021 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:29.832659 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:29.902709 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:29.969033 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:30.037487 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:30.108389 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:30.175839 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:30.241729 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:30.310935 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:30.377437 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:30.447093 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:30.515471 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:30.584313 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:30.648358 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:30.717890 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:30.784694 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:30.853523 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:30.922554 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:30.990118 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:31.055935 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:31.125499 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:31.192338 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:31.260433 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:31.329671 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:31.396953 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:31.463943 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:31.532526 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:31.599376 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:31.668270 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:31.737536 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:31.805512 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:31.871146 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:31.939846 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:32.006135 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:32.075279 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:32.144704 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:32.211578 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:32.277858 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:32.346058 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:32.414180 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:32.480706 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:32.548674 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:32.616901 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:32.683320 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:32.749963 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:32.821185 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:32.885283 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:32.954789 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:33.023483 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:33.090514 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:33.157349 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:33.225368 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:33.293777 12648 cudnn_binary_conv_layer.cu:89] 50000
I0125 17:17:33.361486 12648 cudnn_binary_conv_layer.cu:89] 50000
