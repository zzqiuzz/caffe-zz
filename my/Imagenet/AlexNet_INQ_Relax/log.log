I0928 18:47:22.251178  5189 upgrade_proto.cpp:1113] snapshot_prefix was a directory and is replaced to my/Imagenet/AlexNet_INQ_Relax/snapshot/solver
I0928 18:47:22.251490  5189 caffe.cpp:204] Using GPUs 0
I0928 18:47:22.269582  5189 caffe.cpp:209] GPU 0: GeForce GTX TITAN X
I0928 18:47:22.501391  5189 solver.cpp:45] Initializing solver from parameters: 
test_iter: 1000
test_interval: 3000
base_lr: 0.01
display: 200
max_iter: 200000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 10000
snapshot_prefix: "my/Imagenet/AlexNet_INQ_Relax/snapshot/solver"
solver_mode: GPU
device_id: 0
net: "my/Imagenet/AlexNet_INQ_Relax/train_val.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 100000
stepvalue: 150000
stepvalue: 180000
weights: "my/Imagenet/AlexNet_INQ_Relax/bvlc_alexnet_bn.caffemodel"
quantize_phase_ratio: 0.4
quantize_phase_ratio: 0.2
quantize_phase_ratio: 0
isquantize: true
I0928 18:47:22.501616  5189 solver.cpp:105] Creating training net from net file: my/Imagenet/AlexNet_INQ_Relax/train_val.prototxt
I0928 18:47:22.516609  5189 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0928 18:47:22.516825  5189 net.cpp:51] Initializing net from parameters: 
name: "AlexNet-BN"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_file: "/mnt/data/ilsvrc12/origin/imagenet_mean.binaryproto"
  }
  data_param {
    source: "/mnt/data/ilsvrc12/origin/ilsvrc12_train_lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "BinaryConvolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 96
    bias_term: false
    pad: 2
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    binary_relax: false
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "BinaryConvolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    binary_relax: false
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "BinaryConvolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    binary_relax: false
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "BinaryConvolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    binary_relax: false
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "BinaryConvolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    binary_relax: false
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "scale5"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "BinaryInnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4096
    bias_term: false
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    binary_relax: false
  }
}
layer {
  name: "bn6"
  type: "BatchNorm"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "scale6"
  type: "Scale"
  bottom: "fc6"
  top: "fc6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "BinaryInnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4096
    bias_term: false
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    binary_relax: false
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "scale7"
  type: "Scale"
  bottom: "fc7"
  top: "fc7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "BinaryInnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  debug_param {
    binary_relax: false
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "accuracy_5"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy_5"
  accuracy_param {
    top_k: 5
  }
}
I0928 18:47:22.517454  5189 layer_factory.hpp:77] Creating layer data
I0928 18:47:22.517640  5189 db_lmdb.cpp:35] Opened lmdb /mnt/data/ilsvrc12/origin/ilsvrc12_train_lmdb
I0928 18:47:22.517694  5189 net.cpp:84] Creating Layer data
I0928 18:47:22.517719  5189 net.cpp:380] data -> data
I0928 18:47:22.517835  5189 net.cpp:380] data -> label
I0928 18:47:22.517873  5189 data_transformer.cpp:25] Loading mean file from: /mnt/data/ilsvrc12/origin/imagenet_mean.binaryproto
I0928 18:47:22.525013  5189 data_layer.cpp:45] output data size: 128,3,224,224
I0928 18:47:22.636119  5189 base_data_layer.cpp:72] Initializing prefetch
I0928 18:47:22.636296  5189 base_data_layer.cpp:75] Prefetch initialized.
I0928 18:47:22.636315  5189 net.cpp:122] Setting up data
I0928 18:47:22.636359  5189 net.cpp:129] Top shape: 128 3 224 224 (19267584)
I0928 18:47:22.636395  5189 net.cpp:129] Top shape: 128 (128)
I0928 18:47:22.636399  5189 net.cpp:137] Memory required for data: 77070848
I0928 18:47:22.636435  5189 layer_factory.hpp:77] Creating layer label_data_1_split
I0928 18:47:22.636507  5189 net.cpp:84] Creating Layer label_data_1_split
I0928 18:47:22.636555  5189 net.cpp:406] label_data_1_split <- label
I0928 18:47:22.636615  5189 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0928 18:47:22.636690  5189 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0928 18:47:22.636716  5189 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0928 18:47:22.636777  5189 net.cpp:122] Setting up label_data_1_split
I0928 18:47:22.636788  5189 net.cpp:129] Top shape: 128 (128)
I0928 18:47:22.636799  5189 net.cpp:129] Top shape: 128 (128)
I0928 18:47:22.636806  5189 net.cpp:129] Top shape: 128 (128)
I0928 18:47:22.636811  5189 net.cpp:137] Memory required for data: 77072384
I0928 18:47:22.636816  5189 layer_factory.hpp:77] Creating layer conv1
I0928 18:47:22.636852  5189 net.cpp:84] Creating Layer conv1
I0928 18:47:22.636860  5189 net.cpp:406] conv1 <- data
I0928 18:47:22.636879  5189 net.cpp:380] conv1 -> conv1
I0928 18:47:22.644174  5189 net.cpp:122] Setting up conv1
I0928 18:47:22.644193  5189 net.cpp:129] Top shape: 128 96 55 55 (37171200)
I0928 18:47:22.644199  5189 net.cpp:137] Memory required for data: 225757184
I0928 18:47:22.644246  5189 layer_factory.hpp:77] Creating layer bn1
I0928 18:47:22.644266  5189 net.cpp:84] Creating Layer bn1
I0928 18:47:22.644275  5189 net.cpp:406] bn1 <- conv1
I0928 18:47:22.644290  5189 net.cpp:367] bn1 -> conv1 (in-place)
I0928 18:47:22.644783  5189 net.cpp:122] Setting up bn1
I0928 18:47:22.644793  5189 net.cpp:129] Top shape: 128 96 55 55 (37171200)
I0928 18:47:22.644798  5189 net.cpp:137] Memory required for data: 374441984
I0928 18:47:22.644845  5189 layer_factory.hpp:77] Creating layer scale1
I0928 18:47:22.644883  5189 net.cpp:84] Creating Layer scale1
I0928 18:47:22.644892  5189 net.cpp:406] scale1 <- conv1
I0928 18:47:22.644908  5189 net.cpp:367] scale1 -> conv1 (in-place)
I0928 18:47:22.644971  5189 layer_factory.hpp:77] Creating layer scale1
I0928 18:47:22.645126  5189 net.cpp:122] Setting up scale1
I0928 18:47:22.645136  5189 net.cpp:129] Top shape: 128 96 55 55 (37171200)
I0928 18:47:22.645141  5189 net.cpp:137] Memory required for data: 523126784
I0928 18:47:22.645161  5189 layer_factory.hpp:77] Creating layer relu1
I0928 18:47:22.645200  5189 net.cpp:84] Creating Layer relu1
I0928 18:47:22.645206  5189 net.cpp:406] relu1 <- conv1
I0928 18:47:22.645220  5189 net.cpp:367] relu1 -> conv1 (in-place)
I0928 18:47:23.022584  5189 net.cpp:122] Setting up relu1
I0928 18:47:23.022627  5189 net.cpp:129] Top shape: 128 96 55 55 (37171200)
I0928 18:47:23.022632  5189 net.cpp:137] Memory required for data: 671811584
I0928 18:47:23.022648  5189 layer_factory.hpp:77] Creating layer pool1
I0928 18:47:23.022716  5189 net.cpp:84] Creating Layer pool1
I0928 18:47:23.022740  5189 net.cpp:406] pool1 <- conv1
I0928 18:47:23.022796  5189 net.cpp:380] pool1 -> pool1
I0928 18:47:23.022902  5189 net.cpp:122] Setting up pool1
I0928 18:47:23.022927  5189 net.cpp:129] Top shape: 128 96 27 27 (8957952)
I0928 18:47:23.022930  5189 net.cpp:137] Memory required for data: 707643392
I0928 18:47:23.022936  5189 layer_factory.hpp:77] Creating layer conv2
I0928 18:47:23.022987  5189 net.cpp:84] Creating Layer conv2
I0928 18:47:23.023015  5189 net.cpp:406] conv2 <- pool1
I0928 18:47:23.023041  5189 net.cpp:380] conv2 -> conv2
I0928 18:47:23.108750  5189 net.cpp:122] Setting up conv2
I0928 18:47:23.108781  5189 net.cpp:129] Top shape: 128 256 27 27 (23887872)
I0928 18:47:23.108794  5189 net.cpp:137] Memory required for data: 803194880
I0928 18:47:23.108820  5189 layer_factory.hpp:77] Creating layer bn2
I0928 18:47:23.108876  5189 net.cpp:84] Creating Layer bn2
I0928 18:47:23.108889  5189 net.cpp:406] bn2 <- conv2
I0928 18:47:23.108912  5189 net.cpp:367] bn2 -> conv2 (in-place)
I0928 18:47:23.109125  5189 net.cpp:122] Setting up bn2
I0928 18:47:23.109135  5189 net.cpp:129] Top shape: 128 256 27 27 (23887872)
I0928 18:47:23.109148  5189 net.cpp:137] Memory required for data: 898746368
I0928 18:47:23.109190  5189 layer_factory.hpp:77] Creating layer scale2
I0928 18:47:23.109220  5189 net.cpp:84] Creating Layer scale2
I0928 18:47:23.109227  5189 net.cpp:406] scale2 <- conv2
I0928 18:47:23.109241  5189 net.cpp:367] scale2 -> conv2 (in-place)
I0928 18:47:23.109311  5189 layer_factory.hpp:77] Creating layer scale2
I0928 18:47:23.109493  5189 net.cpp:122] Setting up scale2
I0928 18:47:23.109503  5189 net.cpp:129] Top shape: 128 256 27 27 (23887872)
I0928 18:47:23.109508  5189 net.cpp:137] Memory required for data: 994297856
I0928 18:47:23.109521  5189 layer_factory.hpp:77] Creating layer relu2
I0928 18:47:23.109535  5189 net.cpp:84] Creating Layer relu2
I0928 18:47:23.109544  5189 net.cpp:406] relu2 <- conv2
I0928 18:47:23.109556  5189 net.cpp:367] relu2 -> conv2 (in-place)
I0928 18:47:23.109953  5189 net.cpp:122] Setting up relu2
I0928 18:47:23.109964  5189 net.cpp:129] Top shape: 128 256 27 27 (23887872)
I0928 18:47:23.109969  5189 net.cpp:137] Memory required for data: 1089849344
I0928 18:47:23.109975  5189 layer_factory.hpp:77] Creating layer pool2
I0928 18:47:23.109993  5189 net.cpp:84] Creating Layer pool2
I0928 18:47:23.110002  5189 net.cpp:406] pool2 <- conv2
I0928 18:47:23.110018  5189 net.cpp:380] pool2 -> pool2
I0928 18:47:23.110081  5189 net.cpp:122] Setting up pool2
I0928 18:47:23.110093  5189 net.cpp:129] Top shape: 128 256 13 13 (5537792)
I0928 18:47:23.110098  5189 net.cpp:137] Memory required for data: 1112000512
I0928 18:47:23.110105  5189 layer_factory.hpp:77] Creating layer conv3
I0928 18:47:23.110126  5189 net.cpp:84] Creating Layer conv3
I0928 18:47:23.110136  5189 net.cpp:406] conv3 <- pool2
I0928 18:47:23.110167  5189 net.cpp:380] conv3 -> conv3
I0928 18:47:23.223675  5189 net.cpp:122] Setting up conv3
I0928 18:47:23.223729  5189 net.cpp:129] Top shape: 128 384 13 13 (8306688)
I0928 18:47:23.223733  5189 net.cpp:137] Memory required for data: 1145227264
I0928 18:47:23.223760  5189 layer_factory.hpp:77] Creating layer bn3
I0928 18:47:23.223800  5189 net.cpp:84] Creating Layer bn3
I0928 18:47:23.223824  5189 net.cpp:406] bn3 <- conv3
I0928 18:47:23.223847  5189 net.cpp:367] bn3 -> conv3 (in-place)
I0928 18:47:23.224083  5189 net.cpp:122] Setting up bn3
I0928 18:47:23.224102  5189 net.cpp:129] Top shape: 128 384 13 13 (8306688)
I0928 18:47:23.224105  5189 net.cpp:137] Memory required for data: 1178454016
I0928 18:47:23.224124  5189 layer_factory.hpp:77] Creating layer scale3
I0928 18:47:23.224144  5189 net.cpp:84] Creating Layer scale3
I0928 18:47:23.224161  5189 net.cpp:406] scale3 <- conv3
I0928 18:47:23.224184  5189 net.cpp:367] scale3 -> conv3 (in-place)
I0928 18:47:23.224249  5189 layer_factory.hpp:77] Creating layer scale3
I0928 18:47:23.224416  5189 net.cpp:122] Setting up scale3
I0928 18:47:23.224434  5189 net.cpp:129] Top shape: 128 384 13 13 (8306688)
I0928 18:47:23.224438  5189 net.cpp:137] Memory required for data: 1211680768
I0928 18:47:23.224464  5189 layer_factory.hpp:77] Creating layer relu3
I0928 18:47:23.224498  5189 net.cpp:84] Creating Layer relu3
I0928 18:47:23.224504  5189 net.cpp:406] relu3 <- conv3
I0928 18:47:23.224516  5189 net.cpp:367] relu3 -> conv3 (in-place)
I0928 18:47:23.225164  5189 net.cpp:122] Setting up relu3
I0928 18:47:23.225175  5189 net.cpp:129] Top shape: 128 384 13 13 (8306688)
I0928 18:47:23.225189  5189 net.cpp:137] Memory required for data: 1244907520
I0928 18:47:23.225196  5189 layer_factory.hpp:77] Creating layer conv4
I0928 18:47:23.225237  5189 net.cpp:84] Creating Layer conv4
I0928 18:47:23.225255  5189 net.cpp:406] conv4 <- conv3
I0928 18:47:23.225283  5189 net.cpp:380] conv4 -> conv4
I0928 18:47:23.393206  5189 net.cpp:122] Setting up conv4
I0928 18:47:23.393249  5189 net.cpp:129] Top shape: 128 384 13 13 (8306688)
I0928 18:47:23.393254  5189 net.cpp:137] Memory required for data: 1278134272
I0928 18:47:23.393288  5189 layer_factory.hpp:77] Creating layer bn4
I0928 18:47:23.393332  5189 net.cpp:84] Creating Layer bn4
I0928 18:47:23.393362  5189 net.cpp:406] bn4 <- conv4
I0928 18:47:23.393394  5189 net.cpp:367] bn4 -> conv4 (in-place)
I0928 18:47:23.393643  5189 net.cpp:122] Setting up bn4
I0928 18:47:23.393661  5189 net.cpp:129] Top shape: 128 384 13 13 (8306688)
I0928 18:47:23.393664  5189 net.cpp:137] Memory required for data: 1311361024
I0928 18:47:23.393693  5189 layer_factory.hpp:77] Creating layer scale4
I0928 18:47:23.393744  5189 net.cpp:84] Creating Layer scale4
I0928 18:47:23.393752  5189 net.cpp:406] scale4 <- conv4
I0928 18:47:23.393767  5189 net.cpp:367] scale4 -> conv4 (in-place)
I0928 18:47:23.393826  5189 layer_factory.hpp:77] Creating layer scale4
I0928 18:47:23.393985  5189 net.cpp:122] Setting up scale4
I0928 18:47:23.393995  5189 net.cpp:129] Top shape: 128 384 13 13 (8306688)
I0928 18:47:23.393999  5189 net.cpp:137] Memory required for data: 1344587776
I0928 18:47:23.394012  5189 layer_factory.hpp:77] Creating layer relu4
I0928 18:47:23.394026  5189 net.cpp:84] Creating Layer relu4
I0928 18:47:23.394034  5189 net.cpp:406] relu4 <- conv4
I0928 18:47:23.394049  5189 net.cpp:367] relu4 -> conv4 (in-place)
I0928 18:47:23.394457  5189 net.cpp:122] Setting up relu4
I0928 18:47:23.394467  5189 net.cpp:129] Top shape: 128 384 13 13 (8306688)
I0928 18:47:23.394472  5189 net.cpp:137] Memory required for data: 1377814528
I0928 18:47:23.394479  5189 layer_factory.hpp:77] Creating layer conv5
I0928 18:47:23.394502  5189 net.cpp:84] Creating Layer conv5
I0928 18:47:23.394511  5189 net.cpp:406] conv5 <- conv4
I0928 18:47:23.394532  5189 net.cpp:380] conv5 -> conv5
I0928 18:47:23.509001  5189 net.cpp:122] Setting up conv5
I0928 18:47:23.509040  5189 net.cpp:129] Top shape: 128 256 13 13 (5537792)
I0928 18:47:23.509044  5189 net.cpp:137] Memory required for data: 1399965696
I0928 18:47:23.509066  5189 layer_factory.hpp:77] Creating layer bn5
I0928 18:47:23.509095  5189 net.cpp:84] Creating Layer bn5
I0928 18:47:23.509125  5189 net.cpp:406] bn5 <- conv5
I0928 18:47:23.509145  5189 net.cpp:367] bn5 -> conv5 (in-place)
I0928 18:47:23.509359  5189 net.cpp:122] Setting up bn5
I0928 18:47:23.509369  5189 net.cpp:129] Top shape: 128 256 13 13 (5537792)
I0928 18:47:23.509372  5189 net.cpp:137] Memory required for data: 1422116864
I0928 18:47:23.509392  5189 layer_factory.hpp:77] Creating layer scale5
I0928 18:47:23.509411  5189 net.cpp:84] Creating Layer scale5
I0928 18:47:23.509420  5189 net.cpp:406] scale5 <- conv5
I0928 18:47:23.509435  5189 net.cpp:367] scale5 -> conv5 (in-place)
I0928 18:47:23.509496  5189 layer_factory.hpp:77] Creating layer scale5
I0928 18:47:23.509649  5189 net.cpp:122] Setting up scale5
I0928 18:47:23.509658  5189 net.cpp:129] Top shape: 128 256 13 13 (5537792)
I0928 18:47:23.509663  5189 net.cpp:137] Memory required for data: 1444268032
I0928 18:47:23.509676  5189 layer_factory.hpp:77] Creating layer relu5
I0928 18:47:23.509690  5189 net.cpp:84] Creating Layer relu5
I0928 18:47:23.509697  5189 net.cpp:406] relu5 <- conv5
I0928 18:47:23.509713  5189 net.cpp:367] relu5 -> conv5 (in-place)
I0928 18:47:23.510295  5189 net.cpp:122] Setting up relu5
I0928 18:47:23.510308  5189 net.cpp:129] Top shape: 128 256 13 13 (5537792)
I0928 18:47:23.510313  5189 net.cpp:137] Memory required for data: 1466419200
I0928 18:47:23.510318  5189 layer_factory.hpp:77] Creating layer pool5
I0928 18:47:23.510337  5189 net.cpp:84] Creating Layer pool5
I0928 18:47:23.510345  5189 net.cpp:406] pool5 <- conv5
I0928 18:47:23.510365  5189 net.cpp:380] pool5 -> pool5
I0928 18:47:23.510427  5189 net.cpp:122] Setting up pool5
I0928 18:47:23.510440  5189 net.cpp:129] Top shape: 128 256 6 6 (1179648)
I0928 18:47:23.510445  5189 net.cpp:137] Memory required for data: 1471137792
I0928 18:47:23.510452  5189 layer_factory.hpp:77] Creating layer fc6
I0928 18:47:23.510478  5189 net.cpp:84] Creating Layer fc6
I0928 18:47:23.510488  5189 net.cpp:406] fc6 <- pool5
I0928 18:47:23.510507  5189 net.cpp:380] fc6 -> fc6
I0928 18:47:28.306601  5189 net.cpp:122] Setting up fc6
I0928 18:47:28.306634  5189 net.cpp:129] Top shape: 128 4096 (524288)
I0928 18:47:28.306638  5189 net.cpp:137] Memory required for data: 1473234944
I0928 18:47:28.306675  5189 layer_factory.hpp:77] Creating layer bn6
I0928 18:47:28.306718  5189 net.cpp:84] Creating Layer bn6
I0928 18:47:28.306751  5189 net.cpp:406] bn6 <- fc6
I0928 18:47:28.306780  5189 net.cpp:367] bn6 -> fc6 (in-place)
I0928 18:47:28.307011  5189 net.cpp:122] Setting up bn6
I0928 18:47:28.307020  5189 net.cpp:129] Top shape: 128 4096 (524288)
I0928 18:47:28.307036  5189 net.cpp:137] Memory required for data: 1475332096
I0928 18:47:28.307093  5189 layer_factory.hpp:77] Creating layer scale6
I0928 18:47:28.307132  5189 net.cpp:84] Creating Layer scale6
I0928 18:47:28.307140  5189 net.cpp:406] scale6 <- fc6
I0928 18:47:28.307164  5189 net.cpp:367] scale6 -> fc6 (in-place)
I0928 18:47:28.307262  5189 layer_factory.hpp:77] Creating layer scale6
I0928 18:47:28.307480  5189 net.cpp:122] Setting up scale6
I0928 18:47:28.307489  5189 net.cpp:129] Top shape: 128 4096 (524288)
I0928 18:47:28.307503  5189 net.cpp:137] Memory required for data: 1477429248
I0928 18:47:28.307526  5189 layer_factory.hpp:77] Creating layer relu6
I0928 18:47:28.307551  5189 net.cpp:84] Creating Layer relu6
I0928 18:47:28.307559  5189 net.cpp:406] relu6 <- fc6
I0928 18:47:28.307580  5189 net.cpp:367] relu6 -> fc6 (in-place)
I0928 18:47:28.308148  5189 net.cpp:122] Setting up relu6
I0928 18:47:28.308158  5189 net.cpp:129] Top shape: 128 4096 (524288)
I0928 18:47:28.308162  5189 net.cpp:137] Memory required for data: 1479526400
I0928 18:47:28.308167  5189 layer_factory.hpp:77] Creating layer drop6
I0928 18:47:28.308194  5189 net.cpp:84] Creating Layer drop6
I0928 18:47:28.308203  5189 net.cpp:406] drop6 <- fc6
I0928 18:47:28.308230  5189 net.cpp:367] drop6 -> fc6 (in-place)
I0928 18:47:28.308290  5189 net.cpp:122] Setting up drop6
I0928 18:47:28.308301  5189 net.cpp:129] Top shape: 128 4096 (524288)
I0928 18:47:28.308305  5189 net.cpp:137] Memory required for data: 1481623552
I0928 18:47:28.308320  5189 layer_factory.hpp:77] Creating layer fc7
I0928 18:47:28.308351  5189 net.cpp:84] Creating Layer fc7
I0928 18:47:28.308358  5189 net.cpp:406] fc7 <- fc6
I0928 18:47:28.308378  5189 net.cpp:380] fc7 -> fc7
I0928 18:47:30.415854  5189 net.cpp:122] Setting up fc7
I0928 18:47:30.415891  5189 net.cpp:129] Top shape: 128 4096 (524288)
I0928 18:47:30.415896  5189 net.cpp:137] Memory required for data: 1483720704
I0928 18:47:30.415932  5189 layer_factory.hpp:77] Creating layer bn7
I0928 18:47:30.415984  5189 net.cpp:84] Creating Layer bn7
I0928 18:47:30.416007  5189 net.cpp:406] bn7 <- fc7
I0928 18:47:30.416050  5189 net.cpp:367] bn7 -> fc7 (in-place)
I0928 18:47:30.416298  5189 net.cpp:122] Setting up bn7
I0928 18:47:30.416307  5189 net.cpp:129] Top shape: 128 4096 (524288)
I0928 18:47:30.416311  5189 net.cpp:137] Memory required for data: 1485817856
I0928 18:47:30.416329  5189 layer_factory.hpp:77] Creating layer scale7
I0928 18:47:30.416385  5189 net.cpp:84] Creating Layer scale7
I0928 18:47:30.416411  5189 net.cpp:406] scale7 <- fc7
I0928 18:47:30.416426  5189 net.cpp:367] scale7 -> fc7 (in-place)
I0928 18:47:30.416522  5189 layer_factory.hpp:77] Creating layer scale7
I0928 18:47:30.416700  5189 net.cpp:122] Setting up scale7
I0928 18:47:30.416710  5189 net.cpp:129] Top shape: 128 4096 (524288)
I0928 18:47:30.416713  5189 net.cpp:137] Memory required for data: 1487915008
I0928 18:47:30.416726  5189 layer_factory.hpp:77] Creating layer relu7
I0928 18:47:30.416748  5189 net.cpp:84] Creating Layer relu7
I0928 18:47:30.416756  5189 net.cpp:406] relu7 <- fc7
I0928 18:47:30.416782  5189 net.cpp:367] relu7 -> fc7 (in-place)
I0928 18:47:30.417244  5189 net.cpp:122] Setting up relu7
I0928 18:47:30.417256  5189 net.cpp:129] Top shape: 128 4096 (524288)
I0928 18:47:30.417261  5189 net.cpp:137] Memory required for data: 1490012160
I0928 18:47:30.417268  5189 layer_factory.hpp:77] Creating layer drop7
I0928 18:47:30.417282  5189 net.cpp:84] Creating Layer drop7
I0928 18:47:30.417290  5189 net.cpp:406] drop7 <- fc7
I0928 18:47:30.417315  5189 net.cpp:367] drop7 -> fc7 (in-place)
I0928 18:47:30.417361  5189 net.cpp:122] Setting up drop7
I0928 18:47:30.417378  5189 net.cpp:129] Top shape: 128 4096 (524288)
I0928 18:47:30.417382  5189 net.cpp:137] Memory required for data: 1492109312
I0928 18:47:30.417388  5189 layer_factory.hpp:77] Creating layer fc8
I0928 18:47:30.417412  5189 net.cpp:84] Creating Layer fc8
I0928 18:47:30.417420  5189 net.cpp:406] fc8 <- fc7
I0928 18:47:30.417441  5189 net.cpp:380] fc8 -> fc8
I0928 18:47:30.960129  5189 net.cpp:122] Setting up fc8
I0928 18:47:30.960166  5189 net.cpp:129] Top shape: 128 1000 (128000)
I0928 18:47:30.960170  5189 net.cpp:137] Memory required for data: 1492621312
I0928 18:47:30.960206  5189 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0928 18:47:30.960245  5189 net.cpp:84] Creating Layer fc8_fc8_0_split
I0928 18:47:30.960278  5189 net.cpp:406] fc8_fc8_0_split <- fc8
I0928 18:47:30.960312  5189 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0928 18:47:30.960366  5189 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0928 18:47:30.960392  5189 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0928 18:47:30.960485  5189 net.cpp:122] Setting up fc8_fc8_0_split
I0928 18:47:30.960497  5189 net.cpp:129] Top shape: 128 1000 (128000)
I0928 18:47:30.960502  5189 net.cpp:129] Top shape: 128 1000 (128000)
I0928 18:47:30.960507  5189 net.cpp:129] Top shape: 128 1000 (128000)
I0928 18:47:30.960510  5189 net.cpp:137] Memory required for data: 1494157312
I0928 18:47:30.960515  5189 layer_factory.hpp:77] Creating layer loss
I0928 18:47:30.960544  5189 net.cpp:84] Creating Layer loss
I0928 18:47:30.960572  5189 net.cpp:406] loss <- fc8_fc8_0_split_0
I0928 18:47:30.960583  5189 net.cpp:406] loss <- label_data_1_split_0
I0928 18:47:30.960604  5189 net.cpp:380] loss -> loss
I0928 18:47:30.960636  5189 layer_factory.hpp:77] Creating layer loss
I0928 18:47:30.961992  5189 net.cpp:122] Setting up loss
I0928 18:47:30.962004  5189 net.cpp:129] Top shape: (1)
I0928 18:47:30.962009  5189 net.cpp:132]     with loss weight 1
I0928 18:47:30.962030  5189 net.cpp:137] Memory required for data: 1494157316
I0928 18:47:30.962038  5189 layer_factory.hpp:77] Creating layer accuracy
I0928 18:47:30.962055  5189 net.cpp:84] Creating Layer accuracy
I0928 18:47:30.962064  5189 net.cpp:406] accuracy <- fc8_fc8_0_split_1
I0928 18:47:30.962079  5189 net.cpp:406] accuracy <- label_data_1_split_1
I0928 18:47:30.962093  5189 net.cpp:380] accuracy -> accuracy
I0928 18:47:30.962116  5189 net.cpp:122] Setting up accuracy
I0928 18:47:30.962126  5189 net.cpp:129] Top shape: (1)
I0928 18:47:30.962131  5189 net.cpp:137] Memory required for data: 1494157320
I0928 18:47:30.962136  5189 layer_factory.hpp:77] Creating layer accuracy_5
I0928 18:47:30.962152  5189 net.cpp:84] Creating Layer accuracy_5
I0928 18:47:30.962160  5189 net.cpp:406] accuracy_5 <- fc8_fc8_0_split_2
I0928 18:47:30.962172  5189 net.cpp:406] accuracy_5 <- label_data_1_split_2
I0928 18:47:30.962185  5189 net.cpp:380] accuracy_5 -> accuracy_5
I0928 18:47:30.962208  5189 net.cpp:122] Setting up accuracy_5
I0928 18:47:30.962216  5189 net.cpp:129] Top shape: (1)
I0928 18:47:30.962221  5189 net.cpp:137] Memory required for data: 1494157324
I0928 18:47:30.962229  5189 net.cpp:200] accuracy_5 does not need backward computation.
I0928 18:47:30.962236  5189 net.cpp:200] accuracy does not need backward computation.
I0928 18:47:30.962244  5189 net.cpp:198] loss needs backward computation.
I0928 18:47:30.962250  5189 net.cpp:198] fc8_fc8_0_split needs backward computation.
I0928 18:47:30.962256  5189 net.cpp:198] fc8 needs backward computation.
I0928 18:47:30.962262  5189 net.cpp:198] drop7 needs backward computation.
I0928 18:47:30.962270  5189 net.cpp:198] relu7 needs backward computation.
I0928 18:47:30.962275  5189 net.cpp:198] scale7 needs backward computation.
I0928 18:47:30.962280  5189 net.cpp:198] bn7 needs backward computation.
I0928 18:47:30.962285  5189 net.cpp:198] fc7 needs backward computation.
I0928 18:47:30.962290  5189 net.cpp:198] drop6 needs backward computation.
I0928 18:47:30.962294  5189 net.cpp:198] relu6 needs backward computation.
I0928 18:47:30.962301  5189 net.cpp:198] scale6 needs backward computation.
I0928 18:47:30.962306  5189 net.cpp:198] bn6 needs backward computation.
I0928 18:47:30.962311  5189 net.cpp:198] fc6 needs backward computation.
I0928 18:47:30.962316  5189 net.cpp:198] pool5 needs backward computation.
I0928 18:47:30.962322  5189 net.cpp:198] relu5 needs backward computation.
I0928 18:47:30.962327  5189 net.cpp:198] scale5 needs backward computation.
I0928 18:47:30.962344  5189 net.cpp:198] bn5 needs backward computation.
I0928 18:47:30.962352  5189 net.cpp:198] conv5 needs backward computation.
I0928 18:47:30.962357  5189 net.cpp:198] relu4 needs backward computation.
I0928 18:47:30.962363  5189 net.cpp:198] scale4 needs backward computation.
I0928 18:47:30.962368  5189 net.cpp:198] bn4 needs backward computation.
I0928 18:47:30.962373  5189 net.cpp:198] conv4 needs backward computation.
I0928 18:47:30.962378  5189 net.cpp:198] relu3 needs backward computation.
I0928 18:47:30.962385  5189 net.cpp:198] scale3 needs backward computation.
I0928 18:47:30.962390  5189 net.cpp:198] bn3 needs backward computation.
I0928 18:47:30.962396  5189 net.cpp:198] conv3 needs backward computation.
I0928 18:47:30.962402  5189 net.cpp:198] pool2 needs backward computation.
I0928 18:47:30.962409  5189 net.cpp:198] relu2 needs backward computation.
I0928 18:47:30.962414  5189 net.cpp:198] scale2 needs backward computation.
I0928 18:47:30.962419  5189 net.cpp:198] bn2 needs backward computation.
I0928 18:47:30.962422  5189 net.cpp:198] conv2 needs backward computation.
I0928 18:47:30.962430  5189 net.cpp:198] pool1 needs backward computation.
I0928 18:47:30.962436  5189 net.cpp:198] relu1 needs backward computation.
I0928 18:47:30.962441  5189 net.cpp:198] scale1 needs backward computation.
I0928 18:47:30.962448  5189 net.cpp:198] bn1 needs backward computation.
I0928 18:47:30.962455  5189 net.cpp:198] conv1 needs backward computation.
I0928 18:47:30.962461  5189 net.cpp:200] label_data_1_split does not need backward computation.
I0928 18:47:30.962468  5189 net.cpp:200] data does not need backward computation.
I0928 18:47:30.962476  5189 net.cpp:242] This network produces output accuracy
I0928 18:47:30.962483  5189 net.cpp:242] This network produces output accuracy_5
I0928 18:47:30.962491  5189 net.cpp:242] This network produces output loss
I0928 18:47:30.962543  5189 net.cpp:255] Network initialization done.
I0928 18:47:30.962759  5189 solver.cpp:75] Finetuning from my/Imagenet/AlexNet_INQ_Relax/bvlc_alexnet_bn.caffemodel
I0928 18:47:33.281893  5189 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: my/Imagenet/AlexNet_INQ_Relax/bvlc_alexnet_bn.caffemodel
I0928 18:47:33.281955  5189 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0928 18:47:33.281966  5189 net.cpp:811] net quantization's state : 0
I0928 18:47:33.281982  5189 net.cpp:824] Copying source layer data
I0928 18:47:33.281992  5189 net.cpp:824] Copying source layer label_data_1_split
I0928 18:47:33.281999  5189 net.cpp:824] Copying source layer conv1
I0928 18:47:33.283588  5189 net.cpp:824] Copying source layer bn1
I0928 18:47:33.283761  5189 net.cpp:824] Copying source layer scale1
I0928 18:47:33.283862  5189 net.cpp:824] Copying source layer relu1
I0928 18:47:33.283879  5189 net.cpp:824] Copying source layer pool1
I0928 18:47:33.283887  5189 net.cpp:824] Copying source layer conv2
I0928 18:47:33.306538  5189 net.cpp:824] Copying source layer bn2
I0928 18:47:33.306828  5189 net.cpp:824] Copying source layer scale2
I0928 18:47:33.306921  5189 net.cpp:824] Copying source layer relu2
I0928 18:47:33.306936  5189 net.cpp:824] Copying source layer pool2
I0928 18:47:33.306943  5189 net.cpp:824] Copying source layer conv3
I0928 18:47:33.334641  5189 net.cpp:824] Copying source layer bn3
I0928 18:47:33.334874  5189 net.cpp:824] Copying source layer scale3
I0928 18:47:33.334954  5189 net.cpp:824] Copying source layer relu3
I0928 18:47:33.334969  5189 net.cpp:824] Copying source layer conv4
I0928 18:47:33.371177  5189 net.cpp:824] Copying source layer bn4
I0928 18:47:33.371376  5189 net.cpp:824] Copying source layer scale4
I0928 18:47:33.371446  5189 net.cpp:824] Copying source layer relu4
I0928 18:47:33.371457  5189 net.cpp:824] Copying source layer conv5
I0928 18:47:33.392863  5189 net.cpp:824] Copying source layer bn5
I0928 18:47:33.393034  5189 net.cpp:824] Copying source layer scale5
I0928 18:47:33.393098  5189 net.cpp:824] Copying source layer relu5
I0928 18:47:33.393126  5189 net.cpp:824] Copying source layer pool5
I0928 18:47:33.393133  5189 net.cpp:824] Copying source layer fc6
I0928 18:47:34.050482  5189 net.cpp:824] Copying source layer bn6
I0928 18:47:34.050812  5189 net.cpp:824] Copying source layer scale6
I0928 18:47:34.050992  5189 net.cpp:824] Copying source layer relu6
I0928 18:47:34.051002  5189 net.cpp:824] Copying source layer drop6
I0928 18:47:34.051005  5189 net.cpp:824] Copying source layer fc7
I0928 18:47:34.307916  5189 net.cpp:824] Copying source layer bn7
I0928 18:47:34.308233  5189 net.cpp:824] Copying source layer scale7
I0928 18:47:34.308413  5189 net.cpp:824] Copying source layer relu7
I0928 18:47:34.308423  5189 net.cpp:824] Copying source layer drop7
I0928 18:47:34.308428  5189 net.cpp:824] Copying source layer fc8
I0928 18:47:34.372032  5189 net.cpp:824] Copying source layer fc8_fc8_0_split
I0928 18:47:34.372072  5189 net.cpp:824] Copying source layer loss
I0928 18:47:34.372078  5189 net.cpp:824] Copying source layer accuracy
I0928 18:47:34.372083  5189 net.cpp:824] Copying source layer accuracy_5
I0928 18:47:34.373052  5189 solver.cpp:193] Creating test net (#0) specified by net file: my/Imagenet/AlexNet_INQ_Relax/train_val.prototxt
I0928 18:47:34.373188  5189 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0928 18:47:34.373394  5189 net.cpp:51] Initializing net from parameters: 
name: "AlexNet-BN"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 224
    mean_file: "/mnt/data/ilsvrc12/origin/imagenet_mean.binaryproto"
  }
  data_param {
    source: "/mnt/data/ilsvrc12/origin/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "BinaryConvolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 96
    bias_term: false
    pad: 2
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    binary_relax: false
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "BinaryConvolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    binary_relax: false
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "BinaryConvolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    binary_relax: false
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "BinaryConvolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    binary_relax: false
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "BinaryConvolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    binary_relax: false
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "scale5"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "BinaryInnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4096
    bias_term: false
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    binary_relax: false
  }
}
layer {
  name: "bn6"
  type: "BatchNorm"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "scale6"
  type: "Scale"
  bottom: "fc6"
  top: "fc6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "BinaryInnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4096
    bias_term: false
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    binary_relax: false
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "scale7"
  type: "Scale"
  bottom: "fc7"
  top: "fc7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "BinaryInnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  debug_param {
    binary_relax: false
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "accuracy_5"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy_5"
  accuracy_param {
    top_k: 5
  }
}
I0928 18:47:34.373821  5189 layer_factory.hpp:77] Creating layer data
I0928 18:47:34.373934  5189 db_lmdb.cpp:35] Opened lmdb /mnt/data/ilsvrc12/origin/ilsvrc12_val_lmdb
I0928 18:47:34.373971  5189 net.cpp:84] Creating Layer data
I0928 18:47:34.373987  5189 net.cpp:380] data -> data
I0928 18:47:34.374025  5189 net.cpp:380] data -> label
I0928 18:47:34.374048  5189 data_transformer.cpp:25] Loading mean file from: /mnt/data/ilsvrc12/origin/imagenet_mean.binaryproto
I0928 18:47:34.380578  5189 data_layer.cpp:45] output data size: 50,3,224,224
I0928 18:47:34.425092  5189 base_data_layer.cpp:72] Initializing prefetch
I0928 18:47:34.425202  5189 base_data_layer.cpp:75] Prefetch initialized.
I0928 18:47:34.425231  5189 net.cpp:122] Setting up data
I0928 18:47:34.425261  5189 net.cpp:129] Top shape: 50 3 224 224 (7526400)
I0928 18:47:34.425271  5189 net.cpp:129] Top shape: 50 (50)
I0928 18:47:34.425274  5189 net.cpp:137] Memory required for data: 30105800
I0928 18:47:34.425313  5189 layer_factory.hpp:77] Creating layer label_data_1_split
I0928 18:47:34.425374  5189 net.cpp:84] Creating Layer label_data_1_split
I0928 18:47:34.425390  5189 net.cpp:406] label_data_1_split <- label
I0928 18:47:34.425438  5189 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0928 18:47:34.425493  5189 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0928 18:47:34.425511  5189 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0928 18:47:34.425629  5189 net.cpp:122] Setting up label_data_1_split
I0928 18:47:34.425643  5189 net.cpp:129] Top shape: 50 (50)
I0928 18:47:34.425650  5189 net.cpp:129] Top shape: 50 (50)
I0928 18:47:34.425657  5189 net.cpp:129] Top shape: 50 (50)
I0928 18:47:34.425662  5189 net.cpp:137] Memory required for data: 30106400
I0928 18:47:34.425668  5189 layer_factory.hpp:77] Creating layer conv1
I0928 18:47:34.425703  5189 net.cpp:84] Creating Layer conv1
I0928 18:47:34.425711  5189 net.cpp:406] conv1 <- data
I0928 18:47:34.425732  5189 net.cpp:380] conv1 -> conv1
I0928 18:47:34.430835  5189 net.cpp:122] Setting up conv1
I0928 18:47:34.430851  5189 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0928 18:47:34.430856  5189 net.cpp:137] Memory required for data: 88186400
I0928 18:47:34.430882  5189 layer_factory.hpp:77] Creating layer bn1
I0928 18:47:34.430900  5189 net.cpp:84] Creating Layer bn1
I0928 18:47:34.430910  5189 net.cpp:406] bn1 <- conv1
I0928 18:47:34.430925  5189 net.cpp:367] bn1 -> conv1 (in-place)
I0928 18:47:34.431164  5189 net.cpp:122] Setting up bn1
I0928 18:47:34.431174  5189 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0928 18:47:34.431179  5189 net.cpp:137] Memory required for data: 146266400
I0928 18:47:34.431210  5189 layer_factory.hpp:77] Creating layer scale1
I0928 18:47:34.431233  5189 net.cpp:84] Creating Layer scale1
I0928 18:47:34.431241  5189 net.cpp:406] scale1 <- conv1
I0928 18:47:34.431257  5189 net.cpp:367] scale1 -> conv1 (in-place)
I0928 18:47:34.431326  5189 layer_factory.hpp:77] Creating layer scale1
I0928 18:47:34.431509  5189 net.cpp:122] Setting up scale1
I0928 18:47:34.431519  5189 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0928 18:47:34.431524  5189 net.cpp:137] Memory required for data: 204346400
I0928 18:47:34.431545  5189 layer_factory.hpp:77] Creating layer relu1
I0928 18:47:34.431560  5189 net.cpp:84] Creating Layer relu1
I0928 18:47:34.431566  5189 net.cpp:406] relu1 <- conv1
I0928 18:47:34.431581  5189 net.cpp:367] relu1 -> conv1 (in-place)
I0928 18:47:34.431960  5189 net.cpp:122] Setting up relu1
I0928 18:47:34.431970  5189 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0928 18:47:34.431974  5189 net.cpp:137] Memory required for data: 262426400
I0928 18:47:34.431989  5189 layer_factory.hpp:77] Creating layer pool1
I0928 18:47:34.432009  5189 net.cpp:84] Creating Layer pool1
I0928 18:47:34.432016  5189 net.cpp:406] pool1 <- conv1
I0928 18:47:34.432034  5189 net.cpp:380] pool1 -> pool1
I0928 18:47:34.432097  5189 net.cpp:122] Setting up pool1
I0928 18:47:34.432118  5189 net.cpp:129] Top shape: 50 96 27 27 (3499200)
I0928 18:47:34.432132  5189 net.cpp:137] Memory required for data: 276423200
I0928 18:47:34.432137  5189 layer_factory.hpp:77] Creating layer conv2
I0928 18:47:34.432158  5189 net.cpp:84] Creating Layer conv2
I0928 18:47:34.432166  5189 net.cpp:406] conv2 <- pool1
I0928 18:47:34.432185  5189 net.cpp:380] conv2 -> conv2
I0928 18:47:34.512894  5189 net.cpp:122] Setting up conv2
I0928 18:47:34.512928  5189 net.cpp:129] Top shape: 50 256 27 27 (9331200)
I0928 18:47:34.512933  5189 net.cpp:137] Memory required for data: 313748000
I0928 18:47:34.512961  5189 layer_factory.hpp:77] Creating layer bn2
I0928 18:47:34.513020  5189 net.cpp:84] Creating Layer bn2
I0928 18:47:34.513043  5189 net.cpp:406] bn2 <- conv2
I0928 18:47:34.513077  5189 net.cpp:367] bn2 -> conv2 (in-place)
I0928 18:47:34.513332  5189 net.cpp:122] Setting up bn2
I0928 18:47:34.513350  5189 net.cpp:129] Top shape: 50 256 27 27 (9331200)
I0928 18:47:34.513355  5189 net.cpp:137] Memory required for data: 351072800
I0928 18:47:34.513422  5189 layer_factory.hpp:77] Creating layer scale2
I0928 18:47:34.513443  5189 net.cpp:84] Creating Layer scale2
I0928 18:47:34.513451  5189 net.cpp:406] scale2 <- conv2
I0928 18:47:34.513474  5189 net.cpp:367] scale2 -> conv2 (in-place)
I0928 18:47:34.513548  5189 layer_factory.hpp:77] Creating layer scale2
I0928 18:47:34.513741  5189 net.cpp:122] Setting up scale2
I0928 18:47:34.513751  5189 net.cpp:129] Top shape: 50 256 27 27 (9331200)
I0928 18:47:34.513756  5189 net.cpp:137] Memory required for data: 388397600
I0928 18:47:34.513778  5189 layer_factory.hpp:77] Creating layer relu2
I0928 18:47:34.513792  5189 net.cpp:84] Creating Layer relu2
I0928 18:47:34.513799  5189 net.cpp:406] relu2 <- conv2
I0928 18:47:34.513813  5189 net.cpp:367] relu2 -> conv2 (in-place)
I0928 18:47:34.514420  5189 net.cpp:122] Setting up relu2
I0928 18:47:34.514431  5189 net.cpp:129] Top shape: 50 256 27 27 (9331200)
I0928 18:47:34.514436  5189 net.cpp:137] Memory required for data: 425722400
I0928 18:47:34.514442  5189 layer_factory.hpp:77] Creating layer pool2
I0928 18:47:34.514461  5189 net.cpp:84] Creating Layer pool2
I0928 18:47:34.514469  5189 net.cpp:406] pool2 <- conv2
I0928 18:47:34.514487  5189 net.cpp:380] pool2 -> pool2
I0928 18:47:34.514555  5189 net.cpp:122] Setting up pool2
I0928 18:47:34.514566  5189 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0928 18:47:34.514571  5189 net.cpp:137] Memory required for data: 434375200
I0928 18:47:34.514577  5189 layer_factory.hpp:77] Creating layer conv3
I0928 18:47:34.514600  5189 net.cpp:84] Creating Layer conv3
I0928 18:47:34.514609  5189 net.cpp:406] conv3 <- pool2
I0928 18:47:34.514627  5189 net.cpp:380] conv3 -> conv3
I0928 18:47:34.628026  5189 net.cpp:122] Setting up conv3
I0928 18:47:34.628070  5189 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0928 18:47:34.628074  5189 net.cpp:137] Memory required for data: 447354400
I0928 18:47:34.628109  5189 layer_factory.hpp:77] Creating layer bn3
I0928 18:47:34.628140  5189 net.cpp:84] Creating Layer bn3
I0928 18:47:34.628172  5189 net.cpp:406] bn3 <- conv3
I0928 18:47:34.628196  5189 net.cpp:367] bn3 -> conv3 (in-place)
I0928 18:47:34.628437  5189 net.cpp:122] Setting up bn3
I0928 18:47:34.628455  5189 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0928 18:47:34.628459  5189 net.cpp:137] Memory required for data: 460333600
I0928 18:47:34.628487  5189 layer_factory.hpp:77] Creating layer scale3
I0928 18:47:34.628507  5189 net.cpp:84] Creating Layer scale3
I0928 18:47:34.628515  5189 net.cpp:406] scale3 <- conv3
I0928 18:47:34.628528  5189 net.cpp:367] scale3 -> conv3 (in-place)
I0928 18:47:34.628620  5189 layer_factory.hpp:77] Creating layer scale3
I0928 18:47:34.628794  5189 net.cpp:122] Setting up scale3
I0928 18:47:34.628804  5189 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0928 18:47:34.628809  5189 net.cpp:137] Memory required for data: 473312800
I0928 18:47:34.628844  5189 layer_factory.hpp:77] Creating layer relu3
I0928 18:47:34.628877  5189 net.cpp:84] Creating Layer relu3
I0928 18:47:34.628885  5189 net.cpp:406] relu3 <- conv3
I0928 18:47:34.628897  5189 net.cpp:367] relu3 -> conv3 (in-place)
I0928 18:47:34.629508  5189 net.cpp:122] Setting up relu3
I0928 18:47:34.629519  5189 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0928 18:47:34.629523  5189 net.cpp:137] Memory required for data: 486292000
I0928 18:47:34.629530  5189 layer_factory.hpp:77] Creating layer conv4
I0928 18:47:34.629564  5189 net.cpp:84] Creating Layer conv4
I0928 18:47:34.629572  5189 net.cpp:406] conv4 <- conv3
I0928 18:47:34.629592  5189 net.cpp:380] conv4 -> conv4
I0928 18:47:34.797832  5189 net.cpp:122] Setting up conv4
I0928 18:47:34.797866  5189 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0928 18:47:34.797871  5189 net.cpp:137] Memory required for data: 499271200
I0928 18:47:34.797895  5189 layer_factory.hpp:77] Creating layer bn4
I0928 18:47:34.797935  5189 net.cpp:84] Creating Layer bn4
I0928 18:47:34.797966  5189 net.cpp:406] bn4 <- conv4
I0928 18:47:34.798007  5189 net.cpp:367] bn4 -> conv4 (in-place)
I0928 18:47:34.798290  5189 net.cpp:122] Setting up bn4
I0928 18:47:34.798300  5189 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0928 18:47:34.798303  5189 net.cpp:137] Memory required for data: 512250400
I0928 18:47:34.798322  5189 layer_factory.hpp:77] Creating layer scale4
I0928 18:47:34.798348  5189 net.cpp:84] Creating Layer scale4
I0928 18:47:34.798357  5189 net.cpp:406] scale4 <- conv4
I0928 18:47:34.798370  5189 net.cpp:367] scale4 -> conv4 (in-place)
I0928 18:47:34.798481  5189 layer_factory.hpp:77] Creating layer scale4
I0928 18:47:34.798651  5189 net.cpp:122] Setting up scale4
I0928 18:47:34.798661  5189 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0928 18:47:34.798666  5189 net.cpp:137] Memory required for data: 525229600
I0928 18:47:34.798677  5189 layer_factory.hpp:77] Creating layer relu4
I0928 18:47:34.798689  5189 net.cpp:84] Creating Layer relu4
I0928 18:47:34.798705  5189 net.cpp:406] relu4 <- conv4
I0928 18:47:34.798718  5189 net.cpp:367] relu4 -> conv4 (in-place)
I0928 18:47:34.799108  5189 net.cpp:122] Setting up relu4
I0928 18:47:34.799118  5189 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0928 18:47:34.799123  5189 net.cpp:137] Memory required for data: 538208800
I0928 18:47:34.799129  5189 layer_factory.hpp:77] Creating layer conv5
I0928 18:47:34.799160  5189 net.cpp:84] Creating Layer conv5
I0928 18:47:34.799170  5189 net.cpp:406] conv5 <- conv4
I0928 18:47:34.799197  5189 net.cpp:380] conv5 -> conv5
I0928 18:47:34.911134  5189 net.cpp:122] Setting up conv5
I0928 18:47:34.911167  5189 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0928 18:47:34.911172  5189 net.cpp:137] Memory required for data: 546861600
I0928 18:47:34.911208  5189 layer_factory.hpp:77] Creating layer bn5
I0928 18:47:34.911252  5189 net.cpp:84] Creating Layer bn5
I0928 18:47:34.911267  5189 net.cpp:406] bn5 <- conv5
I0928 18:47:34.911290  5189 net.cpp:367] bn5 -> conv5 (in-place)
I0928 18:47:34.911537  5189 net.cpp:122] Setting up bn5
I0928 18:47:34.911547  5189 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0928 18:47:34.911550  5189 net.cpp:137] Memory required for data: 555514400
I0928 18:47:34.911569  5189 layer_factory.hpp:77] Creating layer scale5
I0928 18:47:34.911602  5189 net.cpp:84] Creating Layer scale5
I0928 18:47:34.911628  5189 net.cpp:406] scale5 <- conv5
I0928 18:47:34.911643  5189 net.cpp:367] scale5 -> conv5 (in-place)
I0928 18:47:34.911743  5189 layer_factory.hpp:77] Creating layer scale5
I0928 18:47:34.911917  5189 net.cpp:122] Setting up scale5
I0928 18:47:34.911927  5189 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0928 18:47:34.911931  5189 net.cpp:137] Memory required for data: 564167200
I0928 18:47:34.911944  5189 layer_factory.hpp:77] Creating layer relu5
I0928 18:47:34.911959  5189 net.cpp:84] Creating Layer relu5
I0928 18:47:34.911980  5189 net.cpp:406] relu5 <- conv5
I0928 18:47:34.912000  5189 net.cpp:367] relu5 -> conv5 (in-place)
I0928 18:47:34.912619  5189 net.cpp:122] Setting up relu5
I0928 18:47:34.912631  5189 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0928 18:47:34.912634  5189 net.cpp:137] Memory required for data: 572820000
I0928 18:47:34.912641  5189 layer_factory.hpp:77] Creating layer pool5
I0928 18:47:34.912658  5189 net.cpp:84] Creating Layer pool5
I0928 18:47:34.912679  5189 net.cpp:406] pool5 <- conv5
I0928 18:47:34.912703  5189 net.cpp:380] pool5 -> pool5
I0928 18:47:34.912789  5189 net.cpp:122] Setting up pool5
I0928 18:47:34.912802  5189 net.cpp:129] Top shape: 50 256 6 6 (460800)
I0928 18:47:34.912808  5189 net.cpp:137] Memory required for data: 574663200
I0928 18:47:34.912819  5189 layer_factory.hpp:77] Creating layer fc6
I0928 18:47:34.912847  5189 net.cpp:84] Creating Layer fc6
I0928 18:47:34.912856  5189 net.cpp:406] fc6 <- pool5
I0928 18:47:34.912895  5189 net.cpp:380] fc6 -> fc6
I0928 18:47:39.679255  5189 net.cpp:122] Setting up fc6
I0928 18:47:39.679291  5189 net.cpp:129] Top shape: 50 4096 (204800)
I0928 18:47:39.679296  5189 net.cpp:137] Memory required for data: 575482400
I0928 18:47:39.679332  5189 layer_factory.hpp:77] Creating layer bn6
I0928 18:47:39.679389  5189 net.cpp:84] Creating Layer bn6
I0928 18:47:39.679420  5189 net.cpp:406] bn6 <- fc6
I0928 18:47:39.679453  5189 net.cpp:367] bn6 -> fc6 (in-place)
I0928 18:47:39.679697  5189 net.cpp:122] Setting up bn6
I0928 18:47:39.679705  5189 net.cpp:129] Top shape: 50 4096 (204800)
I0928 18:47:39.679709  5189 net.cpp:137] Memory required for data: 576301600
I0928 18:47:39.679754  5189 layer_factory.hpp:77] Creating layer scale6
I0928 18:47:39.679774  5189 net.cpp:84] Creating Layer scale6
I0928 18:47:39.679781  5189 net.cpp:406] scale6 <- fc6
I0928 18:47:39.679795  5189 net.cpp:367] scale6 -> fc6 (in-place)
I0928 18:47:39.679898  5189 layer_factory.hpp:77] Creating layer scale6
I0928 18:47:39.680080  5189 net.cpp:122] Setting up scale6
I0928 18:47:39.680099  5189 net.cpp:129] Top shape: 50 4096 (204800)
I0928 18:47:39.680102  5189 net.cpp:137] Memory required for data: 577120800
I0928 18:47:39.680115  5189 layer_factory.hpp:77] Creating layer relu6
I0928 18:47:39.680128  5189 net.cpp:84] Creating Layer relu6
I0928 18:47:39.680135  5189 net.cpp:406] relu6 <- fc6
I0928 18:47:39.680148  5189 net.cpp:367] relu6 -> fc6 (in-place)
I0928 18:47:39.680567  5189 net.cpp:122] Setting up relu6
I0928 18:47:39.680577  5189 net.cpp:129] Top shape: 50 4096 (204800)
I0928 18:47:39.680580  5189 net.cpp:137] Memory required for data: 577940000
I0928 18:47:39.680586  5189 layer_factory.hpp:77] Creating layer drop6
I0928 18:47:39.680600  5189 net.cpp:84] Creating Layer drop6
I0928 18:47:39.680608  5189 net.cpp:406] drop6 <- fc6
I0928 18:47:39.680622  5189 net.cpp:367] drop6 -> fc6 (in-place)
I0928 18:47:39.680660  5189 net.cpp:122] Setting up drop6
I0928 18:47:39.680668  5189 net.cpp:129] Top shape: 50 4096 (204800)
I0928 18:47:39.680672  5189 net.cpp:137] Memory required for data: 578759200
I0928 18:47:39.680677  5189 layer_factory.hpp:77] Creating layer fc7
I0928 18:47:39.680699  5189 net.cpp:84] Creating Layer fc7
I0928 18:47:39.680707  5189 net.cpp:406] fc7 <- fc6
I0928 18:47:39.680724  5189 net.cpp:380] fc7 -> fc7
I0928 18:47:41.781208  5189 net.cpp:122] Setting up fc7
I0928 18:47:41.781245  5189 net.cpp:129] Top shape: 50 4096 (204800)
I0928 18:47:41.781250  5189 net.cpp:137] Memory required for data: 579578400
I0928 18:47:41.781286  5189 layer_factory.hpp:77] Creating layer bn7
I0928 18:47:41.781339  5189 net.cpp:84] Creating Layer bn7
I0928 18:47:41.781353  5189 net.cpp:406] bn7 <- fc7
I0928 18:47:41.781376  5189 net.cpp:367] bn7 -> fc7 (in-place)
I0928 18:47:41.781625  5189 net.cpp:122] Setting up bn7
I0928 18:47:41.781635  5189 net.cpp:129] Top shape: 50 4096 (204800)
I0928 18:47:41.781638  5189 net.cpp:137] Memory required for data: 580397600
I0928 18:47:41.781657  5189 layer_factory.hpp:77] Creating layer scale7
I0928 18:47:41.781710  5189 net.cpp:84] Creating Layer scale7
I0928 18:47:41.781736  5189 net.cpp:406] scale7 <- fc7
I0928 18:47:41.781751  5189 net.cpp:367] scale7 -> fc7 (in-place)
I0928 18:47:41.781853  5189 layer_factory.hpp:77] Creating layer scale7
I0928 18:47:41.782034  5189 net.cpp:122] Setting up scale7
I0928 18:47:41.782044  5189 net.cpp:129] Top shape: 50 4096 (204800)
I0928 18:47:41.782047  5189 net.cpp:137] Memory required for data: 581216800
I0928 18:47:41.782060  5189 layer_factory.hpp:77] Creating layer relu7
I0928 18:47:41.782073  5189 net.cpp:84] Creating Layer relu7
I0928 18:47:41.782091  5189 net.cpp:406] relu7 <- fc7
I0928 18:47:41.782115  5189 net.cpp:367] relu7 -> fc7 (in-place)
I0928 18:47:41.782708  5189 net.cpp:122] Setting up relu7
I0928 18:47:41.782719  5189 net.cpp:129] Top shape: 50 4096 (204800)
I0928 18:47:41.782724  5189 net.cpp:137] Memory required for data: 582036000
I0928 18:47:41.782730  5189 layer_factory.hpp:77] Creating layer drop7
I0928 18:47:41.782747  5189 net.cpp:84] Creating Layer drop7
I0928 18:47:41.782755  5189 net.cpp:406] drop7 <- fc7
I0928 18:47:41.782793  5189 net.cpp:367] drop7 -> fc7 (in-place)
I0928 18:47:41.782850  5189 net.cpp:122] Setting up drop7
I0928 18:47:41.782868  5189 net.cpp:129] Top shape: 50 4096 (204800)
I0928 18:47:41.782881  5189 net.cpp:137] Memory required for data: 582855200
I0928 18:47:41.782908  5189 layer_factory.hpp:77] Creating layer fc8
I0928 18:47:41.782934  5189 net.cpp:84] Creating Layer fc8
I0928 18:47:41.782951  5189 net.cpp:406] fc8 <- fc7
I0928 18:47:41.782979  5189 net.cpp:380] fc8 -> fc8
I0928 18:47:42.297919  5189 net.cpp:122] Setting up fc8
I0928 18:47:42.297955  5189 net.cpp:129] Top shape: 50 1000 (50000)
I0928 18:47:42.297960  5189 net.cpp:137] Memory required for data: 583055200
I0928 18:47:42.297996  5189 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0928 18:47:42.298034  5189 net.cpp:84] Creating Layer fc8_fc8_0_split
I0928 18:47:42.298056  5189 net.cpp:406] fc8_fc8_0_split <- fc8
I0928 18:47:42.298099  5189 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0928 18:47:42.298161  5189 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0928 18:47:42.298187  5189 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0928 18:47:42.298285  5189 net.cpp:122] Setting up fc8_fc8_0_split
I0928 18:47:42.298296  5189 net.cpp:129] Top shape: 50 1000 (50000)
I0928 18:47:42.298301  5189 net.cpp:129] Top shape: 50 1000 (50000)
I0928 18:47:42.298306  5189 net.cpp:129] Top shape: 50 1000 (50000)
I0928 18:47:42.298310  5189 net.cpp:137] Memory required for data: 583655200
I0928 18:47:42.298315  5189 layer_factory.hpp:77] Creating layer loss
I0928 18:47:42.298337  5189 net.cpp:84] Creating Layer loss
I0928 18:47:42.298346  5189 net.cpp:406] loss <- fc8_fc8_0_split_0
I0928 18:47:42.298367  5189 net.cpp:406] loss <- label_data_1_split_0
I0928 18:47:42.298399  5189 net.cpp:380] loss -> loss
I0928 18:47:42.298436  5189 layer_factory.hpp:77] Creating layer loss
I0928 18:47:42.299290  5189 net.cpp:122] Setting up loss
I0928 18:47:42.299311  5189 net.cpp:129] Top shape: (1)
I0928 18:47:42.299315  5189 net.cpp:132]     with loss weight 1
I0928 18:47:42.299327  5189 net.cpp:137] Memory required for data: 583655204
I0928 18:47:42.299334  5189 layer_factory.hpp:77] Creating layer accuracy
I0928 18:47:42.299348  5189 net.cpp:84] Creating Layer accuracy
I0928 18:47:42.299356  5189 net.cpp:406] accuracy <- fc8_fc8_0_split_1
I0928 18:47:42.299368  5189 net.cpp:406] accuracy <- label_data_1_split_1
I0928 18:47:42.299381  5189 net.cpp:380] accuracy -> accuracy
I0928 18:47:42.299401  5189 net.cpp:122] Setting up accuracy
I0928 18:47:42.299409  5189 net.cpp:129] Top shape: (1)
I0928 18:47:42.299414  5189 net.cpp:137] Memory required for data: 583655208
I0928 18:47:42.299428  5189 layer_factory.hpp:77] Creating layer accuracy_5
I0928 18:47:42.299443  5189 net.cpp:84] Creating Layer accuracy_5
I0928 18:47:42.299459  5189 net.cpp:406] accuracy_5 <- fc8_fc8_0_split_2
I0928 18:47:42.299471  5189 net.cpp:406] accuracy_5 <- label_data_1_split_2
I0928 18:47:42.299484  5189 net.cpp:380] accuracy_5 -> accuracy_5
I0928 18:47:42.299504  5189 net.cpp:122] Setting up accuracy_5
I0928 18:47:42.299512  5189 net.cpp:129] Top shape: (1)
I0928 18:47:42.299517  5189 net.cpp:137] Memory required for data: 583655212
I0928 18:47:42.299523  5189 net.cpp:200] accuracy_5 does not need backward computation.
I0928 18:47:42.299531  5189 net.cpp:200] accuracy does not need backward computation.
I0928 18:47:42.299538  5189 net.cpp:198] loss needs backward computation.
I0928 18:47:42.299554  5189 net.cpp:198] fc8_fc8_0_split needs backward computation.
I0928 18:47:42.299561  5189 net.cpp:198] fc8 needs backward computation.
I0928 18:47:42.299567  5189 net.cpp:198] drop7 needs backward computation.
I0928 18:47:42.299573  5189 net.cpp:198] relu7 needs backward computation.
I0928 18:47:42.299588  5189 net.cpp:198] scale7 needs backward computation.
I0928 18:47:42.299593  5189 net.cpp:198] bn7 needs backward computation.
I0928 18:47:42.299598  5189 net.cpp:198] fc7 needs backward computation.
I0928 18:47:42.299604  5189 net.cpp:198] drop6 needs backward computation.
I0928 18:47:42.299610  5189 net.cpp:198] relu6 needs backward computation.
I0928 18:47:42.299615  5189 net.cpp:198] scale6 needs backward computation.
I0928 18:47:42.299619  5189 net.cpp:198] bn6 needs backward computation.
I0928 18:47:42.299638  5189 net.cpp:198] fc6 needs backward computation.
I0928 18:47:42.299645  5189 net.cpp:198] pool5 needs backward computation.
I0928 18:47:42.299651  5189 net.cpp:198] relu5 needs backward computation.
I0928 18:47:42.299656  5189 net.cpp:198] scale5 needs backward computation.
I0928 18:47:42.299662  5189 net.cpp:198] bn5 needs backward computation.
I0928 18:47:42.299667  5189 net.cpp:198] conv5 needs backward computation.
I0928 18:47:42.299674  5189 net.cpp:198] relu4 needs backward computation.
I0928 18:47:42.299679  5189 net.cpp:198] scale4 needs backward computation.
I0928 18:47:42.299685  5189 net.cpp:198] bn4 needs backward computation.
I0928 18:47:42.299690  5189 net.cpp:198] conv4 needs backward computation.
I0928 18:47:42.299706  5189 net.cpp:198] relu3 needs backward computation.
I0928 18:47:42.299712  5189 net.cpp:198] scale3 needs backward computation.
I0928 18:47:42.299717  5189 net.cpp:198] bn3 needs backward computation.
I0928 18:47:42.299723  5189 net.cpp:198] conv3 needs backward computation.
I0928 18:47:42.299729  5189 net.cpp:198] pool2 needs backward computation.
I0928 18:47:42.299736  5189 net.cpp:198] relu2 needs backward computation.
I0928 18:47:42.299741  5189 net.cpp:198] scale2 needs backward computation.
I0928 18:47:42.299757  5189 net.cpp:198] bn2 needs backward computation.
I0928 18:47:42.299762  5189 net.cpp:198] conv2 needs backward computation.
I0928 18:47:42.299768  5189 net.cpp:198] pool1 needs backward computation.
I0928 18:47:42.299774  5189 net.cpp:198] relu1 needs backward computation.
I0928 18:47:42.299779  5189 net.cpp:198] scale1 needs backward computation.
I0928 18:47:42.299785  5189 net.cpp:198] bn1 needs backward computation.
I0928 18:47:42.299790  5189 net.cpp:198] conv1 needs backward computation.
I0928 18:47:42.299798  5189 net.cpp:200] label_data_1_split does not need backward computation.
I0928 18:47:42.299805  5189 net.cpp:200] data does not need backward computation.
I0928 18:47:42.299810  5189 net.cpp:242] This network produces output accuracy
I0928 18:47:42.299818  5189 net.cpp:242] This network produces output accuracy_5
I0928 18:47:42.299823  5189 net.cpp:242] This network produces output loss
I0928 18:47:42.299868  5189 net.cpp:255] Network initialization done.
I0928 18:47:42.299975  5189 solver.cpp:75] Finetuning from my/Imagenet/AlexNet_INQ_Relax/bvlc_alexnet_bn.caffemodel
I0928 18:47:42.689204  5189 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: my/Imagenet/AlexNet_INQ_Relax/bvlc_alexnet_bn.caffemodel
I0928 18:47:42.689245  5189 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0928 18:47:42.689250  5189 net.cpp:811] net quantization's state : 0
I0928 18:47:42.689256  5189 net.cpp:824] Copying source layer data
I0928 18:47:42.689263  5189 net.cpp:824] Copying source layer label_data_1_split
I0928 18:47:42.689266  5189 net.cpp:824] Copying source layer conv1
I0928 18:47:42.689950  5189 net.cpp:824] Copying source layer bn1
I0928 18:47:42.690106  5189 net.cpp:824] Copying source layer scale1
I0928 18:47:42.690173  5189 net.cpp:824] Copying source layer relu1
I0928 18:47:42.690191  5189 net.cpp:824] Copying source layer pool1
I0928 18:47:42.690203  5189 net.cpp:824] Copying source layer conv2
I0928 18:47:42.700153  5189 net.cpp:824] Copying source layer bn2
I0928 18:47:42.700316  5189 net.cpp:824] Copying source layer scale2
I0928 18:47:42.700394  5189 net.cpp:824] Copying source layer relu2
I0928 18:47:42.700402  5189 net.cpp:824] Copying source layer pool2
I0928 18:47:42.700417  5189 net.cpp:824] Copying source layer conv3
I0928 18:47:42.714463  5189 net.cpp:824] Copying source layer bn3
I0928 18:47:42.714655  5189 net.cpp:824] Copying source layer scale3
I0928 18:47:42.714718  5189 net.cpp:824] Copying source layer relu3
I0928 18:47:42.714726  5189 net.cpp:824] Copying source layer conv4
I0928 18:47:42.735643  5189 net.cpp:824] Copying source layer bn4
I0928 18:47:42.735851  5189 net.cpp:824] Copying source layer scale4
I0928 18:47:42.735914  5189 net.cpp:824] Copying source layer relu4
I0928 18:47:42.735944  5189 net.cpp:824] Copying source layer conv5
I0928 18:47:42.749531  5189 net.cpp:824] Copying source layer bn5
I0928 18:47:42.749706  5189 net.cpp:824] Copying source layer scale5
I0928 18:47:42.749773  5189 net.cpp:824] Copying source layer relu5
I0928 18:47:42.749780  5189 net.cpp:824] Copying source layer pool5
I0928 18:47:42.749794  5189 net.cpp:824] Copying source layer fc6
I0928 18:47:45.590275  5189 net.cpp:824] Copying source layer bn6
I0928 18:47:45.590600  5189 net.cpp:824] Copying source layer scale6
I0928 18:47:45.590766  5189 net.cpp:824] Copying source layer relu6
I0928 18:47:45.590778  5189 net.cpp:824] Copying source layer drop6
I0928 18:47:45.590783  5189 net.cpp:824] Copying source layer fc7
I0928 18:47:45.882958  5189 net.cpp:824] Copying source layer bn7
I0928 18:47:45.883261  5189 net.cpp:824] Copying source layer scale7
I0928 18:47:45.883427  5189 net.cpp:824] Copying source layer relu7
I0928 18:47:45.883436  5189 net.cpp:824] Copying source layer drop7
I0928 18:47:45.883440  5189 net.cpp:824] Copying source layer fc8
I0928 18:47:45.946733  5189 net.cpp:824] Copying source layer fc8_fc8_0_split
I0928 18:47:45.946787  5189 net.cpp:824] Copying source layer loss
I0928 18:47:45.946794  5189 net.cpp:824] Copying source layer accuracy
I0928 18:47:45.946799  5189 net.cpp:824] Copying source layer accuracy_5
I0928 18:47:45.955431  5189 solver.cpp:57] Solver scaffolding done.
I0928 18:47:45.957427  5189 caffe.cpp:239] Starting Optimization
I0928 18:47:45.957438  5189 solver.cpp:299] Solving AlexNet-BN
I0928 18:47:45.957451  5189 solver.cpp:300] Learning Rate Policy: multistep
I0928 18:47:45.959738  5189 solver.cpp:384] Iteration 0, Testing net (#0)
I0928 18:47:47.089447  5189 blocking_queue.cpp:49] Waiting for data
I0928 18:50:49.873272  5200 data_layer.cpp:73] Restarting data prefetching from start.
I0928 18:50:50.081918  5189 solver.cpp:452]     Test net output #0: accuracy = 0.00126
I0928 18:50:50.081950  5189 solver.cpp:452]     Test net output #1: accuracy_5 = 0.00488
I0928 18:50:50.081960  5189 solver.cpp:452]     Test net output #2: loss = 7.21246 (* 1 = 7.21246 loss)
I0928 18:50:50.081964  5189 solver.cpp:463] ================================
I0928 18:50:50.081967  5189 solver.cpp:464]     Test net best accuracy1 is: 0.00126
I0928 18:50:50.081971  5189 solver.cpp:466]     Test net best accuracy5 is: 0.00488
I0928 18:50:51.632612  5189 solver.cpp:242] Iteration 0 (-1.82902e-26 iter/s, 185.676s/200 iters), loss = 7.29507
I0928 18:50:51.632654  5189 solver.cpp:261]     Train net output #0: accuracy = 0
I0928 18:50:51.632664  5189 solver.cpp:261]     Train net output #1: accuracy_5 = 0
I0928 18:50:51.632675  5189 solver.cpp:261]     Train net output #2: loss = 7.29507 (* 1 = 7.29507 loss)
I0928 18:50:51.632702  5189 sgd_solver.cpp:122] Iteration 0, lr = 0.01
