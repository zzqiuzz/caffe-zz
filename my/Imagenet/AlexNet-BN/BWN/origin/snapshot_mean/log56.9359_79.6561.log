I0111 23:16:53.961849 48059 upgrade_proto.cpp:1113] snapshot_prefix was a directory and is replaced to snapshot/solver
I0111 23:16:53.962967 48059 caffe.cpp:204] Using GPUs 5
I0111 23:16:54.071427 48059 caffe.cpp:209] GPU 5: GeForce GTX 1080 Ti
I0111 23:16:58.373205 48059 solver.cpp:45] Initializing solver from parameters: 
test_iter: 1000
test_interval: 1000
base_lr: 0.01
display: 200
max_iter: 40000
lr_policy: "modified_lr"
momentum: 0.9
snapshot: 10000
snapshot_prefix: "snapshot/solver"
solver_mode: GPU
device_id: 5
net: "train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
weights: "snapshot/solver_iter_260000.caffemodel"
modified_lr {
  stepvalue: 20000
  stepvalue: 30000
  stepvalue: 40000
  stepvalue: 250000
  stepvalue: 310000
  stepvalue: 350000
  stepvalue: 400000
  stepvalue: 500000
  mlr: 5e-05
  mlr: 1e-05
  mlr: 1e-06
  mlr: 0.0005
  mlr: 0.0001
  mlr: 5e-05
  mlr: 1e-05
  mlr: 1e-06
  weight_decay: 0
  weight_decay: 0
  weight_decay: 0
  weight_decay: 0
  weight_decay: 0
  weight_decay: 0
  weight_decay: 0
  weight_decay: 0
}
I0111 23:16:58.373770 48059 solver.cpp:105] Creating training net from net file: train_test.prototxt
I0111 23:16:58.374943 48059 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0111 23:16:58.375171 48059 net.cpp:51] Initializing net from parameters: 
name: "AlexNet-BN"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/zhengzhe/Data/imagenet_shrt256/ilsvrc12_train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 96
    bias_term: false
    pad: 2
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "BinaryConvolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "BinaryConvolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "BinaryConvolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "BinaryConvolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "scale5"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "BinaryInnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4096
    bias_term: false
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn6"
  type: "BatchNorm"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "scale6"
  type: "Scale"
  bottom: "fc6"
  top: "fc6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "fc7"
  type: "BinaryInnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4096
    bias_term: false
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "scale7"
  type: "Scale"
  bottom: "fc7"
  top: "fc7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "accuracy_5"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy_5"
  accuracy_param {
    top_k: 5
  }
}
I0111 23:16:58.375845 48059 layer_factory.hpp:78] Creating layer data
I0111 23:16:58.376062 48059 db_lmdb.cpp:35] Opened lmdb /home/zhengzhe/Data/imagenet_shrt256/ilsvrc12_train_lmdb
I0111 23:16:58.376163 48059 net.cpp:84] Creating Layer data
I0111 23:16:58.376195 48059 net.cpp:380] data -> data
I0111 23:16:58.376353 48059 net.cpp:380] data -> label
I0111 23:16:58.379139 48059 data_layer.cpp:45] output data size: 256,3,224,224
I0111 23:16:58.857599 48059 base_data_layer.cpp:72] Initializing prefetch
I0111 23:16:58.857928 48059 base_data_layer.cpp:75] Prefetch initialized.
I0111 23:16:58.857942 48059 net.cpp:122] Setting up data
I0111 23:16:58.857985 48059 net.cpp:129] Top shape: 256 3 224 224 (38535168)
I0111 23:16:58.857995 48059 net.cpp:129] Top shape: 256 (256)
I0111 23:16:58.857997 48059 net.cpp:137] Memory required for data: 154141696
I0111 23:16:58.858033 48059 layer_factory.hpp:78] Creating layer label_data_1_split
I0111 23:16:58.858093 48059 net.cpp:84] Creating Layer label_data_1_split
I0111 23:16:58.858121 48059 net.cpp:406] label_data_1_split <- label
I0111 23:16:58.858181 48059 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0111 23:16:58.858218 48059 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0111 23:16:58.858260 48059 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0111 23:16:58.858350 48059 net.cpp:122] Setting up label_data_1_split
I0111 23:16:58.858364 48059 net.cpp:129] Top shape: 256 (256)
I0111 23:16:58.858376 48059 net.cpp:129] Top shape: 256 (256)
I0111 23:16:58.858381 48059 net.cpp:129] Top shape: 256 (256)
I0111 23:16:58.858384 48059 net.cpp:137] Memory required for data: 154144768
I0111 23:16:58.858391 48059 layer_factory.hpp:78] Creating layer conv1
I0111 23:16:58.858467 48059 net.cpp:84] Creating Layer conv1
I0111 23:16:58.858477 48059 net.cpp:406] conv1 <- data
I0111 23:16:58.858496 48059 net.cpp:380] conv1 -> conv1
I0111 23:17:01.087648 48059 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 127416
I0111 23:17:01.088189 48059 net.cpp:122] Setting up conv1
I0111 23:17:01.088227 48059 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0111 23:17:01.088237 48059 net.cpp:137] Memory required for data: 451514368
I0111 23:17:01.088371 48059 layer_factory.hpp:78] Creating layer bn1
I0111 23:17:01.088434 48059 net.cpp:84] Creating Layer bn1
I0111 23:17:01.088452 48059 net.cpp:406] bn1 <- conv1
I0111 23:17:01.088491 48059 net.cpp:367] bn1 -> conv1 (in-place)
I0111 23:17:01.090636 48059 net.cpp:122] Setting up bn1
I0111 23:17:01.090659 48059 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0111 23:17:01.090665 48059 net.cpp:137] Memory required for data: 748883968
I0111 23:17:01.090731 48059 layer_factory.hpp:78] Creating layer scale1
I0111 23:17:01.090786 48059 net.cpp:84] Creating Layer scale1
I0111 23:17:01.090800 48059 net.cpp:406] scale1 <- conv1
I0111 23:17:01.090822 48059 net.cpp:367] scale1 -> conv1 (in-place)
I0111 23:17:01.090951 48059 layer_factory.hpp:78] Creating layer scale1
I0111 23:17:01.091269 48059 net.cpp:122] Setting up scale1
I0111 23:17:01.091289 48059 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0111 23:17:01.091293 48059 net.cpp:137] Memory required for data: 1046253568
I0111 23:17:01.091328 48059 layer_factory.hpp:78] Creating layer relu1
I0111 23:17:01.091378 48059 net.cpp:84] Creating Layer relu1
I0111 23:17:01.091392 48059 net.cpp:406] relu1 <- conv1
I0111 23:17:01.091413 48059 net.cpp:367] relu1 -> conv1 (in-place)
I0111 23:17:01.092272 48059 net.cpp:122] Setting up relu1
I0111 23:17:01.092291 48059 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0111 23:17:01.092298 48059 net.cpp:137] Memory required for data: 1343623168
I0111 23:17:01.092308 48059 layer_factory.hpp:78] Creating layer pool1
I0111 23:17:01.092355 48059 net.cpp:84] Creating Layer pool1
I0111 23:17:01.092366 48059 net.cpp:406] pool1 <- conv1
I0111 23:17:01.092392 48059 net.cpp:380] pool1 -> pool1
I0111 23:17:01.092522 48059 net.cpp:122] Setting up pool1
I0111 23:17:01.092542 48059 net.cpp:129] Top shape: 256 96 27 27 (17915904)
I0111 23:17:01.092550 48059 net.cpp:137] Memory required for data: 1415286784
I0111 23:17:01.092558 48059 layer_factory.hpp:78] Creating layer conv2
I0111 23:17:01.092614 48059 net.cpp:84] Creating Layer conv2
I0111 23:17:01.092628 48059 net.cpp:406] conv2 <- pool1
I0111 23:17:01.092655 48059 net.cpp:380] conv2 -> conv2
I0111 23:17:01.165690 48059 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 19668
I0111 23:17:01.165729 48059 net.cpp:122] Setting up conv2
I0111 23:17:01.165740 48059 net.cpp:129] Top shape: 256 256 27 27 (47775744)
I0111 23:17:01.165745 48059 net.cpp:137] Memory required for data: 1606389760
I0111 23:17:01.165760 48059 layer_factory.hpp:78] Creating layer bn2
I0111 23:17:01.165787 48059 net.cpp:84] Creating Layer bn2
I0111 23:17:01.165799 48059 net.cpp:406] bn2 <- conv2
I0111 23:17:01.165817 48059 net.cpp:367] bn2 -> conv2 (in-place)
I0111 23:17:01.167361 48059 net.cpp:122] Setting up bn2
I0111 23:17:01.167377 48059 net.cpp:129] Top shape: 256 256 27 27 (47775744)
I0111 23:17:01.167381 48059 net.cpp:137] Memory required for data: 1797492736
I0111 23:17:01.167415 48059 layer_factory.hpp:78] Creating layer scale2
I0111 23:17:01.167438 48059 net.cpp:84] Creating Layer scale2
I0111 23:17:01.167448 48059 net.cpp:406] scale2 <- conv2
I0111 23:17:01.167487 48059 net.cpp:367] scale2 -> conv2 (in-place)
I0111 23:17:01.167559 48059 layer_factory.hpp:78] Creating layer scale2
I0111 23:17:01.167747 48059 net.cpp:122] Setting up scale2
I0111 23:17:01.167760 48059 net.cpp:129] Top shape: 256 256 27 27 (47775744)
I0111 23:17:01.167763 48059 net.cpp:137] Memory required for data: 1988595712
I0111 23:17:01.167779 48059 layer_factory.hpp:78] Creating layer relu2
I0111 23:17:01.167796 48059 net.cpp:84] Creating Layer relu2
I0111 23:17:01.167804 48059 net.cpp:406] relu2 <- conv2
I0111 23:17:01.167819 48059 net.cpp:367] relu2 -> conv2 (in-place)
I0111 23:17:01.168450 48059 net.cpp:122] Setting up relu2
I0111 23:17:01.168463 48059 net.cpp:129] Top shape: 256 256 27 27 (47775744)
I0111 23:17:01.168478 48059 net.cpp:137] Memory required for data: 2179698688
I0111 23:17:01.168484 48059 layer_factory.hpp:78] Creating layer pool2
I0111 23:17:01.168503 48059 net.cpp:84] Creating Layer pool2
I0111 23:17:01.168512 48059 net.cpp:406] pool2 <- conv2
I0111 23:17:01.168529 48059 net.cpp:380] pool2 -> pool2
I0111 23:17:01.168604 48059 net.cpp:122] Setting up pool2
I0111 23:17:01.168618 48059 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0111 23:17:01.168622 48059 net.cpp:137] Memory required for data: 2224001024
I0111 23:17:01.168628 48059 layer_factory.hpp:78] Creating layer conv3
I0111 23:17:01.168656 48059 net.cpp:84] Creating Layer conv3
I0111 23:17:01.168666 48059 net.cpp:406] conv3 <- pool2
I0111 23:17:01.168684 48059 net.cpp:380] conv3 -> conv3
I0111 23:17:01.275627 48059 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 18874368
I0111 23:17:01.276129 48059 net.cpp:122] Setting up conv3
I0111 23:17:01.276165 48059 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0111 23:17:01.276172 48059 net.cpp:137] Memory required for data: 2290454528
I0111 23:17:01.276219 48059 layer_factory.hpp:78] Creating layer bn3
I0111 23:17:01.276278 48059 net.cpp:84] Creating Layer bn3
I0111 23:17:01.276304 48059 net.cpp:406] bn3 <- conv3
I0111 23:17:01.276352 48059 net.cpp:367] bn3 -> conv3 (in-place)
I0111 23:17:01.276769 48059 net.cpp:122] Setting up bn3
I0111 23:17:01.276788 48059 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0111 23:17:01.276794 48059 net.cpp:137] Memory required for data: 2356908032
I0111 23:17:01.276839 48059 layer_factory.hpp:78] Creating layer scale3
I0111 23:17:01.276873 48059 net.cpp:84] Creating Layer scale3
I0111 23:17:01.276886 48059 net.cpp:406] scale3 <- conv3
I0111 23:17:01.276914 48059 net.cpp:367] scale3 -> conv3 (in-place)
I0111 23:17:01.277016 48059 layer_factory.hpp:78] Creating layer scale3
I0111 23:17:01.277302 48059 net.cpp:122] Setting up scale3
I0111 23:17:01.277321 48059 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0111 23:17:01.277329 48059 net.cpp:137] Memory required for data: 2423361536
I0111 23:17:01.277379 48059 layer_factory.hpp:78] Creating layer relu3
I0111 23:17:01.277408 48059 net.cpp:84] Creating Layer relu3
I0111 23:17:01.277420 48059 net.cpp:406] relu3 <- conv3
I0111 23:17:01.277447 48059 net.cpp:367] relu3 -> conv3 (in-place)
I0111 23:17:01.278841 48059 net.cpp:122] Setting up relu3
I0111 23:17:01.278868 48059 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0111 23:17:01.278874 48059 net.cpp:137] Memory required for data: 2489815040
I0111 23:17:01.278885 48059 layer_factory.hpp:78] Creating layer conv4
I0111 23:17:01.278935 48059 net.cpp:84] Creating Layer conv4
I0111 23:17:01.278951 48059 net.cpp:406] conv4 <- conv3
I0111 23:17:01.278988 48059 net.cpp:380] conv4 -> conv4
I0111 23:17:01.435250 48059 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 9840
I0111 23:17:01.435302 48059 net.cpp:122] Setting up conv4
I0111 23:17:01.435325 48059 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0111 23:17:01.435329 48059 net.cpp:137] Memory required for data: 2556268544
I0111 23:17:01.435367 48059 layer_factory.hpp:78] Creating layer bn4
I0111 23:17:01.435415 48059 net.cpp:84] Creating Layer bn4
I0111 23:17:01.435433 48059 net.cpp:406] bn4 <- conv4
I0111 23:17:01.435461 48059 net.cpp:367] bn4 -> conv4 (in-place)
I0111 23:17:01.435783 48059 net.cpp:122] Setting up bn4
I0111 23:17:01.435797 48059 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0111 23:17:01.435801 48059 net.cpp:137] Memory required for data: 2622722048
I0111 23:17:01.435835 48059 layer_factory.hpp:78] Creating layer scale4
I0111 23:17:01.435861 48059 net.cpp:84] Creating Layer scale4
I0111 23:17:01.435870 48059 net.cpp:406] scale4 <- conv4
I0111 23:17:01.435887 48059 net.cpp:367] scale4 -> conv4 (in-place)
I0111 23:17:01.435968 48059 layer_factory.hpp:78] Creating layer scale4
I0111 23:17:01.436173 48059 net.cpp:122] Setting up scale4
I0111 23:17:01.436187 48059 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0111 23:17:01.436192 48059 net.cpp:137] Memory required for data: 2689175552
I0111 23:17:01.436208 48059 layer_factory.hpp:78] Creating layer relu4
I0111 23:17:01.436226 48059 net.cpp:84] Creating Layer relu4
I0111 23:17:01.436239 48059 net.cpp:406] relu4 <- conv4
I0111 23:17:01.436261 48059 net.cpp:367] relu4 -> conv4 (in-place)
I0111 23:17:01.441735 48059 net.cpp:122] Setting up relu4
I0111 23:17:01.441757 48059 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0111 23:17:01.441762 48059 net.cpp:137] Memory required for data: 2755629056
I0111 23:17:01.441771 48059 layer_factory.hpp:78] Creating layer conv5
I0111 23:17:01.441821 48059 net.cpp:84] Creating Layer conv5
I0111 23:17:01.441834 48059 net.cpp:406] conv5 <- conv4
I0111 23:17:01.441861 48059 net.cpp:380] conv5 -> conv5
I0111 23:17:01.546823 48059 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 18874368
I0111 23:17:01.547207 48059 net.cpp:122] Setting up conv5
I0111 23:17:01.547240 48059 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0111 23:17:01.547300 48059 net.cpp:137] Memory required for data: 2799931392
I0111 23:17:01.547348 48059 layer_factory.hpp:78] Creating layer bn5
I0111 23:17:01.547403 48059 net.cpp:84] Creating Layer bn5
I0111 23:17:01.547427 48059 net.cpp:406] bn5 <- conv5
I0111 23:17:01.547482 48059 net.cpp:367] bn5 -> conv5 (in-place)
I0111 23:17:01.547791 48059 net.cpp:122] Setting up bn5
I0111 23:17:01.547806 48059 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0111 23:17:01.547813 48059 net.cpp:137] Memory required for data: 2844233728
I0111 23:17:01.547853 48059 layer_factory.hpp:78] Creating layer scale5
I0111 23:17:01.547888 48059 net.cpp:84] Creating Layer scale5
I0111 23:17:01.547901 48059 net.cpp:406] scale5 <- conv5
I0111 23:17:01.547927 48059 net.cpp:367] scale5 -> conv5 (in-place)
I0111 23:17:01.548015 48059 layer_factory.hpp:78] Creating layer scale5
I0111 23:17:01.548224 48059 net.cpp:122] Setting up scale5
I0111 23:17:01.548241 48059 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0111 23:17:01.548249 48059 net.cpp:137] Memory required for data: 2888536064
I0111 23:17:01.548274 48059 layer_factory.hpp:78] Creating layer relu5
I0111 23:17:01.548296 48059 net.cpp:84] Creating Layer relu5
I0111 23:17:01.548308 48059 net.cpp:406] relu5 <- conv5
I0111 23:17:01.548337 48059 net.cpp:367] relu5 -> conv5 (in-place)
I0111 23:17:01.549105 48059 net.cpp:122] Setting up relu5
I0111 23:17:01.549124 48059 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0111 23:17:01.549130 48059 net.cpp:137] Memory required for data: 2932838400
I0111 23:17:01.549142 48059 layer_factory.hpp:78] Creating layer pool5
I0111 23:17:01.549194 48059 net.cpp:84] Creating Layer pool5
I0111 23:17:01.549208 48059 net.cpp:406] pool5 <- conv5
I0111 23:17:01.549239 48059 net.cpp:380] pool5 -> pool5
I0111 23:17:01.549345 48059 net.cpp:122] Setting up pool5
I0111 23:17:01.549365 48059 net.cpp:129] Top shape: 256 256 6 6 (2359296)
I0111 23:17:01.549391 48059 net.cpp:137] Memory required for data: 2942275584
I0111 23:17:01.549402 48059 layer_factory.hpp:78] Creating layer fc6
I0111 23:17:01.549479 48059 net.cpp:84] Creating Layer fc6
I0111 23:17:01.549494 48059 net.cpp:406] fc6 <- pool5
I0111 23:17:01.549527 48059 net.cpp:380] fc6 -> fc6
I0111 23:17:05.085992 48059 net.cpp:122] Setting up fc6
I0111 23:17:05.086055 48059 net.cpp:129] Top shape: 256 4096 (1048576)
I0111 23:17:05.086091 48059 net.cpp:137] Memory required for data: 2946469888
I0111 23:17:05.086153 48059 layer_factory.hpp:78] Creating layer bn6
I0111 23:17:05.086203 48059 net.cpp:84] Creating Layer bn6
I0111 23:17:05.086225 48059 net.cpp:406] bn6 <- fc6
I0111 23:17:05.086253 48059 net.cpp:367] bn6 -> fc6 (in-place)
I0111 23:17:05.086535 48059 net.cpp:122] Setting up bn6
I0111 23:17:05.086552 48059 net.cpp:129] Top shape: 256 4096 (1048576)
I0111 23:17:05.086555 48059 net.cpp:137] Memory required for data: 2950664192
I0111 23:17:05.086596 48059 layer_factory.hpp:78] Creating layer scale6
I0111 23:17:05.086632 48059 net.cpp:84] Creating Layer scale6
I0111 23:17:05.086650 48059 net.cpp:406] scale6 <- fc6
I0111 23:17:05.086664 48059 net.cpp:367] scale6 -> fc6 (in-place)
I0111 23:17:05.086750 48059 layer_factory.hpp:78] Creating layer scale6
I0111 23:17:05.086951 48059 net.cpp:122] Setting up scale6
I0111 23:17:05.086964 48059 net.cpp:129] Top shape: 256 4096 (1048576)
I0111 23:17:05.086967 48059 net.cpp:137] Memory required for data: 2954858496
I0111 23:17:05.086982 48059 layer_factory.hpp:78] Creating layer relu6
I0111 23:17:05.087000 48059 net.cpp:84] Creating Layer relu6
I0111 23:17:05.087010 48059 net.cpp:406] relu6 <- fc6
I0111 23:17:05.087023 48059 net.cpp:367] relu6 -> fc6 (in-place)
I0111 23:17:05.088604 48059 net.cpp:122] Setting up relu6
I0111 23:17:05.088626 48059 net.cpp:129] Top shape: 256 4096 (1048576)
I0111 23:17:05.088630 48059 net.cpp:137] Memory required for data: 2959052800
I0111 23:17:05.088637 48059 layer_factory.hpp:78] Creating layer drop6
I0111 23:17:05.088676 48059 net.cpp:84] Creating Layer drop6
I0111 23:17:05.088694 48059 net.cpp:406] drop6 <- fc6
I0111 23:17:05.088711 48059 net.cpp:367] drop6 -> fc6 (in-place)
I0111 23:17:05.088774 48059 net.cpp:122] Setting up drop6
I0111 23:17:05.088789 48059 net.cpp:129] Top shape: 256 4096 (1048576)
I0111 23:17:05.088793 48059 net.cpp:137] Memory required for data: 2963247104
I0111 23:17:05.088798 48059 layer_factory.hpp:78] Creating layer fc7
I0111 23:17:05.088831 48059 net.cpp:84] Creating Layer fc7
I0111 23:17:05.088841 48059 net.cpp:406] fc7 <- fc6
I0111 23:17:05.088874 48059 net.cpp:380] fc7 -> fc7
I0111 23:17:06.860328 48059 net.cpp:122] Setting up fc7
I0111 23:17:06.860391 48059 net.cpp:129] Top shape: 256 4096 (1048576)
I0111 23:17:06.860396 48059 net.cpp:137] Memory required for data: 2967441408
I0111 23:17:06.860440 48059 layer_factory.hpp:78] Creating layer bn7
I0111 23:17:06.860482 48059 net.cpp:84] Creating Layer bn7
I0111 23:17:06.860498 48059 net.cpp:406] bn7 <- fc7
I0111 23:17:06.860522 48059 net.cpp:367] bn7 -> fc7 (in-place)
I0111 23:17:06.860816 48059 net.cpp:122] Setting up bn7
I0111 23:17:06.860827 48059 net.cpp:129] Top shape: 256 4096 (1048576)
I0111 23:17:06.860831 48059 net.cpp:137] Memory required for data: 2971635712
I0111 23:17:06.860855 48059 layer_factory.hpp:78] Creating layer scale7
I0111 23:17:06.860890 48059 net.cpp:84] Creating Layer scale7
I0111 23:17:06.860899 48059 net.cpp:406] scale7 <- fc7
I0111 23:17:06.860914 48059 net.cpp:367] scale7 -> fc7 (in-place)
I0111 23:17:06.860998 48059 layer_factory.hpp:78] Creating layer scale7
I0111 23:17:06.861188 48059 net.cpp:122] Setting up scale7
I0111 23:17:06.861201 48059 net.cpp:129] Top shape: 256 4096 (1048576)
I0111 23:17:06.861205 48059 net.cpp:137] Memory required for data: 2975830016
I0111 23:17:06.861220 48059 layer_factory.hpp:78] Creating layer relu7
I0111 23:17:06.861235 48059 net.cpp:84] Creating Layer relu7
I0111 23:17:06.861243 48059 net.cpp:406] relu7 <- fc7
I0111 23:17:06.861258 48059 net.cpp:367] relu7 -> fc7 (in-place)
I0111 23:17:06.862401 48059 net.cpp:122] Setting up relu7
I0111 23:17:06.862416 48059 net.cpp:129] Top shape: 256 4096 (1048576)
I0111 23:17:06.862419 48059 net.cpp:137] Memory required for data: 2980024320
I0111 23:17:06.862426 48059 layer_factory.hpp:78] Creating layer drop7
I0111 23:17:06.862458 48059 net.cpp:84] Creating Layer drop7
I0111 23:17:06.862468 48059 net.cpp:406] drop7 <- fc7
I0111 23:17:06.862488 48059 net.cpp:367] drop7 -> fc7 (in-place)
I0111 23:17:06.862560 48059 net.cpp:122] Setting up drop7
I0111 23:17:06.862571 48059 net.cpp:129] Top shape: 256 4096 (1048576)
I0111 23:17:06.862573 48059 net.cpp:137] Memory required for data: 2984218624
I0111 23:17:06.862579 48059 layer_factory.hpp:78] Creating layer fc8
I0111 23:17:06.862620 48059 net.cpp:84] Creating Layer fc8
I0111 23:17:06.862629 48059 net.cpp:406] fc8 <- fc7
I0111 23:17:06.862650 48059 net.cpp:380] fc8 -> fc8
I0111 23:17:07.239070 48059 net.cpp:122] Setting up fc8
I0111 23:17:07.239126 48059 net.cpp:129] Top shape: 256 1000 (256000)
I0111 23:17:07.239135 48059 net.cpp:137] Memory required for data: 2985242624
I0111 23:17:07.239168 48059 layer_factory.hpp:78] Creating layer fc8_fc8_0_split
I0111 23:17:07.239208 48059 net.cpp:84] Creating Layer fc8_fc8_0_split
I0111 23:17:07.239223 48059 net.cpp:406] fc8_fc8_0_split <- fc8
I0111 23:17:07.239248 48059 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0111 23:17:07.239286 48059 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0111 23:17:07.239302 48059 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0111 23:17:07.239382 48059 net.cpp:122] Setting up fc8_fc8_0_split
I0111 23:17:07.239397 48059 net.cpp:129] Top shape: 256 1000 (256000)
I0111 23:17:07.239403 48059 net.cpp:129] Top shape: 256 1000 (256000)
I0111 23:17:07.239408 48059 net.cpp:129] Top shape: 256 1000 (256000)
I0111 23:17:07.239410 48059 net.cpp:137] Memory required for data: 2988314624
I0111 23:17:07.239416 48059 layer_factory.hpp:78] Creating layer loss
I0111 23:17:07.239460 48059 net.cpp:84] Creating Layer loss
I0111 23:17:07.239470 48059 net.cpp:406] loss <- fc8_fc8_0_split_0
I0111 23:17:07.239483 48059 net.cpp:406] loss <- label_data_1_split_0
I0111 23:17:07.239496 48059 net.cpp:380] loss -> loss
I0111 23:17:07.239531 48059 layer_factory.hpp:78] Creating layer loss
I0111 23:17:07.242594 48059 net.cpp:122] Setting up loss
I0111 23:17:07.242611 48059 net.cpp:129] Top shape: (1)
I0111 23:17:07.242615 48059 net.cpp:132]     with loss weight 1
I0111 23:17:07.242740 48059 net.cpp:137] Memory required for data: 2988314628
I0111 23:17:07.242751 48059 layer_factory.hpp:78] Creating layer accuracy
I0111 23:17:07.242776 48059 net.cpp:84] Creating Layer accuracy
I0111 23:17:07.242785 48059 net.cpp:406] accuracy <- fc8_fc8_0_split_1
I0111 23:17:07.242805 48059 net.cpp:406] accuracy <- label_data_1_split_1
I0111 23:17:07.242817 48059 net.cpp:380] accuracy -> accuracy
I0111 23:17:07.242854 48059 net.cpp:122] Setting up accuracy
I0111 23:17:07.242867 48059 net.cpp:129] Top shape: (1)
I0111 23:17:07.242871 48059 net.cpp:137] Memory required for data: 2988314632
I0111 23:17:07.242877 48059 layer_factory.hpp:78] Creating layer accuracy_5
I0111 23:17:07.242893 48059 net.cpp:84] Creating Layer accuracy_5
I0111 23:17:07.242902 48059 net.cpp:406] accuracy_5 <- fc8_fc8_0_split_2
I0111 23:17:07.242918 48059 net.cpp:406] accuracy_5 <- label_data_1_split_2
I0111 23:17:07.242936 48059 net.cpp:380] accuracy_5 -> accuracy_5
I0111 23:17:07.242978 48059 net.cpp:122] Setting up accuracy_5
I0111 23:17:07.242992 48059 net.cpp:129] Top shape: (1)
I0111 23:17:07.242998 48059 net.cpp:137] Memory required for data: 2988314636
I0111 23:17:07.243010 48059 net.cpp:200] accuracy_5 does not need backward computation.
I0111 23:17:07.243019 48059 net.cpp:200] accuracy does not need backward computation.
I0111 23:17:07.243027 48059 net.cpp:198] loss needs backward computation.
I0111 23:17:07.243032 48059 net.cpp:198] fc8_fc8_0_split needs backward computation.
I0111 23:17:07.243037 48059 net.cpp:198] fc8 needs backward computation.
I0111 23:17:07.243041 48059 net.cpp:198] drop7 needs backward computation.
I0111 23:17:07.243047 48059 net.cpp:198] relu7 needs backward computation.
I0111 23:17:07.243052 48059 net.cpp:198] scale7 needs backward computation.
I0111 23:17:07.243057 48059 net.cpp:198] bn7 needs backward computation.
I0111 23:17:07.243060 48059 net.cpp:198] fc7 needs backward computation.
I0111 23:17:07.243065 48059 net.cpp:198] drop6 needs backward computation.
I0111 23:17:07.243075 48059 net.cpp:198] relu6 needs backward computation.
I0111 23:17:07.243100 48059 net.cpp:198] scale6 needs backward computation.
I0111 23:17:07.243105 48059 net.cpp:198] bn6 needs backward computation.
I0111 23:17:07.243109 48059 net.cpp:198] fc6 needs backward computation.
I0111 23:17:07.243115 48059 net.cpp:198] pool5 needs backward computation.
I0111 23:17:07.243121 48059 net.cpp:198] relu5 needs backward computation.
I0111 23:17:07.243127 48059 net.cpp:198] scale5 needs backward computation.
I0111 23:17:07.243132 48059 net.cpp:198] bn5 needs backward computation.
I0111 23:17:07.243139 48059 net.cpp:198] conv5 needs backward computation.
I0111 23:17:07.243144 48059 net.cpp:198] relu4 needs backward computation.
I0111 23:17:07.243149 48059 net.cpp:198] scale4 needs backward computation.
I0111 23:17:07.243154 48059 net.cpp:198] bn4 needs backward computation.
I0111 23:17:07.243158 48059 net.cpp:198] conv4 needs backward computation.
I0111 23:17:07.243170 48059 net.cpp:198] relu3 needs backward computation.
I0111 23:17:07.243176 48059 net.cpp:198] scale3 needs backward computation.
I0111 23:17:07.243180 48059 net.cpp:198] bn3 needs backward computation.
I0111 23:17:07.243185 48059 net.cpp:198] conv3 needs backward computation.
I0111 23:17:07.243191 48059 net.cpp:198] pool2 needs backward computation.
I0111 23:17:07.243196 48059 net.cpp:198] relu2 needs backward computation.
I0111 23:17:07.243201 48059 net.cpp:198] scale2 needs backward computation.
I0111 23:17:07.243206 48059 net.cpp:198] bn2 needs backward computation.
I0111 23:17:07.243209 48059 net.cpp:198] conv2 needs backward computation.
I0111 23:17:07.243213 48059 net.cpp:198] pool1 needs backward computation.
I0111 23:17:07.243218 48059 net.cpp:198] relu1 needs backward computation.
I0111 23:17:07.243223 48059 net.cpp:198] scale1 needs backward computation.
I0111 23:17:07.243228 48059 net.cpp:198] bn1 needs backward computation.
I0111 23:17:07.243242 48059 net.cpp:198] conv1 needs backward computation.
I0111 23:17:07.243250 48059 net.cpp:200] label_data_1_split does not need backward computation.
I0111 23:17:07.243257 48059 net.cpp:200] data does not need backward computation.
I0111 23:17:07.243273 48059 net.cpp:242] This network produces output accuracy
I0111 23:17:07.243280 48059 net.cpp:242] This network produces output accuracy_5
I0111 23:17:07.243286 48059 net.cpp:242] This network produces output loss
I0111 23:17:07.243343 48059 net.cpp:255] Network initialization done.
I0111 23:17:07.243733 48059 solver.cpp:75] Finetuning from snapshot/solver_iter_260000.caffemodel
I0111 23:17:15.287303 48059 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: snapshot/solver_iter_260000.caffemodel
I0111 23:17:15.287384 48059 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0111 23:17:15.287400 48059 net.cpp:824] Copying source layer data
I0111 23:17:15.287410 48059 net.cpp:824] Copying source layer label_data_1_split
I0111 23:17:15.287416 48059 net.cpp:824] Copying source layer conv1
I0111 23:17:15.288250 48059 net.cpp:824] Copying source layer bn1
I0111 23:17:15.288470 48059 net.cpp:824] Copying source layer scale1
I0111 23:17:15.288519 48059 net.cpp:824] Copying source layer relu1
I0111 23:17:15.288527 48059 net.cpp:824] Copying source layer pool1
I0111 23:17:15.288530 48059 net.cpp:824] Copying source layer conv2
I0111 23:17:15.298877 48059 net.cpp:824] Copying source layer bn2
I0111 23:17:15.298980 48059 net.cpp:824] Copying source layer scale2
I0111 23:17:15.299034 48059 net.cpp:824] Copying source layer relu2
I0111 23:17:15.299041 48059 net.cpp:824] Copying source layer pool2
I0111 23:17:15.299046 48059 net.cpp:824] Copying source layer conv3
I0111 23:17:15.313344 48059 net.cpp:824] Copying source layer bn3
I0111 23:17:15.313509 48059 net.cpp:824] Copying source layer scale3
I0111 23:17:15.313556 48059 net.cpp:824] Copying source layer relu3
I0111 23:17:15.313565 48059 net.cpp:824] Copying source layer conv4
I0111 23:17:15.336032 48059 net.cpp:824] Copying source layer bn4
I0111 23:17:15.336175 48059 net.cpp:824] Copying source layer scale4
I0111 23:17:15.336247 48059 net.cpp:824] Copying source layer relu4
I0111 23:17:15.336256 48059 net.cpp:824] Copying source layer conv5
I0111 23:17:15.364998 48059 net.cpp:824] Copying source layer bn5
I0111 23:17:15.365325 48059 net.cpp:824] Copying source layer scale5
I0111 23:17:15.365430 48059 net.cpp:824] Copying source layer relu5
I0111 23:17:15.365442 48059 net.cpp:824] Copying source layer pool5
I0111 23:17:15.365450 48059 net.cpp:824] Copying source layer fc6
I0111 23:17:16.086028 48059 net.cpp:824] Copying source layer bn6
I0111 23:17:16.086369 48059 net.cpp:824] Copying source layer scale6
I0111 23:17:16.086535 48059 net.cpp:824] Copying source layer relu6
I0111 23:17:16.086549 48059 net.cpp:824] Copying source layer drop6
I0111 23:17:16.086560 48059 net.cpp:824] Copying source layer fc7
I0111 23:17:16.345110 48059 net.cpp:824] Copying source layer bn7
I0111 23:17:16.345471 48059 net.cpp:824] Copying source layer scale7
I0111 23:17:16.345628 48059 net.cpp:824] Copying source layer relu7
I0111 23:17:16.345635 48059 net.cpp:824] Copying source layer drop7
I0111 23:17:16.345639 48059 net.cpp:824] Copying source layer fc8
I0111 23:17:16.407886 48059 net.cpp:824] Copying source layer fc8_fc8_0_split
I0111 23:17:16.407938 48059 net.cpp:824] Copying source layer loss
I0111 23:17:16.407958 48059 net.cpp:824] Copying source layer accuracy
I0111 23:17:16.407963 48059 net.cpp:824] Copying source layer accuracy_5
I0111 23:17:16.436553 48059 solver.cpp:193] Creating test net (#0) specified by net file: train_test.prototxt
I0111 23:17:16.436753 48059 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0111 23:17:16.436993 48059 net.cpp:51] Initializing net from parameters: 
name: "AlexNet-BN"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 224
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/zhengzhe/Data/imagenet_shrt256/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 96
    bias_term: false
    pad: 2
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "BinaryConvolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "BinaryConvolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "BinaryConvolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "BinaryConvolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "scale5"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "BinaryInnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4096
    bias_term: false
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn6"
  type: "BatchNorm"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "scale6"
  type: "Scale"
  bottom: "fc6"
  top: "fc6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "fc7"
  type: "BinaryInnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4096
    bias_term: false
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "scale7"
  type: "Scale"
  bottom: "fc7"
  top: "fc7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "accuracy_5"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy_5"
  accuracy_param {
    top_k: 5
  }
}
I0111 23:17:16.437459 48059 layer_factory.hpp:78] Creating layer data
I0111 23:17:16.437602 48059 db_lmdb.cpp:35] Opened lmdb /home/zhengzhe/Data/imagenet_shrt256/ilsvrc12_val_lmdb
I0111 23:17:16.437639 48059 net.cpp:84] Creating Layer data
I0111 23:17:16.437656 48059 net.cpp:380] data -> data
I0111 23:17:16.437728 48059 net.cpp:380] data -> label
I0111 23:17:16.438380 48059 data_layer.cpp:45] output data size: 50,3,224,224
I0111 23:17:16.527367 48059 base_data_layer.cpp:72] Initializing prefetch
I0111 23:17:16.527530 48059 base_data_layer.cpp:75] Prefetch initialized.
I0111 23:17:16.527541 48059 net.cpp:122] Setting up data
I0111 23:17:16.527562 48059 net.cpp:129] Top shape: 50 3 224 224 (7526400)
I0111 23:17:16.527590 48059 net.cpp:129] Top shape: 50 (50)
I0111 23:17:16.527593 48059 net.cpp:137] Memory required for data: 30105800
I0111 23:17:16.527616 48059 layer_factory.hpp:78] Creating layer label_data_1_split
I0111 23:17:16.527678 48059 net.cpp:84] Creating Layer label_data_1_split
I0111 23:17:16.527691 48059 net.cpp:406] label_data_1_split <- label
I0111 23:17:16.527719 48059 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0111 23:17:16.527753 48059 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0111 23:17:16.527770 48059 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0111 23:17:16.528136 48059 net.cpp:122] Setting up label_data_1_split
I0111 23:17:16.528151 48059 net.cpp:129] Top shape: 50 (50)
I0111 23:17:16.528157 48059 net.cpp:129] Top shape: 50 (50)
I0111 23:17:16.528162 48059 net.cpp:129] Top shape: 50 (50)
I0111 23:17:16.528165 48059 net.cpp:137] Memory required for data: 30106400
I0111 23:17:16.528170 48059 layer_factory.hpp:78] Creating layer conv1
I0111 23:17:16.528210 48059 net.cpp:84] Creating Layer conv1
I0111 23:17:16.528220 48059 net.cpp:406] conv1 <- data
I0111 23:17:16.528240 48059 net.cpp:380] conv1 -> conv1
I0111 23:17:16.536571 48059 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 127416
I0111 23:17:16.536634 48059 net.cpp:122] Setting up conv1
I0111 23:17:16.536654 48059 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0111 23:17:16.536692 48059 net.cpp:137] Memory required for data: 88186400
I0111 23:17:16.536733 48059 layer_factory.hpp:78] Creating layer bn1
I0111 23:17:16.536765 48059 net.cpp:84] Creating Layer bn1
I0111 23:17:16.536778 48059 net.cpp:406] bn1 <- conv1
I0111 23:17:16.536823 48059 net.cpp:367] bn1 -> conv1 (in-place)
I0111 23:17:16.537163 48059 net.cpp:122] Setting up bn1
I0111 23:17:16.537175 48059 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0111 23:17:16.537178 48059 net.cpp:137] Memory required for data: 146266400
I0111 23:17:16.537212 48059 layer_factory.hpp:78] Creating layer scale1
I0111 23:17:16.537240 48059 net.cpp:84] Creating Layer scale1
I0111 23:17:16.537247 48059 net.cpp:406] scale1 <- conv1
I0111 23:17:16.537262 48059 net.cpp:367] scale1 -> conv1 (in-place)
I0111 23:17:16.537350 48059 layer_factory.hpp:78] Creating layer scale1
I0111 23:17:16.537576 48059 net.cpp:122] Setting up scale1
I0111 23:17:16.537590 48059 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0111 23:17:16.537592 48059 net.cpp:137] Memory required for data: 204346400
I0111 23:17:16.537617 48059 layer_factory.hpp:78] Creating layer relu1
I0111 23:17:16.537634 48059 net.cpp:84] Creating Layer relu1
I0111 23:17:16.537642 48059 net.cpp:406] relu1 <- conv1
I0111 23:17:16.537654 48059 net.cpp:367] relu1 -> conv1 (in-place)
I0111 23:17:16.538301 48059 net.cpp:122] Setting up relu1
I0111 23:17:16.538316 48059 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0111 23:17:16.538318 48059 net.cpp:137] Memory required for data: 262426400
I0111 23:17:16.538324 48059 layer_factory.hpp:78] Creating layer pool1
I0111 23:17:16.538358 48059 net.cpp:84] Creating Layer pool1
I0111 23:17:16.538373 48059 net.cpp:406] pool1 <- conv1
I0111 23:17:16.538421 48059 net.cpp:380] pool1 -> pool1
I0111 23:17:16.538514 48059 net.cpp:122] Setting up pool1
I0111 23:17:16.538530 48059 net.cpp:129] Top shape: 50 96 27 27 (3499200)
I0111 23:17:16.538535 48059 net.cpp:137] Memory required for data: 276423200
I0111 23:17:16.538561 48059 layer_factory.hpp:78] Creating layer conv2
I0111 23:17:16.538599 48059 net.cpp:84] Creating Layer conv2
I0111 23:17:16.538610 48059 net.cpp:406] conv2 <- pool1
I0111 23:17:16.538636 48059 net.cpp:380] conv2 -> conv2
I0111 23:17:16.596727 48059 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 19668
I0111 23:17:16.596781 48059 net.cpp:122] Setting up conv2
I0111 23:17:16.596802 48059 net.cpp:129] Top shape: 50 256 27 27 (9331200)
I0111 23:17:16.596840 48059 net.cpp:137] Memory required for data: 313748000
I0111 23:17:16.596889 48059 layer_factory.hpp:78] Creating layer bn2
I0111 23:17:16.596936 48059 net.cpp:84] Creating Layer bn2
I0111 23:17:16.596953 48059 net.cpp:406] bn2 <- conv2
I0111 23:17:16.597005 48059 net.cpp:367] bn2 -> conv2 (in-place)
I0111 23:17:16.597313 48059 net.cpp:122] Setting up bn2
I0111 23:17:16.597327 48059 net.cpp:129] Top shape: 50 256 27 27 (9331200)
I0111 23:17:16.597332 48059 net.cpp:137] Memory required for data: 351072800
I0111 23:17:16.597381 48059 layer_factory.hpp:78] Creating layer scale2
I0111 23:17:16.597411 48059 net.cpp:84] Creating Layer scale2
I0111 23:17:16.597421 48059 net.cpp:406] scale2 <- conv2
I0111 23:17:16.597465 48059 net.cpp:367] scale2 -> conv2 (in-place)
I0111 23:17:16.597553 48059 layer_factory.hpp:78] Creating layer scale2
I0111 23:17:16.597774 48059 net.cpp:122] Setting up scale2
I0111 23:17:16.597787 48059 net.cpp:129] Top shape: 50 256 27 27 (9331200)
I0111 23:17:16.597790 48059 net.cpp:137] Memory required for data: 388397600
I0111 23:17:16.597805 48059 layer_factory.hpp:78] Creating layer relu2
I0111 23:17:16.597822 48059 net.cpp:84] Creating Layer relu2
I0111 23:17:16.597829 48059 net.cpp:406] relu2 <- conv2
I0111 23:17:16.597842 48059 net.cpp:367] relu2 -> conv2 (in-place)
I0111 23:17:16.598853 48059 net.cpp:122] Setting up relu2
I0111 23:17:16.598870 48059 net.cpp:129] Top shape: 50 256 27 27 (9331200)
I0111 23:17:16.598876 48059 net.cpp:137] Memory required for data: 425722400
I0111 23:17:16.598886 48059 layer_factory.hpp:78] Creating layer pool2
I0111 23:17:16.598932 48059 net.cpp:84] Creating Layer pool2
I0111 23:17:16.598944 48059 net.cpp:406] pool2 <- conv2
I0111 23:17:16.598970 48059 net.cpp:380] pool2 -> pool2
I0111 23:17:16.599066 48059 net.cpp:122] Setting up pool2
I0111 23:17:16.599083 48059 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0111 23:17:16.599092 48059 net.cpp:137] Memory required for data: 434375200
I0111 23:17:16.599099 48059 layer_factory.hpp:78] Creating layer conv3
I0111 23:17:16.599131 48059 net.cpp:84] Creating Layer conv3
I0111 23:17:16.599141 48059 net.cpp:406] conv3 <- pool2
I0111 23:17:16.599169 48059 net.cpp:380] conv3 -> conv3
I0111 23:17:16.682159 48059 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 18874368
I0111 23:17:16.682601 48059 net.cpp:122] Setting up conv3
I0111 23:17:16.682636 48059 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0111 23:17:16.682646 48059 net.cpp:137] Memory required for data: 447354400
I0111 23:17:16.682678 48059 layer_factory.hpp:78] Creating layer bn3
I0111 23:17:16.682710 48059 net.cpp:84] Creating Layer bn3
I0111 23:17:16.682723 48059 net.cpp:406] bn3 <- conv3
I0111 23:17:16.682749 48059 net.cpp:367] bn3 -> conv3 (in-place)
I0111 23:17:16.683041 48059 net.cpp:122] Setting up bn3
I0111 23:17:16.683055 48059 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0111 23:17:16.683061 48059 net.cpp:137] Memory required for data: 460333600
I0111 23:17:16.683091 48059 layer_factory.hpp:78] Creating layer scale3
I0111 23:17:16.683120 48059 net.cpp:84] Creating Layer scale3
I0111 23:17:16.683130 48059 net.cpp:406] scale3 <- conv3
I0111 23:17:16.683154 48059 net.cpp:367] scale3 -> conv3 (in-place)
I0111 23:17:16.683235 48059 layer_factory.hpp:78] Creating layer scale3
I0111 23:17:16.683434 48059 net.cpp:122] Setting up scale3
I0111 23:17:16.683446 48059 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0111 23:17:16.683450 48059 net.cpp:137] Memory required for data: 473312800
I0111 23:17:16.683477 48059 layer_factory.hpp:78] Creating layer relu3
I0111 23:17:16.683495 48059 net.cpp:84] Creating Layer relu3
I0111 23:17:16.683502 48059 net.cpp:406] relu3 <- conv3
I0111 23:17:16.683516 48059 net.cpp:367] relu3 -> conv3 (in-place)
I0111 23:17:16.684461 48059 net.cpp:122] Setting up relu3
I0111 23:17:16.684478 48059 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0111 23:17:16.684482 48059 net.cpp:137] Memory required for data: 486292000
I0111 23:17:16.684489 48059 layer_factory.hpp:78] Creating layer conv4
I0111 23:17:16.684528 48059 net.cpp:84] Creating Layer conv4
I0111 23:17:16.684538 48059 net.cpp:406] conv4 <- conv3
I0111 23:17:16.684559 48059 net.cpp:380] conv4 -> conv4
I0111 23:17:16.807129 48059 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 9840
I0111 23:17:16.807238 48059 net.cpp:122] Setting up conv4
I0111 23:17:16.807293 48059 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0111 23:17:16.807319 48059 net.cpp:137] Memory required for data: 499271200
I0111 23:17:16.807379 48059 layer_factory.hpp:78] Creating layer bn4
I0111 23:17:16.807430 48059 net.cpp:84] Creating Layer bn4
I0111 23:17:16.807449 48059 net.cpp:406] bn4 <- conv4
I0111 23:17:16.807523 48059 net.cpp:367] bn4 -> conv4 (in-place)
I0111 23:17:16.807859 48059 net.cpp:122] Setting up bn4
I0111 23:17:16.807873 48059 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0111 23:17:16.807879 48059 net.cpp:137] Memory required for data: 512250400
I0111 23:17:16.807915 48059 layer_factory.hpp:78] Creating layer scale4
I0111 23:17:16.807946 48059 net.cpp:84] Creating Layer scale4
I0111 23:17:16.807958 48059 net.cpp:406] scale4 <- conv4
I0111 23:17:16.808007 48059 net.cpp:367] scale4 -> conv4 (in-place)
I0111 23:17:16.808106 48059 layer_factory.hpp:78] Creating layer scale4
I0111 23:17:16.808344 48059 net.cpp:122] Setting up scale4
I0111 23:17:16.808368 48059 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0111 23:17:16.808378 48059 net.cpp:137] Memory required for data: 525229600
I0111 23:17:16.808401 48059 layer_factory.hpp:78] Creating layer relu4
I0111 23:17:16.808424 48059 net.cpp:84] Creating Layer relu4
I0111 23:17:16.808434 48059 net.cpp:406] relu4 <- conv4
I0111 23:17:16.808471 48059 net.cpp:367] relu4 -> conv4 (in-place)
I0111 23:17:16.809193 48059 net.cpp:122] Setting up relu4
I0111 23:17:16.809209 48059 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0111 23:17:16.809214 48059 net.cpp:137] Memory required for data: 538208800
I0111 23:17:16.809223 48059 layer_factory.hpp:78] Creating layer conv5
I0111 23:17:16.809264 48059 net.cpp:84] Creating Layer conv5
I0111 23:17:16.809273 48059 net.cpp:406] conv5 <- conv4
I0111 23:17:16.809303 48059 net.cpp:380] conv5 -> conv5
I0111 23:17:16.893378 48059 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 18874368
I0111 23:17:16.893743 48059 net.cpp:122] Setting up conv5
I0111 23:17:16.893771 48059 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0111 23:17:16.893781 48059 net.cpp:137] Memory required for data: 546861600
I0111 23:17:16.893815 48059 layer_factory.hpp:78] Creating layer bn5
I0111 23:17:16.893851 48059 net.cpp:84] Creating Layer bn5
I0111 23:17:16.893868 48059 net.cpp:406] bn5 <- conv5
I0111 23:17:16.893908 48059 net.cpp:367] bn5 -> conv5 (in-place)
I0111 23:17:16.894243 48059 net.cpp:122] Setting up bn5
I0111 23:17:16.894258 48059 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0111 23:17:16.894263 48059 net.cpp:137] Memory required for data: 555514400
I0111 23:17:16.894295 48059 layer_factory.hpp:78] Creating layer scale5
I0111 23:17:16.894327 48059 net.cpp:84] Creating Layer scale5
I0111 23:17:16.894343 48059 net.cpp:406] scale5 <- conv5
I0111 23:17:16.894368 48059 net.cpp:367] scale5 -> conv5 (in-place)
I0111 23:17:16.894466 48059 layer_factory.hpp:78] Creating layer scale5
I0111 23:17:16.894698 48059 net.cpp:122] Setting up scale5
I0111 23:17:16.894714 48059 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0111 23:17:16.894719 48059 net.cpp:137] Memory required for data: 564167200
I0111 23:17:16.894742 48059 layer_factory.hpp:78] Creating layer relu5
I0111 23:17:16.894762 48059 net.cpp:84] Creating Layer relu5
I0111 23:17:16.894771 48059 net.cpp:406] relu5 <- conv5
I0111 23:17:16.894798 48059 net.cpp:367] relu5 -> conv5 (in-place)
I0111 23:17:16.895479 48059 net.cpp:122] Setting up relu5
I0111 23:17:16.895493 48059 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0111 23:17:16.895498 48059 net.cpp:137] Memory required for data: 572820000
I0111 23:17:16.895509 48059 layer_factory.hpp:78] Creating layer pool5
I0111 23:17:16.895536 48059 net.cpp:84] Creating Layer pool5
I0111 23:17:16.895546 48059 net.cpp:406] pool5 <- conv5
I0111 23:17:16.895567 48059 net.cpp:380] pool5 -> pool5
I0111 23:17:16.895650 48059 net.cpp:122] Setting up pool5
I0111 23:17:16.895663 48059 net.cpp:129] Top shape: 50 256 6 6 (460800)
I0111 23:17:16.895689 48059 net.cpp:137] Memory required for data: 574663200
I0111 23:17:16.895695 48059 layer_factory.hpp:78] Creating layer fc6
I0111 23:17:16.895720 48059 net.cpp:84] Creating Layer fc6
I0111 23:17:16.895728 48059 net.cpp:406] fc6 <- pool5
I0111 23:17:16.895746 48059 net.cpp:380] fc6 -> fc6
I0111 23:17:20.562785 48059 net.cpp:122] Setting up fc6
I0111 23:17:20.562849 48059 net.cpp:129] Top shape: 50 4096 (204800)
I0111 23:17:20.562855 48059 net.cpp:137] Memory required for data: 575482400
I0111 23:17:20.562888 48059 layer_factory.hpp:78] Creating layer bn6
I0111 23:17:20.562927 48059 net.cpp:84] Creating Layer bn6
I0111 23:17:20.562943 48059 net.cpp:406] bn6 <- fc6
I0111 23:17:20.562968 48059 net.cpp:367] bn6 -> fc6 (in-place)
I0111 23:17:20.563271 48059 net.cpp:122] Setting up bn6
I0111 23:17:20.563282 48059 net.cpp:129] Top shape: 50 4096 (204800)
I0111 23:17:20.563284 48059 net.cpp:137] Memory required for data: 576301600
I0111 23:17:20.563325 48059 layer_factory.hpp:78] Creating layer scale6
I0111 23:17:20.563360 48059 net.cpp:84] Creating Layer scale6
I0111 23:17:20.563369 48059 net.cpp:406] scale6 <- fc6
I0111 23:17:20.563385 48059 net.cpp:367] scale6 -> fc6 (in-place)
I0111 23:17:20.563486 48059 layer_factory.hpp:78] Creating layer scale6
I0111 23:17:20.563688 48059 net.cpp:122] Setting up scale6
I0111 23:17:20.563701 48059 net.cpp:129] Top shape: 50 4096 (204800)
I0111 23:17:20.563706 48059 net.cpp:137] Memory required for data: 577120800
I0111 23:17:20.563721 48059 layer_factory.hpp:78] Creating layer relu6
I0111 23:17:20.563738 48059 net.cpp:84] Creating Layer relu6
I0111 23:17:20.563745 48059 net.cpp:406] relu6 <- fc6
I0111 23:17:20.563758 48059 net.cpp:367] relu6 -> fc6 (in-place)
I0111 23:17:20.565101 48059 net.cpp:122] Setting up relu6
I0111 23:17:20.565116 48059 net.cpp:129] Top shape: 50 4096 (204800)
I0111 23:17:20.565119 48059 net.cpp:137] Memory required for data: 577940000
I0111 23:17:20.565126 48059 layer_factory.hpp:78] Creating layer drop6
I0111 23:17:20.565145 48059 net.cpp:84] Creating Layer drop6
I0111 23:17:20.565152 48059 net.cpp:406] drop6 <- fc6
I0111 23:17:20.565168 48059 net.cpp:367] drop6 -> fc6 (in-place)
I0111 23:17:20.565217 48059 net.cpp:122] Setting up drop6
I0111 23:17:20.565227 48059 net.cpp:129] Top shape: 50 4096 (204800)
I0111 23:17:20.565230 48059 net.cpp:137] Memory required for data: 578759200
I0111 23:17:20.565237 48059 layer_factory.hpp:78] Creating layer fc7
I0111 23:17:20.565259 48059 net.cpp:84] Creating Layer fc7
I0111 23:17:20.565266 48059 net.cpp:406] fc7 <- fc6
I0111 23:17:20.565285 48059 net.cpp:380] fc7 -> fc7
I0111 23:17:22.163189 48059 net.cpp:122] Setting up fc7
I0111 23:17:22.163234 48059 net.cpp:129] Top shape: 50 4096 (204800)
I0111 23:17:22.163239 48059 net.cpp:137] Memory required for data: 579578400
I0111 23:17:22.163269 48059 layer_factory.hpp:78] Creating layer bn7
I0111 23:17:22.163316 48059 net.cpp:84] Creating Layer bn7
I0111 23:17:22.163331 48059 net.cpp:406] bn7 <- fc7
I0111 23:17:22.163365 48059 net.cpp:367] bn7 -> fc7 (in-place)
I0111 23:17:22.163671 48059 net.cpp:122] Setting up bn7
I0111 23:17:22.163683 48059 net.cpp:129] Top shape: 50 4096 (204800)
I0111 23:17:22.163689 48059 net.cpp:137] Memory required for data: 580397600
I0111 23:17:22.163718 48059 layer_factory.hpp:78] Creating layer scale7
I0111 23:17:22.163777 48059 net.cpp:84] Creating Layer scale7
I0111 23:17:22.163787 48059 net.cpp:406] scale7 <- fc7
I0111 23:17:22.163805 48059 net.cpp:367] scale7 -> fc7 (in-place)
I0111 23:17:22.163904 48059 layer_factory.hpp:78] Creating layer scale7
I0111 23:17:22.164104 48059 net.cpp:122] Setting up scale7
I0111 23:17:22.164116 48059 net.cpp:129] Top shape: 50 4096 (204800)
I0111 23:17:22.164121 48059 net.cpp:137] Memory required for data: 581216800
I0111 23:17:22.164136 48059 layer_factory.hpp:78] Creating layer relu7
I0111 23:17:22.164155 48059 net.cpp:84] Creating Layer relu7
I0111 23:17:22.164162 48059 net.cpp:406] relu7 <- fc7
I0111 23:17:22.164177 48059 net.cpp:367] relu7 -> fc7 (in-place)
I0111 23:17:22.165374 48059 net.cpp:122] Setting up relu7
I0111 23:17:22.165410 48059 net.cpp:129] Top shape: 50 4096 (204800)
I0111 23:17:22.165415 48059 net.cpp:137] Memory required for data: 582036000
I0111 23:17:22.165422 48059 layer_factory.hpp:78] Creating layer drop7
I0111 23:17:22.165441 48059 net.cpp:84] Creating Layer drop7
I0111 23:17:22.165449 48059 net.cpp:406] drop7 <- fc7
I0111 23:17:22.165467 48059 net.cpp:367] drop7 -> fc7 (in-place)
I0111 23:17:22.165518 48059 net.cpp:122] Setting up drop7
I0111 23:17:22.165529 48059 net.cpp:129] Top shape: 50 4096 (204800)
I0111 23:17:22.165531 48059 net.cpp:137] Memory required for data: 582855200
I0111 23:17:22.165537 48059 layer_factory.hpp:78] Creating layer fc8
I0111 23:17:22.165557 48059 net.cpp:84] Creating Layer fc8
I0111 23:17:22.165565 48059 net.cpp:406] fc8 <- fc7
I0111 23:17:22.165580 48059 net.cpp:380] fc8 -> fc8
I0111 23:17:22.543117 48059 net.cpp:122] Setting up fc8
I0111 23:17:22.543157 48059 net.cpp:129] Top shape: 50 1000 (50000)
I0111 23:17:22.543162 48059 net.cpp:137] Memory required for data: 583055200
I0111 23:17:22.543193 48059 layer_factory.hpp:78] Creating layer fc8_fc8_0_split
I0111 23:17:22.543227 48059 net.cpp:84] Creating Layer fc8_fc8_0_split
I0111 23:17:22.543241 48059 net.cpp:406] fc8_fc8_0_split <- fc8
I0111 23:17:22.543265 48059 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0111 23:17:22.543298 48059 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0111 23:17:22.543313 48059 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0111 23:17:22.543409 48059 net.cpp:122] Setting up fc8_fc8_0_split
I0111 23:17:22.543423 48059 net.cpp:129] Top shape: 50 1000 (50000)
I0111 23:17:22.543431 48059 net.cpp:129] Top shape: 50 1000 (50000)
I0111 23:17:22.543434 48059 net.cpp:129] Top shape: 50 1000 (50000)
I0111 23:17:22.543437 48059 net.cpp:137] Memory required for data: 583655200
I0111 23:17:22.543443 48059 layer_factory.hpp:78] Creating layer loss
I0111 23:17:22.543462 48059 net.cpp:84] Creating Layer loss
I0111 23:17:22.543467 48059 net.cpp:406] loss <- fc8_fc8_0_split_0
I0111 23:17:22.543480 48059 net.cpp:406] loss <- label_data_1_split_0
I0111 23:17:22.543491 48059 net.cpp:380] loss -> loss
I0111 23:17:22.543514 48059 layer_factory.hpp:78] Creating layer loss
I0111 23:17:22.544579 48059 net.cpp:122] Setting up loss
I0111 23:17:22.544595 48059 net.cpp:129] Top shape: (1)
I0111 23:17:22.544597 48059 net.cpp:132]     with loss weight 1
I0111 23:17:22.544608 48059 net.cpp:137] Memory required for data: 583655204
I0111 23:17:22.544615 48059 layer_factory.hpp:78] Creating layer accuracy
I0111 23:17:22.544629 48059 net.cpp:84] Creating Layer accuracy
I0111 23:17:22.544636 48059 net.cpp:406] accuracy <- fc8_fc8_0_split_1
I0111 23:17:22.544649 48059 net.cpp:406] accuracy <- label_data_1_split_1
I0111 23:17:22.544659 48059 net.cpp:380] accuracy -> accuracy
I0111 23:17:22.544682 48059 net.cpp:122] Setting up accuracy
I0111 23:17:22.544692 48059 net.cpp:129] Top shape: (1)
I0111 23:17:22.544695 48059 net.cpp:137] Memory required for data: 583655208
I0111 23:17:22.544700 48059 layer_factory.hpp:78] Creating layer accuracy_5
I0111 23:17:22.544713 48059 net.cpp:84] Creating Layer accuracy_5
I0111 23:17:22.544719 48059 net.cpp:406] accuracy_5 <- fc8_fc8_0_split_2
I0111 23:17:22.544730 48059 net.cpp:406] accuracy_5 <- label_data_1_split_2
I0111 23:17:22.544742 48059 net.cpp:380] accuracy_5 -> accuracy_5
I0111 23:17:22.544762 48059 net.cpp:122] Setting up accuracy_5
I0111 23:17:22.544772 48059 net.cpp:129] Top shape: (1)
I0111 23:17:22.544775 48059 net.cpp:137] Memory required for data: 583655212
I0111 23:17:22.544782 48059 net.cpp:200] accuracy_5 does not need backward computation.
I0111 23:17:22.544790 48059 net.cpp:200] accuracy does not need backward computation.
I0111 23:17:22.544795 48059 net.cpp:198] loss needs backward computation.
I0111 23:17:22.544800 48059 net.cpp:198] fc8_fc8_0_split needs backward computation.
I0111 23:17:22.544804 48059 net.cpp:198] fc8 needs backward computation.
I0111 23:17:22.544808 48059 net.cpp:198] drop7 needs backward computation.
I0111 23:17:22.544812 48059 net.cpp:198] relu7 needs backward computation.
I0111 23:17:22.544839 48059 net.cpp:198] scale7 needs backward computation.
I0111 23:17:22.544844 48059 net.cpp:198] bn7 needs backward computation.
I0111 23:17:22.544849 48059 net.cpp:198] fc7 needs backward computation.
I0111 23:17:22.544854 48059 net.cpp:198] drop6 needs backward computation.
I0111 23:17:22.544857 48059 net.cpp:198] relu6 needs backward computation.
I0111 23:17:22.544862 48059 net.cpp:198] scale6 needs backward computation.
I0111 23:17:22.544867 48059 net.cpp:198] bn6 needs backward computation.
I0111 23:17:22.544870 48059 net.cpp:198] fc6 needs backward computation.
I0111 23:17:22.544888 48059 net.cpp:198] pool5 needs backward computation.
I0111 23:17:22.544893 48059 net.cpp:198] relu5 needs backward computation.
I0111 23:17:22.544898 48059 net.cpp:198] scale5 needs backward computation.
I0111 23:17:22.544903 48059 net.cpp:198] bn5 needs backward computation.
I0111 23:17:22.544908 48059 net.cpp:198] conv5 needs backward computation.
I0111 23:17:22.544912 48059 net.cpp:198] relu4 needs backward computation.
I0111 23:17:22.544917 48059 net.cpp:198] scale4 needs backward computation.
I0111 23:17:22.544921 48059 net.cpp:198] bn4 needs backward computation.
I0111 23:17:22.544926 48059 net.cpp:198] conv4 needs backward computation.
I0111 23:17:22.544932 48059 net.cpp:198] relu3 needs backward computation.
I0111 23:17:22.544937 48059 net.cpp:198] scale3 needs backward computation.
I0111 23:17:22.544942 48059 net.cpp:198] bn3 needs backward computation.
I0111 23:17:22.544946 48059 net.cpp:198] conv3 needs backward computation.
I0111 23:17:22.544951 48059 net.cpp:198] pool2 needs backward computation.
I0111 23:17:22.544956 48059 net.cpp:198] relu2 needs backward computation.
I0111 23:17:22.544962 48059 net.cpp:198] scale2 needs backward computation.
I0111 23:17:22.544966 48059 net.cpp:198] bn2 needs backward computation.
I0111 23:17:22.544970 48059 net.cpp:198] conv2 needs backward computation.
I0111 23:17:22.544975 48059 net.cpp:198] pool1 needs backward computation.
I0111 23:17:22.544981 48059 net.cpp:198] relu1 needs backward computation.
I0111 23:17:22.544986 48059 net.cpp:198] scale1 needs backward computation.
I0111 23:17:22.544989 48059 net.cpp:198] bn1 needs backward computation.
I0111 23:17:22.544993 48059 net.cpp:198] conv1 needs backward computation.
I0111 23:17:22.545001 48059 net.cpp:200] label_data_1_split does not need backward computation.
I0111 23:17:22.545006 48059 net.cpp:200] data does not need backward computation.
I0111 23:17:22.545012 48059 net.cpp:242] This network produces output accuracy
I0111 23:17:22.545019 48059 net.cpp:242] This network produces output accuracy_5
I0111 23:17:22.545024 48059 net.cpp:242] This network produces output loss
I0111 23:17:22.545071 48059 net.cpp:255] Network initialization done.
I0111 23:17:22.545219 48059 solver.cpp:75] Finetuning from snapshot/solver_iter_260000.caffemodel
I0111 23:17:30.876646 48059 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: snapshot/solver_iter_260000.caffemodel
I0111 23:17:30.876751 48059 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0111 23:17:30.876770 48059 net.cpp:824] Copying source layer data
I0111 23:17:30.876778 48059 net.cpp:824] Copying source layer label_data_1_split
I0111 23:17:30.876785 48059 net.cpp:824] Copying source layer conv1
I0111 23:17:30.877738 48059 net.cpp:824] Copying source layer bn1
I0111 23:17:30.878084 48059 net.cpp:824] Copying source layer scale1
I0111 23:17:30.878139 48059 net.cpp:824] Copying source layer relu1
I0111 23:17:30.878144 48059 net.cpp:824] Copying source layer pool1
I0111 23:17:30.878149 48059 net.cpp:824] Copying source layer conv2
I0111 23:17:30.888021 48059 net.cpp:824] Copying source layer bn2
I0111 23:17:30.888135 48059 net.cpp:824] Copying source layer scale2
I0111 23:17:30.888206 48059 net.cpp:824] Copying source layer relu2
I0111 23:17:30.888218 48059 net.cpp:824] Copying source layer pool2
I0111 23:17:30.888222 48059 net.cpp:824] Copying source layer conv3
I0111 23:17:30.901715 48059 net.cpp:824] Copying source layer bn3
I0111 23:17:30.901990 48059 net.cpp:824] Copying source layer scale3
I0111 23:17:30.902057 48059 net.cpp:824] Copying source layer relu3
I0111 23:17:30.902065 48059 net.cpp:824] Copying source layer conv4
I0111 23:17:30.923487 48059 net.cpp:824] Copying source layer bn4
I0111 23:17:30.923728 48059 net.cpp:824] Copying source layer scale4
I0111 23:17:30.923782 48059 net.cpp:824] Copying source layer relu4
I0111 23:17:30.923794 48059 net.cpp:824] Copying source layer conv5
I0111 23:17:30.939748 48059 net.cpp:824] Copying source layer bn5
I0111 23:17:30.939982 48059 net.cpp:824] Copying source layer scale5
I0111 23:17:30.940057 48059 net.cpp:824] Copying source layer relu5
I0111 23:17:30.940063 48059 net.cpp:824] Copying source layer pool5
I0111 23:17:30.940070 48059 net.cpp:824] Copying source layer fc6
I0111 23:17:31.603379 48059 net.cpp:824] Copying source layer bn6
I0111 23:17:31.603719 48059 net.cpp:824] Copying source layer scale6
I0111 23:17:31.603878 48059 net.cpp:824] Copying source layer relu6
I0111 23:17:31.603886 48059 net.cpp:824] Copying source layer drop6
I0111 23:17:31.603893 48059 net.cpp:824] Copying source layer fc7
I0111 23:17:31.860226 48059 net.cpp:824] Copying source layer bn7
I0111 23:17:31.860642 48059 net.cpp:824] Copying source layer scale7
I0111 23:17:31.860888 48059 net.cpp:824] Copying source layer relu7
I0111 23:17:31.860898 48059 net.cpp:824] Copying source layer drop7
I0111 23:17:31.860905 48059 net.cpp:824] Copying source layer fc8
I0111 23:17:31.926110 48059 net.cpp:824] Copying source layer fc8_fc8_0_split
I0111 23:17:31.926142 48059 net.cpp:824] Copying source layer loss
I0111 23:17:31.926148 48059 net.cpp:824] Copying source layer accuracy
I0111 23:17:31.926152 48059 net.cpp:824] Copying source layer accuracy_5
I0111 23:17:31.953819 48059 solver.cpp:57] Solver scaffolding done.
I0111 23:17:31.956246 48059 caffe.cpp:239] Starting Optimization
I0111 23:17:31.956264 48059 solver.cpp:299] Solving AlexNet-BN
I0111 23:17:31.956267 48059 solver.cpp:300] Learning Rate Policy: modified_lr
I0111 23:17:31.959825 48059 solver.cpp:384] Iteration 0, Testing net (#0)
I0111 23:17:32.287176 48059 blocking_queue.cpp:49] Waiting for data
I0111 23:19:42.990633 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0111 23:19:43.042727 48059 solver.cpp:452]     Test net output #0: accuracy = 0.55516
I0111 23:19:43.042791 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.785641
I0111 23:19:43.042809 48059 solver.cpp:452]     Test net output #2: loss = 1.9633 (* 1 = 1.9633 loss)
I0111 23:19:43.042819 48059 solver.cpp:463] ================================
I0111 23:19:43.042824 48059 solver.cpp:464]     Test net best accuracy1 is: 0.55516
I0111 23:19:43.042830 48059 solver.cpp:466]     Test net best accuracy5 is: 0.785641
I0111 23:19:43.779301 48059 solver.cpp:242] Iteration 0 (1.57358e+12 iter/s, 131.819s/200 iters), loss = 1.17645
I0111 23:19:43.779460 48059 solver.cpp:261]     Train net output #0: accuracy = 0.703125
I0111 23:19:43.779506 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.898438
I0111 23:19:43.779546 48059 solver.cpp:261]     Train net output #2: loss = 1.17645 (* 1 = 1.17645 loss)
I0111 23:19:43.779592 48059 sgd_solver.cpp:122] Iteration 0, lr = 5e-05
I0111 23:19:53.353420 48059 blocking_queue.cpp:49] Waiting for data
I0111 23:22:16.663121 48059 solver.cpp:242] Iteration 200 (1.30822 iter/s, 152.88s/200 iters), loss = 0.982445
I0111 23:22:16.674840 48059 solver.cpp:261]     Train net output #0: accuracy = 0.773438
I0111 23:22:16.674861 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.921875
I0111 23:22:16.674880 48059 solver.cpp:261]     Train net output #2: loss = 0.982445 (* 1 = 0.982445 loss)
I0111 23:22:16.674896 48059 sgd_solver.cpp:122] Iteration 200, lr = 5e-05
I0111 23:24:50.869300 48059 solver.cpp:242] Iteration 400 (1.2971 iter/s, 154.19s/200 iters), loss = 1.1853
I0111 23:24:50.881098 48059 solver.cpp:261]     Train net output #0: accuracy = 0.746094
I0111 23:24:50.881162 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.886719
I0111 23:24:50.881197 48059 solver.cpp:261]     Train net output #2: loss = 1.1853 (* 1 = 1.1853 loss)
I0111 23:24:50.881230 48059 sgd_solver.cpp:122] Iteration 400, lr = 5e-05
I0111 23:27:27.671085 48059 solver.cpp:242] Iteration 600 (1.27563 iter/s, 156.786s/200 iters), loss = 1.32147
I0111 23:27:27.671170 48059 solver.cpp:261]     Train net output #0: accuracy = 0.691406
I0111 23:27:27.671183 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.878906
I0111 23:27:27.671205 48059 solver.cpp:261]     Train net output #2: loss = 1.32147 (* 1 = 1.32147 loss)
I0111 23:27:27.671216 48059 sgd_solver.cpp:122] Iteration 600, lr = 5e-05
I0111 23:30:15.533267 48059 solver.cpp:242] Iteration 800 (1.19149 iter/s, 167.858s/200 iters), loss = 1.36034
I0111 23:30:15.533429 48059 solver.cpp:261]     Train net output #0: accuracy = 0.679688
I0111 23:30:15.533440 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.867188
I0111 23:30:15.533465 48059 solver.cpp:261]     Train net output #2: loss = 1.36034 (* 1 = 1.36034 loss)
I0111 23:30:15.533484 48059 sgd_solver.cpp:122] Iteration 800, lr = 5e-05
I0111 23:32:59.333176 48059 solver.cpp:384] Iteration 1000, Testing net (#0)
I0111 23:33:02.577858 48059 blocking_queue.cpp:49] Waiting for data
I0111 23:36:34.837148 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0111 23:36:34.889281 48059 solver.cpp:452]     Test net output #0: accuracy = 0.56112
I0111 23:36:34.889364 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.792141
I0111 23:36:34.889392 48059 solver.cpp:452]     Test net output #2: loss = 1.93579 (* 1 = 1.93579 loss)
I0111 23:36:34.889410 48059 solver.cpp:463] ================================
I0111 23:36:34.889418 48059 solver.cpp:464]     Test net best accuracy1 is: 0.56112
I0111 23:36:34.889431 48059 solver.cpp:466]     Test net best accuracy5 is: 0.792141
I0111 23:36:35.604141 48059 solver.cpp:242] Iteration 1000 (0.526232 iter/s, 380.061s/200 iters), loss = 1.25153
I0111 23:36:35.604241 48059 solver.cpp:261]     Train net output #0: accuracy = 0.707031
I0111 23:36:35.604257 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.886719
I0111 23:36:35.604313 48059 solver.cpp:261]     Train net output #2: loss = 1.25153 (* 1 = 1.25153 loss)
I0111 23:36:35.604332 48059 sgd_solver.cpp:122] Iteration 1000, lr = 5e-05
I0111 23:36:54.519845 48059 blocking_queue.cpp:49] Waiting for data
I0111 23:39:17.831445 48059 solver.cpp:242] Iteration 1200 (1.23287 iter/s, 162.223s/200 iters), loss = 1.10341
I0111 23:39:17.843333 48059 solver.cpp:261]     Train net output #0: accuracy = 0.710938
I0111 23:39:17.843415 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.914062
I0111 23:39:17.843451 48059 solver.cpp:261]     Train net output #2: loss = 1.10341 (* 1 = 1.10341 loss)
I0111 23:39:17.843466 48059 sgd_solver.cpp:122] Iteration 1200, lr = 5e-05
I0111 23:42:05.690400 48059 solver.cpp:242] Iteration 1400 (1.19159 iter/s, 167.842s/200 iters), loss = 1.22538
I0111 23:42:05.690505 48059 solver.cpp:261]     Train net output #0: accuracy = 0.699219
I0111 23:42:05.690551 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.898438
I0111 23:42:05.690615 48059 solver.cpp:261]     Train net output #2: loss = 1.22538 (* 1 = 1.22538 loss)
I0111 23:42:05.690634 48059 sgd_solver.cpp:122] Iteration 1400, lr = 5e-05
I0111 23:44:54.813304 48059 solver.cpp:242] Iteration 1600 (1.18261 iter/s, 169.118s/200 iters), loss = 1.33061
I0111 23:44:54.825120 48059 solver.cpp:261]     Train net output #0: accuracy = 0.671875
I0111 23:44:54.825161 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.882812
I0111 23:44:54.825189 48059 solver.cpp:261]     Train net output #2: loss = 1.33061 (* 1 = 1.33061 loss)
I0111 23:44:54.825203 48059 sgd_solver.cpp:122] Iteration 1600, lr = 5e-05
I0111 23:47:40.699612 48059 solver.cpp:242] Iteration 1800 (1.20576 iter/s, 165.87s/200 iters), loss = 1.22301
I0111 23:47:40.711446 48059 solver.cpp:261]     Train net output #0: accuracy = 0.691406
I0111 23:47:40.711473 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.898438
I0111 23:47:40.711500 48059 solver.cpp:261]     Train net output #2: loss = 1.22301 (* 1 = 1.22301 loss)
I0111 23:47:40.711513 48059 sgd_solver.cpp:122] Iteration 1800, lr = 5e-05
I0111 23:50:27.760938 48059 solver.cpp:384] Iteration 2000, Testing net (#0)
I0111 23:50:32.404345 48059 blocking_queue.cpp:49] Waiting for data
I0111 23:52:47.391369 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0111 23:52:47.443645 48059 solver.cpp:452]     Test net output #0: accuracy = 0.55798
I0111 23:52:47.443714 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.788001
I0111 23:52:47.443751 48059 solver.cpp:452]     Test net output #2: loss = 1.95033 (* 1 = 1.95033 loss)
I0111 23:52:47.443775 48059 solver.cpp:463] ================================
I0111 23:52:47.443789 48059 solver.cpp:464]     Test net best accuracy1 is: 0.56112
I0111 23:52:47.443801 48059 solver.cpp:466]     Test net best accuracy5 is: 0.792141
I0111 23:52:48.165581 48059 solver.cpp:242] Iteration 2000 (0.650521 iter/s, 307.446s/200 iters), loss = 1.24821
I0111 23:52:48.167892 48059 solver.cpp:261]     Train net output #0: accuracy = 0.671875
I0111 23:52:48.167922 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.890625
I0111 23:52:48.167963 48059 solver.cpp:261]     Train net output #2: loss = 1.24821 (* 1 = 1.24821 loss)
I0111 23:52:48.167986 48059 sgd_solver.cpp:122] Iteration 2000, lr = 5e-05
I0111 23:53:19.517447 48059 blocking_queue.cpp:49] Waiting for data
I0111 23:55:29.693737 48059 solver.cpp:242] Iteration 2200 (1.23823 iter/s, 161.521s/200 iters), loss = 1.18183
I0111 23:55:29.705557 48059 solver.cpp:261]     Train net output #0: accuracy = 0.675781
I0111 23:55:29.705605 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.894531
I0111 23:55:29.705636 48059 solver.cpp:261]     Train net output #2: loss = 1.18183 (* 1 = 1.18183 loss)
I0111 23:55:29.705649 48059 sgd_solver.cpp:122] Iteration 2200, lr = 5e-05
I0111 23:58:18.770706 48059 solver.cpp:242] Iteration 2400 (1.18301 iter/s, 169.06s/200 iters), loss = 1.11418
I0111 23:58:18.770853 48059 solver.cpp:261]     Train net output #0: accuracy = 0.707031
I0111 23:58:18.770906 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.898438
I0111 23:58:18.770944 48059 solver.cpp:261]     Train net output #2: loss = 1.11418 (* 1 = 1.11418 loss)
I0111 23:58:18.770963 48059 sgd_solver.cpp:122] Iteration 2400, lr = 5e-05
I0112 00:01:01.874579 48059 solver.cpp:242] Iteration 2600 (1.22625 iter/s, 163.099s/200 iters), loss = 1.12973
I0112 00:01:01.874725 48059 solver.cpp:261]     Train net output #0: accuracy = 0.734375
I0112 00:01:01.874747 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.890625
I0112 00:01:01.874790 48059 solver.cpp:261]     Train net output #2: loss = 1.12973 (* 1 = 1.12973 loss)
I0112 00:01:01.874811 48059 sgd_solver.cpp:122] Iteration 2600, lr = 5e-05
I0112 00:04:24.090642 48059 solver.cpp:242] Iteration 2800 (0.98907 iter/s, 202.21s/200 iters), loss = 1.12396
I0112 00:04:24.090761 48059 solver.cpp:261]     Train net output #0: accuracy = 0.722656
I0112 00:04:24.090780 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.902344
I0112 00:04:24.090808 48059 solver.cpp:261]     Train net output #2: loss = 1.12396 (* 1 = 1.12396 loss)
I0112 00:04:24.090821 48059 sgd_solver.cpp:122] Iteration 2800, lr = 5e-05
I0112 00:08:04.019287 48059 solver.cpp:384] Iteration 3000, Testing net (#0)
I0112 00:08:09.612174 48059 blocking_queue.cpp:49] Waiting for data
I0112 00:10:09.436183 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 00:10:09.488492 48059 solver.cpp:452]     Test net output #0: accuracy = 0.561939
I0112 00:10:09.488540 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.790761
I0112 00:10:09.488560 48059 solver.cpp:452]     Test net output #2: loss = 1.93969 (* 1 = 1.93969 loss)
I0112 00:10:09.488572 48059 solver.cpp:463] ================================
I0112 00:10:09.488579 48059 solver.cpp:464]     Test net best accuracy1 is: 0.561939
I0112 00:10:09.488586 48059 solver.cpp:466]     Test net best accuracy5 is: 0.790761
I0112 00:10:10.213860 48059 solver.cpp:242] Iteration 3000 (0.577846 iter/s, 346.113s/200 iters), loss = 1.11478
I0112 00:10:10.216151 48059 solver.cpp:261]     Train net output #0: accuracy = 0.734375
I0112 00:10:10.216171 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.910156
I0112 00:10:10.216199 48059 solver.cpp:261]     Train net output #2: loss = 1.11478 (* 1 = 1.11478 loss)
I0112 00:10:10.216217 48059 sgd_solver.cpp:122] Iteration 3000, lr = 5e-05
I0112 00:11:31.162598 48059 blocking_queue.cpp:49] Waiting for data
I0112 00:14:32.267582 48059 solver.cpp:242] Iteration 3200 (0.763231 iter/s, 262.044s/200 iters), loss = 1.25377
I0112 00:14:32.279362 48059 solver.cpp:261]     Train net output #0: accuracy = 0.675781
I0112 00:14:32.279415 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.902344
I0112 00:14:32.279479 48059 solver.cpp:261]     Train net output #2: loss = 1.25377 (* 1 = 1.25377 loss)
I0112 00:14:32.279512 48059 sgd_solver.cpp:122] Iteration 3200, lr = 5e-05
I0112 00:18:03.180407 48059 solver.cpp:242] Iteration 3400 (0.948339 iter/s, 210.895s/200 iters), loss = 0.923288
I0112 00:18:03.180506 48059 solver.cpp:261]     Train net output #0: accuracy = 0.78125
I0112 00:18:03.180518 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.929688
I0112 00:18:03.180541 48059 solver.cpp:261]     Train net output #2: loss = 0.923288 (* 1 = 0.923288 loss)
I0112 00:18:03.180552 48059 sgd_solver.cpp:122] Iteration 3400, lr = 5e-05
I0112 00:22:17.279156 48059 solver.cpp:242] Iteration 3600 (0.787118 iter/s, 254.091s/200 iters), loss = 1.01575
I0112 00:22:17.290889 48059 solver.cpp:261]     Train net output #0: accuracy = 0.742188
I0112 00:22:17.290913 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.925781
I0112 00:22:17.290940 48059 solver.cpp:261]     Train net output #2: loss = 1.01575 (* 1 = 1.01575 loss)
I0112 00:22:17.290951 48059 sgd_solver.cpp:122] Iteration 3600, lr = 5e-05
I0112 00:26:02.047350 48059 solver.cpp:242] Iteration 3800 (0.889877 iter/s, 224.75s/200 iters), loss = 0.985434
I0112 00:26:02.047471 48059 solver.cpp:261]     Train net output #0: accuracy = 0.738281
I0112 00:26:02.047484 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.949219
I0112 00:26:02.047513 48059 solver.cpp:261]     Train net output #2: loss = 0.985434 (* 1 = 0.985434 loss)
I0112 00:26:02.047528 48059 sgd_solver.cpp:122] Iteration 3800, lr = 5e-05
I0112 00:29:47.032979 48059 solver.cpp:384] Iteration 4000, Testing net (#0)
I0112 00:29:54.777849 48059 blocking_queue.cpp:49] Waiting for data
I0112 00:31:57.845764 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 00:31:57.897861 48059 solver.cpp:452]     Test net output #0: accuracy = 0.56102
I0112 00:31:57.897923 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.791321
I0112 00:31:57.897941 48059 solver.cpp:452]     Test net output #2: loss = 1.94436 (* 1 = 1.94436 loss)
I0112 00:31:57.897950 48059 solver.cpp:463] ================================
I0112 00:31:57.897955 48059 solver.cpp:464]     Test net best accuracy1 is: 0.561939
I0112 00:31:57.897961 48059 solver.cpp:466]     Test net best accuracy5 is: 0.790761
I0112 00:31:58.619228 48059 solver.cpp:242] Iteration 4000 (0.560913 iter/s, 356.561s/200 iters), loss = 1.04525
I0112 00:31:58.621562 48059 solver.cpp:261]     Train net output #0: accuracy = 0.734375
I0112 00:31:58.621596 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.917969
I0112 00:31:58.621628 48059 solver.cpp:261]     Train net output #2: loss = 1.04525 (* 1 = 1.04525 loss)
I0112 00:31:58.621647 48059 sgd_solver.cpp:122] Iteration 4000, lr = 5e-05
I0112 00:33:10.846001 48059 blocking_queue.cpp:49] Waiting for data
I0112 00:35:48.529160 48059 solver.cpp:242] Iteration 4200 (0.86994 iter/s, 229.901s/200 iters), loss = 1.04381
I0112 00:35:48.529279 48059 solver.cpp:261]     Train net output #0: accuracy = 0.773438
I0112 00:35:48.529297 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.921875
I0112 00:35:48.529332 48059 solver.cpp:261]     Train net output #2: loss = 1.04381 (* 1 = 1.04381 loss)
I0112 00:35:48.529358 48059 sgd_solver.cpp:122] Iteration 4200, lr = 5e-05
I0112 00:39:40.866127 48059 solver.cpp:242] Iteration 4400 (0.860844 iter/s, 232.33s/200 iters), loss = 1.15906
I0112 00:39:40.877949 48059 solver.cpp:261]     Train net output #0: accuracy = 0.734375
I0112 00:39:40.878003 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.894531
I0112 00:39:40.878036 48059 solver.cpp:261]     Train net output #2: loss = 1.15906 (* 1 = 1.15906 loss)
I0112 00:39:40.878051 48059 sgd_solver.cpp:122] Iteration 4400, lr = 5e-05
I0112 00:43:49.142649 48059 solver.cpp:242] Iteration 4600 (0.805615 iter/s, 248.258s/200 iters), loss = 1.19719
I0112 00:43:49.142771 48059 solver.cpp:261]     Train net output #0: accuracy = 0.679688
I0112 00:43:49.142827 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.894531
I0112 00:43:49.142865 48059 solver.cpp:261]     Train net output #2: loss = 1.19719 (* 1 = 1.19719 loss)
I0112 00:43:49.142885 48059 sgd_solver.cpp:122] Iteration 4600, lr = 5e-05
I0112 00:47:05.644400 48059 solver.cpp:242] Iteration 4800 (1.01783 iter/s, 196.496s/200 iters), loss = 1.06673
I0112 00:47:05.644497 48059 solver.cpp:261]     Train net output #0: accuracy = 0.734375
I0112 00:47:05.644512 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.910156
I0112 00:47:05.644543 48059 solver.cpp:261]     Train net output #2: loss = 1.06673 (* 1 = 1.06673 loss)
I0112 00:47:05.644562 48059 sgd_solver.cpp:122] Iteration 4800, lr = 5e-05
I0112 00:51:26.840770 48059 solver.cpp:384] Iteration 5000, Testing net (#0)
I0112 00:51:35.910228 48059 blocking_queue.cpp:49] Waiting for data
I0112 00:53:34.892437 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 00:53:34.944886 48059 solver.cpp:452]     Test net output #0: accuracy = 0.56108
I0112 00:53:34.944968 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.789161
I0112 00:53:34.944998 48059 solver.cpp:452]     Test net output #2: loss = 1.94331 (* 1 = 1.94331 loss)
I0112 00:53:34.945072 48059 solver.cpp:463] ================================
I0112 00:53:34.945117 48059 solver.cpp:464]     Test net best accuracy1 is: 0.561939
I0112 00:53:34.945137 48059 solver.cpp:466]     Test net best accuracy5 is: 0.790761
I0112 00:53:35.666617 48059 solver.cpp:242] Iteration 5000 (0.512806 iter/s, 390.011s/200 iters), loss = 1.25982
I0112 00:53:35.668942 48059 solver.cpp:261]     Train net output #0: accuracy = 0.695312
I0112 00:53:35.668964 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.867188
I0112 00:53:35.668988 48059 solver.cpp:261]     Train net output #2: loss = 1.25982 (* 1 = 1.25982 loss)
I0112 00:53:35.669000 48059 sgd_solver.cpp:122] Iteration 5000, lr = 5e-05
I0112 00:53:36.419214 48149 data_layer.cpp:73] Restarting data prefetching from start.
I0112 00:54:48.747752 48059 blocking_queue.cpp:49] Waiting for data
I0112 00:56:58.486384 48059 solver.cpp:242] Iteration 5200 (0.986137 iter/s, 202.812s/200 iters), loss = 1.22562
I0112 00:56:58.486486 48059 solver.cpp:261]     Train net output #0: accuracy = 0.691406
I0112 00:56:58.486500 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.875
I0112 00:56:58.486521 48059 solver.cpp:261]     Train net output #2: loss = 1.22562 (* 1 = 1.22562 loss)
I0112 00:56:58.486533 48059 sgd_solver.cpp:122] Iteration 5200, lr = 5e-05
I0112 00:59:43.407011 48059 solver.cpp:242] Iteration 5400 (1.21274 iter/s, 164.916s/200 iters), loss = 1.09211
I0112 00:59:43.418758 48059 solver.cpp:261]     Train net output #0: accuracy = 0.722656
I0112 00:59:43.418808 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.90625
I0112 00:59:43.418838 48059 solver.cpp:261]     Train net output #2: loss = 1.09211 (* 1 = 1.09211 loss)
I0112 00:59:43.418854 48059 sgd_solver.cpp:122] Iteration 5400, lr = 5e-05
I0112 01:02:22.332398 48059 solver.cpp:242] Iteration 5600 (1.25858 iter/s, 158.909s/200 iters), loss = 1.12016
I0112 01:02:22.332510 48059 solver.cpp:261]     Train net output #0: accuracy = 0.722656
I0112 01:02:22.332528 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.910156
I0112 01:02:22.332556 48059 solver.cpp:261]     Train net output #2: loss = 1.12016 (* 1 = 1.12016 loss)
I0112 01:02:22.332571 48059 sgd_solver.cpp:122] Iteration 5600, lr = 5e-05
I0112 01:05:08.474835 48059 solver.cpp:242] Iteration 5800 (1.20382 iter/s, 166.137s/200 iters), loss = 1.33727
I0112 01:05:08.474941 48059 solver.cpp:261]     Train net output #0: accuracy = 0.671875
I0112 01:05:08.474957 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.871094
I0112 01:05:08.474982 48059 solver.cpp:261]     Train net output #2: loss = 1.33727 (* 1 = 1.33727 loss)
I0112 01:05:08.474998 48059 sgd_solver.cpp:122] Iteration 5800, lr = 5e-05
I0112 01:08:14.403205 48059 solver.cpp:384] Iteration 6000, Testing net (#0)
I0112 01:08:24.234591 48059 blocking_queue.cpp:49] Waiting for data
I0112 01:10:20.353617 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 01:10:20.405580 48059 solver.cpp:452]     Test net output #0: accuracy = 0.55752
I0112 01:10:20.405637 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.789441
I0112 01:10:20.405649 48059 solver.cpp:452]     Test net output #2: loss = 1.9512 (* 1 = 1.9512 loss)
I0112 01:10:20.405656 48059 solver.cpp:463] ================================
I0112 01:10:20.405659 48059 solver.cpp:464]     Test net best accuracy1 is: 0.561939
I0112 01:10:20.405663 48059 solver.cpp:466]     Test net best accuracy5 is: 0.790761
I0112 01:10:21.136296 48059 solver.cpp:242] Iteration 6000 (0.639688 iter/s, 312.652s/200 iters), loss = 1.12907
I0112 01:10:21.138658 48059 solver.cpp:261]     Train net output #0: accuracy = 0.707031
I0112 01:10:21.138672 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.921875
I0112 01:10:21.138700 48059 solver.cpp:261]     Train net output #2: loss = 1.12907 (* 1 = 1.12907 loss)
I0112 01:10:21.138728 48059 sgd_solver.cpp:122] Iteration 6000, lr = 5e-05
I0112 01:11:40.906849 48059 blocking_queue.cpp:49] Waiting for data
I0112 01:13:31.933588 48059 solver.cpp:242] Iteration 6200 (1.04828 iter/s, 190.789s/200 iters), loss = 1.26452
I0112 01:13:31.933715 48059 solver.cpp:261]     Train net output #0: accuracy = 0.667969
I0112 01:13:31.933734 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.882812
I0112 01:13:31.933770 48059 solver.cpp:261]     Train net output #2: loss = 1.26452 (* 1 = 1.26452 loss)
I0112 01:13:31.933789 48059 sgd_solver.cpp:122] Iteration 6200, lr = 5e-05
I0112 01:16:38.685581 48059 solver.cpp:242] Iteration 6400 (1.07097 iter/s, 186.746s/200 iters), loss = 1.24156
I0112 01:16:38.685693 48059 solver.cpp:261]     Train net output #0: accuracy = 0.664062
I0112 01:16:38.685704 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.890625
I0112 01:16:38.685726 48059 solver.cpp:261]     Train net output #2: loss = 1.24156 (* 1 = 1.24156 loss)
I0112 01:16:38.685740 48059 sgd_solver.cpp:122] Iteration 6400, lr = 5e-05
I0112 01:19:40.587044 48059 solver.cpp:242] Iteration 6600 (1.09953 iter/s, 181.896s/200 iters), loss = 1.18903
I0112 01:19:40.587213 48059 solver.cpp:261]     Train net output #0: accuracy = 0.691406
I0112 01:19:40.587249 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.898438
I0112 01:19:40.587325 48059 solver.cpp:261]     Train net output #2: loss = 1.18903 (* 1 = 1.18903 loss)
I0112 01:19:40.587349 48059 sgd_solver.cpp:122] Iteration 6600, lr = 5e-05
I0112 01:22:29.833225 48059 solver.cpp:242] Iteration 6800 (1.18175 iter/s, 169.241s/200 iters), loss = 1.18711
I0112 01:22:29.833374 48059 solver.cpp:261]     Train net output #0: accuracy = 0.710938
I0112 01:22:29.833405 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.902344
I0112 01:22:29.833436 48059 solver.cpp:261]     Train net output #2: loss = 1.18711 (* 1 = 1.18711 loss)
I0112 01:22:29.833448 48059 sgd_solver.cpp:122] Iteration 6800, lr = 5e-05
I0112 01:25:20.309566 48059 solver.cpp:384] Iteration 7000, Testing net (#0)
I0112 01:25:31.874732 48059 blocking_queue.cpp:49] Waiting for data
I0112 01:27:34.134320 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 01:27:34.186280 48059 solver.cpp:452]     Test net output #0: accuracy = 0.56064
I0112 01:27:34.186313 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.789441
I0112 01:27:34.186326 48059 solver.cpp:452]     Test net output #2: loss = 1.94256 (* 1 = 1.94256 loss)
I0112 01:27:34.186332 48059 solver.cpp:463] ================================
I0112 01:27:34.186336 48059 solver.cpp:464]     Test net best accuracy1 is: 0.561939
I0112 01:27:34.186342 48059 solver.cpp:466]     Test net best accuracy5 is: 0.790761
I0112 01:27:34.903522 48059 solver.cpp:242] Iteration 7000 (0.655606 iter/s, 305.061s/200 iters), loss = 1.24156
I0112 01:27:34.905846 48059 solver.cpp:261]     Train net output #0: accuracy = 0.679688
I0112 01:27:34.905874 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.902344
I0112 01:27:34.905901 48059 solver.cpp:261]     Train net output #2: loss = 1.24156 (* 1 = 1.24156 loss)
I0112 01:27:34.905916 48059 sgd_solver.cpp:122] Iteration 7000, lr = 5e-05
I0112 01:28:51.181964 48059 blocking_queue.cpp:49] Waiting for data
I0112 01:30:19.644292 48059 solver.cpp:242] Iteration 7200 (1.21408 iter/s, 164.734s/200 iters), loss = 1.06298
I0112 01:30:19.644471 48059 solver.cpp:261]     Train net output #0: accuracy = 0.75
I0112 01:30:19.644490 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.910156
I0112 01:30:19.644520 48059 solver.cpp:261]     Train net output #2: loss = 1.06298 (* 1 = 1.06298 loss)
I0112 01:30:19.644534 48059 sgd_solver.cpp:122] Iteration 7200, lr = 5e-05
I0112 01:33:17.658032 48059 solver.cpp:242] Iteration 7400 (1.12354 iter/s, 178.008s/200 iters), loss = 1.05106
I0112 01:33:17.658200 48059 solver.cpp:261]     Train net output #0: accuracy = 0.757812
I0112 01:33:17.658231 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.925781
I0112 01:33:17.658296 48059 solver.cpp:261]     Train net output #2: loss = 1.05106 (* 1 = 1.05106 loss)
I0112 01:33:17.658329 48059 sgd_solver.cpp:122] Iteration 7400, lr = 5e-05
I0112 01:36:00.640627 48059 solver.cpp:242] Iteration 7600 (1.22716 iter/s, 162.978s/200 iters), loss = 1.19706
I0112 01:36:00.640713 48059 solver.cpp:261]     Train net output #0: accuracy = 0.691406
I0112 01:36:00.640727 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.890625
I0112 01:36:00.640748 48059 solver.cpp:261]     Train net output #2: loss = 1.19706 (* 1 = 1.19706 loss)
I0112 01:36:00.640759 48059 sgd_solver.cpp:122] Iteration 7600, lr = 5e-05
I0112 01:38:40.336380 48059 solver.cpp:242] Iteration 7800 (1.25242 iter/s, 159.691s/200 iters), loss = 1.08155
I0112 01:38:40.336480 48059 solver.cpp:261]     Train net output #0: accuracy = 0.746094
I0112 01:38:40.336493 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.90625
I0112 01:38:40.336516 48059 solver.cpp:261]     Train net output #2: loss = 1.08155 (* 1 = 1.08155 loss)
I0112 01:38:40.336530 48059 sgd_solver.cpp:122] Iteration 7800, lr = 5e-05
I0112 01:41:30.343215 48059 solver.cpp:384] Iteration 8000, Testing net (#0)
I0112 01:41:49.692180 48059 blocking_queue.cpp:49] Waiting for data
I0112 01:44:21.733973 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 01:44:21.786095 48059 solver.cpp:452]     Test net output #0: accuracy = 0.560839
I0112 01:44:21.786170 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.790441
I0112 01:44:21.786214 48059 solver.cpp:452]     Test net output #2: loss = 1.94035 (* 1 = 1.94035 loss)
I0112 01:44:21.786244 48059 solver.cpp:463] ================================
I0112 01:44:21.786253 48059 solver.cpp:464]     Test net best accuracy1 is: 0.561939
I0112 01:44:21.786272 48059 solver.cpp:466]     Test net best accuracy5 is: 0.790761
I0112 01:44:22.509063 48059 solver.cpp:242] Iteration 8000 (0.584517 iter/s, 342.163s/200 iters), loss = 1.0187
I0112 01:44:22.509280 48059 solver.cpp:261]     Train net output #0: accuracy = 0.75
I0112 01:44:22.509310 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.90625
I0112 01:44:22.509371 48059 solver.cpp:261]     Train net output #2: loss = 1.0187 (* 1 = 1.0187 loss)
I0112 01:44:22.509408 48059 sgd_solver.cpp:122] Iteration 8000, lr = 5e-05
I0112 01:45:46.321447 48059 blocking_queue.cpp:49] Waiting for data
I0112 01:47:09.572888 48059 solver.cpp:242] Iteration 8200 (1.19718 iter/s, 167.059s/200 iters), loss = 1.04075
I0112 01:47:09.572994 48059 solver.cpp:261]     Train net output #0: accuracy = 0.769531
I0112 01:47:09.573007 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.929688
I0112 01:47:09.573031 48059 solver.cpp:261]     Train net output #2: loss = 1.04075 (* 1 = 1.04075 loss)
I0112 01:47:09.573046 48059 sgd_solver.cpp:122] Iteration 8200, lr = 5e-05
I0112 01:50:05.869393 48059 solver.cpp:242] Iteration 8400 (1.13449 iter/s, 176.291s/200 iters), loss = 1.21534
I0112 01:50:05.869516 48059 solver.cpp:261]     Train net output #0: accuracy = 0.703125
I0112 01:50:05.869531 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.878906
I0112 01:50:05.869562 48059 solver.cpp:261]     Train net output #2: loss = 1.21534 (* 1 = 1.21534 loss)
I0112 01:50:05.869578 48059 sgd_solver.cpp:122] Iteration 8400, lr = 5e-05
I0112 01:52:59.091713 48059 solver.cpp:242] Iteration 8600 (1.15462 iter/s, 173.217s/200 iters), loss = 1.08357
I0112 01:52:59.091833 48059 solver.cpp:261]     Train net output #0: accuracy = 0.695312
I0112 01:52:59.091900 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.921875
I0112 01:52:59.091936 48059 solver.cpp:261]     Train net output #2: loss = 1.08357 (* 1 = 1.08357 loss)
I0112 01:52:59.091954 48059 sgd_solver.cpp:122] Iteration 8600, lr = 5e-05
I0112 01:55:46.343719 48059 solver.cpp:242] Iteration 8800 (1.19584 iter/s, 167.247s/200 iters), loss = 0.975034
I0112 01:55:46.343823 48059 solver.cpp:261]     Train net output #0: accuracy = 0.761719
I0112 01:55:46.343837 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.945312
I0112 01:55:46.343861 48059 solver.cpp:261]     Train net output #2: loss = 0.975034 (* 1 = 0.975034 loss)
I0112 01:55:46.343876 48059 sgd_solver.cpp:122] Iteration 8800, lr = 5e-05
I0112 01:58:25.271142 48059 solver.cpp:384] Iteration 9000, Testing net (#0)
I0112 01:58:38.227319 48059 blocking_queue.cpp:49] Waiting for data
I0112 02:00:29.883898 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 02:00:29.935909 48059 solver.cpp:452]     Test net output #0: accuracy = 0.55872
I0112 02:00:29.935984 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.7874
I0112 02:00:29.935997 48059 solver.cpp:452]     Test net output #2: loss = 1.94874 (* 1 = 1.94874 loss)
I0112 02:00:29.936002 48059 solver.cpp:463] ================================
I0112 02:00:29.936004 48059 solver.cpp:464]     Test net best accuracy1 is: 0.561939
I0112 02:00:29.936008 48059 solver.cpp:466]     Test net best accuracy5 is: 0.790761
I0112 02:00:30.657886 48059 solver.cpp:242] Iteration 9000 (0.703468 iter/s, 284.306s/200 iters), loss = 1.11702
I0112 02:00:30.660212 48059 solver.cpp:261]     Train net output #0: accuracy = 0.726562
I0112 02:00:30.660233 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.902344
I0112 02:00:30.660256 48059 solver.cpp:261]     Train net output #2: loss = 1.11702 (* 1 = 1.11702 loss)
I0112 02:00:30.660270 48059 sgd_solver.cpp:122] Iteration 9000, lr = 5e-05
I0112 02:01:59.420281 48059 blocking_queue.cpp:49] Waiting for data
I0112 02:03:08.539654 48059 solver.cpp:242] Iteration 9200 (1.26683 iter/s, 157.875s/200 iters), loss = 1.27244
I0112 02:03:08.551403 48059 solver.cpp:261]     Train net output #0: accuracy = 0.699219
I0112 02:03:08.551437 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.878906
I0112 02:03:08.551467 48059 solver.cpp:261]     Train net output #2: loss = 1.27244 (* 1 = 1.27244 loss)
I0112 02:03:08.551481 48059 sgd_solver.cpp:122] Iteration 9200, lr = 5e-05
I0112 02:05:50.201493 48059 solver.cpp:242] Iteration 9400 (1.23728 iter/s, 161.645s/200 iters), loss = 1.21983
I0112 02:05:50.201632 48059 solver.cpp:261]     Train net output #0: accuracy = 0.691406
I0112 02:05:50.201647 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.894531
I0112 02:05:50.201676 48059 solver.cpp:261]     Train net output #2: loss = 1.21983 (* 1 = 1.21983 loss)
I0112 02:05:50.201691 48059 sgd_solver.cpp:122] Iteration 9400, lr = 5e-05
I0112 02:08:31.440057 48059 solver.cpp:242] Iteration 9600 (1.24044 iter/s, 161.234s/200 iters), loss = 1.10175
I0112 02:08:31.451787 48059 solver.cpp:261]     Train net output #0: accuracy = 0.722656
I0112 02:08:31.451822 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.921875
I0112 02:08:31.451887 48059 solver.cpp:261]     Train net output #2: loss = 1.10175 (* 1 = 1.10175 loss)
I0112 02:08:31.451922 48059 sgd_solver.cpp:122] Iteration 9600, lr = 5e-05
I0112 02:11:32.280895 48059 solver.cpp:242] Iteration 9800 (1.10605 iter/s, 180.824s/200 iters), loss = 1.09839
I0112 02:11:32.281013 48059 solver.cpp:261]     Train net output #0: accuracy = 0.730469
I0112 02:11:32.281026 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.894531
I0112 02:11:32.281050 48059 solver.cpp:261]     Train net output #2: loss = 1.09839 (* 1 = 1.09839 loss)
I0112 02:11:32.281064 48059 sgd_solver.cpp:122] Iteration 9800, lr = 5e-05
I0112 02:14:33.316787 48059 solver.cpp:514] Snapshotting to binary proto file snapshot/solver_iter_10000.caffemodel
I0112 02:14:33.316905 48059 net.cpp:928] Serializing 40 layers
I0112 02:14:48.560931 48059 sgd_solver.cpp:311] Snapshotting solver state to binary proto file snapshot/solver_iter_10000.solverstate
I0112 02:14:51.240947 48059 solver.cpp:384] Iteration 10000, Testing net (#0)
I0112 02:15:06.328589 48059 blocking_queue.cpp:49] Waiting for data
I0112 02:16:57.058346 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 02:16:57.110525 48059 solver.cpp:452]     Test net output #0: accuracy = 0.56058
I0112 02:16:57.110574 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.788501
I0112 02:16:57.110585 48059 solver.cpp:452]     Test net output #2: loss = 1.94894 (* 1 = 1.94894 loss)
I0112 02:16:57.110591 48059 solver.cpp:463] ================================
I0112 02:16:57.110594 48059 solver.cpp:464]     Test net best accuracy1 is: 0.561939
I0112 02:16:57.110597 48059 solver.cpp:466]     Test net best accuracy5 is: 0.790761
I0112 02:16:57.838485 48059 solver.cpp:242] Iteration 10000 (0.614349 iter/s, 325.548s/200 iters), loss = 1.21075
I0112 02:16:57.840811 48059 solver.cpp:261]     Train net output #0: accuracy = 0.6875
I0112 02:16:57.840844 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.898438
I0112 02:16:57.840869 48059 solver.cpp:261]     Train net output #2: loss = 1.21075 (* 1 = 1.21075 loss)
I0112 02:16:57.840883 48059 sgd_solver.cpp:122] Iteration 10000, lr = 5e-05
I0112 02:17:03.334389 48149 data_layer.cpp:73] Restarting data prefetching from start.
I0112 02:18:43.342265 48059 blocking_queue.cpp:49] Waiting for data
I0112 02:19:52.474052 48059 solver.cpp:242] Iteration 10200 (1.14529 iter/s, 174.628s/200 iters), loss = 1.26609
I0112 02:19:52.474172 48059 solver.cpp:261]     Train net output #0: accuracy = 0.703125
I0112 02:19:52.474207 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.886719
I0112 02:19:52.474257 48059 solver.cpp:261]     Train net output #2: loss = 1.26609 (* 1 = 1.26609 loss)
I0112 02:19:52.474278 48059 sgd_solver.cpp:122] Iteration 10200, lr = 5e-05
I0112 02:22:42.001147 48059 solver.cpp:242] Iteration 10400 (1.17979 iter/s, 169.522s/200 iters), loss = 1.08658
I0112 02:22:42.012914 48059 solver.cpp:261]     Train net output #0: accuracy = 0.75
I0112 02:22:42.012956 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.90625
I0112 02:22:42.012989 48059 solver.cpp:261]     Train net output #2: loss = 1.08658 (* 1 = 1.08658 loss)
I0112 02:22:42.013002 48059 sgd_solver.cpp:122] Iteration 10400, lr = 5e-05
I0112 02:25:23.452105 48059 solver.cpp:242] Iteration 10600 (1.23889 iter/s, 161.434s/200 iters), loss = 1.16197
I0112 02:25:23.463843 48059 solver.cpp:261]     Train net output #0: accuracy = 0.71875
I0112 02:25:23.463986 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.910156
I0112 02:25:23.464107 48059 solver.cpp:261]     Train net output #2: loss = 1.16197 (* 1 = 1.16197 loss)
I0112 02:25:23.464167 48059 sgd_solver.cpp:122] Iteration 10600, lr = 5e-05
I0112 02:28:10.124575 48059 solver.cpp:242] Iteration 10800 (1.20008 iter/s, 166.656s/200 iters), loss = 1.00672
I0112 02:28:10.124738 48059 solver.cpp:261]     Train net output #0: accuracy = 0.71875
I0112 02:28:10.124754 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.917969
I0112 02:28:10.124783 48059 solver.cpp:261]     Train net output #2: loss = 1.00672 (* 1 = 1.00672 loss)
I0112 02:28:10.124796 48059 sgd_solver.cpp:122] Iteration 10800, lr = 5e-05
I0112 02:31:01.504979 48059 solver.cpp:384] Iteration 11000, Testing net (#0)
I0112 02:31:18.010248 48059 blocking_queue.cpp:49] Waiting for data
I0112 02:33:09.071468 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 02:33:09.123919 48059 solver.cpp:452]     Test net output #0: accuracy = 0.55838
I0112 02:33:09.123970 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.787701
I0112 02:33:09.123983 48059 solver.cpp:452]     Test net output #2: loss = 1.95453 (* 1 = 1.95453 loss)
I0112 02:33:09.123991 48059 solver.cpp:463] ================================
I0112 02:33:09.123993 48059 solver.cpp:464]     Test net best accuracy1 is: 0.561939
I0112 02:33:09.123997 48059 solver.cpp:466]     Test net best accuracy5 is: 0.790761
I0112 02:33:09.843885 48059 solver.cpp:242] Iteration 11000 (0.667311 iter/s, 299.71s/200 iters), loss = 0.923383
I0112 02:33:09.846232 48059 solver.cpp:261]     Train net output #0: accuracy = 0.765625
I0112 02:33:09.846269 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.945312
I0112 02:33:09.846307 48059 solver.cpp:261]     Train net output #2: loss = 0.923383 (* 1 = 0.923383 loss)
I0112 02:33:09.846325 48059 sgd_solver.cpp:122] Iteration 11000, lr = 5e-05
I0112 02:35:01.059934 48059 blocking_queue.cpp:49] Waiting for data
I0112 02:35:54.989114 48059 solver.cpp:242] Iteration 11200 (1.21111 iter/s, 165.138s/200 iters), loss = 1.16454
I0112 02:35:54.989202 48059 solver.cpp:261]     Train net output #0: accuracy = 0.738281
I0112 02:35:54.989214 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.910156
I0112 02:35:54.989236 48059 solver.cpp:261]     Train net output #2: loss = 1.16454 (* 1 = 1.16454 loss)
I0112 02:35:54.989249 48059 sgd_solver.cpp:122] Iteration 11200, lr = 5e-05
I0112 02:38:38.899647 48059 solver.cpp:242] Iteration 11400 (1.22021 iter/s, 163.906s/200 iters), loss = 1.09087
I0112 02:38:38.899889 48059 solver.cpp:261]     Train net output #0: accuracy = 0.71875
I0112 02:38:38.900027 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.910156
I0112 02:38:38.900091 48059 solver.cpp:261]     Train net output #2: loss = 1.09087 (* 1 = 1.09087 loss)
I0112 02:38:38.900130 48059 sgd_solver.cpp:122] Iteration 11400, lr = 5e-05
I0112 02:41:30.830658 48059 solver.cpp:242] Iteration 11600 (1.16329 iter/s, 171.926s/200 iters), loss = 1.18756
I0112 02:41:30.842422 48059 solver.cpp:261]     Train net output #0: accuracy = 0.738281
I0112 02:41:30.842470 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.886719
I0112 02:41:30.842502 48059 solver.cpp:261]     Train net output #2: loss = 1.18756 (* 1 = 1.18756 loss)
I0112 02:41:30.842516 48059 sgd_solver.cpp:122] Iteration 11600, lr = 5e-05
I0112 02:44:35.867568 48059 solver.cpp:242] Iteration 11800 (1.08097 iter/s, 185.019s/200 iters), loss = 1.08507
I0112 02:44:35.867759 48059 solver.cpp:261]     Train net output #0: accuracy = 0.742188
I0112 02:44:35.867784 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.921875
I0112 02:44:35.867878 48059 solver.cpp:261]     Train net output #2: loss = 1.08507 (* 1 = 1.08507 loss)
I0112 02:44:35.867902 48059 sgd_solver.cpp:122] Iteration 11800, lr = 5e-05
I0112 02:47:47.440183 48059 solver.cpp:384] Iteration 12000, Testing net (#0)
I0112 02:48:04.996716 48059 blocking_queue.cpp:49] Waiting for data
I0112 02:49:56.595095 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 02:49:56.647145 48059 solver.cpp:452]     Test net output #0: accuracy = 0.55876
I0112 02:49:56.647194 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.788621
I0112 02:49:56.647205 48059 solver.cpp:452]     Test net output #2: loss = 1.9447 (* 1 = 1.9447 loss)
I0112 02:49:56.647210 48059 solver.cpp:463] ================================
I0112 02:49:56.647213 48059 solver.cpp:464]     Test net best accuracy1 is: 0.561939
I0112 02:49:56.647217 48059 solver.cpp:466]     Test net best accuracy5 is: 0.790761
I0112 02:49:57.367946 48059 solver.cpp:242] Iteration 12000 (0.622107 iter/s, 321.488s/200 iters), loss = 1.1586
I0112 02:49:57.370275 48059 solver.cpp:261]     Train net output #0: accuracy = 0.726562
I0112 02:49:57.370301 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.886719
I0112 02:49:57.370337 48059 solver.cpp:261]     Train net output #2: loss = 1.1586 (* 1 = 1.1586 loss)
I0112 02:49:57.370362 48059 sgd_solver.cpp:122] Iteration 12000, lr = 5e-05
I0112 02:51:54.446288 48059 blocking_queue.cpp:49] Waiting for data
I0112 02:52:42.156699 48059 solver.cpp:242] Iteration 12200 (1.21374 iter/s, 164.78s/200 iters), loss = 1.07774
I0112 02:52:42.168442 48059 solver.cpp:261]     Train net output #0: accuracy = 0.742188
I0112 02:52:42.168468 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.921875
I0112 02:52:42.168501 48059 solver.cpp:261]     Train net output #2: loss = 1.07774 (* 1 = 1.07774 loss)
I0112 02:52:42.168514 48059 sgd_solver.cpp:122] Iteration 12200, lr = 5e-05
I0112 02:55:37.012140 48059 solver.cpp:242] Iteration 12400 (1.14392 iter/s, 174.837s/200 iters), loss = 1.17146
I0112 02:55:37.024641 48059 solver.cpp:261]     Train net output #0: accuracy = 0.71875
I0112 02:55:37.024667 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.886719
I0112 02:55:37.024695 48059 solver.cpp:261]     Train net output #2: loss = 1.17146 (* 1 = 1.17146 loss)
I0112 02:55:37.024706 48059 sgd_solver.cpp:122] Iteration 12400, lr = 5e-05
I0112 02:58:21.842492 48059 solver.cpp:242] Iteration 12600 (1.21351 iter/s, 164.812s/200 iters), loss = 1.15586
I0112 02:58:21.842655 48059 solver.cpp:261]     Train net output #0: accuracy = 0.71875
I0112 02:58:21.842675 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.933594
I0112 02:58:21.842716 48059 solver.cpp:261]     Train net output #2: loss = 1.15586 (* 1 = 1.15586 loss)
I0112 02:58:21.842736 48059 sgd_solver.cpp:122] Iteration 12600, lr = 5e-05
I0112 03:01:07.386806 48059 solver.cpp:242] Iteration 12800 (1.20818 iter/s, 165.538s/200 iters), loss = 1.08923
I0112 03:01:07.386950 48059 solver.cpp:261]     Train net output #0: accuracy = 0.738281
I0112 03:01:07.386965 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.902344
I0112 03:01:07.386996 48059 solver.cpp:261]     Train net output #2: loss = 1.08923 (* 1 = 1.08923 loss)
I0112 03:01:07.387032 48059 sgd_solver.cpp:122] Iteration 12800, lr = 5e-05
I0112 03:03:45.779933 48059 solver.cpp:384] Iteration 13000, Testing net (#0)
I0112 03:04:20.432687 48059 blocking_queue.cpp:49] Waiting for data
I0112 03:06:45.505405 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 03:06:45.558804 48059 solver.cpp:452]     Test net output #0: accuracy = 0.56058
I0112 03:06:45.558892 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.789441
I0112 03:06:45.558920 48059 solver.cpp:452]     Test net output #2: loss = 1.94243 (* 1 = 1.94243 loss)
I0112 03:06:45.558939 48059 solver.cpp:463] ================================
I0112 03:06:45.558948 48059 solver.cpp:464]     Test net best accuracy1 is: 0.561939
I0112 03:06:45.558960 48059 solver.cpp:466]     Test net best accuracy5 is: 0.790761
I0112 03:06:46.288452 48059 solver.cpp:242] Iteration 13000 (0.590161 iter/s, 338.891s/200 iters), loss = 1.13124
I0112 03:06:46.290756 48059 solver.cpp:261]     Train net output #0: accuracy = 0.734375
I0112 03:06:46.290838 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.898438
I0112 03:06:46.290891 48059 solver.cpp:261]     Train net output #2: loss = 1.13124 (* 1 = 1.13124 loss)
I0112 03:06:46.290928 48059 sgd_solver.cpp:122] Iteration 13000, lr = 5e-05
I0112 03:08:50.092181 48059 blocking_queue.cpp:49] Waiting for data
I0112 03:09:27.481549 48059 solver.cpp:242] Iteration 13200 (1.24081 iter/s, 161.186s/200 iters), loss = 1.26621
I0112 03:09:27.493731 48059 solver.cpp:261]     Train net output #0: accuracy = 0.695312
I0112 03:09:27.493786 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.863281
I0112 03:09:27.493824 48059 solver.cpp:261]     Train net output #2: loss = 1.26621 (* 1 = 1.26621 loss)
I0112 03:09:27.493837 48059 sgd_solver.cpp:122] Iteration 13200, lr = 5e-05
I0112 03:12:07.465284 48059 solver.cpp:242] Iteration 13400 (1.25026 iter/s, 159.967s/200 iters), loss = 1.10847
I0112 03:12:07.465375 48059 solver.cpp:261]     Train net output #0: accuracy = 0.710938
I0112 03:12:07.465390 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.910156
I0112 03:12:07.465415 48059 solver.cpp:261]     Train net output #2: loss = 1.10847 (* 1 = 1.10847 loss)
I0112 03:12:07.465430 48059 sgd_solver.cpp:122] Iteration 13400, lr = 5e-05
I0112 03:14:46.669481 48059 solver.cpp:242] Iteration 13600 (1.25629 iter/s, 159.198s/200 iters), loss = 1.09577
I0112 03:14:46.680505 48059 solver.cpp:261]     Train net output #0: accuracy = 0.726562
I0112 03:14:46.680593 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.90625
I0112 03:14:46.680675 48059 solver.cpp:261]     Train net output #2: loss = 1.09577 (* 1 = 1.09577 loss)
I0112 03:14:46.680711 48059 sgd_solver.cpp:122] Iteration 13600, lr = 5e-05
I0112 03:17:27.100639 48059 solver.cpp:242] Iteration 13800 (1.24676 iter/s, 160.415s/200 iters), loss = 1.05237
I0112 03:17:27.100749 48059 solver.cpp:261]     Train net output #0: accuracy = 0.742188
I0112 03:17:27.100790 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.921875
I0112 03:17:27.100826 48059 solver.cpp:261]     Train net output #2: loss = 1.05237 (* 1 = 1.05237 loss)
I0112 03:17:27.100843 48059 sgd_solver.cpp:122] Iteration 13800, lr = 5e-05
I0112 03:20:13.928792 48059 solver.cpp:384] Iteration 14000, Testing net (#0)
I0112 03:20:52.630797 48059 blocking_queue.cpp:49] Waiting for data
I0112 03:24:18.467381 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 03:24:18.519834 48059 solver.cpp:452]     Test net output #0: accuracy = 0.55862
I0112 03:24:18.519935 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.7885
I0112 03:24:18.519959 48059 solver.cpp:452]     Test net output #2: loss = 1.94595 (* 1 = 1.94595 loss)
I0112 03:24:18.519971 48059 solver.cpp:463] ================================
I0112 03:24:18.519978 48059 solver.cpp:464]     Test net best accuracy1 is: 0.561939
I0112 03:24:18.519985 48059 solver.cpp:466]     Test net best accuracy5 is: 0.790761
I0112 03:24:19.246898 48059 solver.cpp:242] Iteration 14000 (0.48528 iter/s, 412.133s/200 iters), loss = 1.12669
I0112 03:24:19.246974 48059 solver.cpp:261]     Train net output #0: accuracy = 0.726562
I0112 03:24:19.246986 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.890625
I0112 03:24:19.247009 48059 solver.cpp:261]     Train net output #2: loss = 1.12669 (* 1 = 1.12669 loss)
I0112 03:24:19.247025 48059 sgd_solver.cpp:122] Iteration 14000, lr = 5e-05
I0112 03:26:37.012925 48059 blocking_queue.cpp:49] Waiting for data
I0112 03:27:06.616390 48059 solver.cpp:242] Iteration 14200 (1.195 iter/s, 167.364s/200 iters), loss = 1.12956
I0112 03:27:06.616467 48059 solver.cpp:261]     Train net output #0: accuracy = 0.722656
I0112 03:27:06.616478 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.882812
I0112 03:27:06.616520 48059 solver.cpp:261]     Train net output #2: loss = 1.12956 (* 1 = 1.12956 loss)
I0112 03:27:06.616536 48059 sgd_solver.cpp:122] Iteration 14200, lr = 5e-05
I0112 03:29:52.481870 48059 solver.cpp:242] Iteration 14400 (1.20583 iter/s, 165.86s/200 iters), loss = 1.04482
I0112 03:29:52.493597 48059 solver.cpp:261]     Train net output #0: accuracy = 0.726562
I0112 03:29:52.493626 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.917969
I0112 03:29:52.493680 48059 solver.cpp:261]     Train net output #2: loss = 1.04482 (* 1 = 1.04482 loss)
I0112 03:29:52.493702 48059 sgd_solver.cpp:122] Iteration 14400, lr = 5e-05
I0112 03:32:31.112907 48059 solver.cpp:242] Iteration 14600 (1.26092 iter/s, 158.614s/200 iters), loss = 1.03228
I0112 03:32:31.113024 48059 solver.cpp:261]     Train net output #0: accuracy = 0.726562
I0112 03:32:31.113044 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.921875
I0112 03:32:31.113082 48059 solver.cpp:261]     Train net output #2: loss = 1.03228 (* 1 = 1.03228 loss)
I0112 03:32:31.113102 48059 sgd_solver.cpp:122] Iteration 14600, lr = 5e-05
I0112 03:35:09.573330 48059 solver.cpp:242] Iteration 14800 (1.26218 iter/s, 158.455s/200 iters), loss = 1.17308
I0112 03:35:09.573436 48059 solver.cpp:261]     Train net output #0: accuracy = 0.703125
I0112 03:35:09.573448 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.882812
I0112 03:35:09.573472 48059 solver.cpp:261]     Train net output #2: loss = 1.17308 (* 1 = 1.17308 loss)
I0112 03:35:09.573487 48059 sgd_solver.cpp:122] Iteration 14800, lr = 5e-05
I0112 03:37:42.665264 48059 solver.cpp:384] Iteration 15000, Testing net (#0)
I0112 03:38:04.806377 48059 blocking_queue.cpp:49] Waiting for data
I0112 03:39:51.685783 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 03:39:51.737881 48059 solver.cpp:452]     Test net output #0: accuracy = 0.55894
I0112 03:39:51.737941 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.78722
I0112 03:39:51.737960 48059 solver.cpp:452]     Test net output #2: loss = 1.95227 (* 1 = 1.95227 loss)
I0112 03:39:51.737970 48059 solver.cpp:463] ================================
I0112 03:39:51.737977 48059 solver.cpp:464]     Test net best accuracy1 is: 0.561939
I0112 03:39:51.737982 48059 solver.cpp:466]     Test net best accuracy5 is: 0.790761
I0112 03:39:52.463717 48059 solver.cpp:242] Iteration 15000 (0.707009 iter/s, 282.882s/200 iters), loss = 1.3171
I0112 03:39:52.466058 48059 solver.cpp:261]     Train net output #0: accuracy = 0.671875
I0112 03:39:52.466086 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.863281
I0112 03:39:52.466115 48059 solver.cpp:261]     Train net output #2: loss = 1.3171 (* 1 = 1.3171 loss)
I0112 03:39:52.466132 48059 sgd_solver.cpp:122] Iteration 15000, lr = 5e-05
I0112 03:40:01.220914 48149 data_layer.cpp:73] Restarting data prefetching from start.
I0112 03:42:08.066092 48059 blocking_queue.cpp:49] Waiting for data
I0112 03:42:25.110111 48059 solver.cpp:242] Iteration 15200 (1.31028 iter/s, 152.639s/200 iters), loss = 1.01177
I0112 03:42:25.110242 48059 solver.cpp:261]     Train net output #0: accuracy = 0.742188
I0112 03:42:25.110308 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.933594
I0112 03:42:25.110352 48059 solver.cpp:261]     Train net output #2: loss = 1.01177 (* 1 = 1.01177 loss)
I0112 03:42:25.110373 48059 sgd_solver.cpp:122] Iteration 15200, lr = 5e-05
I0112 03:45:00.624508 48059 solver.cpp:242] Iteration 15400 (1.28609 iter/s, 155.51s/200 iters), loss = 0.972942
I0112 03:45:00.624622 48059 solver.cpp:261]     Train net output #0: accuracy = 0.75
I0112 03:45:00.624694 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.929688
I0112 03:45:00.624732 48059 solver.cpp:261]     Train net output #2: loss = 0.972942 (* 1 = 0.972942 loss)
I0112 03:45:00.624749 48059 sgd_solver.cpp:122] Iteration 15400, lr = 5e-05
I0112 03:47:35.982108 48059 solver.cpp:242] Iteration 15600 (1.28739 iter/s, 155.353s/200 iters), loss = 1.04557
I0112 03:47:35.982204 48059 solver.cpp:261]     Train net output #0: accuracy = 0.757812
I0112 03:47:35.982221 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.921875
I0112 03:47:35.982254 48059 solver.cpp:261]     Train net output #2: loss = 1.04557 (* 1 = 1.04557 loss)
I0112 03:47:35.982271 48059 sgd_solver.cpp:122] Iteration 15600, lr = 5e-05
I0112 03:50:10.480082 48059 solver.cpp:242] Iteration 15800 (1.29456 iter/s, 154.493s/200 iters), loss = 1.17181
I0112 03:50:10.492112 48059 solver.cpp:261]     Train net output #0: accuracy = 0.679688
I0112 03:50:10.492146 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.914062
I0112 03:50:10.492203 48059 solver.cpp:261]     Train net output #2: loss = 1.17181 (* 1 = 1.17181 loss)
I0112 03:50:10.492226 48059 sgd_solver.cpp:122] Iteration 15800, lr = 5e-05
I0112 03:52:45.583047 48059 solver.cpp:384] Iteration 16000, Testing net (#0)
I0112 03:53:10.568073 48059 blocking_queue.cpp:49] Waiting for data
I0112 03:54:58.643270 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 03:54:58.695806 48059 solver.cpp:452]     Test net output #0: accuracy = 0.55782
I0112 03:54:58.695873 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.788341
I0112 03:54:58.695896 48059 solver.cpp:452]     Test net output #2: loss = 1.95892 (* 1 = 1.95892 loss)
I0112 03:54:58.695906 48059 solver.cpp:463] ================================
I0112 03:54:58.695911 48059 solver.cpp:464]     Test net best accuracy1 is: 0.561939
I0112 03:54:58.695921 48059 solver.cpp:466]     Test net best accuracy5 is: 0.790761
I0112 03:54:59.420825 48059 solver.cpp:242] Iteration 16000 (0.692233 iter/s, 288.92s/200 iters), loss = 1.18359
I0112 03:54:59.423179 48059 solver.cpp:261]     Train net output #0: accuracy = 0.707031
I0112 03:54:59.423199 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.886719
I0112 03:54:59.423224 48059 solver.cpp:261]     Train net output #2: loss = 1.18359 (* 1 = 1.18359 loss)
I0112 03:54:59.423239 48059 sgd_solver.cpp:122] Iteration 16000, lr = 5e-05
I0112 03:57:24.057380 48059 blocking_queue.cpp:49] Waiting for data
I0112 03:57:33.447494 48059 solver.cpp:242] Iteration 16200 (1.29854 iter/s, 154.02s/200 iters), loss = 1.33716
I0112 03:57:33.447620 48059 solver.cpp:261]     Train net output #0: accuracy = 0.652344
I0112 03:57:33.447640 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.886719
I0112 03:57:33.447679 48059 solver.cpp:261]     Train net output #2: loss = 1.33716 (* 1 = 1.33716 loss)
I0112 03:57:33.447697 48059 sgd_solver.cpp:122] Iteration 16200, lr = 5e-05
I0112 04:00:07.967034 48059 solver.cpp:242] Iteration 16400 (1.29438 iter/s, 154.515s/200 iters), loss = 1.07675
I0112 04:00:07.967154 48059 solver.cpp:261]     Train net output #0: accuracy = 0.746094
I0112 04:00:07.967166 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.914062
I0112 04:00:07.967191 48059 solver.cpp:261]     Train net output #2: loss = 1.07675 (* 1 = 1.07675 loss)
I0112 04:00:07.967206 48059 sgd_solver.cpp:122] Iteration 16400, lr = 5e-05
I0112 04:02:44.817250 48059 solver.cpp:242] Iteration 16600 (1.27514 iter/s, 156.845s/200 iters), loss = 1.20117
I0112 04:02:44.817354 48059 solver.cpp:261]     Train net output #0: accuracy = 0.664062
I0112 04:02:44.817368 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.890625
I0112 04:02:44.817387 48059 solver.cpp:261]     Train net output #2: loss = 1.20117 (* 1 = 1.20117 loss)
I0112 04:02:44.817400 48059 sgd_solver.cpp:122] Iteration 16600, lr = 5e-05
I0112 04:05:18.110363 48059 solver.cpp:242] Iteration 16800 (1.30473 iter/s, 153.288s/200 iters), loss = 1.23554
I0112 04:05:18.122432 48059 solver.cpp:261]     Train net output #0: accuracy = 0.679688
I0112 04:05:18.122469 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.886719
I0112 04:05:18.122516 48059 solver.cpp:261]     Train net output #2: loss = 1.23554 (* 1 = 1.23554 loss)
I0112 04:05:18.122547 48059 sgd_solver.cpp:122] Iteration 16800, lr = 5e-05
I0112 04:07:56.971684 48059 solver.cpp:384] Iteration 17000, Testing net (#0)
I0112 04:08:33.495441 48059 blocking_queue.cpp:49] Waiting for data
I0112 04:10:38.975575 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 04:10:39.028199 48059 solver.cpp:452]     Test net output #0: accuracy = 0.5594
I0112 04:10:39.028280 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.789341
I0112 04:10:39.028313 48059 solver.cpp:452]     Test net output #2: loss = 1.94122 (* 1 = 1.94122 loss)
I0112 04:10:39.028326 48059 solver.cpp:463] ================================
I0112 04:10:39.028336 48059 solver.cpp:464]     Test net best accuracy1 is: 0.561939
I0112 04:10:39.028357 48059 solver.cpp:466]     Test net best accuracy5 is: 0.790761
I0112 04:10:39.758436 48059 solver.cpp:242] Iteration 17000 (0.62184 iter/s, 321.626s/200 iters), loss = 1.14143
I0112 04:10:39.760789 48059 solver.cpp:261]     Train net output #0: accuracy = 0.714844
I0112 04:10:39.760824 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.914062
I0112 04:10:39.760871 48059 solver.cpp:261]     Train net output #2: loss = 1.14143 (* 1 = 1.14143 loss)
I0112 04:10:39.760887 48059 sgd_solver.cpp:122] Iteration 17000, lr = 5e-05
I0112 04:13:18.959786 48059 solver.cpp:242] Iteration 17200 (1.25633 iter/s, 159.194s/200 iters), loss = 1.42799
I0112 04:13:18.971523 48059 solver.cpp:261]     Train net output #0: accuracy = 0.648438
I0112 04:13:18.971572 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.867188
I0112 04:13:18.971616 48059 solver.cpp:261]     Train net output #2: loss = 1.42799 (* 1 = 1.42799 loss)
I0112 04:13:18.971652 48059 sgd_solver.cpp:122] Iteration 17200, lr = 5e-05
I0112 04:13:21.213423 48059 blocking_queue.cpp:49] Waiting for data
I0112 04:16:01.286280 48059 solver.cpp:242] Iteration 17400 (1.23221 iter/s, 162.31s/200 iters), loss = 1.22973
I0112 04:16:01.286442 48059 solver.cpp:261]     Train net output #0: accuracy = 0.699219
I0112 04:16:01.286471 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.886719
I0112 04:16:01.286520 48059 solver.cpp:261]     Train net output #2: loss = 1.22973 (* 1 = 1.22973 loss)
I0112 04:16:01.286545 48059 sgd_solver.cpp:122] Iteration 17400, lr = 5e-05
I0112 04:18:41.389132 48059 solver.cpp:242] Iteration 17600 (1.24924 iter/s, 160.098s/200 iters), loss = 1.12212
I0112 04:18:41.389250 48059 solver.cpp:261]     Train net output #0: accuracy = 0.648438
I0112 04:18:41.389266 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.910156
I0112 04:18:41.389295 48059 solver.cpp:261]     Train net output #2: loss = 1.12212 (* 1 = 1.12212 loss)
I0112 04:18:41.389317 48059 sgd_solver.cpp:122] Iteration 17600, lr = 5e-05
I0112 04:21:20.435376 48059 solver.cpp:242] Iteration 17800 (1.25753 iter/s, 159.041s/200 iters), loss = 1.11932
I0112 04:21:20.435521 48059 solver.cpp:261]     Train net output #0: accuracy = 0.722656
I0112 04:21:20.435539 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.902344
I0112 04:21:20.435562 48059 solver.cpp:261]     Train net output #2: loss = 1.11932 (* 1 = 1.11932 loss)
I0112 04:21:20.435580 48059 sgd_solver.cpp:122] Iteration 17800, lr = 5e-05
I0112 04:23:58.835729 48059 solver.cpp:384] Iteration 18000, Testing net (#0)
I0112 04:24:25.914695 48059 blocking_queue.cpp:49] Waiting for data
I0112 04:26:13.333441 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 04:26:13.390491 48059 solver.cpp:452]     Test net output #0: accuracy = 0.55892
I0112 04:26:13.390594 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.78824
I0112 04:26:13.390627 48059 solver.cpp:452]     Test net output #2: loss = 1.9528 (* 1 = 1.9528 loss)
I0112 04:26:13.390735 48059 solver.cpp:463] ================================
I0112 04:26:13.390787 48059 solver.cpp:464]     Test net best accuracy1 is: 0.561939
I0112 04:26:13.390848 48059 solver.cpp:466]     Test net best accuracy5 is: 0.790761
I0112 04:26:14.124856 48059 solver.cpp:242] Iteration 18000 (0.681012 iter/s, 293.681s/200 iters), loss = 1.0731
I0112 04:26:14.127132 48059 solver.cpp:261]     Train net output #0: accuracy = 0.722656
I0112 04:26:14.127192 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.929688
I0112 04:26:14.127313 48059 solver.cpp:261]     Train net output #2: loss = 1.0731 (* 1 = 1.0731 loss)
I0112 04:26:14.127372 48059 sgd_solver.cpp:122] Iteration 18000, lr = 5e-05
I0112 04:28:52.478206 48059 solver.cpp:242] Iteration 18200 (1.26305 iter/s, 158.346s/200 iters), loss = 1.09823
I0112 04:28:52.478379 48059 solver.cpp:261]     Train net output #0: accuracy = 0.757812
I0112 04:28:52.478431 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.882812
I0112 04:28:52.478492 48059 solver.cpp:261]     Train net output #2: loss = 1.09823 (* 1 = 1.09823 loss)
I0112 04:28:52.478513 48059 sgd_solver.cpp:122] Iteration 18200, lr = 5e-05
I0112 04:29:02.352689 48059 blocking_queue.cpp:49] Waiting for data
I0112 04:31:30.518869 48059 solver.cpp:242] Iteration 18400 (1.26554 iter/s, 158.036s/200 iters), loss = 1.1502
I0112 04:31:30.519014 48059 solver.cpp:261]     Train net output #0: accuracy = 0.726562
I0112 04:31:30.519032 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.902344
I0112 04:31:30.519073 48059 solver.cpp:261]     Train net output #2: loss = 1.1502 (* 1 = 1.1502 loss)
I0112 04:31:30.519096 48059 sgd_solver.cpp:122] Iteration 18400, lr = 5e-05
I0112 04:34:09.658279 48059 solver.cpp:242] Iteration 18600 (1.2568 iter/s, 159.135s/200 iters), loss = 1.1463
I0112 04:34:09.658409 48059 solver.cpp:261]     Train net output #0: accuracy = 0.683594
I0112 04:34:09.658424 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.910156
I0112 04:34:09.658452 48059 solver.cpp:261]     Train net output #2: loss = 1.1463 (* 1 = 1.1463 loss)
I0112 04:34:09.658466 48059 sgd_solver.cpp:122] Iteration 18600, lr = 5e-05
I0112 04:36:46.653203 48059 solver.cpp:242] Iteration 18800 (1.27397 iter/s, 156.99s/200 iters), loss = 1.08929
I0112 04:36:46.653375 48059 solver.cpp:261]     Train net output #0: accuracy = 0.746094
I0112 04:36:46.653394 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.917969
I0112 04:36:46.653434 48059 solver.cpp:261]     Train net output #2: loss = 1.08929 (* 1 = 1.08929 loss)
I0112 04:36:46.653452 48059 sgd_solver.cpp:122] Iteration 18800, lr = 5e-05
I0112 04:39:21.827368 48059 solver.cpp:384] Iteration 19000, Testing net (#0)
I0112 04:39:50.996505 48059 blocking_queue.cpp:49] Waiting for data
I0112 04:41:37.132480 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 04:41:37.184772 48059 solver.cpp:452]     Test net output #0: accuracy = 0.55938
I0112 04:41:37.184849 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.787481
I0112 04:41:37.184868 48059 solver.cpp:452]     Test net output #2: loss = 1.95691 (* 1 = 1.95691 loss)
I0112 04:41:37.184877 48059 solver.cpp:463] ================================
I0112 04:41:37.184882 48059 solver.cpp:464]     Test net best accuracy1 is: 0.561939
I0112 04:41:37.184890 48059 solver.cpp:466]     Test net best accuracy5 is: 0.790761
I0112 04:41:37.906344 48059 solver.cpp:242] Iteration 19000 (0.686708 iter/s, 291.245s/200 iters), loss = 1.08063
I0112 04:41:37.908680 48059 solver.cpp:261]     Train net output #0: accuracy = 0.726562
I0112 04:41:37.908713 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.902344
I0112 04:41:37.908766 48059 solver.cpp:261]     Train net output #2: loss = 1.08063 (* 1 = 1.08063 loss)
I0112 04:41:37.908787 48059 sgd_solver.cpp:122] Iteration 19000, lr = 5e-05
I0112 04:44:13.920646 48059 solver.cpp:242] Iteration 19200 (1.28199 iter/s, 156.007s/200 iters), loss = 1.03846
I0112 04:44:13.920790 48059 solver.cpp:261]     Train net output #0: accuracy = 0.765625
I0112 04:44:13.920804 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.910156
I0112 04:44:13.920828 48059 solver.cpp:261]     Train net output #2: loss = 1.03846 (* 1 = 1.03846 loss)
I0112 04:44:13.920845 48059 sgd_solver.cpp:122] Iteration 19200, lr = 5e-05
I0112 04:44:31.619271 48059 blocking_queue.cpp:49] Waiting for data
I0112 04:46:47.157307 48059 solver.cpp:242] Iteration 19400 (1.30521 iter/s, 153.232s/200 iters), loss = 0.848759
I0112 04:46:47.157474 48059 solver.cpp:261]     Train net output #0: accuracy = 0.792969
I0112 04:46:47.157490 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.957031
I0112 04:46:47.157513 48059 solver.cpp:261]     Train net output #2: loss = 0.848759 (* 1 = 0.848759 loss)
I0112 04:46:47.157541 48059 sgd_solver.cpp:122] Iteration 19400, lr = 5e-05
I0112 04:49:19.120532 48059 solver.cpp:242] Iteration 19600 (1.31615 iter/s, 151.959s/200 iters), loss = 1.16226
I0112 04:49:19.132270 48059 solver.cpp:261]     Train net output #0: accuracy = 0.707031
I0112 04:49:19.132324 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.921875
I0112 04:49:19.132378 48059 solver.cpp:261]     Train net output #2: loss = 1.16226 (* 1 = 1.16226 loss)
I0112 04:49:19.132431 48059 sgd_solver.cpp:122] Iteration 19600, lr = 5e-05
I0112 04:51:50.996033 48059 solver.cpp:242] Iteration 19800 (1.31701 iter/s, 151.859s/200 iters), loss = 0.98101
I0112 04:51:50.996140 48059 solver.cpp:261]     Train net output #0: accuracy = 0.753906
I0112 04:51:50.996152 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.933594
I0112 04:51:50.996183 48059 solver.cpp:261]     Train net output #2: loss = 0.98101 (* 1 = 0.98101 loss)
I0112 04:51:50.996201 48059 sgd_solver.cpp:122] Iteration 19800, lr = 5e-05
I0112 04:54:22.709354 48059 solver.cpp:514] Snapshotting to binary proto file snapshot/solver_iter_20000.caffemodel
I0112 04:54:22.709473 48059 net.cpp:928] Serializing 40 layers
I0112 04:54:38.612424 48059 sgd_solver.cpp:311] Snapshotting solver state to binary proto file snapshot/solver_iter_20000.solverstate
I0112 04:54:40.522313 48059 solver.cpp:384] Iteration 20000, Testing net (#0)
I0112 04:55:12.830576 48059 blocking_queue.cpp:49] Waiting for data
I0112 04:57:02.385745 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 04:57:02.438091 48059 solver.cpp:452]     Test net output #0: accuracy = 0.56048
I0112 04:57:02.438163 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.78806
I0112 04:57:02.438186 48059 solver.cpp:452]     Test net output #2: loss = 1.94912 (* 1 = 1.94912 loss)
I0112 04:57:02.438197 48059 solver.cpp:463] ================================
I0112 04:57:02.438203 48059 solver.cpp:464]     Test net best accuracy1 is: 0.561939
I0112 04:57:02.438211 48059 solver.cpp:466]     Test net best accuracy5 is: 0.790761
I0112 04:57:03.161099 48059 solver.cpp:242] Iteration 20000 (0.640705 iter/s, 312.156s/200 iters), loss = 1.40664
I0112 04:57:03.163580 48059 solver.cpp:261]     Train net output #0: accuracy = 0.65625
I0112 04:57:03.163609 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.84375
I0112 04:57:03.163650 48059 solver.cpp:261]     Train net output #2: loss = 1.40664 (* 1 = 1.40664 loss)
I0112 04:57:03.163672 48059 sgd_solver.cpp:37] Modified_lr Status: Iteration 20000, step = 1
I0112 04:57:03.163681 48059 sgd_solver.cpp:122] Iteration 20000, lr = 1e-05
I0112 04:57:15.647080 48149 data_layer.cpp:73] Restarting data prefetching from start.
I0112 04:59:36.188982 48059 solver.cpp:242] Iteration 20200 (1.30701 iter/s, 153.021s/200 iters), loss = 1.11254
I0112 04:59:36.200866 48059 solver.cpp:261]     Train net output #0: accuracy = 0.707031
I0112 04:59:36.200897 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.90625
I0112 04:59:36.200951 48059 solver.cpp:261]     Train net output #2: loss = 1.11254 (* 1 = 1.11254 loss)
I0112 04:59:36.200973 48059 sgd_solver.cpp:122] Iteration 20200, lr = 1e-05
I0112 05:00:03.573700 48059 blocking_queue.cpp:49] Waiting for data
I0112 05:02:08.986387 48059 solver.cpp:242] Iteration 20400 (1.30906 iter/s, 152.781s/200 iters), loss = 0.955736
I0112 05:02:08.986522 48059 solver.cpp:261]     Train net output #0: accuracy = 0.78125
I0112 05:02:08.986538 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.933594
I0112 05:02:08.986564 48059 solver.cpp:261]     Train net output #2: loss = 0.955736 (* 1 = 0.955736 loss)
I0112 05:02:08.986582 48059 sgd_solver.cpp:122] Iteration 20400, lr = 1e-05
I0112 05:04:42.477501 48059 solver.cpp:242] Iteration 20600 (1.30305 iter/s, 153.486s/200 iters), loss = 1.10433
I0112 05:04:42.489207 48059 solver.cpp:261]     Train net output #0: accuracy = 0.734375
I0112 05:04:42.489387 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.925781
I0112 05:04:42.489534 48059 solver.cpp:261]     Train net output #2: loss = 1.10433 (* 1 = 1.10433 loss)
I0112 05:04:42.489600 48059 sgd_solver.cpp:122] Iteration 20600, lr = 1e-05
I0112 05:07:15.798537 48059 solver.cpp:242] Iteration 20800 (1.30459 iter/s, 153.305s/200 iters), loss = 1.12298
I0112 05:07:15.798655 48059 solver.cpp:261]     Train net output #0: accuracy = 0.703125
I0112 05:07:15.798667 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.925781
I0112 05:07:15.798691 48059 solver.cpp:261]     Train net output #2: loss = 1.12298 (* 1 = 1.12298 loss)
I0112 05:07:15.798709 48059 sgd_solver.cpp:122] Iteration 20800, lr = 1e-05
I0112 05:09:50.341526 48059 solver.cpp:384] Iteration 21000, Testing net (#0)
I0112 05:10:25.965227 48059 blocking_queue.cpp:49] Waiting for data
I0112 05:12:34.148376 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 05:12:34.200799 48059 solver.cpp:452]     Test net output #0: accuracy = 0.5645
I0112 05:12:34.200917 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.792861
I0112 05:12:34.200947 48059 solver.cpp:452]     Test net output #2: loss = 1.92048 (* 1 = 1.92048 loss)
I0112 05:12:34.200959 48059 solver.cpp:463] ================================
I0112 05:12:34.200968 48059 solver.cpp:464]     Test net best accuracy1 is: 0.5645
I0112 05:12:34.200978 48059 solver.cpp:466]     Test net best accuracy5 is: 0.792861
I0112 05:12:34.929318 48059 solver.cpp:242] Iteration 21000 (0.626721 iter/s, 319.121s/200 iters), loss = 1.02808
I0112 05:12:34.931706 48059 solver.cpp:261]     Train net output #0: accuracy = 0.742188
I0112 05:12:34.931728 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.921875
I0112 05:12:34.931752 48059 solver.cpp:261]     Train net output #2: loss = 1.02808 (* 1 = 1.02808 loss)
I0112 05:12:34.931777 48059 sgd_solver.cpp:122] Iteration 21000, lr = 1e-05
I0112 05:15:07.716226 48059 solver.cpp:242] Iteration 21200 (1.30907 iter/s, 152.78s/200 iters), loss = 1.04612
I0112 05:15:07.728418 48059 solver.cpp:261]     Train net output #0: accuracy = 0.730469
I0112 05:15:07.728463 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.925781
I0112 05:15:07.728514 48059 solver.cpp:261]     Train net output #2: loss = 1.04612 (* 1 = 1.04612 loss)
I0112 05:15:07.728538 48059 sgd_solver.cpp:122] Iteration 21200, lr = 1e-05
I0112 05:15:44.535645 48059 blocking_queue.cpp:49] Waiting for data
I0112 05:17:40.277890 48059 solver.cpp:242] Iteration 21400 (1.31109 iter/s, 152.545s/200 iters), loss = 1.03236
I0112 05:17:40.277984 48059 solver.cpp:261]     Train net output #0: accuracy = 0.734375
I0112 05:17:40.277998 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.929688
I0112 05:17:40.278038 48059 solver.cpp:261]     Train net output #2: loss = 1.03236 (* 1 = 1.03236 loss)
I0112 05:17:40.278054 48059 sgd_solver.cpp:122] Iteration 21400, lr = 1e-05
I0112 05:20:12.489634 48059 solver.cpp:242] Iteration 21600 (1.314 iter/s, 152.207s/200 iters), loss = 1.21167
I0112 05:20:12.489748 48059 solver.cpp:261]     Train net output #0: accuracy = 0.683594
I0112 05:20:12.489760 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.894531
I0112 05:20:12.489786 48059 solver.cpp:261]     Train net output #2: loss = 1.21167 (* 1 = 1.21167 loss)
I0112 05:20:12.489801 48059 sgd_solver.cpp:122] Iteration 21600, lr = 1e-05
I0112 05:22:52.575145 48059 solver.cpp:242] Iteration 21800 (1.24937 iter/s, 160.081s/200 iters), loss = 1.1345
I0112 05:22:52.575330 48059 solver.cpp:261]     Train net output #0: accuracy = 0.695312
I0112 05:22:52.575356 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.902344
I0112 05:22:52.575388 48059 solver.cpp:261]     Train net output #2: loss = 1.1345 (* 1 = 1.1345 loss)
I0112 05:22:52.575409 48059 sgd_solver.cpp:122] Iteration 21800, lr = 1e-05
I0112 05:25:36.804818 48059 solver.cpp:384] Iteration 22000, Testing net (#0)
I0112 05:26:10.141971 48059 blocking_queue.cpp:49] Waiting for data
I0112 05:27:53.339076 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 05:27:53.391712 48059 solver.cpp:452]     Test net output #0: accuracy = 0.56602
I0112 05:27:53.391808 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.79412
I0112 05:27:53.391830 48059 solver.cpp:452]     Test net output #2: loss = 1.91396 (* 1 = 1.91396 loss)
I0112 05:27:53.391840 48059 solver.cpp:463] ================================
I0112 05:27:53.391845 48059 solver.cpp:464]     Test net best accuracy1 is: 0.56602
I0112 05:27:53.391851 48059 solver.cpp:466]     Test net best accuracy5 is: 0.79412
I0112 05:27:54.121675 48059 solver.cpp:242] Iteration 22000 (0.663267 iter/s, 301.538s/200 iters), loss = 1.26333
I0112 05:27:54.124130 48059 solver.cpp:261]     Train net output #0: accuracy = 0.691406
I0112 05:27:54.124164 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.890625
I0112 05:27:54.124205 48059 solver.cpp:261]     Train net output #2: loss = 1.26333 (* 1 = 1.26333 loss)
I0112 05:27:54.124227 48059 sgd_solver.cpp:122] Iteration 22000, lr = 1e-05
I0112 05:30:29.195538 48059 solver.cpp:242] Iteration 22200 (1.28977 iter/s, 155.067s/200 iters), loss = 0.93306
I0112 05:30:29.195683 48059 solver.cpp:261]     Train net output #0: accuracy = 0.769531
I0112 05:30:29.195700 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.941406
I0112 05:30:29.195744 48059 solver.cpp:261]     Train net output #2: loss = 0.93306 (* 1 = 0.93306 loss)
I0112 05:30:29.195775 48059 sgd_solver.cpp:122] Iteration 22200, lr = 1e-05
I0112 05:31:20.431738 48059 blocking_queue.cpp:49] Waiting for data
I0112 05:33:06.866477 48059 solver.cpp:242] Iteration 22400 (1.2685 iter/s, 157.666s/200 iters), loss = 1.00839
I0112 05:33:06.878268 48059 solver.cpp:261]     Train net output #0: accuracy = 0.792969
I0112 05:33:06.878295 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.898438
I0112 05:33:06.878332 48059 solver.cpp:261]     Train net output #2: loss = 1.00839 (* 1 = 1.00839 loss)
I0112 05:33:06.878358 48059 sgd_solver.cpp:122] Iteration 22400, lr = 1e-05
I0112 05:35:42.015305 48059 solver.cpp:242] Iteration 22600 (1.28922 iter/s, 155.132s/200 iters), loss = 1.10153
I0112 05:35:42.015440 48059 solver.cpp:261]     Train net output #0: accuracy = 0.746094
I0112 05:35:42.015458 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.902344
I0112 05:35:42.015489 48059 solver.cpp:261]     Train net output #2: loss = 1.10153 (* 1 = 1.10153 loss)
I0112 05:35:42.015508 48059 sgd_solver.cpp:122] Iteration 22600, lr = 1e-05
I0112 05:38:15.715665 48059 solver.cpp:242] Iteration 22800 (1.30127 iter/s, 153.696s/200 iters), loss = 1.11787
I0112 05:38:15.715775 48059 solver.cpp:261]     Train net output #0: accuracy = 0.722656
I0112 05:38:15.715795 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.890625
I0112 05:38:15.715826 48059 solver.cpp:261]     Train net output #2: loss = 1.11787 (* 1 = 1.11787 loss)
I0112 05:38:15.715845 48059 sgd_solver.cpp:122] Iteration 22800, lr = 1e-05
I0112 05:40:52.524451 48059 solver.cpp:384] Iteration 23000, Testing net (#0)
I0112 05:41:26.941606 48059 blocking_queue.cpp:49] Waiting for data
I0112 05:43:10.091589 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 05:43:10.144088 48059 solver.cpp:452]     Test net output #0: accuracy = 0.566279
I0112 05:43:10.144191 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.794001
I0112 05:43:10.144222 48059 solver.cpp:452]     Test net output #2: loss = 1.91703 (* 1 = 1.91703 loss)
I0112 05:43:10.144238 48059 solver.cpp:463] ================================
I0112 05:43:10.144302 48059 solver.cpp:464]     Test net best accuracy1 is: 0.566279
I0112 05:43:10.144335 48059 solver.cpp:466]     Test net best accuracy5 is: 0.794001
I0112 05:43:10.875892 48059 solver.cpp:242] Iteration 23000 (0.677618 iter/s, 295.151s/200 iters), loss = 1.13551
I0112 05:43:10.878239 48059 solver.cpp:261]     Train net output #0: accuracy = 0.746094
I0112 05:43:10.878293 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.886719
I0112 05:43:10.878365 48059 solver.cpp:261]     Train net output #2: loss = 1.13551 (* 1 = 1.13551 loss)
I0112 05:43:10.878393 48059 sgd_solver.cpp:122] Iteration 23000, lr = 1e-05
I0112 05:45:47.651793 48059 solver.cpp:242] Iteration 23200 (1.27576 iter/s, 156.769s/200 iters), loss = 1.06337
I0112 05:45:47.663519 48059 solver.cpp:261]     Train net output #0: accuracy = 0.707031
I0112 05:45:47.663638 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.929688
I0112 05:45:47.663691 48059 solver.cpp:261]     Train net output #2: loss = 1.06337 (* 1 = 1.06337 loss)
I0112 05:45:47.663708 48059 sgd_solver.cpp:122] Iteration 23200, lr = 1e-05
I0112 05:46:45.505491 48059 blocking_queue.cpp:49] Waiting for data
I0112 05:48:25.552017 48059 solver.cpp:242] Iteration 23400 (1.26675 iter/s, 157.884s/200 iters), loss = 1.12722
I0112 05:48:25.552145 48059 solver.cpp:261]     Train net output #0: accuracy = 0.699219
I0112 05:48:25.552157 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.898438
I0112 05:48:25.552182 48059 solver.cpp:261]     Train net output #2: loss = 1.12722 (* 1 = 1.12722 loss)
I0112 05:48:25.552197 48059 sgd_solver.cpp:122] Iteration 23400, lr = 1e-05
I0112 05:51:03.414008 48059 solver.cpp:242] Iteration 23600 (1.26697 iter/s, 157.857s/200 iters), loss = 1.01864
I0112 05:51:03.425756 48059 solver.cpp:261]     Train net output #0: accuracy = 0.761719
I0112 05:51:03.425804 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.925781
I0112 05:51:03.425838 48059 solver.cpp:261]     Train net output #2: loss = 1.01864 (* 1 = 1.01864 loss)
I0112 05:51:03.425853 48059 sgd_solver.cpp:122] Iteration 23600, lr = 1e-05
I0112 05:53:37.241228 48059 solver.cpp:242] Iteration 23800 (1.3003 iter/s, 153.811s/200 iters), loss = 1.01544
I0112 05:53:37.241344 48059 solver.cpp:261]     Train net output #0: accuracy = 0.773438
I0112 05:53:37.241364 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.90625
I0112 05:53:37.241392 48059 solver.cpp:261]     Train net output #2: loss = 1.01544 (* 1 = 1.01544 loss)
I0112 05:53:37.241405 48059 sgd_solver.cpp:122] Iteration 23800, lr = 1e-05
I0112 05:56:10.238690 48059 solver.cpp:384] Iteration 24000, Testing net (#0)
I0112 05:57:01.143236 48059 blocking_queue.cpp:49] Waiting for data
I0112 05:58:54.282290 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 05:58:54.334525 48059 solver.cpp:452]     Test net output #0: accuracy = 0.5656
I0112 05:58:54.334580 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.793161
I0112 05:58:54.334604 48059 solver.cpp:452]     Test net output #2: loss = 1.92143 (* 1 = 1.92143 loss)
I0112 05:58:54.334612 48059 solver.cpp:463] ================================
I0112 05:58:54.334617 48059 solver.cpp:464]     Test net best accuracy1 is: 0.566279
I0112 05:58:54.334623 48059 solver.cpp:466]     Test net best accuracy5 is: 0.794001
I0112 05:58:55.050140 48059 solver.cpp:242] Iteration 24000 (0.629328 iter/s, 317.799s/200 iters), loss = 1.08458
I0112 05:58:55.052489 48059 solver.cpp:261]     Train net output #0: accuracy = 0.75
I0112 05:58:55.052525 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.898438
I0112 05:58:55.052577 48059 solver.cpp:261]     Train net output #2: loss = 1.08458 (* 1 = 1.08458 loss)
I0112 05:58:55.052624 48059 sgd_solver.cpp:122] Iteration 24000, lr = 1e-05
I0112 06:01:31.765343 48059 solver.cpp:242] Iteration 24200 (1.27626 iter/s, 156.708s/200 iters), loss = 1.03977
I0112 06:01:31.765461 48059 solver.cpp:261]     Train net output #0: accuracy = 0.722656
I0112 06:01:31.765483 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.917969
I0112 06:01:31.765511 48059 solver.cpp:261]     Train net output #2: loss = 1.03977 (* 1 = 1.03977 loss)
I0112 06:01:31.765524 48059 sgd_solver.cpp:122] Iteration 24200, lr = 1e-05
I0112 06:02:40.383885 48059 blocking_queue.cpp:49] Waiting for data
I0112 06:04:12.810320 48059 solver.cpp:242] Iteration 24400 (1.24193 iter/s, 161.04s/200 iters), loss = 1.07955
I0112 06:04:12.810510 48059 solver.cpp:261]     Train net output #0: accuracy = 0.714844
I0112 06:04:12.810530 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.902344
I0112 06:04:12.810570 48059 solver.cpp:261]     Train net output #2: loss = 1.07955 (* 1 = 1.07955 loss)
I0112 06:04:12.810591 48059 sgd_solver.cpp:122] Iteration 24400, lr = 1e-05
I0112 06:06:53.864135 48059 solver.cpp:242] Iteration 24600 (1.24186 iter/s, 161.049s/200 iters), loss = 0.983175
I0112 06:06:53.864274 48059 solver.cpp:261]     Train net output #0: accuracy = 0.757812
I0112 06:06:53.864300 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.921875
I0112 06:06:53.864383 48059 solver.cpp:261]     Train net output #2: loss = 0.983175 (* 1 = 0.983175 loss)
I0112 06:06:53.864415 48059 sgd_solver.cpp:122] Iteration 24600, lr = 1e-05
I0112 06:09:29.391865 48059 solver.cpp:242] Iteration 24800 (1.28599 iter/s, 155.523s/200 iters), loss = 1.07856
I0112 06:09:29.403592 48059 solver.cpp:261]     Train net output #0: accuracy = 0.734375
I0112 06:09:29.403630 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.902344
I0112 06:09:29.403661 48059 solver.cpp:261]     Train net output #2: loss = 1.07856 (* 1 = 1.07856 loss)
I0112 06:09:29.403686 48059 sgd_solver.cpp:122] Iteration 24800, lr = 1e-05
I0112 06:12:03.592118 48059 solver.cpp:384] Iteration 25000, Testing net (#0)
I0112 06:12:43.048198 48059 blocking_queue.cpp:49] Waiting for data
I0112 06:14:19.788774 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 06:14:19.842664 48059 solver.cpp:452]     Test net output #0: accuracy = 0.56586
I0112 06:14:19.842727 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.792361
I0112 06:14:19.842744 48059 solver.cpp:452]     Test net output #2: loss = 1.92018 (* 1 = 1.92018 loss)
I0112 06:14:19.842752 48059 solver.cpp:463] ================================
I0112 06:14:19.842757 48059 solver.cpp:464]     Test net best accuracy1 is: 0.566279
I0112 06:14:19.842762 48059 solver.cpp:466]     Test net best accuracy5 is: 0.794001
I0112 06:14:20.564404 48059 solver.cpp:242] Iteration 25000 (0.686927 iter/s, 291.152s/200 iters), loss = 0.85252
I0112 06:14:20.566715 48059 solver.cpp:261]     Train net output #0: accuracy = 0.773438
I0112 06:14:20.566740 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.953125
I0112 06:14:20.566776 48059 solver.cpp:261]     Train net output #2: loss = 0.85252 (* 1 = 0.85252 loss)
I0112 06:14:20.566790 48059 sgd_solver.cpp:122] Iteration 25000, lr = 1e-05
I0112 06:14:35.950706 48149 data_layer.cpp:73] Restarting data prefetching from start.
I0112 06:16:53.573956 48059 solver.cpp:242] Iteration 25200 (1.30717 iter/s, 153.002s/200 iters), loss = 1.1538
I0112 06:16:53.574090 48059 solver.cpp:261]     Train net output #0: accuracy = 0.710938
I0112 06:16:53.574105 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.910156
I0112 06:16:53.574146 48059 solver.cpp:261]     Train net output #2: loss = 1.1538 (* 1 = 1.1538 loss)
I0112 06:16:53.574160 48059 sgd_solver.cpp:122] Iteration 25200, lr = 1e-05
I0112 06:18:10.854794 48059 blocking_queue.cpp:49] Waiting for data
I0112 06:19:27.207989 48059 solver.cpp:242] Iteration 25400 (1.30184 iter/s, 153.629s/200 iters), loss = 1.00635
I0112 06:19:27.220046 48059 solver.cpp:261]     Train net output #0: accuracy = 0.753906
I0112 06:19:27.220091 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.929688
I0112 06:19:27.220124 48059 solver.cpp:261]     Train net output #2: loss = 1.00635 (* 1 = 1.00635 loss)
I0112 06:19:27.220136 48059 sgd_solver.cpp:122] Iteration 25400, lr = 1e-05
I0112 06:22:00.074213 48059 solver.cpp:242] Iteration 25600 (1.30848 iter/s, 152.85s/200 iters), loss = 1.04119
I0112 06:22:00.074357 48059 solver.cpp:261]     Train net output #0: accuracy = 0.703125
I0112 06:22:00.074370 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.933594
I0112 06:22:00.074394 48059 solver.cpp:261]     Train net output #2: loss = 1.04119 (* 1 = 1.04119 loss)
I0112 06:22:00.074407 48059 sgd_solver.cpp:122] Iteration 25600, lr = 1e-05
I0112 06:24:33.851928 48059 solver.cpp:242] Iteration 25800 (1.30062 iter/s, 153.773s/200 iters), loss = 1.25872
I0112 06:24:33.865329 48059 solver.cpp:261]     Train net output #0: accuracy = 0.683594
I0112 06:24:33.865357 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.890625
I0112 06:24:33.865401 48059 solver.cpp:261]     Train net output #2: loss = 1.25872 (* 1 = 1.25872 loss)
I0112 06:24:33.865432 48059 sgd_solver.cpp:122] Iteration 25800, lr = 1e-05
I0112 06:27:05.348526 48059 solver.cpp:384] Iteration 26000, Testing net (#0)
I0112 06:27:45.356113 48059 blocking_queue.cpp:49] Waiting for data
I0112 06:29:32.848333 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 06:29:32.900414 48059 solver.cpp:452]     Test net output #0: accuracy = 0.56648
I0112 06:29:32.900485 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.79406
I0112 06:29:32.900503 48059 solver.cpp:452]     Test net output #2: loss = 1.91598 (* 1 = 1.91598 loss)
I0112 06:29:32.900512 48059 solver.cpp:463] ================================
I0112 06:29:32.900516 48059 solver.cpp:464]     Test net best accuracy1 is: 0.56648
I0112 06:29:32.900522 48059 solver.cpp:466]     Test net best accuracy5 is: 0.79406
I0112 06:29:33.620185 48059 solver.cpp:242] Iteration 26000 (0.667232 iter/s, 299.746s/200 iters), loss = 1.1378
I0112 06:29:33.622710 48059 solver.cpp:261]     Train net output #0: accuracy = 0.726562
I0112 06:29:33.622750 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.898438
I0112 06:29:33.622783 48059 solver.cpp:261]     Train net output #2: loss = 1.1378 (* 1 = 1.1378 loss)
I0112 06:29:33.622804 48059 sgd_solver.cpp:122] Iteration 26000, lr = 1e-05
I0112 06:32:06.314779 48059 solver.cpp:242] Iteration 26200 (1.30986 iter/s, 152.688s/200 iters), loss = 1.21948
I0112 06:32:06.314898 48059 solver.cpp:261]     Train net output #0: accuracy = 0.695312
I0112 06:32:06.314910 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.898438
I0112 06:32:06.314949 48059 solver.cpp:261]     Train net output #2: loss = 1.21948 (* 1 = 1.21948 loss)
I0112 06:32:06.314980 48059 sgd_solver.cpp:122] Iteration 26200, lr = 1e-05
I0112 06:33:33.293788 48059 blocking_queue.cpp:49] Waiting for data
I0112 06:34:39.871711 48059 solver.cpp:242] Iteration 26400 (1.30249 iter/s, 153.552s/200 iters), loss = 1.44019
I0112 06:34:39.871827 48059 solver.cpp:261]     Train net output #0: accuracy = 0.632812
I0112 06:34:39.871839 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.871094
I0112 06:34:39.871857 48059 solver.cpp:261]     Train net output #2: loss = 1.44019 (* 1 = 1.44019 loss)
I0112 06:34:39.871902 48059 sgd_solver.cpp:122] Iteration 26400, lr = 1e-05
I0112 06:37:12.558811 48059 solver.cpp:242] Iteration 26600 (1.30991 iter/s, 152.682s/200 iters), loss = 1.0094
I0112 06:37:12.558970 48059 solver.cpp:261]     Train net output #0: accuracy = 0.746094
I0112 06:37:12.558987 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.921875
I0112 06:37:12.559015 48059 solver.cpp:261]     Train net output #2: loss = 1.0094 (* 1 = 1.0094 loss)
I0112 06:37:12.559029 48059 sgd_solver.cpp:122] Iteration 26600, lr = 1e-05
I0112 06:39:48.489521 48059 solver.cpp:242] Iteration 26800 (1.28266 iter/s, 155.926s/200 iters), loss = 0.956554
I0112 06:39:48.489648 48059 solver.cpp:261]     Train net output #0: accuracy = 0.757812
I0112 06:39:48.489662 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.949219
I0112 06:39:48.489688 48059 solver.cpp:261]     Train net output #2: loss = 0.956554 (* 1 = 0.956554 loss)
I0112 06:39:48.489703 48059 sgd_solver.cpp:122] Iteration 26800, lr = 1e-05
I0112 06:42:33.177462 48059 solver.cpp:384] Iteration 27000, Testing net (#0)
I0112 06:43:21.950654 48059 blocking_queue.cpp:49] Waiting for data
I0112 06:45:05.876441 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 06:45:05.933892 48059 solver.cpp:452]     Test net output #0: accuracy = 0.56606
I0112 06:45:05.933925 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.794561
I0112 06:45:05.933964 48059 solver.cpp:452]     Test net output #2: loss = 1.91655 (* 1 = 1.91655 loss)
I0112 06:45:05.933977 48059 solver.cpp:463] ================================
I0112 06:45:05.933980 48059 solver.cpp:464]     Test net best accuracy1 is: 0.56648
I0112 06:45:05.933990 48059 solver.cpp:466]     Test net best accuracy5 is: 0.79406
I0112 06:45:06.662214 48059 solver.cpp:242] Iteration 27000 (0.628609 iter/s, 318.163s/200 iters), loss = 1.0432
I0112 06:45:06.664546 48059 solver.cpp:261]     Train net output #0: accuracy = 0.753906
I0112 06:45:06.664579 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.921875
I0112 06:45:06.664614 48059 solver.cpp:261]     Train net output #2: loss = 1.0432 (* 1 = 1.0432 loss)
I0112 06:45:06.664635 48059 sgd_solver.cpp:122] Iteration 27000, lr = 1e-05
I0112 06:47:50.157742 48059 solver.cpp:242] Iteration 27200 (1.22333 iter/s, 163.488s/200 iters), loss = 0.958517
I0112 06:47:50.169533 48059 solver.cpp:261]     Train net output #0: accuracy = 0.78125
I0112 06:47:50.169560 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.929688
I0112 06:47:50.169589 48059 solver.cpp:261]     Train net output #2: loss = 0.958517 (* 1 = 0.958517 loss)
I0112 06:47:50.169605 48059 sgd_solver.cpp:122] Iteration 27200, lr = 1e-05
I0112 06:49:30.471390 48059 blocking_queue.cpp:49] Waiting for data
I0112 06:50:30.033102 48059 solver.cpp:242] Iteration 27400 (1.2511 iter/s, 159.859s/200 iters), loss = 1.20635
I0112 06:50:30.033226 48059 solver.cpp:261]     Train net output #0: accuracy = 0.714844
I0112 06:50:30.033247 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.882812
I0112 06:50:30.033287 48059 solver.cpp:261]     Train net output #2: loss = 1.20635 (* 1 = 1.20635 loss)
I0112 06:50:30.033305 48059 sgd_solver.cpp:122] Iteration 27400, lr = 1e-05
I0112 06:53:10.917304 48059 solver.cpp:242] Iteration 27600 (1.24317 iter/s, 160.879s/200 iters), loss = 1.1982
I0112 06:53:10.917464 48059 solver.cpp:261]     Train net output #0: accuracy = 0.71875
I0112 06:53:10.917485 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.878906
I0112 06:53:10.917516 48059 solver.cpp:261]     Train net output #2: loss = 1.1982 (* 1 = 1.1982 loss)
I0112 06:53:10.917537 48059 sgd_solver.cpp:122] Iteration 27600, lr = 1e-05
I0112 06:55:49.662757 48059 solver.cpp:242] Iteration 27800 (1.25992 iter/s, 158.74s/200 iters), loss = 0.898969
I0112 06:55:49.662873 48059 solver.cpp:261]     Train net output #0: accuracy = 0.785156
I0112 06:55:49.662884 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.933594
I0112 06:55:49.662905 48059 solver.cpp:261]     Train net output #2: loss = 0.898969 (* 1 = 0.898969 loss)
I0112 06:55:49.662917 48059 sgd_solver.cpp:122] Iteration 27800, lr = 1e-05
I0112 06:58:27.375993 48059 solver.cpp:384] Iteration 28000, Testing net (#0)
I0112 06:59:32.193308 48059 blocking_queue.cpp:49] Waiting for data
I0112 07:01:39.619537 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 07:01:39.671651 48059 solver.cpp:452]     Test net output #0: accuracy = 0.56352
I0112 07:01:39.671713 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.792661
I0112 07:01:39.671730 48059 solver.cpp:452]     Test net output #2: loss = 1.9283 (* 1 = 1.9283 loss)
I0112 07:01:39.671746 48059 solver.cpp:463] ================================
I0112 07:01:39.671751 48059 solver.cpp:464]     Test net best accuracy1 is: 0.56648
I0112 07:01:39.671757 48059 solver.cpp:466]     Test net best accuracy5 is: 0.79406
I0112 07:01:40.401499 48059 solver.cpp:242] Iteration 28000 (0.570242 iter/s, 350.728s/200 iters), loss = 0.938325
I0112 07:01:40.403854 48059 solver.cpp:261]     Train net output #0: accuracy = 0.777344
I0112 07:01:40.403901 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.925781
I0112 07:01:40.403942 48059 solver.cpp:261]     Train net output #2: loss = 0.938325 (* 1 = 0.938325 loss)
I0112 07:01:40.403965 48059 sgd_solver.cpp:122] Iteration 28000, lr = 1e-05
I0112 07:04:20.629828 48059 solver.cpp:242] Iteration 28200 (1.24828 iter/s, 160.221s/200 iters), loss = 1.03523
I0112 07:04:20.630151 48059 solver.cpp:261]     Train net output #0: accuracy = 0.746094
I0112 07:04:20.630232 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.917969
I0112 07:04:20.630326 48059 solver.cpp:261]     Train net output #2: loss = 1.03523 (* 1 = 1.03523 loss)
I0112 07:04:20.630393 48059 sgd_solver.cpp:122] Iteration 28200, lr = 1e-05
I0112 07:06:07.892383 48059 blocking_queue.cpp:49] Waiting for data
I0112 07:07:00.019852 48059 solver.cpp:242] Iteration 28400 (1.25482 iter/s, 159.385s/200 iters), loss = 1.00244
I0112 07:07:00.020033 48059 solver.cpp:261]     Train net output #0: accuracy = 0.765625
I0112 07:07:00.020059 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.921875
I0112 07:07:00.020104 48059 solver.cpp:261]     Train net output #2: loss = 1.00244 (* 1 = 1.00244 loss)
I0112 07:07:00.020120 48059 sgd_solver.cpp:122] Iteration 28400, lr = 1e-05
I0112 07:09:34.704272 48059 solver.cpp:242] Iteration 28600 (1.293 iter/s, 154.68s/200 iters), loss = 1.23044
I0112 07:09:34.704368 48059 solver.cpp:261]     Train net output #0: accuracy = 0.691406
I0112 07:09:34.704380 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.886719
I0112 07:09:34.704402 48059 solver.cpp:261]     Train net output #2: loss = 1.23044 (* 1 = 1.23044 loss)
I0112 07:09:34.704423 48059 sgd_solver.cpp:122] Iteration 28600, lr = 1e-05
I0112 07:12:12.111874 48059 solver.cpp:242] Iteration 28800 (1.27063 iter/s, 157.403s/200 iters), loss = 0.978363
I0112 07:12:12.123709 48059 solver.cpp:261]     Train net output #0: accuracy = 0.746094
I0112 07:12:12.123783 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.925781
I0112 07:12:12.123845 48059 solver.cpp:261]     Train net output #2: loss = 0.978363 (* 1 = 0.978363 loss)
I0112 07:12:12.123873 48059 sgd_solver.cpp:122] Iteration 28800, lr = 1e-05
I0112 07:14:48.225397 48059 solver.cpp:384] Iteration 29000, Testing net (#0)
I0112 07:15:45.769949 48059 blocking_queue.cpp:49] Waiting for data
I0112 07:17:35.087116 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 07:17:35.140120 48059 solver.cpp:452]     Test net output #0: accuracy = 0.56478
I0112 07:17:35.140230 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.7925
I0112 07:17:35.140276 48059 solver.cpp:452]     Test net output #2: loss = 1.92257 (* 1 = 1.92257 loss)
I0112 07:17:35.140303 48059 solver.cpp:463] ================================
I0112 07:17:35.140317 48059 solver.cpp:464]     Test net best accuracy1 is: 0.56648
I0112 07:17:35.140337 48059 solver.cpp:466]     Test net best accuracy5 is: 0.79406
I0112 07:17:35.865608 48059 solver.cpp:242] Iteration 29000 (0.617795 iter/s, 323.732s/200 iters), loss = 1.06104
I0112 07:17:35.868026 48059 solver.cpp:261]     Train net output #0: accuracy = 0.734375
I0112 07:17:35.868074 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.894531
I0112 07:17:35.868122 48059 solver.cpp:261]     Train net output #2: loss = 1.06104 (* 1 = 1.06104 loss)
I0112 07:17:35.868156 48059 sgd_solver.cpp:122] Iteration 29000, lr = 1e-05
I0112 07:20:10.201536 48059 solver.cpp:242] Iteration 29200 (1.29593 iter/s, 154.329s/200 iters), loss = 1.14328
I0112 07:20:10.213271 48059 solver.cpp:261]     Train net output #0: accuracy = 0.71875
I0112 07:20:10.213291 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.894531
I0112 07:20:10.213318 48059 solver.cpp:261]     Train net output #2: loss = 1.14328 (* 1 = 1.14328 loss)
I0112 07:20:10.213331 48059 sgd_solver.cpp:122] Iteration 29200, lr = 1e-05
I0112 07:22:01.479391 48059 blocking_queue.cpp:49] Waiting for data
I0112 07:22:43.319195 48059 solver.cpp:242] Iteration 29400 (1.30633 iter/s, 153.101s/200 iters), loss = 1.03382
I0112 07:22:43.330963 48059 solver.cpp:261]     Train net output #0: accuracy = 0.730469
I0112 07:22:43.331003 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.921875
I0112 07:22:43.331051 48059 solver.cpp:261]     Train net output #2: loss = 1.03382 (* 1 = 1.03382 loss)
I0112 07:22:43.331073 48059 sgd_solver.cpp:122] Iteration 29400, lr = 1e-05
I0112 07:25:15.968329 48059 solver.cpp:242] Iteration 29600 (1.31034 iter/s, 152.633s/200 iters), loss = 0.848746
I0112 07:25:15.980108 48059 solver.cpp:261]     Train net output #0: accuracy = 0.765625
I0112 07:25:15.980171 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.941406
I0112 07:25:15.980211 48059 solver.cpp:261]     Train net output #2: loss = 0.848746 (* 1 = 0.848746 loss)
I0112 07:25:15.980227 48059 sgd_solver.cpp:122] Iteration 29600, lr = 1e-05
I0112 07:27:46.840504 48059 solver.cpp:242] Iteration 29800 (1.32577 iter/s, 150.856s/200 iters), loss = 1.11605
I0112 07:27:46.852284 48059 solver.cpp:261]     Train net output #0: accuracy = 0.722656
I0112 07:27:46.852318 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.917969
I0112 07:27:46.852362 48059 solver.cpp:261]     Train net output #2: loss = 1.11605 (* 1 = 1.11605 loss)
I0112 07:27:46.852381 48059 sgd_solver.cpp:122] Iteration 29800, lr = 1e-05
I0112 07:30:18.236111 48059 solver.cpp:514] Snapshotting to binary proto file snapshot/solver_iter_30000.caffemodel
I0112 07:30:18.236196 48059 net.cpp:928] Serializing 40 layers
I0112 07:30:36.450194 48059 sgd_solver.cpp:311] Snapshotting solver state to binary proto file snapshot/solver_iter_30000.solverstate
I0112 07:30:38.436589 48059 solver.cpp:384] Iteration 30000, Testing net (#0)
I0112 07:31:28.061847 48059 blocking_queue.cpp:49] Waiting for data
I0112 07:32:56.344307 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 07:32:56.397115 48059 solver.cpp:452]     Test net output #0: accuracy = 0.56786
I0112 07:32:56.397223 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.793761
I0112 07:32:56.397264 48059 solver.cpp:452]     Test net output #2: loss = 1.91698 (* 1 = 1.91698 loss)
I0112 07:32:56.397284 48059 solver.cpp:463] ================================
I0112 07:32:56.397297 48059 solver.cpp:464]     Test net best accuracy1 is: 0.56786
I0112 07:32:56.397305 48059 solver.cpp:466]     Test net best accuracy5 is: 0.793761
I0112 07:32:57.115063 48059 solver.cpp:242] Iteration 30000 (0.644634 iter/s, 310.253s/200 iters), loss = 1.1399
I0112 07:32:57.117354 48059 solver.cpp:261]     Train net output #0: accuracy = 0.707031
I0112 07:32:57.117373 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.890625
I0112 07:32:57.117398 48059 solver.cpp:261]     Train net output #2: loss = 1.1399 (* 1 = 1.1399 loss)
I0112 07:32:57.117410 48059 sgd_solver.cpp:37] Modified_lr Status: Iteration 30000, step = 2
I0112 07:32:57.117415 48059 sgd_solver.cpp:122] Iteration 30000, lr = 1e-06
I0112 07:33:16.615213 48149 data_layer.cpp:73] Restarting data prefetching from start.
I0112 07:35:30.695480 48059 solver.cpp:242] Iteration 30200 (1.30231 iter/s, 153.574s/200 iters), loss = 1.15134
I0112 07:35:30.707314 48059 solver.cpp:261]     Train net output #0: accuracy = 0.71875
I0112 07:35:30.707337 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.90625
I0112 07:35:30.707370 48059 solver.cpp:261]     Train net output #2: loss = 1.15134 (* 1 = 1.15134 loss)
I0112 07:35:30.707381 48059 sgd_solver.cpp:122] Iteration 30200, lr = 1e-06
I0112 07:37:33.917925 48059 blocking_queue.cpp:49] Waiting for data
I0112 07:38:03.437530 48059 solver.cpp:242] Iteration 30400 (1.30954 iter/s, 152.726s/200 iters), loss = 1.20198
I0112 07:38:03.449324 48059 solver.cpp:261]     Train net output #0: accuracy = 0.722656
I0112 07:38:03.449386 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.902344
I0112 07:38:03.449431 48059 solver.cpp:261]     Train net output #2: loss = 1.20198 (* 1 = 1.20198 loss)
I0112 07:38:03.449445 48059 sgd_solver.cpp:122] Iteration 30400, lr = 1e-06
I0112 07:40:36.210065 48059 solver.cpp:242] Iteration 30600 (1.30928 iter/s, 152.756s/200 iters), loss = 1.1635
I0112 07:40:36.210213 48059 solver.cpp:261]     Train net output #0: accuracy = 0.691406
I0112 07:40:36.210232 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.910156
I0112 07:40:36.210265 48059 solver.cpp:261]     Train net output #2: loss = 1.1635 (* 1 = 1.1635 loss)
I0112 07:40:36.210289 48059 sgd_solver.cpp:122] Iteration 30600, lr = 1e-06
I0112 07:43:08.477247 48059 solver.cpp:242] Iteration 30800 (1.31352 iter/s, 152.262s/200 iters), loss = 1.09159
I0112 07:43:08.477460 48059 solver.cpp:261]     Train net output #0: accuracy = 0.75
I0112 07:43:08.477504 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.925781
I0112 07:43:08.477557 48059 solver.cpp:261]     Train net output #2: loss = 1.09159 (* 1 = 1.09159 loss)
I0112 07:43:08.477593 48059 sgd_solver.cpp:122] Iteration 30800, lr = 1e-06
I0112 07:45:40.932070 48059 solver.cpp:384] Iteration 31000, Testing net (#0)
I0112 07:46:29.986441 48059 blocking_queue.cpp:49] Waiting for data
I0112 07:48:06.771114 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 07:48:06.823774 48059 solver.cpp:452]     Test net output #0: accuracy = 0.568819
I0112 07:48:06.823822 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.794601
I0112 07:48:06.823848 48059 solver.cpp:452]     Test net output #2: loss = 1.90413 (* 1 = 1.90413 loss)
I0112 07:48:06.823858 48059 solver.cpp:463] ================================
I0112 07:48:06.823863 48059 solver.cpp:464]     Test net best accuracy1 is: 0.568819
I0112 07:48:06.823870 48059 solver.cpp:466]     Test net best accuracy5 is: 0.794601
I0112 07:48:07.550333 48059 solver.cpp:242] Iteration 31000 (0.668753 iter/s, 299.064s/200 iters), loss = 1.13003
I0112 07:48:07.552685 48059 solver.cpp:261]     Train net output #0: accuracy = 0.742188
I0112 07:48:07.552703 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.898438
I0112 07:48:07.552731 48059 solver.cpp:261]     Train net output #2: loss = 1.13003 (* 1 = 1.13003 loss)
I0112 07:48:07.552747 48059 sgd_solver.cpp:122] Iteration 31000, lr = 1e-06
I0112 07:50:38.899250 48059 solver.cpp:242] Iteration 31200 (1.32151 iter/s, 151.342s/200 iters), loss = 1.13774
I0112 07:50:38.899397 48059 solver.cpp:261]     Train net output #0: accuracy = 0.703125
I0112 07:50:38.899411 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.910156
I0112 07:50:38.899437 48059 solver.cpp:261]     Train net output #2: loss = 1.13774 (* 1 = 1.13774 loss)
I0112 07:50:38.899474 48059 sgd_solver.cpp:122] Iteration 31200, lr = 1e-06
I0112 07:52:50.162744 48059 blocking_queue.cpp:49] Waiting for data
I0112 07:53:11.850898 48059 solver.cpp:242] Iteration 31400 (1.30764 iter/s, 152.947s/200 iters), loss = 1.04018
I0112 07:53:11.862694 48059 solver.cpp:261]     Train net output #0: accuracy = 0.746094
I0112 07:53:11.862737 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.902344
I0112 07:53:11.862772 48059 solver.cpp:261]     Train net output #2: loss = 1.04018 (* 1 = 1.04018 loss)
I0112 07:53:11.862807 48059 sgd_solver.cpp:122] Iteration 31400, lr = 1e-06
I0112 07:55:44.297024 48059 solver.cpp:242] Iteration 31600 (1.31208 iter/s, 152.43s/200 iters), loss = 1.25954
I0112 07:55:44.308804 48059 solver.cpp:261]     Train net output #0: accuracy = 0.714844
I0112 07:55:44.308866 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.886719
I0112 07:55:44.308926 48059 solver.cpp:261]     Train net output #2: loss = 1.25954 (* 1 = 1.25954 loss)
I0112 07:55:44.308961 48059 sgd_solver.cpp:122] Iteration 31600, lr = 1e-06
I0112 07:58:16.997670 48059 solver.cpp:242] Iteration 31800 (1.30989 iter/s, 152.684s/200 iters), loss = 1.25786
I0112 07:58:16.997879 48059 solver.cpp:261]     Train net output #0: accuracy = 0.695312
I0112 07:58:16.997900 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.886719
I0112 07:58:16.997942 48059 solver.cpp:261]     Train net output #2: loss = 1.25786 (* 1 = 1.25786 loss)
I0112 07:58:16.997961 48059 sgd_solver.cpp:122] Iteration 31800, lr = 1e-06
I0112 08:00:48.403568 48059 solver.cpp:384] Iteration 32000, Testing net (#0)
I0112 08:01:36.990094 48059 blocking_queue.cpp:49] Waiting for data
I0112 08:03:01.180955 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 08:03:01.233829 48059 solver.cpp:452]     Test net output #0: accuracy = 0.56838
I0112 08:03:01.233893 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.795221
I0112 08:03:01.233913 48059 solver.cpp:452]     Test net output #2: loss = 1.9042 (* 1 = 1.9042 loss)
I0112 08:03:01.233927 48059 solver.cpp:463] ================================
I0112 08:03:01.233932 48059 solver.cpp:464]     Test net best accuracy1 is: 0.568819
I0112 08:03:01.233937 48059 solver.cpp:466]     Test net best accuracy5 is: 0.794601
I0112 08:03:01.959635 48059 solver.cpp:242] Iteration 32000 (0.701869 iter/s, 284.953s/200 iters), loss = 1.26985
I0112 08:03:01.961958 48059 solver.cpp:261]     Train net output #0: accuracy = 0.691406
I0112 08:03:01.961974 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.890625
I0112 08:03:01.962005 48059 solver.cpp:261]     Train net output #2: loss = 1.26985 (* 1 = 1.26985 loss)
I0112 08:03:01.962019 48059 sgd_solver.cpp:122] Iteration 32000, lr = 1e-06
I0112 08:05:36.722396 48059 solver.cpp:242] Iteration 32200 (1.29236 iter/s, 154.756s/200 iters), loss = 1.15485
I0112 08:05:36.722560 48059 solver.cpp:261]     Train net output #0: accuracy = 0.710938
I0112 08:05:36.722579 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.910156
I0112 08:05:36.722615 48059 solver.cpp:261]     Train net output #2: loss = 1.15485 (* 1 = 1.15485 loss)
I0112 08:05:36.722645 48059 sgd_solver.cpp:122] Iteration 32200, lr = 1e-06
I0112 08:08:01.646106 48059 blocking_queue.cpp:49] Waiting for data
I0112 08:08:10.794595 48059 solver.cpp:242] Iteration 32400 (1.29813 iter/s, 154.068s/200 iters), loss = 1.20459
I0112 08:08:10.806332 48059 solver.cpp:261]     Train net output #0: accuracy = 0.714844
I0112 08:08:10.806352 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.886719
I0112 08:08:10.806380 48059 solver.cpp:261]     Train net output #2: loss = 1.20459 (* 1 = 1.20459 loss)
I0112 08:08:10.806392 48059 sgd_solver.cpp:122] Iteration 32400, lr = 1e-06
I0112 08:10:43.728786 48059 solver.cpp:242] Iteration 32600 (1.30789 iter/s, 152.918s/200 iters), loss = 1.38602
I0112 08:10:43.740586 48059 solver.cpp:261]     Train net output #0: accuracy = 0.671875
I0112 08:10:43.740619 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.855469
I0112 08:10:43.740646 48059 solver.cpp:261]     Train net output #2: loss = 1.38602 (* 1 = 1.38602 loss)
I0112 08:10:43.740660 48059 sgd_solver.cpp:122] Iteration 32600, lr = 1e-06
I0112 08:13:25.860735 48059 solver.cpp:242] Iteration 32800 (1.23369 iter/s, 162.115s/200 iters), loss = 1.04319
I0112 08:13:25.860862 48059 solver.cpp:261]     Train net output #0: accuracy = 0.734375
I0112 08:13:25.860900 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.9375
I0112 08:13:25.860937 48059 solver.cpp:261]     Train net output #2: loss = 1.04319 (* 1 = 1.04319 loss)
I0112 08:13:25.860962 48059 sgd_solver.cpp:122] Iteration 32800, lr = 1e-06
I0112 08:16:11.048743 48059 solver.cpp:384] Iteration 33000, Testing net (#0)
I0112 08:17:04.437070 48059 blocking_queue.cpp:49] Waiting for data
I0112 08:18:27.370829 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 08:18:27.422971 48059 solver.cpp:452]     Test net output #0: accuracy = 0.56922
I0112 08:18:27.423039 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.796541
I0112 08:18:27.423056 48059 solver.cpp:452]     Test net output #2: loss = 1.9003 (* 1 = 1.9003 loss)
I0112 08:18:27.423064 48059 solver.cpp:463] ================================
I0112 08:18:27.423069 48059 solver.cpp:464]     Test net best accuracy1 is: 0.56922
I0112 08:18:27.423074 48059 solver.cpp:466]     Test net best accuracy5 is: 0.796541
I0112 08:18:28.153367 48059 solver.cpp:242] Iteration 33000 (0.66163 iter/s, 302.284s/200 iters), loss = 0.946601
I0112 08:18:28.155745 48059 solver.cpp:261]     Train net output #0: accuracy = 0.75
I0112 08:18:28.155805 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.941406
I0112 08:18:28.155841 48059 solver.cpp:261]     Train net output #2: loss = 0.946601 (* 1 = 0.946601 loss)
I0112 08:18:28.155858 48059 sgd_solver.cpp:122] Iteration 33000, lr = 1e-06
I0112 08:21:01.388551 48059 solver.cpp:242] Iteration 33200 (1.30524 iter/s, 153.228s/200 iters), loss = 1.04686
I0112 08:21:01.388700 48059 solver.cpp:261]     Train net output #0: accuracy = 0.71875
I0112 08:21:01.388713 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.929688
I0112 08:21:01.388739 48059 solver.cpp:261]     Train net output #2: loss = 1.04686 (* 1 = 1.04686 loss)
I0112 08:21:01.388753 48059 sgd_solver.cpp:122] Iteration 33200, lr = 1e-06
I0112 08:23:38.300026 48059 solver.cpp:242] Iteration 33400 (1.27464 iter/s, 156.907s/200 iters), loss = 0.977617
I0112 08:23:38.300148 48059 solver.cpp:261]     Train net output #0: accuracy = 0.757812
I0112 08:23:38.300159 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.925781
I0112 08:23:38.300189 48059 solver.cpp:261]     Train net output #2: loss = 0.977617 (* 1 = 0.977617 loss)
I0112 08:23:38.300204 48059 sgd_solver.cpp:122] Iteration 33400, lr = 1e-06
I0112 08:23:39.783437 48059 blocking_queue.cpp:49] Waiting for data
I0112 08:26:12.330153 48059 solver.cpp:242] Iteration 33600 (1.29849 iter/s, 154.026s/200 iters), loss = 0.97542
I0112 08:26:12.330265 48059 solver.cpp:261]     Train net output #0: accuracy = 0.753906
I0112 08:26:12.330277 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.925781
I0112 08:26:12.330308 48059 solver.cpp:261]     Train net output #2: loss = 0.97542 (* 1 = 0.97542 loss)
I0112 08:26:12.330323 48059 sgd_solver.cpp:122] Iteration 33600, lr = 1e-06
I0112 08:28:48.248474 48059 solver.cpp:242] Iteration 33800 (1.28276 iter/s, 155.914s/200 iters), loss = 1.21473
I0112 08:28:48.260272 48059 solver.cpp:261]     Train net output #0: accuracy = 0.703125
I0112 08:28:48.260309 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.878906
I0112 08:28:48.260345 48059 solver.cpp:261]     Train net output #2: loss = 1.21473 (* 1 = 1.21473 loss)
I0112 08:28:48.260359 48059 sgd_solver.cpp:122] Iteration 33800, lr = 1e-06
I0112 08:31:25.641847 48059 solver.cpp:384] Iteration 34000, Testing net (#0)
I0112 08:32:18.048741 48059 blocking_queue.cpp:49] Waiting for data
I0112 08:33:37.248878 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 08:33:37.301121 48059 solver.cpp:452]     Test net output #0: accuracy = 0.5687
I0112 08:33:37.301183 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.796121
I0112 08:33:37.301201 48059 solver.cpp:452]     Test net output #2: loss = 1.9025 (* 1 = 1.9025 loss)
I0112 08:33:37.301209 48059 solver.cpp:463] ================================
I0112 08:33:37.301214 48059 solver.cpp:464]     Test net best accuracy1 is: 0.56922
I0112 08:33:37.301220 48059 solver.cpp:466]     Test net best accuracy5 is: 0.796541
I0112 08:33:38.026979 48059 solver.cpp:242] Iteration 34000 (0.690228 iter/s, 289.759s/200 iters), loss = 1.15913
I0112 08:33:38.029305 48059 solver.cpp:261]     Train net output #0: accuracy = 0.769531
I0112 08:33:38.029355 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.90625
I0112 08:33:38.029386 48059 solver.cpp:261]     Train net output #2: loss = 1.15913 (* 1 = 1.15913 loss)
I0112 08:33:38.029400 48059 sgd_solver.cpp:122] Iteration 34000, lr = 1e-06
I0112 08:36:14.106626 48059 solver.cpp:242] Iteration 34200 (1.28145 iter/s, 156.073s/200 iters), loss = 1.11152
I0112 08:36:14.106760 48059 solver.cpp:261]     Train net output #0: accuracy = 0.722656
I0112 08:36:14.106777 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.882812
I0112 08:36:14.106817 48059 solver.cpp:261]     Train net output #2: loss = 1.11152 (* 1 = 1.11152 loss)
I0112 08:36:14.106848 48059 sgd_solver.cpp:122] Iteration 34200, lr = 1e-06
I0112 08:38:53.625957 48059 solver.cpp:242] Iteration 34400 (1.25378 iter/s, 159.517s/200 iters), loss = 1.06622
I0112 08:38:53.637900 48059 solver.cpp:261]     Train net output #0: accuracy = 0.753906
I0112 08:38:53.637961 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.902344
I0112 08:38:53.637995 48059 solver.cpp:261]     Train net output #2: loss = 1.06622 (* 1 = 1.06622 loss)
I0112 08:38:53.638008 48059 sgd_solver.cpp:122] Iteration 34400, lr = 1e-06
I0112 08:39:05.009670 48059 blocking_queue.cpp:49] Waiting for data
I0112 08:41:25.852821 48059 solver.cpp:242] Iteration 34600 (1.31394 iter/s, 152.213s/200 iters), loss = 1.13397
I0112 08:41:25.865130 48059 solver.cpp:261]     Train net output #0: accuracy = 0.738281
I0112 08:41:25.865204 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.910156
I0112 08:41:25.865265 48059 solver.cpp:261]     Train net output #2: loss = 1.13397 (* 1 = 1.13397 loss)
I0112 08:41:25.865306 48059 sgd_solver.cpp:122] Iteration 34600, lr = 1e-06
I0112 08:43:57.220681 48059 solver.cpp:242] Iteration 34800 (1.32142 iter/s, 151.352s/200 iters), loss = 0.925379
I0112 08:43:57.232585 48059 solver.cpp:261]     Train net output #0: accuracy = 0.769531
I0112 08:43:57.232658 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.929688
I0112 08:43:57.232722 48059 solver.cpp:261]     Train net output #2: loss = 0.925379 (* 1 = 0.925379 loss)
I0112 08:43:57.232745 48059 sgd_solver.cpp:122] Iteration 34800, lr = 1e-06
I0112 08:46:28.876508 48059 solver.cpp:384] Iteration 35000, Testing net (#0)
I0112 08:47:31.130599 48059 blocking_queue.cpp:49] Waiting for data
I0112 08:49:04.575263 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 08:49:04.627370 48059 solver.cpp:452]     Test net output #0: accuracy = 0.568599
I0112 08:49:04.627441 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.79544
I0112 08:49:04.627465 48059 solver.cpp:452]     Test net output #2: loss = 1.90583 (* 1 = 1.90583 loss)
I0112 08:49:04.627477 48059 solver.cpp:463] ================================
I0112 08:49:04.627483 48059 solver.cpp:464]     Test net best accuracy1 is: 0.56922
I0112 08:49:04.627492 48059 solver.cpp:466]     Test net best accuracy5 is: 0.796541
I0112 08:49:05.351325 48059 solver.cpp:242] Iteration 35000 (0.649116 iter/s, 308.111s/200 iters), loss = 0.953689
I0112 08:49:05.351430 48059 solver.cpp:261]     Train net output #0: accuracy = 0.765625
I0112 08:49:05.351444 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.910156
I0112 08:49:05.351483 48059 solver.cpp:261]     Train net output #2: loss = 0.953689 (* 1 = 0.953689 loss)
I0112 08:49:05.351502 48059 sgd_solver.cpp:122] Iteration 35000, lr = 1e-06
I0112 08:49:27.729090 48149 data_layer.cpp:73] Restarting data prefetching from start.
I0112 08:51:37.143036 48059 solver.cpp:242] Iteration 35200 (1.31763 iter/s, 151.788s/200 iters), loss = 1.22696
I0112 08:51:37.154785 48059 solver.cpp:261]     Train net output #0: accuracy = 0.6875
I0112 08:51:37.154808 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.886719
I0112 08:51:37.154839 48059 solver.cpp:261]     Train net output #2: loss = 1.22696 (* 1 = 1.22696 loss)
I0112 08:51:37.154857 48059 sgd_solver.cpp:122] Iteration 35200, lr = 1e-06
I0112 08:54:08.989205 48059 solver.cpp:242] Iteration 35400 (1.31725 iter/s, 151.831s/200 iters), loss = 1.28694
I0112 08:54:08.989362 48059 solver.cpp:261]     Train net output #0: accuracy = 0.710938
I0112 08:54:08.989382 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.871094
I0112 08:54:08.989425 48059 solver.cpp:261]     Train net output #2: loss = 1.28694 (* 1 = 1.28694 loss)
I0112 08:54:08.989447 48059 sgd_solver.cpp:122] Iteration 35400, lr = 1e-06
I0112 08:54:30.366472 48059 blocking_queue.cpp:49] Waiting for data
I0112 08:56:40.580883 48059 solver.cpp:242] Iteration 35600 (1.31936 iter/s, 151.588s/200 iters), loss = 1.2028
I0112 08:56:40.580983 48059 solver.cpp:261]     Train net output #0: accuracy = 0.71875
I0112 08:56:40.580996 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.890625
I0112 08:56:40.581018 48059 solver.cpp:261]     Train net output #2: loss = 1.2028 (* 1 = 1.2028 loss)
I0112 08:56:40.581032 48059 sgd_solver.cpp:122] Iteration 35600, lr = 1e-06
I0112 08:59:14.295754 48059 solver.cpp:242] Iteration 35800 (1.30113 iter/s, 153.712s/200 iters), loss = 1.12161
I0112 08:59:14.307497 48059 solver.cpp:261]     Train net output #0: accuracy = 0.710938
I0112 08:59:14.307523 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.929688
I0112 08:59:14.307551 48059 solver.cpp:261]     Train net output #2: loss = 1.12161 (* 1 = 1.12161 loss)
I0112 08:59:14.307564 48059 sgd_solver.cpp:122] Iteration 35800, lr = 1e-06
I0112 09:01:48.753690 48059 solver.cpp:384] Iteration 36000, Testing net (#0)
I0112 09:02:51.493091 48059 blocking_queue.cpp:49] Waiting for data
I0112 09:04:21.853206 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 09:04:21.905328 48059 solver.cpp:452]     Test net output #0: accuracy = 0.56828
I0112 09:04:21.905412 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.796341
I0112 09:04:21.905444 48059 solver.cpp:452]     Test net output #2: loss = 1.90096 (* 1 = 1.90096 loss)
I0112 09:04:21.905458 48059 solver.cpp:463] ================================
I0112 09:04:21.905467 48059 solver.cpp:464]     Test net best accuracy1 is: 0.56922
I0112 09:04:21.905478 48059 solver.cpp:466]     Test net best accuracy5 is: 0.796541
I0112 09:04:22.624433 48059 solver.cpp:242] Iteration 36000 (0.648699 iter/s, 308.309s/200 iters), loss = 1.12234
I0112 09:04:22.626773 48059 solver.cpp:261]     Train net output #0: accuracy = 0.683594
I0112 09:04:22.626824 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.929688
I0112 09:04:22.626875 48059 solver.cpp:261]     Train net output #2: loss = 1.12234 (* 1 = 1.12234 loss)
I0112 09:04:22.626899 48059 sgd_solver.cpp:122] Iteration 36000, lr = 1e-06
I0112 09:06:55.686422 48059 solver.cpp:242] Iteration 36200 (1.30672 iter/s, 153.055s/200 iters), loss = 1.19
I0112 09:06:55.698635 48059 solver.cpp:261]     Train net output #0: accuracy = 0.742188
I0112 09:06:55.698727 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.910156
I0112 09:06:55.698781 48059 solver.cpp:261]     Train net output #2: loss = 1.19 (* 1 = 1.19 loss)
I0112 09:06:55.698801 48059 sgd_solver.cpp:122] Iteration 36200, lr = 1e-06
I0112 09:09:30.318217 48059 solver.cpp:242] Iteration 36400 (1.29354 iter/s, 154.615s/200 iters), loss = 1.06908
I0112 09:09:30.318349 48059 solver.cpp:261]     Train net output #0: accuracy = 0.753906
I0112 09:09:30.318367 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.902344
I0112 09:09:30.318397 48059 solver.cpp:261]     Train net output #2: loss = 1.06908 (* 1 = 1.06908 loss)
I0112 09:09:30.318414 48059 sgd_solver.cpp:122] Iteration 36400, lr = 1e-06
I0112 09:10:03.153601 48059 blocking_queue.cpp:49] Waiting for data
I0112 09:12:09.047235 48059 solver.cpp:242] Iteration 36600 (1.26005 iter/s, 158.724s/200 iters), loss = 1.05816
I0112 09:12:09.058995 48059 solver.cpp:261]     Train net output #0: accuracy = 0.691406
I0112 09:12:09.059060 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.917969
I0112 09:12:09.059100 48059 solver.cpp:261]     Train net output #2: loss = 1.05816 (* 1 = 1.05816 loss)
I0112 09:12:09.059115 48059 sgd_solver.cpp:122] Iteration 36600, lr = 1e-06
I0112 09:14:47.232275 48059 solver.cpp:242] Iteration 36800 (1.26447 iter/s, 158.169s/200 iters), loss = 1.03614
I0112 09:14:47.232379 48059 solver.cpp:261]     Train net output #0: accuracy = 0.742188
I0112 09:14:47.232398 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.921875
I0112 09:14:47.232426 48059 solver.cpp:261]     Train net output #2: loss = 1.03614 (* 1 = 1.03614 loss)
I0112 09:14:47.232444 48059 sgd_solver.cpp:122] Iteration 36800, lr = 1e-06
I0112 09:17:22.642819 48059 solver.cpp:384] Iteration 37000, Testing net (#0)
I0112 09:18:35.555634 48059 blocking_queue.cpp:49] Waiting for data
I0112 09:20:07.743588 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 09:20:07.795557 48059 solver.cpp:452]     Test net output #0: accuracy = 0.569359
I0112 09:20:07.795660 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.796561
I0112 09:20:07.795682 48059 solver.cpp:452]     Test net output #2: loss = 1.90088 (* 1 = 1.90088 loss)
I0112 09:20:07.795699 48059 solver.cpp:463] ================================
I0112 09:20:07.795704 48059 solver.cpp:464]     Test net best accuracy1 is: 0.569359
I0112 09:20:07.795713 48059 solver.cpp:466]     Test net best accuracy5 is: 0.796561
I0112 09:20:08.524444 48059 solver.cpp:242] Iteration 37000 (0.622505 iter/s, 321.283s/200 iters), loss = 1.08253
I0112 09:20:08.526789 48059 solver.cpp:261]     Train net output #0: accuracy = 0.726562
I0112 09:20:08.526832 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.90625
I0112 09:20:08.526916 48059 solver.cpp:261]     Train net output #2: loss = 1.08253 (* 1 = 1.08253 loss)
I0112 09:20:08.526934 48059 sgd_solver.cpp:122] Iteration 37000, lr = 1e-06
I0112 09:22:43.425241 48059 solver.cpp:242] Iteration 37200 (1.29121 iter/s, 154.894s/200 iters), loss = 1.05077
I0112 09:22:43.425426 48059 solver.cpp:261]     Train net output #0: accuracy = 0.761719
I0112 09:22:43.425449 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.898438
I0112 09:22:43.425524 48059 solver.cpp:261]     Train net output #2: loss = 1.05077 (* 1 = 1.05077 loss)
I0112 09:22:43.425565 48059 sgd_solver.cpp:122] Iteration 37200, lr = 1e-06
I0112 09:25:17.508469 48059 solver.cpp:242] Iteration 37400 (1.29804 iter/s, 154.079s/200 iters), loss = 1.15396
I0112 09:25:17.520936 48059 solver.cpp:261]     Train net output #0: accuracy = 0.679688
I0112 09:25:17.520957 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.910156
I0112 09:25:17.520982 48059 solver.cpp:261]     Train net output #2: loss = 1.15396 (* 1 = 1.15396 loss)
I0112 09:25:17.520992 48059 sgd_solver.cpp:122] Iteration 37400, lr = 1e-06
I0112 09:26:02.581406 48059 blocking_queue.cpp:49] Waiting for data
I0112 09:28:13.346807 48059 solver.cpp:242] Iteration 37600 (1.13752 iter/s, 175.821s/200 iters), loss = 1.22717
I0112 09:28:13.346967 48059 solver.cpp:261]     Train net output #0: accuracy = 0.710938
I0112 09:28:13.346985 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.886719
I0112 09:28:13.347038 48059 solver.cpp:261]     Train net output #2: loss = 1.22717 (* 1 = 1.22717 loss)
I0112 09:28:13.347060 48059 sgd_solver.cpp:122] Iteration 37600, lr = 1e-06
I0112 09:30:59.921591 48059 solver.cpp:242] Iteration 37800 (1.2007 iter/s, 166.57s/200 iters), loss = 1.23314
I0112 09:30:59.921716 48059 solver.cpp:261]     Train net output #0: accuracy = 0.644531
I0112 09:30:59.921728 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.917969
I0112 09:30:59.921753 48059 solver.cpp:261]     Train net output #2: loss = 1.23314 (* 1 = 1.23314 loss)
I0112 09:30:59.921778 48059 sgd_solver.cpp:122] Iteration 37800, lr = 1e-06
I0112 09:33:39.143234 48059 solver.cpp:384] Iteration 38000, Testing net (#0)
I0112 09:34:59.499907 48059 blocking_queue.cpp:49] Waiting for data
I0112 09:36:27.926170 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 09:36:27.978577 48059 solver.cpp:452]     Test net output #0: accuracy = 0.56918
I0112 09:36:27.978782 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.79604
I0112 09:36:27.978822 48059 solver.cpp:452]     Test net output #2: loss = 1.90216 (* 1 = 1.90216 loss)
I0112 09:36:27.978849 48059 solver.cpp:463] ================================
I0112 09:36:27.978951 48059 solver.cpp:464]     Test net best accuracy1 is: 0.569359
I0112 09:36:27.978979 48059 solver.cpp:466]     Test net best accuracy5 is: 0.796561
I0112 09:36:28.700590 48059 solver.cpp:242] Iteration 38000 (0.608329 iter/s, 328.769s/200 iters), loss = 1.14165
I0112 09:36:28.702962 48059 solver.cpp:261]     Train net output #0: accuracy = 0.695312
I0112 09:36:28.702991 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.902344
I0112 09:36:28.703080 48059 solver.cpp:261]     Train net output #2: loss = 1.14165 (* 1 = 1.14165 loss)
I0112 09:36:28.703099 48059 sgd_solver.cpp:122] Iteration 38000, lr = 1e-06
I0112 09:39:05.385150 48059 solver.cpp:242] Iteration 38200 (1.27651 iter/s, 156.678s/200 iters), loss = 1.0692
I0112 09:39:05.396890 48059 solver.cpp:261]     Train net output #0: accuracy = 0.75
I0112 09:39:05.396942 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.9375
I0112 09:39:05.396983 48059 solver.cpp:261]     Train net output #2: loss = 1.0692 (* 1 = 1.0692 loss)
I0112 09:39:05.397051 48059 sgd_solver.cpp:122] Iteration 38200, lr = 1e-06
I0112 09:41:42.725165 48059 solver.cpp:242] Iteration 38400 (1.27127 iter/s, 157.324s/200 iters), loss = 1.01929
I0112 09:41:42.725368 48059 solver.cpp:261]     Train net output #0: accuracy = 0.753906
I0112 09:41:42.725394 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.914062
I0112 09:41:42.725447 48059 solver.cpp:261]     Train net output #2: loss = 1.01929 (* 1 = 1.01929 loss)
I0112 09:41:42.725466 48059 sgd_solver.cpp:122] Iteration 38400, lr = 1e-06
I0112 09:42:35.947429 48059 blocking_queue.cpp:49] Waiting for data
I0112 09:44:16.100415 48059 solver.cpp:242] Iteration 38600 (1.30403 iter/s, 153.371s/200 iters), loss = 1.11455
I0112 09:44:16.100525 48059 solver.cpp:261]     Train net output #0: accuracy = 0.742188
I0112 09:44:16.100538 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.902344
I0112 09:44:16.100569 48059 solver.cpp:261]     Train net output #2: loss = 1.11455 (* 1 = 1.11455 loss)
I0112 09:44:16.100584 48059 sgd_solver.cpp:122] Iteration 38600, lr = 1e-06
I0112 09:46:53.545307 48059 solver.cpp:242] Iteration 38800 (1.27032 iter/s, 157.44s/200 iters), loss = 1.12151
I0112 09:46:53.545459 48059 solver.cpp:261]     Train net output #0: accuracy = 0.726562
I0112 09:46:53.545473 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.914062
I0112 09:46:53.545516 48059 solver.cpp:261]     Train net output #2: loss = 1.12151 (* 1 = 1.12151 loss)
I0112 09:46:53.545533 48059 sgd_solver.cpp:122] Iteration 38800, lr = 1e-06
I0112 09:49:28.720407 48059 solver.cpp:384] Iteration 39000, Testing net (#0)
I0112 09:50:42.968992 48059 blocking_queue.cpp:49] Waiting for data
I0112 09:52:12.219974 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 09:52:12.272596 48059 solver.cpp:452]     Test net output #0: accuracy = 0.567979
I0112 09:52:12.272711 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.796842
I0112 09:52:12.272817 48059 solver.cpp:452]     Test net output #2: loss = 1.90416 (* 1 = 1.90416 loss)
I0112 09:52:12.272869 48059 solver.cpp:463] ================================
I0112 09:52:12.272922 48059 solver.cpp:464]     Test net best accuracy1 is: 0.569359
I0112 09:52:12.272964 48059 solver.cpp:466]     Test net best accuracy5 is: 0.796561
I0112 09:52:12.998334 48059 solver.cpp:242] Iteration 39000 (0.626089 iter/s, 319.444s/200 iters), loss = 1.01001
I0112 09:52:13.000653 48059 solver.cpp:261]     Train net output #0: accuracy = 0.757812
I0112 09:52:13.000713 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.914062
I0112 09:52:13.000844 48059 solver.cpp:261]     Train net output #2: loss = 1.01001 (* 1 = 1.01001 loss)
I0112 09:52:13.000887 48059 sgd_solver.cpp:122] Iteration 39000, lr = 1e-06
I0112 09:54:48.446322 48059 solver.cpp:242] Iteration 39200 (1.28666 iter/s, 155.441s/200 iters), loss = 1.06613
I0112 09:54:48.446458 48059 solver.cpp:261]     Train net output #0: accuracy = 0.734375
I0112 09:54:48.446475 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.917969
I0112 09:54:48.446514 48059 solver.cpp:261]     Train net output #2: loss = 1.06613 (* 1 = 1.06613 loss)
I0112 09:54:48.446566 48059 sgd_solver.cpp:122] Iteration 39200, lr = 1e-06
I0112 09:57:25.754313 48059 solver.cpp:242] Iteration 39400 (1.27143 iter/s, 157.303s/200 iters), loss = 1.13353
I0112 09:57:25.754415 48059 solver.cpp:261]     Train net output #0: accuracy = 0.738281
I0112 09:57:25.754428 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.886719
I0112 09:57:25.754451 48059 solver.cpp:261]     Train net output #2: loss = 1.13353 (* 1 = 1.13353 loss)
I0112 09:57:25.754463 48059 sgd_solver.cpp:122] Iteration 39400, lr = 1e-06
I0112 09:58:29.618851 48059 blocking_queue.cpp:49] Waiting for data
I0112 10:00:04.859787 48059 solver.cpp:242] Iteration 39600 (1.25707 iter/s, 159.101s/200 iters), loss = 0.900135
I0112 10:00:04.871863 48059 solver.cpp:261]     Train net output #0: accuracy = 0.800781
I0112 10:00:04.871927 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.941406
I0112 10:00:04.871958 48059 solver.cpp:261]     Train net output #2: loss = 0.900135 (* 1 = 0.900135 loss)
I0112 10:00:04.871973 48059 sgd_solver.cpp:122] Iteration 39600, lr = 1e-06
I0112 10:02:39.485129 48059 solver.cpp:242] Iteration 39800 (1.29359 iter/s, 154.609s/200 iters), loss = 0.989983
I0112 10:02:39.485316 48059 solver.cpp:261]     Train net output #0: accuracy = 0.777344
I0112 10:02:39.485337 48059 solver.cpp:261]     Train net output #1: accuracy_5 = 0.921875
I0112 10:02:39.485388 48059 solver.cpp:261]     Train net output #2: loss = 0.989983 (* 1 = 0.989983 loss)
I0112 10:02:39.485414 48059 sgd_solver.cpp:122] Iteration 39800, lr = 1e-06
I0112 10:05:16.341840 48059 solver.cpp:514] Snapshotting to binary proto file snapshot/solver_iter_40000.caffemodel
I0112 10:05:16.362251 48059 net.cpp:928] Serializing 40 layers
I0112 10:05:34.475147 48059 sgd_solver.cpp:311] Snapshotting solver state to binary proto file snapshot/solver_iter_40000.solverstate
I0112 10:05:36.742262 48059 solver.cpp:364] Iteration 40000, loss = 1.10053
I0112 10:05:36.742334 48059 solver.cpp:384] Iteration 40000, Testing net (#0)
I0112 10:07:11.652842 48059 blocking_queue.cpp:49] Waiting for data
I0112 10:08:43.509388 48261 data_layer.cpp:73] Restarting data prefetching from start.
I0112 10:08:43.569123 48059 solver.cpp:452]     Test net output #0: accuracy = 0.56884
I0112 10:08:43.569243 48059 solver.cpp:452]     Test net output #1: accuracy_5 = 0.796641
I0112 10:08:43.569283 48059 solver.cpp:452]     Test net output #2: loss = 1.90229 (* 1 = 1.90229 loss)
I0112 10:08:43.569306 48059 solver.cpp:463] ================================
I0112 10:08:43.569325 48059 solver.cpp:464]     Test net best accuracy1 is: 0.569359
I0112 10:08:43.569351 48059 solver.cpp:466]     Test net best accuracy5 is: 0.796561
I0112 10:08:43.569388 48059 solver.cpp:369] Optimization Done.
I0112 10:08:43.588455 48059 caffe.cpp:250] Optimization Done.
