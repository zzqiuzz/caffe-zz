I0111 22:29:42.504428 29996 upgrade_proto.cpp:1113] snapshot_prefix was a directory and is replaced to snapshot/solver
I0111 22:29:42.506294 29996 caffe.cpp:204] Using GPUs 5
I0111 22:29:45.076786 29996 caffe.cpp:209] GPU 5: GeForce GTX 1080 Ti
I0111 22:29:46.412436 29996 solver.cpp:45] Initializing solver from parameters: 
test_iter: 1000
test_interval: 1000
base_lr: 0.01
display: 200
max_iter: 1000000
lr_policy: "modified_lr"
momentum: 0.9
snapshot: 10000
snapshot_prefix: "snapshot/solver"
solver_mode: GPU
device_id: 5
net: "train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
weights: "snapshot/solver_iter_260000.caffemodel"
modified_lr {
  stepvalue: 30000
  stepvalue: 60000
  stepvalue: 90000
  stepvalue: 250000
  stepvalue: 310000
  stepvalue: 350000
  stepvalue: 400000
  stepvalue: 500000
  mlr: 5e-05
  mlr: 1e-05
  mlr: 1e-06
  mlr: 0.0005
  mlr: 0.0001
  mlr: 5e-05
  mlr: 1e-05
  mlr: 1e-06
  weight_decay: 0
  weight_decay: 0
  weight_decay: 0
  weight_decay: 0
  weight_decay: 0
  weight_decay: 0
  weight_decay: 0
  weight_decay: 0
}
I0111 22:29:46.413177 29996 solver.cpp:105] Creating training net from net file: train_test.prototxt
I0111 22:29:46.414938 29996 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0111 22:29:46.415271 29996 net.cpp:51] Initializing net from parameters: 
name: "AlexNet-BN"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/zhengzhe/Data/imagenet_shrt256/ilsvrc12_train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 96
    bias_term: false
    pad: 2
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "BinaryConvolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "BinaryConvolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "BinaryConvolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "BinaryConvolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "scale5"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "BinaryInnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4096
    bias_term: false
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn6"
  type: "BatchNorm"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "scale6"
  type: "Scale"
  bottom: "fc6"
  top: "fc6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "fc7"
  type: "BinaryInnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4096
    bias_term: false
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "scale7"
  type: "Scale"
  bottom: "fc7"
  top: "fc7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "accuracy_5"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy_5"
  accuracy_param {
    top_k: 5
  }
}
I0111 22:29:46.416242 29996 layer_factory.hpp:78] Creating layer data
I0111 22:29:46.416582 29996 db_lmdb.cpp:35] Opened lmdb /home/zhengzhe/Data/imagenet_shrt256/ilsvrc12_train_lmdb
I0111 22:29:46.416728 29996 net.cpp:84] Creating Layer data
I0111 22:29:46.416769 29996 net.cpp:380] data -> data
I0111 22:29:46.416962 29996 net.cpp:380] data -> label
I0111 22:29:46.419972 29996 data_layer.cpp:45] output data size: 256,3,224,224
I0111 22:29:46.836068 29996 base_data_layer.cpp:72] Initializing prefetch
I0111 22:29:47.512059 29996 base_data_layer.cpp:75] Prefetch initialized.
I0111 22:29:47.512135 29996 net.cpp:122] Setting up data
I0111 22:29:47.512192 29996 net.cpp:129] Top shape: 256 3 224 224 (38535168)
I0111 22:29:47.512229 29996 net.cpp:129] Top shape: 256 (256)
I0111 22:29:47.512234 29996 net.cpp:137] Memory required for data: 154141696
I0111 22:29:47.512287 29996 layer_factory.hpp:78] Creating layer label_data_1_split
I0111 22:29:47.512414 29996 net.cpp:84] Creating Layer label_data_1_split
I0111 22:29:47.512456 29996 net.cpp:406] label_data_1_split <- label
I0111 22:29:47.512537 29996 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0111 22:29:47.512595 29996 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0111 22:29:47.512653 29996 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0111 22:29:47.512822 29996 net.cpp:122] Setting up label_data_1_split
I0111 22:29:47.512838 29996 net.cpp:129] Top shape: 256 (256)
I0111 22:29:47.512852 29996 net.cpp:129] Top shape: 256 (256)
I0111 22:29:47.512861 29996 net.cpp:129] Top shape: 256 (256)
I0111 22:29:47.512881 29996 net.cpp:137] Memory required for data: 154144768
I0111 22:29:47.512888 29996 layer_factory.hpp:78] Creating layer conv1
I0111 22:29:47.512987 29996 net.cpp:84] Creating Layer conv1
I0111 22:29:47.513000 29996 net.cpp:406] conv1 <- data
I0111 22:29:47.513025 29996 net.cpp:380] conv1 -> conv1
I0111 22:29:49.355417 29996 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 127416
I0111 22:29:49.355790 29996 net.cpp:122] Setting up conv1
I0111 22:29:49.355825 29996 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0111 22:29:49.355865 29996 net.cpp:137] Memory required for data: 451514368
I0111 22:29:49.355979 29996 layer_factory.hpp:78] Creating layer bn1
I0111 22:29:49.356036 29996 net.cpp:84] Creating Layer bn1
I0111 22:29:49.356055 29996 net.cpp:406] bn1 <- conv1
I0111 22:29:49.356110 29996 net.cpp:367] bn1 -> conv1 (in-place)
I0111 22:29:49.357802 29996 net.cpp:122] Setting up bn1
I0111 22:29:49.357823 29996 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0111 22:29:49.357830 29996 net.cpp:137] Memory required for data: 748883968
I0111 22:29:49.357889 29996 layer_factory.hpp:78] Creating layer scale1
I0111 22:29:49.357941 29996 net.cpp:84] Creating Layer scale1
I0111 22:29:49.357954 29996 net.cpp:406] scale1 <- conv1
I0111 22:29:49.357983 29996 net.cpp:367] scale1 -> conv1 (in-place)
I0111 22:29:49.358094 29996 layer_factory.hpp:78] Creating layer scale1
I0111 22:29:49.358338 29996 net.cpp:122] Setting up scale1
I0111 22:29:49.358358 29996 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0111 22:29:49.358363 29996 net.cpp:137] Memory required for data: 1046253568
I0111 22:29:49.358395 29996 layer_factory.hpp:78] Creating layer relu1
I0111 22:29:49.358438 29996 net.cpp:84] Creating Layer relu1
I0111 22:29:49.358450 29996 net.cpp:406] relu1 <- conv1
I0111 22:29:49.358470 29996 net.cpp:367] relu1 -> conv1 (in-place)
I0111 22:29:49.359082 29996 net.cpp:122] Setting up relu1
I0111 22:29:49.359098 29996 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0111 22:29:49.359103 29996 net.cpp:137] Memory required for data: 1343623168
I0111 22:29:49.359113 29996 layer_factory.hpp:78] Creating layer pool1
I0111 22:29:49.359155 29996 net.cpp:84] Creating Layer pool1
I0111 22:29:49.359166 29996 net.cpp:406] pool1 <- conv1
I0111 22:29:49.359190 29996 net.cpp:380] pool1 -> pool1
I0111 22:29:49.359290 29996 net.cpp:122] Setting up pool1
I0111 22:29:49.359308 29996 net.cpp:129] Top shape: 256 96 27 27 (17915904)
I0111 22:29:49.359334 29996 net.cpp:137] Memory required for data: 1415286784
I0111 22:29:49.359350 29996 layer_factory.hpp:78] Creating layer conv2
I0111 22:29:49.359397 29996 net.cpp:84] Creating Layer conv2
I0111 22:29:49.359408 29996 net.cpp:406] conv2 <- pool1
I0111 22:29:49.359438 29996 net.cpp:380] conv2 -> conv2
I0111 22:29:49.417726 29996 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 19668
I0111 22:29:49.417790 29996 net.cpp:122] Setting up conv2
I0111 22:29:49.417817 29996 net.cpp:129] Top shape: 256 256 27 27 (47775744)
I0111 22:29:49.417826 29996 net.cpp:137] Memory required for data: 1606389760
I0111 22:29:49.417883 29996 layer_factory.hpp:78] Creating layer bn2
I0111 22:29:49.417934 29996 net.cpp:84] Creating Layer bn2
I0111 22:29:49.417948 29996 net.cpp:406] bn2 <- conv2
I0111 22:29:49.417980 29996 net.cpp:367] bn2 -> conv2 (in-place)
I0111 22:29:49.419651 29996 net.cpp:122] Setting up bn2
I0111 22:29:49.419682 29996 net.cpp:129] Top shape: 256 256 27 27 (47775744)
I0111 22:29:49.419700 29996 net.cpp:137] Memory required for data: 1797492736
I0111 22:29:49.419745 29996 layer_factory.hpp:78] Creating layer scale2
I0111 22:29:49.419802 29996 net.cpp:84] Creating Layer scale2
I0111 22:29:49.419809 29996 net.cpp:406] scale2 <- conv2
I0111 22:29:49.419849 29996 net.cpp:367] scale2 -> conv2 (in-place)
I0111 22:29:49.419948 29996 layer_factory.hpp:78] Creating layer scale2
I0111 22:29:49.420132 29996 net.cpp:122] Setting up scale2
I0111 22:29:49.420145 29996 net.cpp:129] Top shape: 256 256 27 27 (47775744)
I0111 22:29:49.420150 29996 net.cpp:137] Memory required for data: 1988595712
I0111 22:29:49.420164 29996 layer_factory.hpp:78] Creating layer relu2
I0111 22:29:49.420200 29996 net.cpp:84] Creating Layer relu2
I0111 22:29:49.420208 29996 net.cpp:406] relu2 <- conv2
I0111 22:29:49.420222 29996 net.cpp:367] relu2 -> conv2 (in-place)
I0111 22:29:49.420846 29996 net.cpp:122] Setting up relu2
I0111 22:29:49.420858 29996 net.cpp:129] Top shape: 256 256 27 27 (47775744)
I0111 22:29:49.420877 29996 net.cpp:137] Memory required for data: 2179698688
I0111 22:29:49.420886 29996 layer_factory.hpp:78] Creating layer pool2
I0111 22:29:49.420907 29996 net.cpp:84] Creating Layer pool2
I0111 22:29:49.420917 29996 net.cpp:406] pool2 <- conv2
I0111 22:29:49.420949 29996 net.cpp:380] pool2 -> pool2
I0111 22:29:49.421027 29996 net.cpp:122] Setting up pool2
I0111 22:29:49.421042 29996 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0111 22:29:49.421046 29996 net.cpp:137] Memory required for data: 2224001024
I0111 22:29:49.421052 29996 layer_factory.hpp:78] Creating layer conv3
I0111 22:29:49.421082 29996 net.cpp:84] Creating Layer conv3
I0111 22:29:49.421090 29996 net.cpp:406] conv3 <- pool2
I0111 22:29:49.421111 29996 net.cpp:380] conv3 -> conv3
I0111 22:29:49.510203 29996 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 18874368
I0111 22:29:49.510632 29996 net.cpp:122] Setting up conv3
I0111 22:29:49.510689 29996 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0111 22:29:49.510694 29996 net.cpp:137] Memory required for data: 2290454528
I0111 22:29:49.510732 29996 layer_factory.hpp:78] Creating layer bn3
I0111 22:29:49.510774 29996 net.cpp:84] Creating Layer bn3
I0111 22:29:49.510789 29996 net.cpp:406] bn3 <- conv3
I0111 22:29:49.510836 29996 net.cpp:367] bn3 -> conv3 (in-place)
I0111 22:29:49.511091 29996 net.cpp:122] Setting up bn3
I0111 22:29:49.511103 29996 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0111 22:29:49.511106 29996 net.cpp:137] Memory required for data: 2356908032
I0111 22:29:49.511128 29996 layer_factory.hpp:78] Creating layer scale3
I0111 22:29:49.511165 29996 net.cpp:84] Creating Layer scale3
I0111 22:29:49.511173 29996 net.cpp:406] scale3 <- conv3
I0111 22:29:49.511186 29996 net.cpp:367] scale3 -> conv3 (in-place)
I0111 22:29:49.511255 29996 layer_factory.hpp:78] Creating layer scale3
I0111 22:29:49.511451 29996 net.cpp:122] Setting up scale3
I0111 22:29:49.511462 29996 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0111 22:29:49.511466 29996 net.cpp:137] Memory required for data: 2423361536
I0111 22:29:49.511497 29996 layer_factory.hpp:78] Creating layer relu3
I0111 22:29:49.511515 29996 net.cpp:84] Creating Layer relu3
I0111 22:29:49.511523 29996 net.cpp:406] relu3 <- conv3
I0111 22:29:49.511535 29996 net.cpp:367] relu3 -> conv3 (in-place)
I0111 22:29:49.512439 29996 net.cpp:122] Setting up relu3
I0111 22:29:49.512459 29996 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0111 22:29:49.512465 29996 net.cpp:137] Memory required for data: 2489815040
I0111 22:29:49.512470 29996 layer_factory.hpp:78] Creating layer conv4
I0111 22:29:49.512518 29996 net.cpp:84] Creating Layer conv4
I0111 22:29:49.512529 29996 net.cpp:406] conv4 <- conv3
I0111 22:29:49.512552 29996 net.cpp:380] conv4 -> conv4
I0111 22:29:49.640009 29996 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 9840
I0111 22:29:49.640072 29996 net.cpp:122] Setting up conv4
I0111 22:29:49.640111 29996 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0111 22:29:49.640116 29996 net.cpp:137] Memory required for data: 2556268544
I0111 22:29:49.640152 29996 layer_factory.hpp:78] Creating layer bn4
I0111 22:29:49.640205 29996 net.cpp:84] Creating Layer bn4
I0111 22:29:49.640221 29996 net.cpp:406] bn4 <- conv4
I0111 22:29:49.640250 29996 net.cpp:367] bn4 -> conv4 (in-place)
I0111 22:29:49.640549 29996 net.cpp:122] Setting up bn4
I0111 22:29:49.640564 29996 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0111 22:29:49.640568 29996 net.cpp:137] Memory required for data: 2622722048
I0111 22:29:49.640590 29996 layer_factory.hpp:78] Creating layer scale4
I0111 22:29:49.640614 29996 net.cpp:84] Creating Layer scale4
I0111 22:29:49.640622 29996 net.cpp:406] scale4 <- conv4
I0111 22:29:49.640652 29996 net.cpp:367] scale4 -> conv4 (in-place)
I0111 22:29:49.640739 29996 layer_factory.hpp:78] Creating layer scale4
I0111 22:29:49.640913 29996 net.cpp:122] Setting up scale4
I0111 22:29:49.640926 29996 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0111 22:29:49.640931 29996 net.cpp:137] Memory required for data: 2689175552
I0111 22:29:49.640947 29996 layer_factory.hpp:78] Creating layer relu4
I0111 22:29:49.640965 29996 net.cpp:84] Creating Layer relu4
I0111 22:29:49.640974 29996 net.cpp:406] relu4 <- conv4
I0111 22:29:49.640986 29996 net.cpp:367] relu4 -> conv4 (in-place)
I0111 22:29:49.642772 29996 net.cpp:122] Setting up relu4
I0111 22:29:49.642812 29996 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0111 22:29:49.642817 29996 net.cpp:137] Memory required for data: 2755629056
I0111 22:29:49.642834 29996 layer_factory.hpp:78] Creating layer conv5
I0111 22:29:49.642918 29996 net.cpp:84] Creating Layer conv5
I0111 22:29:49.642936 29996 net.cpp:406] conv5 <- conv4
I0111 22:29:49.642982 29996 net.cpp:380] conv5 -> conv5
I0111 22:29:49.740989 29996 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 18874368
I0111 22:29:49.741363 29996 net.cpp:122] Setting up conv5
I0111 22:29:49.741392 29996 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0111 22:29:49.741400 29996 net.cpp:137] Memory required for data: 2799931392
I0111 22:29:49.741434 29996 layer_factory.hpp:78] Creating layer bn5
I0111 22:29:49.741475 29996 net.cpp:84] Creating Layer bn5
I0111 22:29:49.741492 29996 net.cpp:406] bn5 <- conv5
I0111 22:29:49.741523 29996 net.cpp:367] bn5 -> conv5 (in-place)
I0111 22:29:49.741824 29996 net.cpp:122] Setting up bn5
I0111 22:29:49.741837 29996 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0111 22:29:49.741842 29996 net.cpp:137] Memory required for data: 2844233728
I0111 22:29:49.741866 29996 layer_factory.hpp:78] Creating layer scale5
I0111 22:29:49.741891 29996 net.cpp:84] Creating Layer scale5
I0111 22:29:49.741899 29996 net.cpp:406] scale5 <- conv5
I0111 22:29:49.741914 29996 net.cpp:367] scale5 -> conv5 (in-place)
I0111 22:29:49.741998 29996 layer_factory.hpp:78] Creating layer scale5
I0111 22:29:49.742198 29996 net.cpp:122] Setting up scale5
I0111 22:29:49.742213 29996 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0111 22:29:49.742216 29996 net.cpp:137] Memory required for data: 2888536064
I0111 22:29:49.742250 29996 layer_factory.hpp:78] Creating layer relu5
I0111 22:29:49.742271 29996 net.cpp:84] Creating Layer relu5
I0111 22:29:49.742280 29996 net.cpp:406] relu5 <- conv5
I0111 22:29:49.742296 29996 net.cpp:367] relu5 -> conv5 (in-place)
I0111 22:29:49.743055 29996 net.cpp:122] Setting up relu5
I0111 22:29:49.743072 29996 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0111 22:29:49.743075 29996 net.cpp:137] Memory required for data: 2932838400
I0111 22:29:49.743083 29996 layer_factory.hpp:78] Creating layer pool5
I0111 22:29:49.743119 29996 net.cpp:84] Creating Layer pool5
I0111 22:29:49.743129 29996 net.cpp:406] pool5 <- conv5
I0111 22:29:49.743155 29996 net.cpp:380] pool5 -> pool5
I0111 22:29:49.743240 29996 net.cpp:122] Setting up pool5
I0111 22:29:49.743259 29996 net.cpp:129] Top shape: 256 256 6 6 (2359296)
I0111 22:29:49.743265 29996 net.cpp:137] Memory required for data: 2942275584
I0111 22:29:49.743271 29996 layer_factory.hpp:78] Creating layer fc6
I0111 22:29:49.743305 29996 net.cpp:84] Creating Layer fc6
I0111 22:29:49.743315 29996 net.cpp:406] fc6 <- pool5
I0111 22:29:49.743336 29996 net.cpp:380] fc6 -> fc6
I0111 22:29:54.766319 29996 net.cpp:122] Setting up fc6
I0111 22:29:54.766422 29996 net.cpp:129] Top shape: 256 4096 (1048576)
I0111 22:29:54.766472 29996 net.cpp:137] Memory required for data: 2946469888
I0111 22:29:54.766546 29996 layer_factory.hpp:78] Creating layer bn6
I0111 22:29:54.766623 29996 net.cpp:84] Creating Layer bn6
I0111 22:29:54.766655 29996 net.cpp:406] bn6 <- fc6
I0111 22:29:54.766700 29996 net.cpp:367] bn6 -> fc6 (in-place)
I0111 22:29:54.767138 29996 net.cpp:122] Setting up bn6
I0111 22:29:54.767154 29996 net.cpp:129] Top shape: 256 4096 (1048576)
I0111 22:29:54.767160 29996 net.cpp:137] Memory required for data: 2950664192
I0111 22:29:54.767232 29996 layer_factory.hpp:78] Creating layer scale6
I0111 22:29:54.767277 29996 net.cpp:84] Creating Layer scale6
I0111 22:29:54.767290 29996 net.cpp:406] scale6 <- fc6
I0111 22:29:54.767311 29996 net.cpp:367] scale6 -> fc6 (in-place)
I0111 22:29:54.767454 29996 layer_factory.hpp:78] Creating layer scale6
I0111 22:29:54.767745 29996 net.cpp:122] Setting up scale6
I0111 22:29:54.767765 29996 net.cpp:129] Top shape: 256 4096 (1048576)
I0111 22:29:54.767772 29996 net.cpp:137] Memory required for data: 2954858496
I0111 22:29:54.767799 29996 layer_factory.hpp:78] Creating layer relu6
I0111 22:29:54.767827 29996 net.cpp:84] Creating Layer relu6
I0111 22:29:54.767838 29996 net.cpp:406] relu6 <- fc6
I0111 22:29:54.767859 29996 net.cpp:367] relu6 -> fc6 (in-place)
I0111 22:29:54.769866 29996 net.cpp:122] Setting up relu6
I0111 22:29:54.769891 29996 net.cpp:129] Top shape: 256 4096 (1048576)
I0111 22:29:54.769898 29996 net.cpp:137] Memory required for data: 2959052800
I0111 22:29:54.769912 29996 layer_factory.hpp:78] Creating layer drop6
I0111 22:29:54.769953 29996 net.cpp:84] Creating Layer drop6
I0111 22:29:54.769966 29996 net.cpp:406] drop6 <- fc6
I0111 22:29:54.769995 29996 net.cpp:367] drop6 -> fc6 (in-place)
I0111 22:29:54.770092 29996 net.cpp:122] Setting up drop6
I0111 22:29:54.770108 29996 net.cpp:129] Top shape: 256 4096 (1048576)
I0111 22:29:54.770113 29996 net.cpp:137] Memory required for data: 2963247104
I0111 22:29:54.770124 29996 layer_factory.hpp:78] Creating layer fc7
I0111 22:29:54.770167 29996 net.cpp:84] Creating Layer fc7
I0111 22:29:54.770179 29996 net.cpp:406] fc7 <- fc6
I0111 22:29:54.770206 29996 net.cpp:380] fc7 -> fc7
I0111 22:29:57.041895 29996 net.cpp:122] Setting up fc7
I0111 22:29:57.041950 29996 net.cpp:129] Top shape: 256 4096 (1048576)
I0111 22:29:57.041954 29996 net.cpp:137] Memory required for data: 2967441408
I0111 22:29:57.041988 29996 layer_factory.hpp:78] Creating layer bn7
I0111 22:29:57.042037 29996 net.cpp:84] Creating Layer bn7
I0111 22:29:57.042057 29996 net.cpp:406] bn7 <- fc7
I0111 22:29:57.042093 29996 net.cpp:367] bn7 -> fc7 (in-place)
I0111 22:29:57.042397 29996 net.cpp:122] Setting up bn7
I0111 22:29:57.042412 29996 net.cpp:129] Top shape: 256 4096 (1048576)
I0111 22:29:57.042416 29996 net.cpp:137] Memory required for data: 2971635712
I0111 22:29:57.042448 29996 layer_factory.hpp:78] Creating layer scale7
I0111 22:29:57.042487 29996 net.cpp:84] Creating Layer scale7
I0111 22:29:57.042498 29996 net.cpp:406] scale7 <- fc7
I0111 22:29:57.042521 29996 net.cpp:367] scale7 -> fc7 (in-place)
I0111 22:29:57.042614 29996 layer_factory.hpp:78] Creating layer scale7
I0111 22:29:57.042815 29996 net.cpp:122] Setting up scale7
I0111 22:29:57.042829 29996 net.cpp:129] Top shape: 256 4096 (1048576)
I0111 22:29:57.042835 29996 net.cpp:137] Memory required for data: 2975830016
I0111 22:29:57.042856 29996 layer_factory.hpp:78] Creating layer relu7
I0111 22:29:57.042877 29996 net.cpp:84] Creating Layer relu7
I0111 22:29:57.042887 29996 net.cpp:406] relu7 <- fc7
I0111 22:29:57.042908 29996 net.cpp:367] relu7 -> fc7 (in-place)
I0111 22:29:57.043776 29996 net.cpp:122] Setting up relu7
I0111 22:29:57.043792 29996 net.cpp:129] Top shape: 256 4096 (1048576)
I0111 22:29:57.043797 29996 net.cpp:137] Memory required for data: 2980024320
I0111 22:29:57.043807 29996 layer_factory.hpp:78] Creating layer drop7
I0111 22:29:57.043833 29996 net.cpp:84] Creating Layer drop7
I0111 22:29:57.043843 29996 net.cpp:406] drop7 <- fc7
I0111 22:29:57.043865 29996 net.cpp:367] drop7 -> fc7 (in-place)
I0111 22:29:57.043943 29996 net.cpp:122] Setting up drop7
I0111 22:29:57.043956 29996 net.cpp:129] Top shape: 256 4096 (1048576)
I0111 22:29:57.043962 29996 net.cpp:137] Memory required for data: 2984218624
I0111 22:29:57.043969 29996 layer_factory.hpp:78] Creating layer fc8
I0111 22:29:57.044014 29996 net.cpp:84] Creating Layer fc8
I0111 22:29:57.044026 29996 net.cpp:406] fc8 <- fc7
I0111 22:29:57.044051 29996 net.cpp:380] fc8 -> fc8
I0111 22:29:57.413314 29996 net.cpp:122] Setting up fc8
I0111 22:29:57.413379 29996 net.cpp:129] Top shape: 256 1000 (256000)
I0111 22:29:57.413386 29996 net.cpp:137] Memory required for data: 2985242624
I0111 22:29:57.413426 29996 layer_factory.hpp:78] Creating layer fc8_fc8_0_split
I0111 22:29:57.413467 29996 net.cpp:84] Creating Layer fc8_fc8_0_split
I0111 22:29:57.413489 29996 net.cpp:406] fc8_fc8_0_split <- fc8
I0111 22:29:57.413516 29996 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0111 22:29:57.413563 29996 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0111 22:29:57.413588 29996 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0111 22:29:57.413707 29996 net.cpp:122] Setting up fc8_fc8_0_split
I0111 22:29:57.413727 29996 net.cpp:129] Top shape: 256 1000 (256000)
I0111 22:29:57.413753 29996 net.cpp:129] Top shape: 256 1000 (256000)
I0111 22:29:57.413760 29996 net.cpp:129] Top shape: 256 1000 (256000)
I0111 22:29:57.413765 29996 net.cpp:137] Memory required for data: 2988314624
I0111 22:29:57.413774 29996 layer_factory.hpp:78] Creating layer loss
I0111 22:29:57.413825 29996 net.cpp:84] Creating Layer loss
I0111 22:29:57.413852 29996 net.cpp:406] loss <- fc8_fc8_0_split_0
I0111 22:29:57.413883 29996 net.cpp:406] loss <- label_data_1_split_0
I0111 22:29:57.413918 29996 net.cpp:380] loss -> loss
I0111 22:29:57.413969 29996 layer_factory.hpp:78] Creating layer loss
I0111 22:29:57.417253 29996 net.cpp:122] Setting up loss
I0111 22:29:57.417292 29996 net.cpp:129] Top shape: (1)
I0111 22:29:57.417296 29996 net.cpp:132]     with loss weight 1
I0111 22:29:57.417371 29996 net.cpp:137] Memory required for data: 2988314628
I0111 22:29:57.417390 29996 layer_factory.hpp:78] Creating layer accuracy
I0111 22:29:57.417436 29996 net.cpp:84] Creating Layer accuracy
I0111 22:29:57.417455 29996 net.cpp:406] accuracy <- fc8_fc8_0_split_1
I0111 22:29:57.417510 29996 net.cpp:406] accuracy <- label_data_1_split_1
I0111 22:29:57.417532 29996 net.cpp:380] accuracy -> accuracy
I0111 22:29:57.417601 29996 net.cpp:122] Setting up accuracy
I0111 22:29:57.417635 29996 net.cpp:129] Top shape: (1)
I0111 22:29:57.417707 29996 net.cpp:137] Memory required for data: 2988314632
I0111 22:29:57.417732 29996 layer_factory.hpp:78] Creating layer accuracy_5
I0111 22:29:57.417768 29996 net.cpp:84] Creating Layer accuracy_5
I0111 22:29:57.417781 29996 net.cpp:406] accuracy_5 <- fc8_fc8_0_split_2
I0111 22:29:57.417801 29996 net.cpp:406] accuracy_5 <- label_data_1_split_2
I0111 22:29:57.417838 29996 net.cpp:380] accuracy_5 -> accuracy_5
I0111 22:29:57.417902 29996 net.cpp:122] Setting up accuracy_5
I0111 22:29:57.417917 29996 net.cpp:129] Top shape: (1)
I0111 22:29:57.417923 29996 net.cpp:137] Memory required for data: 2988314636
I0111 22:29:57.417935 29996 net.cpp:200] accuracy_5 does not need backward computation.
I0111 22:29:57.417946 29996 net.cpp:200] accuracy does not need backward computation.
I0111 22:29:57.417968 29996 net.cpp:198] loss needs backward computation.
I0111 22:29:57.417979 29996 net.cpp:198] fc8_fc8_0_split needs backward computation.
I0111 22:29:57.417987 29996 net.cpp:198] fc8 needs backward computation.
I0111 22:29:57.417997 29996 net.cpp:198] drop7 needs backward computation.
I0111 22:29:57.418009 29996 net.cpp:198] relu7 needs backward computation.
I0111 22:29:57.418017 29996 net.cpp:198] scale7 needs backward computation.
I0111 22:29:57.418026 29996 net.cpp:198] bn7 needs backward computation.
I0111 22:29:57.418033 29996 net.cpp:198] fc7 needs backward computation.
I0111 22:29:57.418043 29996 net.cpp:198] drop6 needs backward computation.
I0111 22:29:57.418051 29996 net.cpp:198] relu6 needs backward computation.
I0111 22:29:57.418074 29996 net.cpp:198] scale6 needs backward computation.
I0111 22:29:57.418083 29996 net.cpp:198] bn6 needs backward computation.
I0111 22:29:57.418090 29996 net.cpp:198] fc6 needs backward computation.
I0111 22:29:57.418098 29996 net.cpp:198] pool5 needs backward computation.
I0111 22:29:57.418108 29996 net.cpp:198] relu5 needs backward computation.
I0111 22:29:57.418117 29996 net.cpp:198] scale5 needs backward computation.
I0111 22:29:57.418125 29996 net.cpp:198] bn5 needs backward computation.
I0111 22:29:57.418138 29996 net.cpp:198] conv5 needs backward computation.
I0111 22:29:57.418149 29996 net.cpp:198] relu4 needs backward computation.
I0111 22:29:57.418157 29996 net.cpp:198] scale4 needs backward computation.
I0111 22:29:57.418166 29996 net.cpp:198] bn4 needs backward computation.
I0111 22:29:57.418176 29996 net.cpp:198] conv4 needs backward computation.
I0111 22:29:57.418186 29996 net.cpp:198] relu3 needs backward computation.
I0111 22:29:57.418195 29996 net.cpp:198] scale3 needs backward computation.
I0111 22:29:57.418205 29996 net.cpp:198] bn3 needs backward computation.
I0111 22:29:57.418215 29996 net.cpp:198] conv3 needs backward computation.
I0111 22:29:57.418224 29996 net.cpp:198] pool2 needs backward computation.
I0111 22:29:57.418236 29996 net.cpp:198] relu2 needs backward computation.
I0111 22:29:57.418243 29996 net.cpp:198] scale2 needs backward computation.
I0111 22:29:57.418252 29996 net.cpp:198] bn2 needs backward computation.
I0111 22:29:57.418260 29996 net.cpp:198] conv2 needs backward computation.
I0111 22:29:57.418270 29996 net.cpp:198] pool1 needs backward computation.
I0111 22:29:57.418282 29996 net.cpp:198] relu1 needs backward computation.
I0111 22:29:57.418292 29996 net.cpp:198] scale1 needs backward computation.
I0111 22:29:57.418301 29996 net.cpp:198] bn1 needs backward computation.
I0111 22:29:57.418311 29996 net.cpp:198] conv1 needs backward computation.
I0111 22:29:57.418323 29996 net.cpp:200] label_data_1_split does not need backward computation.
I0111 22:29:57.418334 29996 net.cpp:200] data does not need backward computation.
I0111 22:29:57.418356 29996 net.cpp:242] This network produces output accuracy
I0111 22:29:57.418370 29996 net.cpp:242] This network produces output accuracy_5
I0111 22:29:57.418378 29996 net.cpp:242] This network produces output loss
I0111 22:29:57.418438 29996 net.cpp:255] Network initialization done.
I0111 22:29:57.418798 29996 solver.cpp:75] Finetuning from snapshot/solver_iter_260000.caffemodel
I0111 22:30:10.895046 29996 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: snapshot/solver_iter_260000.caffemodel
I0111 22:30:10.895157 29996 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0111 22:30:10.895185 29996 net.cpp:824] Copying source layer data
I0111 22:30:10.895198 29996 net.cpp:824] Copying source layer label_data_1_split
I0111 22:30:10.895210 29996 net.cpp:824] Copying source layer conv1
I0111 22:30:10.896519 29996 net.cpp:824] Copying source layer bn1
I0111 22:30:10.896839 29996 net.cpp:824] Copying source layer scale1
I0111 22:30:10.896898 29996 net.cpp:824] Copying source layer relu1
I0111 22:30:10.896911 29996 net.cpp:824] Copying source layer pool1
I0111 22:30:10.896914 29996 net.cpp:824] Copying source layer conv2
I0111 22:30:10.906841 29996 net.cpp:824] Copying source layer bn2
I0111 22:30:10.907088 29996 net.cpp:824] Copying source layer scale2
I0111 22:30:10.907166 29996 net.cpp:824] Copying source layer relu2
I0111 22:30:10.907193 29996 net.cpp:824] Copying source layer pool2
I0111 22:30:10.907208 29996 net.cpp:824] Copying source layer conv3
I0111 22:30:10.920936 29996 net.cpp:824] Copying source layer bn3
I0111 22:30:10.921286 29996 net.cpp:824] Copying source layer scale3
I0111 22:30:10.921366 29996 net.cpp:824] Copying source layer relu3
I0111 22:30:10.921388 29996 net.cpp:824] Copying source layer conv4
I0111 22:30:10.941999 29996 net.cpp:824] Copying source layer bn4
I0111 22:30:10.942239 29996 net.cpp:824] Copying source layer scale4
I0111 22:30:10.942346 29996 net.cpp:824] Copying source layer relu4
I0111 22:30:10.942361 29996 net.cpp:824] Copying source layer conv5
I0111 22:30:10.956032 29996 net.cpp:824] Copying source layer bn5
I0111 22:30:10.956252 29996 net.cpp:824] Copying source layer scale5
I0111 22:30:10.956326 29996 net.cpp:824] Copying source layer relu5
I0111 22:30:10.956334 29996 net.cpp:824] Copying source layer pool5
I0111 22:30:10.956343 29996 net.cpp:824] Copying source layer fc6
I0111 22:30:11.862092 29996 net.cpp:824] Copying source layer bn6
I0111 22:30:11.862836 29996 net.cpp:824] Copying source layer scale6
I0111 22:30:11.863171 29996 net.cpp:824] Copying source layer relu6
I0111 22:30:11.863196 29996 net.cpp:824] Copying source layer drop6
I0111 22:30:11.863211 29996 net.cpp:824] Copying source layer fc7
I0111 22:30:12.272370 29996 net.cpp:824] Copying source layer bn7
I0111 22:30:12.272704 29996 net.cpp:824] Copying source layer scale7
I0111 22:30:12.272856 29996 net.cpp:824] Copying source layer relu7
I0111 22:30:12.272863 29996 net.cpp:824] Copying source layer drop7
I0111 22:30:12.272867 29996 net.cpp:824] Copying source layer fc8
I0111 22:30:12.332628 29996 net.cpp:824] Copying source layer fc8_fc8_0_split
I0111 22:30:12.332689 29996 net.cpp:824] Copying source layer loss
I0111 22:30:12.332695 29996 net.cpp:824] Copying source layer accuracy
I0111 22:30:12.332697 29996 net.cpp:824] Copying source layer accuracy_5
I0111 22:30:12.361296 29996 solver.cpp:193] Creating test net (#0) specified by net file: train_test.prototxt
I0111 22:30:12.361501 29996 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0111 22:30:12.361764 29996 net.cpp:51] Initializing net from parameters: 
name: "AlexNet-BN"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 224
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/zhengzhe/Data/imagenet_shrt256/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 96
    bias_term: false
    pad: 2
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "BinaryConvolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "BinaryConvolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "BinaryConvolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "BinaryConvolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "scale5"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "BinaryInnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4096
    bias_term: false
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn6"
  type: "BatchNorm"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "scale6"
  type: "Scale"
  bottom: "fc6"
  top: "fc6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "fc7"
  type: "BinaryInnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4096
    bias_term: false
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "scale7"
  type: "Scale"
  bottom: "fc7"
  top: "fc7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "accuracy_5"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy_5"
  accuracy_param {
    top_k: 5
  }
}
I0111 22:30:12.362262 29996 layer_factory.hpp:78] Creating layer data
I0111 22:30:12.362416 29996 db_lmdb.cpp:35] Opened lmdb /home/zhengzhe/Data/imagenet_shrt256/ilsvrc12_val_lmdb
I0111 22:30:12.362454 29996 net.cpp:84] Creating Layer data
I0111 22:30:12.362478 29996 net.cpp:380] data -> data
I0111 22:30:12.362530 29996 net.cpp:380] data -> label
I0111 22:30:12.363147 29996 data_layer.cpp:45] output data size: 50,3,224,224
I0111 22:30:12.449060 29996 base_data_layer.cpp:72] Initializing prefetch
I0111 22:30:13.338477 29996 base_data_layer.cpp:75] Prefetch initialized.
I0111 22:30:13.338539 29996 net.cpp:122] Setting up data
I0111 22:30:13.338564 29996 net.cpp:129] Top shape: 50 3 224 224 (7526400)
I0111 22:30:13.338572 29996 net.cpp:129] Top shape: 50 (50)
I0111 22:30:13.338574 29996 net.cpp:137] Memory required for data: 30105800
I0111 22:30:13.338601 29996 layer_factory.hpp:78] Creating layer label_data_1_split
I0111 22:30:13.338662 29996 net.cpp:84] Creating Layer label_data_1_split
I0111 22:30:13.338677 29996 net.cpp:406] label_data_1_split <- label
I0111 22:30:13.338713 29996 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0111 22:30:13.338752 29996 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0111 22:30:13.338766 29996 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0111 22:30:13.339198 29996 net.cpp:122] Setting up label_data_1_split
I0111 22:30:13.339223 29996 net.cpp:129] Top shape: 50 (50)
I0111 22:30:13.339238 29996 net.cpp:129] Top shape: 50 (50)
I0111 22:30:13.339248 29996 net.cpp:129] Top shape: 50 (50)
I0111 22:30:13.339254 29996 net.cpp:137] Memory required for data: 30106400
I0111 22:30:13.339265 29996 layer_factory.hpp:78] Creating layer conv1
I0111 22:30:13.339329 29996 net.cpp:84] Creating Layer conv1
I0111 22:30:13.339356 29996 net.cpp:406] conv1 <- data
I0111 22:30:13.339390 29996 net.cpp:380] conv1 -> conv1
I0111 22:30:13.350248 29996 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 127416
I0111 22:30:13.350417 29996 net.cpp:122] Setting up conv1
I0111 22:30:13.350445 29996 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0111 22:30:13.350527 29996 net.cpp:137] Memory required for data: 88186400
I0111 22:30:13.350600 29996 layer_factory.hpp:78] Creating layer bn1
I0111 22:30:13.350642 29996 net.cpp:84] Creating Layer bn1
I0111 22:30:13.350658 29996 net.cpp:406] bn1 <- conv1
I0111 22:30:13.350716 29996 net.cpp:367] bn1 -> conv1 (in-place)
I0111 22:30:13.351138 29996 net.cpp:122] Setting up bn1
I0111 22:30:13.351156 29996 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0111 22:30:13.351163 29996 net.cpp:137] Memory required for data: 146266400
I0111 22:30:13.351213 29996 layer_factory.hpp:78] Creating layer scale1
I0111 22:30:13.351250 29996 net.cpp:84] Creating Layer scale1
I0111 22:30:13.351263 29996 net.cpp:406] scale1 <- conv1
I0111 22:30:13.351284 29996 net.cpp:367] scale1 -> conv1 (in-place)
I0111 22:30:13.351397 29996 layer_factory.hpp:78] Creating layer scale1
I0111 22:30:13.351737 29996 net.cpp:122] Setting up scale1
I0111 22:30:13.351754 29996 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0111 22:30:13.351759 29996 net.cpp:137] Memory required for data: 204346400
I0111 22:30:13.351794 29996 layer_factory.hpp:78] Creating layer relu1
I0111 22:30:13.351816 29996 net.cpp:84] Creating Layer relu1
I0111 22:30:13.351826 29996 net.cpp:406] relu1 <- conv1
I0111 22:30:13.351846 29996 net.cpp:367] relu1 -> conv1 (in-place)
I0111 22:30:13.352838 29996 net.cpp:122] Setting up relu1
I0111 22:30:13.352864 29996 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0111 22:30:13.352870 29996 net.cpp:137] Memory required for data: 262426400
I0111 22:30:13.352880 29996 layer_factory.hpp:78] Creating layer pool1
I0111 22:30:13.352911 29996 net.cpp:84] Creating Layer pool1
I0111 22:30:13.352923 29996 net.cpp:406] pool1 <- conv1
I0111 22:30:13.352947 29996 net.cpp:380] pool1 -> pool1
I0111 22:30:13.353051 29996 net.cpp:122] Setting up pool1
I0111 22:30:13.353070 29996 net.cpp:129] Top shape: 50 96 27 27 (3499200)
I0111 22:30:13.353075 29996 net.cpp:137] Memory required for data: 276423200
I0111 22:30:13.353085 29996 layer_factory.hpp:78] Creating layer conv2
I0111 22:30:13.353121 29996 net.cpp:84] Creating Layer conv2
I0111 22:30:13.353133 29996 net.cpp:406] conv2 <- pool1
I0111 22:30:13.353163 29996 net.cpp:380] conv2 -> conv2
I0111 22:30:13.434697 29996 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 19668
I0111 22:30:13.434762 29996 net.cpp:122] Setting up conv2
I0111 22:30:13.434787 29996 net.cpp:129] Top shape: 50 256 27 27 (9331200)
I0111 22:30:13.434826 29996 net.cpp:137] Memory required for data: 313748000
I0111 22:30:13.434876 29996 layer_factory.hpp:78] Creating layer bn2
I0111 22:30:13.434993 29996 net.cpp:84] Creating Layer bn2
I0111 22:30:13.435014 29996 net.cpp:406] bn2 <- conv2
I0111 22:30:13.435101 29996 net.cpp:367] bn2 -> conv2 (in-place)
I0111 22:30:13.435716 29996 net.cpp:122] Setting up bn2
I0111 22:30:13.435750 29996 net.cpp:129] Top shape: 50 256 27 27 (9331200)
I0111 22:30:13.435762 29996 net.cpp:137] Memory required for data: 351072800
I0111 22:30:13.435863 29996 layer_factory.hpp:78] Creating layer scale2
I0111 22:30:13.435912 29996 net.cpp:84] Creating Layer scale2
I0111 22:30:13.435935 29996 net.cpp:406] scale2 <- conv2
I0111 22:30:13.435979 29996 net.cpp:367] scale2 -> conv2 (in-place)
I0111 22:30:13.436158 29996 layer_factory.hpp:78] Creating layer scale2
I0111 22:30:13.436676 29996 net.cpp:122] Setting up scale2
I0111 22:30:13.436702 29996 net.cpp:129] Top shape: 50 256 27 27 (9331200)
I0111 22:30:13.436714 29996 net.cpp:137] Memory required for data: 388397600
I0111 22:30:13.436758 29996 layer_factory.hpp:78] Creating layer relu2
I0111 22:30:13.436796 29996 net.cpp:84] Creating Layer relu2
I0111 22:30:13.436818 29996 net.cpp:406] relu2 <- conv2
I0111 22:30:13.436858 29996 net.cpp:367] relu2 -> conv2 (in-place)
I0111 22:30:13.438546 29996 net.cpp:122] Setting up relu2
I0111 22:30:13.438575 29996 net.cpp:129] Top shape: 50 256 27 27 (9331200)
I0111 22:30:13.438588 29996 net.cpp:137] Memory required for data: 425722400
I0111 22:30:13.438607 29996 layer_factory.hpp:78] Creating layer pool2
I0111 22:30:13.438655 29996 net.cpp:84] Creating Layer pool2
I0111 22:30:13.438678 29996 net.cpp:406] pool2 <- conv2
I0111 22:30:13.438733 29996 net.cpp:380] pool2 -> pool2
I0111 22:30:13.438913 29996 net.cpp:122] Setting up pool2
I0111 22:30:13.438949 29996 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0111 22:30:13.438963 29996 net.cpp:137] Memory required for data: 434375200
I0111 22:30:13.438980 29996 layer_factory.hpp:78] Creating layer conv3
I0111 22:30:13.439049 29996 net.cpp:84] Creating Layer conv3
I0111 22:30:13.439072 29996 net.cpp:406] conv3 <- pool2
I0111 22:30:13.439124 29996 net.cpp:380] conv3 -> conv3
I0111 22:30:13.557418 29996 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 18874368
I0111 22:30:13.557855 29996 net.cpp:122] Setting up conv3
I0111 22:30:13.557889 29996 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0111 22:30:13.557899 29996 net.cpp:137] Memory required for data: 447354400
I0111 22:30:13.557938 29996 layer_factory.hpp:78] Creating layer bn3
I0111 22:30:13.557976 29996 net.cpp:84] Creating Layer bn3
I0111 22:30:13.557991 29996 net.cpp:406] bn3 <- conv3
I0111 22:30:13.558025 29996 net.cpp:367] bn3 -> conv3 (in-place)
I0111 22:30:13.558380 29996 net.cpp:122] Setting up bn3
I0111 22:30:13.558394 29996 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0111 22:30:13.558398 29996 net.cpp:137] Memory required for data: 460333600
I0111 22:30:13.558423 29996 layer_factory.hpp:78] Creating layer scale3
I0111 22:30:13.558447 29996 net.cpp:84] Creating Layer scale3
I0111 22:30:13.558456 29996 net.cpp:406] scale3 <- conv3
I0111 22:30:13.558475 29996 net.cpp:367] scale3 -> conv3 (in-place)
I0111 22:30:13.558568 29996 layer_factory.hpp:78] Creating layer scale3
I0111 22:30:13.558804 29996 net.cpp:122] Setting up scale3
I0111 22:30:13.558818 29996 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0111 22:30:13.558823 29996 net.cpp:137] Memory required for data: 473312800
I0111 22:30:13.558861 29996 layer_factory.hpp:78] Creating layer relu3
I0111 22:30:13.558882 29996 net.cpp:84] Creating Layer relu3
I0111 22:30:13.558892 29996 net.cpp:406] relu3 <- conv3
I0111 22:30:13.558910 29996 net.cpp:367] relu3 -> conv3 (in-place)
I0111 22:30:13.559995 29996 net.cpp:122] Setting up relu3
I0111 22:30:13.560014 29996 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0111 22:30:13.560019 29996 net.cpp:137] Memory required for data: 486292000
I0111 22:30:13.560039 29996 layer_factory.hpp:78] Creating layer conv4
I0111 22:30:13.560087 29996 net.cpp:84] Creating Layer conv4
I0111 22:30:13.560101 29996 net.cpp:406] conv4 <- conv3
I0111 22:30:13.560154 29996 net.cpp:380] conv4 -> conv4
I0111 22:30:13.740411 29996 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 9840
I0111 22:30:13.740497 29996 net.cpp:122] Setting up conv4
I0111 22:30:13.740521 29996 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0111 22:30:13.740528 29996 net.cpp:137] Memory required for data: 499271200
I0111 22:30:13.740558 29996 layer_factory.hpp:78] Creating layer bn4
I0111 22:30:13.740593 29996 net.cpp:84] Creating Layer bn4
I0111 22:30:13.740612 29996 net.cpp:406] bn4 <- conv4
I0111 22:30:13.740658 29996 net.cpp:367] bn4 -> conv4 (in-place)
I0111 22:30:13.741158 29996 net.cpp:122] Setting up bn4
I0111 22:30:13.741191 29996 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0111 22:30:13.741196 29996 net.cpp:137] Memory required for data: 512250400
I0111 22:30:13.741235 29996 layer_factory.hpp:78] Creating layer scale4
I0111 22:30:13.741271 29996 net.cpp:84] Creating Layer scale4
I0111 22:30:13.741283 29996 net.cpp:406] scale4 <- conv4
I0111 22:30:13.741312 29996 net.cpp:367] scale4 -> conv4 (in-place)
I0111 22:30:13.741457 29996 layer_factory.hpp:78] Creating layer scale4
I0111 22:30:13.741782 29996 net.cpp:122] Setting up scale4
I0111 22:30:13.741814 29996 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0111 22:30:13.741832 29996 net.cpp:137] Memory required for data: 525229600
I0111 22:30:13.741854 29996 layer_factory.hpp:78] Creating layer relu4
I0111 22:30:13.741880 29996 net.cpp:84] Creating Layer relu4
I0111 22:30:13.741894 29996 net.cpp:406] relu4 <- conv4
I0111 22:30:13.741919 29996 net.cpp:367] relu4 -> conv4 (in-place)
I0111 22:30:13.743082 29996 net.cpp:122] Setting up relu4
I0111 22:30:13.743105 29996 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0111 22:30:13.743120 29996 net.cpp:137] Memory required for data: 538208800
I0111 22:30:13.743134 29996 layer_factory.hpp:78] Creating layer conv5
I0111 22:30:13.743203 29996 net.cpp:84] Creating Layer conv5
I0111 22:30:13.743221 29996 net.cpp:406] conv5 <- conv4
I0111 22:30:13.743260 29996 net.cpp:380] conv5 -> conv5
I0111 22:30:13.883747 29996 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 18874368
I0111 22:30:13.884284 29996 net.cpp:122] Setting up conv5
I0111 22:30:13.884327 29996 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0111 22:30:13.884336 29996 net.cpp:137] Memory required for data: 546861600
I0111 22:30:13.884394 29996 layer_factory.hpp:78] Creating layer bn5
I0111 22:30:13.884449 29996 net.cpp:84] Creating Layer bn5
I0111 22:30:13.884469 29996 net.cpp:406] bn5 <- conv5
I0111 22:30:13.884510 29996 net.cpp:367] bn5 -> conv5 (in-place)
I0111 22:30:13.885063 29996 net.cpp:122] Setting up bn5
I0111 22:30:13.885097 29996 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0111 22:30:13.885102 29996 net.cpp:137] Memory required for data: 555514400
I0111 22:30:13.885144 29996 layer_factory.hpp:78] Creating layer scale5
I0111 22:30:13.885193 29996 net.cpp:84] Creating Layer scale5
I0111 22:30:13.885208 29996 net.cpp:406] scale5 <- conv5
I0111 22:30:13.885232 29996 net.cpp:367] scale5 -> conv5 (in-place)
I0111 22:30:13.885390 29996 layer_factory.hpp:78] Creating layer scale5
I0111 22:30:13.885741 29996 net.cpp:122] Setting up scale5
I0111 22:30:13.885762 29996 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0111 22:30:13.885769 29996 net.cpp:137] Memory required for data: 564167200
I0111 22:30:13.885794 29996 layer_factory.hpp:78] Creating layer relu5
I0111 22:30:13.885819 29996 net.cpp:84] Creating Layer relu5
I0111 22:30:13.885833 29996 net.cpp:406] relu5 <- conv5
I0111 22:30:13.885860 29996 net.cpp:367] relu5 -> conv5 (in-place)
I0111 22:30:13.887086 29996 net.cpp:122] Setting up relu5
I0111 22:30:13.887135 29996 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0111 22:30:13.887140 29996 net.cpp:137] Memory required for data: 572820000
I0111 22:30:13.887151 29996 layer_factory.hpp:78] Creating layer pool5
I0111 22:30:13.887188 29996 net.cpp:84] Creating Layer pool5
I0111 22:30:13.887217 29996 net.cpp:406] pool5 <- conv5
I0111 22:30:13.887248 29996 net.cpp:380] pool5 -> pool5
I0111 22:30:13.887447 29996 net.cpp:122] Setting up pool5
I0111 22:30:13.887470 29996 net.cpp:129] Top shape: 50 256 6 6 (460800)
I0111 22:30:13.887480 29996 net.cpp:137] Memory required for data: 574663200
I0111 22:30:13.887490 29996 layer_factory.hpp:78] Creating layer fc6
I0111 22:30:13.887537 29996 net.cpp:84] Creating Layer fc6
I0111 22:30:13.887552 29996 net.cpp:406] fc6 <- pool5
I0111 22:30:13.887585 29996 net.cpp:380] fc6 -> fc6
I0111 22:30:17.905289 29996 net.cpp:122] Setting up fc6
I0111 22:30:17.905354 29996 net.cpp:129] Top shape: 50 4096 (204800)
I0111 22:30:17.905359 29996 net.cpp:137] Memory required for data: 575482400
I0111 22:30:17.905392 29996 layer_factory.hpp:78] Creating layer bn6
I0111 22:30:17.905439 29996 net.cpp:84] Creating Layer bn6
I0111 22:30:17.905458 29996 net.cpp:406] bn6 <- fc6
I0111 22:30:17.905483 29996 net.cpp:367] bn6 -> fc6 (in-place)
I0111 22:30:17.905807 29996 net.cpp:122] Setting up bn6
I0111 22:30:17.905817 29996 net.cpp:129] Top shape: 50 4096 (204800)
I0111 22:30:17.905822 29996 net.cpp:137] Memory required for data: 576301600
I0111 22:30:17.905864 29996 layer_factory.hpp:78] Creating layer scale6
I0111 22:30:17.905889 29996 net.cpp:84] Creating Layer scale6
I0111 22:30:17.905900 29996 net.cpp:406] scale6 <- fc6
I0111 22:30:17.905913 29996 net.cpp:367] scale6 -> fc6 (in-place)
I0111 22:30:17.906025 29996 layer_factory.hpp:78] Creating layer scale6
I0111 22:30:17.906234 29996 net.cpp:122] Setting up scale6
I0111 22:30:17.906247 29996 net.cpp:129] Top shape: 50 4096 (204800)
I0111 22:30:17.906250 29996 net.cpp:137] Memory required for data: 577120800
I0111 22:30:17.906265 29996 layer_factory.hpp:78] Creating layer relu6
I0111 22:30:17.906282 29996 net.cpp:84] Creating Layer relu6
I0111 22:30:17.906289 29996 net.cpp:406] relu6 <- fc6
I0111 22:30:17.906302 29996 net.cpp:367] relu6 -> fc6 (in-place)
I0111 22:30:17.907220 29996 net.cpp:122] Setting up relu6
I0111 22:30:17.907234 29996 net.cpp:129] Top shape: 50 4096 (204800)
I0111 22:30:17.907238 29996 net.cpp:137] Memory required for data: 577940000
I0111 22:30:17.907245 29996 layer_factory.hpp:78] Creating layer drop6
I0111 22:30:17.907263 29996 net.cpp:84] Creating Layer drop6
I0111 22:30:17.907271 29996 net.cpp:406] drop6 <- fc6
I0111 22:30:17.907286 29996 net.cpp:367] drop6 -> fc6 (in-place)
I0111 22:30:17.907346 29996 net.cpp:122] Setting up drop6
I0111 22:30:17.907354 29996 net.cpp:129] Top shape: 50 4096 (204800)
I0111 22:30:17.907358 29996 net.cpp:137] Memory required for data: 578759200
I0111 22:30:17.907363 29996 layer_factory.hpp:78] Creating layer fc7
I0111 22:30:17.907387 29996 net.cpp:84] Creating Layer fc7
I0111 22:30:17.907393 29996 net.cpp:406] fc7 <- fc6
I0111 22:30:17.907410 29996 net.cpp:380] fc7 -> fc7
I0111 22:30:20.064927 29996 net.cpp:122] Setting up fc7
I0111 22:30:20.065006 29996 net.cpp:129] Top shape: 50 4096 (204800)
I0111 22:30:20.065011 29996 net.cpp:137] Memory required for data: 579578400
I0111 22:30:20.065042 29996 layer_factory.hpp:78] Creating layer bn7
I0111 22:30:20.065081 29996 net.cpp:84] Creating Layer bn7
I0111 22:30:20.065095 29996 net.cpp:406] bn7 <- fc7
I0111 22:30:20.065119 29996 net.cpp:367] bn7 -> fc7 (in-place)
I0111 22:30:20.065438 29996 net.cpp:122] Setting up bn7
I0111 22:30:20.065451 29996 net.cpp:129] Top shape: 50 4096 (204800)
I0111 22:30:20.065455 29996 net.cpp:137] Memory required for data: 580397600
I0111 22:30:20.065476 29996 layer_factory.hpp:78] Creating layer scale7
I0111 22:30:20.065507 29996 net.cpp:84] Creating Layer scale7
I0111 22:30:20.065516 29996 net.cpp:406] scale7 <- fc7
I0111 22:30:20.065536 29996 net.cpp:367] scale7 -> fc7 (in-place)
I0111 22:30:20.065636 29996 layer_factory.hpp:78] Creating layer scale7
I0111 22:30:20.065846 29996 net.cpp:122] Setting up scale7
I0111 22:30:20.065865 29996 net.cpp:129] Top shape: 50 4096 (204800)
I0111 22:30:20.065872 29996 net.cpp:137] Memory required for data: 581216800
I0111 22:30:20.065888 29996 layer_factory.hpp:78] Creating layer relu7
I0111 22:30:20.065907 29996 net.cpp:84] Creating Layer relu7
I0111 22:30:20.065914 29996 net.cpp:406] relu7 <- fc7
I0111 22:30:20.065955 29996 net.cpp:367] relu7 -> fc7 (in-place)
I0111 22:30:20.067220 29996 net.cpp:122] Setting up relu7
I0111 22:30:20.067236 29996 net.cpp:129] Top shape: 50 4096 (204800)
I0111 22:30:20.067257 29996 net.cpp:137] Memory required for data: 582036000
I0111 22:30:20.067265 29996 layer_factory.hpp:78] Creating layer drop7
I0111 22:30:20.067286 29996 net.cpp:84] Creating Layer drop7
I0111 22:30:20.067296 29996 net.cpp:406] drop7 <- fc7
I0111 22:30:20.067312 29996 net.cpp:367] drop7 -> fc7 (in-place)
I0111 22:30:20.067365 29996 net.cpp:122] Setting up drop7
I0111 22:30:20.067375 29996 net.cpp:129] Top shape: 50 4096 (204800)
I0111 22:30:20.067378 29996 net.cpp:137] Memory required for data: 582855200
I0111 22:30:20.067384 29996 layer_factory.hpp:78] Creating layer fc8
I0111 22:30:20.067406 29996 net.cpp:84] Creating Layer fc8
I0111 22:30:20.067414 29996 net.cpp:406] fc8 <- fc7
I0111 22:30:20.067435 29996 net.cpp:380] fc8 -> fc8
I0111 22:30:20.537904 29996 net.cpp:122] Setting up fc8
I0111 22:30:20.537995 29996 net.cpp:129] Top shape: 50 1000 (50000)
I0111 22:30:20.538002 29996 net.cpp:137] Memory required for data: 583055200
I0111 22:30:20.538053 29996 layer_factory.hpp:78] Creating layer fc8_fc8_0_split
I0111 22:30:20.538108 29996 net.cpp:84] Creating Layer fc8_fc8_0_split
I0111 22:30:20.538130 29996 net.cpp:406] fc8_fc8_0_split <- fc8
I0111 22:30:20.538175 29996 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0111 22:30:20.538235 29996 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0111 22:30:20.538262 29996 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0111 22:30:20.538408 29996 net.cpp:122] Setting up fc8_fc8_0_split
I0111 22:30:20.538429 29996 net.cpp:129] Top shape: 50 1000 (50000)
I0111 22:30:20.538441 29996 net.cpp:129] Top shape: 50 1000 (50000)
I0111 22:30:20.538450 29996 net.cpp:129] Top shape: 50 1000 (50000)
I0111 22:30:20.538455 29996 net.cpp:137] Memory required for data: 583655200
I0111 22:30:20.538465 29996 layer_factory.hpp:78] Creating layer loss
I0111 22:30:20.538516 29996 net.cpp:84] Creating Layer loss
I0111 22:30:20.538528 29996 net.cpp:406] loss <- fc8_fc8_0_split_0
I0111 22:30:20.538552 29996 net.cpp:406] loss <- label_data_1_split_0
I0111 22:30:20.538576 29996 net.cpp:380] loss -> loss
I0111 22:30:20.538611 29996 layer_factory.hpp:78] Creating layer loss
I0111 22:30:20.540347 29996 net.cpp:122] Setting up loss
I0111 22:30:20.540374 29996 net.cpp:129] Top shape: (1)
I0111 22:30:20.540380 29996 net.cpp:132]     with loss weight 1
I0111 22:30:20.540400 29996 net.cpp:137] Memory required for data: 583655204
I0111 22:30:20.540410 29996 layer_factory.hpp:78] Creating layer accuracy
I0111 22:30:20.540431 29996 net.cpp:84] Creating Layer accuracy
I0111 22:30:20.540443 29996 net.cpp:406] accuracy <- fc8_fc8_0_split_1
I0111 22:30:20.540467 29996 net.cpp:406] accuracy <- label_data_1_split_1
I0111 22:30:20.540491 29996 net.cpp:380] accuracy -> accuracy
I0111 22:30:20.540532 29996 net.cpp:122] Setting up accuracy
I0111 22:30:20.540549 29996 net.cpp:129] Top shape: (1)
I0111 22:30:20.540555 29996 net.cpp:137] Memory required for data: 583655208
I0111 22:30:20.540563 29996 layer_factory.hpp:78] Creating layer accuracy_5
I0111 22:30:20.540588 29996 net.cpp:84] Creating Layer accuracy_5
I0111 22:30:20.540599 29996 net.cpp:406] accuracy_5 <- fc8_fc8_0_split_2
I0111 22:30:20.540618 29996 net.cpp:406] accuracy_5 <- label_data_1_split_2
I0111 22:30:20.540637 29996 net.cpp:380] accuracy_5 -> accuracy_5
I0111 22:30:20.540673 29996 net.cpp:122] Setting up accuracy_5
I0111 22:30:20.540686 29996 net.cpp:129] Top shape: (1)
I0111 22:30:20.540693 29996 net.cpp:137] Memory required for data: 583655212
I0111 22:30:20.540705 29996 net.cpp:200] accuracy_5 does not need backward computation.
I0111 22:30:20.540721 29996 net.cpp:200] accuracy does not need backward computation.
I0111 22:30:20.540729 29996 net.cpp:198] loss needs backward computation.
I0111 22:30:20.540740 29996 net.cpp:198] fc8_fc8_0_split needs backward computation.
I0111 22:30:20.540748 29996 net.cpp:198] fc8 needs backward computation.
I0111 22:30:20.540794 29996 net.cpp:198] drop7 needs backward computation.
I0111 22:30:20.540804 29996 net.cpp:198] relu7 needs backward computation.
I0111 22:30:20.540812 29996 net.cpp:198] scale7 needs backward computation.
I0111 22:30:20.540817 29996 net.cpp:198] bn7 needs backward computation.
I0111 22:30:20.540823 29996 net.cpp:198] fc7 needs backward computation.
I0111 22:30:20.540832 29996 net.cpp:198] drop6 needs backward computation.
I0111 22:30:20.540839 29996 net.cpp:198] relu6 needs backward computation.
I0111 22:30:20.540845 29996 net.cpp:198] scale6 needs backward computation.
I0111 22:30:20.540853 29996 net.cpp:198] bn6 needs backward computation.
I0111 22:30:20.540860 29996 net.cpp:198] fc6 needs backward computation.
I0111 22:30:20.540868 29996 net.cpp:198] pool5 needs backward computation.
I0111 22:30:20.540876 29996 net.cpp:198] relu5 needs backward computation.
I0111 22:30:20.540885 29996 net.cpp:198] scale5 needs backward computation.
I0111 22:30:20.540892 29996 net.cpp:198] bn5 needs backward computation.
I0111 22:30:20.540900 29996 net.cpp:198] conv5 needs backward computation.
I0111 22:30:20.540908 29996 net.cpp:198] relu4 needs backward computation.
I0111 22:30:20.540917 29996 net.cpp:198] scale4 needs backward computation.
I0111 22:30:20.540923 29996 net.cpp:198] bn4 needs backward computation.
I0111 22:30:20.540926 29996 net.cpp:198] conv4 needs backward computation.
I0111 22:30:20.540931 29996 net.cpp:198] relu3 needs backward computation.
I0111 22:30:20.540938 29996 net.cpp:198] scale3 needs backward computation.
I0111 22:30:20.540946 29996 net.cpp:198] bn3 needs backward computation.
I0111 22:30:20.540953 29996 net.cpp:198] conv3 needs backward computation.
I0111 22:30:20.540961 29996 net.cpp:198] pool2 needs backward computation.
I0111 22:30:20.540969 29996 net.cpp:198] relu2 needs backward computation.
I0111 22:30:20.540977 29996 net.cpp:198] scale2 needs backward computation.
I0111 22:30:20.540983 29996 net.cpp:198] bn2 needs backward computation.
I0111 22:30:20.540992 29996 net.cpp:198] conv2 needs backward computation.
I0111 22:30:20.541002 29996 net.cpp:198] pool1 needs backward computation.
I0111 22:30:20.541013 29996 net.cpp:198] relu1 needs backward computation.
I0111 22:30:20.541019 29996 net.cpp:198] scale1 needs backward computation.
I0111 22:30:20.541028 29996 net.cpp:198] bn1 needs backward computation.
I0111 22:30:20.541034 29996 net.cpp:198] conv1 needs backward computation.
I0111 22:30:20.541044 29996 net.cpp:200] label_data_1_split does not need backward computation.
I0111 22:30:20.541056 29996 net.cpp:200] data does not need backward computation.
I0111 22:30:20.541064 29996 net.cpp:242] This network produces output accuracy
I0111 22:30:20.541076 29996 net.cpp:242] This network produces output accuracy_5
I0111 22:30:20.541085 29996 net.cpp:242] This network produces output loss
I0111 22:30:20.541164 29996 net.cpp:255] Network initialization done.
I0111 22:30:20.541394 29996 solver.cpp:75] Finetuning from snapshot/solver_iter_260000.caffemodel
I0111 22:30:31.418192 29996 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: snapshot/solver_iter_260000.caffemodel
I0111 22:30:31.418258 29996 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0111 22:30:31.418267 29996 net.cpp:824] Copying source layer data
I0111 22:30:31.418274 29996 net.cpp:824] Copying source layer label_data_1_split
I0111 22:30:31.418278 29996 net.cpp:824] Copying source layer conv1
I0111 22:30:31.419054 29996 net.cpp:824] Copying source layer bn1
I0111 22:30:31.419231 29996 net.cpp:824] Copying source layer scale1
I0111 22:30:31.419282 29996 net.cpp:824] Copying source layer relu1
I0111 22:30:31.419288 29996 net.cpp:824] Copying source layer pool1
I0111 22:30:31.419292 29996 net.cpp:824] Copying source layer conv2
I0111 22:30:31.428947 29996 net.cpp:824] Copying source layer bn2
I0111 22:30:31.429126 29996 net.cpp:824] Copying source layer scale2
I0111 22:30:31.429181 29996 net.cpp:824] Copying source layer relu2
I0111 22:30:31.429224 29996 net.cpp:824] Copying source layer pool2
I0111 22:30:31.429229 29996 net.cpp:824] Copying source layer conv3
I0111 22:30:31.449396 29996 net.cpp:824] Copying source layer bn3
I0111 22:30:31.449595 29996 net.cpp:824] Copying source layer scale3
I0111 22:30:31.449642 29996 net.cpp:824] Copying source layer relu3
I0111 22:30:31.449651 29996 net.cpp:824] Copying source layer conv4
I0111 22:30:31.470146 29996 net.cpp:824] Copying source layer bn4
I0111 22:30:31.470283 29996 net.cpp:824] Copying source layer scale4
I0111 22:30:31.470329 29996 net.cpp:824] Copying source layer relu4
I0111 22:30:31.470336 29996 net.cpp:824] Copying source layer conv5
I0111 22:30:31.483523 29996 net.cpp:824] Copying source layer bn5
I0111 22:30:31.483631 29996 net.cpp:824] Copying source layer scale5
I0111 22:30:31.483685 29996 net.cpp:824] Copying source layer relu5
I0111 22:30:31.483691 29996 net.cpp:824] Copying source layer pool5
I0111 22:30:31.483696 29996 net.cpp:824] Copying source layer fc6
I0111 22:30:32.431092 29996 net.cpp:824] Copying source layer bn6
I0111 22:30:32.431669 29996 net.cpp:824] Copying source layer scale6
I0111 22:30:32.432054 29996 net.cpp:824] Copying source layer relu6
I0111 22:30:32.432078 29996 net.cpp:824] Copying source layer drop6
I0111 22:30:32.432217 29996 net.cpp:824] Copying source layer fc7
I0111 22:30:32.894841 29996 net.cpp:824] Copying source layer bn7
I0111 22:30:32.895474 29996 net.cpp:824] Copying source layer scale7
I0111 22:30:32.895743 29996 net.cpp:824] Copying source layer relu7
I0111 22:30:32.895759 29996 net.cpp:824] Copying source layer drop7
I0111 22:30:32.895777 29996 net.cpp:824] Copying source layer fc8
I0111 22:30:32.990386 29996 net.cpp:824] Copying source layer fc8_fc8_0_split
I0111 22:30:32.990432 29996 net.cpp:824] Copying source layer loss
I0111 22:30:32.990442 29996 net.cpp:824] Copying source layer accuracy
I0111 22:30:32.990448 29996 net.cpp:824] Copying source layer accuracy_5
I0111 22:30:33.015601 29996 solver.cpp:57] Solver scaffolding done.
I0111 22:30:33.018007 29996 caffe.cpp:239] Starting Optimization
I0111 22:30:33.018039 29996 solver.cpp:299] Solving AlexNet-BN
I0111 22:30:33.018043 29996 solver.cpp:300] Learning Rate Policy: modified_lr
I0111 22:30:33.021709 29996 solver.cpp:384] Iteration 0, Testing net (#0)
I0111 22:30:33.327998 29996 blocking_queue.cpp:49] Waiting for data
I0111 22:33:06.438974 30272 data_layer.cpp:73] Restarting data prefetching from start.
I0111 22:33:06.491029 29996 solver.cpp:452]     Test net output #0: accuracy = 0.55516
I0111 22:33:06.491107 29996 solver.cpp:452]     Test net output #1: accuracy_5 = 0.785641
I0111 22:33:06.491133 29996 solver.cpp:452]     Test net output #2: loss = 1.9633 (* 1 = 1.9633 loss)
I0111 22:33:06.491147 29996 solver.cpp:463] ================================
I0111 22:33:06.491202 29996 solver.cpp:464]     Test net best accuracy1 is: 0.55516
I0111 22:33:06.491240 29996 solver.cpp:466]     Test net best accuracy5 is: 0.785641
I0111 22:33:07.225313 29996 solver.cpp:242] Iteration 0 (9.72225e-11 iter/s, 154.203s/200 iters), loss = 1.14597
I0111 22:33:07.225528 29996 solver.cpp:261]     Train net output #0: accuracy = 0.71875
I0111 22:33:07.225569 29996 solver.cpp:261]     Train net output #1: accuracy_5 = 0.914062
I0111 22:33:07.225620 29996 solver.cpp:261]     Train net output #2: loss = 1.14597 (* 1 = 1.14597 loss)
I0111 22:33:07.225680 29996 sgd_solver.cpp:122] Iteration 0, lr = 5e-05
I0111 22:33:13.275159 29996 blocking_queue.cpp:49] Waiting for data
I0111 22:36:15.461517 29996 solver.cpp:242] Iteration 200 (1.06253 iter/s, 188.231s/200 iters), loss = 1.0551
I0111 22:36:15.461627 29996 solver.cpp:261]     Train net output #0: accuracy = 0.726562
I0111 22:36:15.461644 29996 solver.cpp:261]     Train net output #1: accuracy_5 = 0.925781
I0111 22:36:15.461699 29996 solver.cpp:261]     Train net output #2: loss = 1.0551 (* 1 = 1.0551 loss)
I0111 22:36:15.461740 29996 sgd_solver.cpp:122] Iteration 200, lr = 5e-05
I0111 22:39:23.968886 29996 solver.cpp:242] Iteration 400 (1.061 iter/s, 188.502s/200 iters), loss = 1.1713
I0111 22:39:23.969087 29996 solver.cpp:261]     Train net output #0: accuracy = 0.703125
I0111 22:39:23.969113 29996 solver.cpp:261]     Train net output #1: accuracy_5 = 0.898438
I0111 22:39:23.969221 29996 solver.cpp:261]     Train net output #2: loss = 1.1713 (* 1 = 1.1713 loss)
I0111 22:39:23.969245 29996 sgd_solver.cpp:122] Iteration 400, lr = 5e-05
I0111 22:42:30.346101 29996 solver.cpp:242] Iteration 600 (1.07313 iter/s, 186.372s/200 iters), loss = 1.36589
I0111 22:42:30.346261 29996 solver.cpp:261]     Train net output #0: accuracy = 0.664062
I0111 22:42:30.346282 29996 solver.cpp:261]     Train net output #1: accuracy_5 = 0.871094
I0111 22:42:30.346303 29996 solver.cpp:261]     Train net output #2: loss = 1.36589 (* 1 = 1.36589 loss)
I0111 22:42:30.346316 29996 sgd_solver.cpp:122] Iteration 600, lr = 5e-05
I0111 22:45:34.685392 29996 solver.cpp:242] Iteration 800 (1.08499 iter/s, 184.334s/200 iters), loss = 1.27015
I0111 22:45:34.685508 29996 solver.cpp:261]     Train net output #0: accuracy = 0.671875
I0111 22:45:34.685521 29996 solver.cpp:261]     Train net output #1: accuracy_5 = 0.867188
I0111 22:45:34.685539 29996 solver.cpp:261]     Train net output #2: loss = 1.27015 (* 1 = 1.27015 loss)
I0111 22:45:34.685554 29996 sgd_solver.cpp:122] Iteration 800, lr = 5e-05
I0111 22:48:25.705039 29996 solver.cpp:384] Iteration 1000, Testing net (#0)
I0111 22:48:27.319031 29996 blocking_queue.cpp:49] Waiting for data
I0111 22:50:49.706640 30272 data_layer.cpp:73] Restarting data prefetching from start.
I0111 22:50:49.759639 29996 solver.cpp:452]     Test net output #0: accuracy = 0.56098
I0111 22:50:49.759702 29996 solver.cpp:452]     Test net output #1: accuracy_5 = 0.790881
I0111 22:50:49.759721 29996 solver.cpp:452]     Test net output #2: loss = 1.94188 (* 1 = 1.94188 loss)
I0111 22:50:49.759730 29996 solver.cpp:463] ================================
I0111 22:50:49.759733 29996 solver.cpp:464]     Test net best accuracy1 is: 0.56098
I0111 22:50:49.759737 29996 solver.cpp:466]     Test net best accuracy5 is: 0.790881
I0111 22:50:50.483762 29996 solver.cpp:242] Iteration 1000 (0.633334 iter/s, 315.789s/200 iters), loss = 1.18692
I0111 22:50:50.486156 29996 solver.cpp:261]     Train net output #0: accuracy = 0.722656
I0111 22:50:50.486178 29996 solver.cpp:261]     Train net output #1: accuracy_5 = 0.882812
I0111 22:50:50.486227 29996 solver.cpp:261]     Train net output #2: loss = 1.18692 (* 1 = 1.18692 loss)
I0111 22:50:50.486254 29996 sgd_solver.cpp:122] Iteration 1000, lr = 5e-05
I0111 22:51:04.395690 29996 blocking_queue.cpp:49] Waiting for data
I0111 22:53:49.580260 29996 solver.cpp:242] Iteration 1200 (1.11676 iter/s, 179.089s/200 iters), loss = 1.16625
I0111 22:53:49.580477 29996 solver.cpp:261]     Train net output #0: accuracy = 0.753906
I0111 22:53:49.580533 29996 solver.cpp:261]     Train net output #1: accuracy_5 = 0.894531
I0111 22:53:49.580605 29996 solver.cpp:261]     Train net output #2: loss = 1.16625 (* 1 = 1.16625 loss)
I0111 22:53:49.580646 29996 sgd_solver.cpp:122] Iteration 1200, lr = 5e-05
I0111 22:56:54.232954 29996 solver.cpp:242] Iteration 1400 (1.08315 iter/s, 184.647s/200 iters), loss = 1.26419
I0111 22:56:54.233105 29996 solver.cpp:261]     Train net output #0: accuracy = 0.691406
I0111 22:56:54.233119 29996 solver.cpp:261]     Train net output #1: accuracy_5 = 0.882812
I0111 22:56:54.233140 29996 solver.cpp:261]     Train net output #2: loss = 1.26419 (* 1 = 1.26419 loss)
I0111 22:56:54.233161 29996 sgd_solver.cpp:122] Iteration 1400, lr = 5e-05
I0111 22:59:49.152642 29996 solver.cpp:242] Iteration 1600 (1.14342 iter/s, 174.914s/200 iters), loss = 1.12976
I0111 22:59:49.152776 29996 solver.cpp:261]     Train net output #0: accuracy = 0.683594
I0111 22:59:49.152787 29996 solver.cpp:261]     Train net output #1: accuracy_5 = 0.882812
I0111 22:59:49.152817 29996 solver.cpp:261]     Train net output #2: loss = 1.12976 (* 1 = 1.12976 loss)
I0111 22:59:49.152842 29996 sgd_solver.cpp:122] Iteration 1600, lr = 5e-05
I0111 23:02:33.706939 29996 solver.cpp:242] Iteration 1800 (1.21544 iter/s, 164.55s/200 iters), loss = 1.18943
I0111 23:02:33.718803 29996 solver.cpp:261]     Train net output #0: accuracy = 0.726562
I0111 23:02:33.718855 29996 solver.cpp:261]     Train net output #1: accuracy_5 = 0.886719
I0111 23:02:33.718883 29996 solver.cpp:261]     Train net output #2: loss = 1.18943 (* 1 = 1.18943 loss)
I0111 23:02:33.718896 29996 sgd_solver.cpp:122] Iteration 1800, lr = 5e-05
I0111 23:05:13.601784 29996 solver.cpp:384] Iteration 2000, Testing net (#0)
I0111 23:05:16.544003 29996 blocking_queue.cpp:49] Waiting for data
I0111 23:07:36.534487 30272 data_layer.cpp:73] Restarting data prefetching from start.
I0111 23:07:36.589988 29996 solver.cpp:452]     Test net output #0: accuracy = 0.55866
I0111 23:07:36.590173 29996 solver.cpp:452]     Test net output #1: accuracy_5 = 0.789581
I0111 23:07:36.590242 29996 solver.cpp:452]     Test net output #2: loss = 1.94852 (* 1 = 1.94852 loss)
I0111 23:07:36.590301 29996 solver.cpp:463] ================================
I0111 23:07:36.590327 29996 solver.cpp:464]     Test net best accuracy1 is: 0.56098
I0111 23:07:36.590350 29996 solver.cpp:466]     Test net best accuracy5 is: 0.790881
I0111 23:07:37.326803 29996 solver.cpp:242] Iteration 2000 (0.658761 iter/s, 303.6s/200 iters), loss = 1.15837
I0111 23:07:37.329217 29996 solver.cpp:261]     Train net output #0: accuracy = 0.738281
I0111 23:07:37.329260 29996 solver.cpp:261]     Train net output #1: accuracy_5 = 0.878906
I0111 23:07:37.329290 29996 solver.cpp:261]     Train net output #2: loss = 1.15837 (* 1 = 1.15837 loss)
I0111 23:07:37.329305 29996 sgd_solver.cpp:122] Iteration 2000, lr = 5e-05
I0111 23:07:58.108777 29996 blocking_queue.cpp:49] Waiting for data
