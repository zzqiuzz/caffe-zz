I0910 12:58:33.958768  1862 caffe.cpp:204] Using GPUs 0, 2
I0910 12:58:36.245143  1862 caffe.cpp:209] GPU 0: TITAN Xp
I0910 12:58:36.250105  1862 caffe.cpp:209] GPU 2: TITAN Xp
I0910 12:58:37.193418  1862 solver.cpp:45] Initializing solver from parameters: 
test_iter: 1000
test_interval: 1000
base_lr: 0.05
display: 200
max_iter: 320000
lr_policy: "poly"
gamma: 0.1
power: 1
momentum: 0.9
weight_decay: 0.0005
snapshot: 10000
snapshot_prefix: "my/Imagenet/AlexNet-BN/XnorNet_FWN/snapshot/xnor_net"
solver_mode: GPU
device_id: 0
net: "my/Imagenet/AlexNet-BN/XnorNet_FWN/train_val.prototxt"
train_state {
  level: 0
  stage: ""
}
I0910 12:58:37.218401  1862 solver.cpp:105] Creating training net from net file: my/Imagenet/AlexNet-BN/XnorNet_FWN/train_val.prototxt
I0910 12:58:37.229038  1862 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0910 12:58:37.229074  1862 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0910 12:58:37.229079  1862 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_5
I0910 12:58:37.229318  1862 net.cpp:51] Initializing net from parameters: 
name: "AlexNet-BN"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 103.939
    mean_value: 116.779
    mean_value: 123.68
  }
  data_param {
    source: "/home/zhengzhe/Data/ilsvrc12/ilsvrc12_train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "BinaryConvolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 2
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "BinaryConvolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "BinaryConvolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "BinaryConvolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "BinaryConvolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "scale5"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "pool5"
  top: "pool5"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "fc6"
  type: "BinaryInnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn6"
  type: "BatchNorm"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "scale6"
  type: "Scale"
  bottom: "fc6"
  top: "fc6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "fc7"
  type: "BinaryInnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "scale7"
  type: "Scale"
  bottom: "fc7"
  top: "fc7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "fc8"
  type: "BinaryInnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "accuracy_5_TRAIN"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy_5_TRAIN"
  include {
    phase: TRAIN
  }
  accuracy_param {
    top_k: 5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0910 12:58:37.229529  1862 layer_factory.hpp:77] Creating layer data
I0910 12:58:37.229679  1862 db_lmdb.cpp:35] Opened lmdb /home/zhengzhe/Data/ilsvrc12/ilsvrc12_train_lmdb
I0910 12:58:37.229723  1862 net.cpp:84] Creating Layer data
I0910 12:58:37.229738  1862 net.cpp:380] data -> data
I0910 12:58:37.229771  1862 net.cpp:380] data -> label
I0910 12:58:37.231771  1862 data_layer.cpp:45] output data size: 256,3,224,224
I0910 12:58:38.385323  1862 net.cpp:122] Setting up data
I0910 12:58:38.392714  1862 net.cpp:129] Top shape: 256 3 224 224 (38535168)
I0910 12:58:38.392784  1862 net.cpp:129] Top shape: 256 (256)
I0910 12:58:38.392818  1862 net.cpp:137] Memory required for data: 154141696
I0910 12:58:38.392863  1862 layer_factory.hpp:77] Creating layer label_data_1_split
I0910 12:58:38.392918  1862 net.cpp:84] Creating Layer label_data_1_split
I0910 12:58:38.392977  1862 net.cpp:406] label_data_1_split <- label
I0910 12:58:38.393401  1862 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0910 12:58:38.393442  1862 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0910 12:58:38.413938  1862 net.cpp:122] Setting up label_data_1_split
I0910 12:58:38.413969  1862 net.cpp:129] Top shape: 256 (256)
I0910 12:58:38.413986  1862 net.cpp:129] Top shape: 256 (256)
I0910 12:58:38.414002  1862 net.cpp:137] Memory required for data: 154143744
I0910 12:58:38.414018  1862 layer_factory.hpp:77] Creating layer conv1
I0910 12:58:38.414050  1862 net.cpp:84] Creating Layer conv1
I0910 12:58:38.414068  1862 net.cpp:406] conv1 <- data
I0910 12:58:38.414089  1862 net.cpp:380] conv1 -> conv1
I0910 12:58:38.427604  1862 net.cpp:122] Setting up conv1
I0910 12:58:38.427644  1862 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0910 12:58:38.427661  1862 net.cpp:137] Memory required for data: 451513344
I0910 12:58:38.427695  1862 layer_factory.hpp:77] Creating layer bn1
I0910 12:58:38.427718  1862 net.cpp:84] Creating Layer bn1
I0910 12:58:38.427737  1862 net.cpp:406] bn1 <- conv1
I0910 12:58:38.427755  1862 net.cpp:367] bn1 -> conv1 (in-place)
I0910 12:58:38.427973  1862 net.cpp:122] Setting up bn1
I0910 12:58:38.427996  1862 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0910 12:58:38.428014  1862 net.cpp:137] Memory required for data: 748882944
I0910 12:58:38.428037  1862 layer_factory.hpp:77] Creating layer scale1
I0910 12:58:38.428061  1862 net.cpp:84] Creating Layer scale1
I0910 12:58:38.428077  1862 net.cpp:406] scale1 <- conv1
I0910 12:58:38.428097  1862 net.cpp:367] scale1 -> conv1 (in-place)
I0910 12:58:38.428153  1862 layer_factory.hpp:77] Creating layer scale1
I0910 12:58:38.428303  1862 net.cpp:122] Setting up scale1
I0910 12:58:38.428325  1862 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0910 12:58:38.428341  1862 net.cpp:137] Memory required for data: 1046252544
I0910 12:58:38.428361  1862 layer_factory.hpp:77] Creating layer relu1
I0910 12:58:38.428387  1862 net.cpp:84] Creating Layer relu1
I0910 12:58:38.428405  1862 net.cpp:406] relu1 <- conv1
I0910 12:58:38.428423  1862 net.cpp:367] relu1 -> conv1 (in-place)
I0910 12:58:38.428443  1862 net.cpp:122] Setting up relu1
I0910 12:58:38.428462  1862 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0910 12:58:38.428478  1862 net.cpp:137] Memory required for data: 1343622144
I0910 12:58:38.428494  1862 layer_factory.hpp:77] Creating layer pool1
I0910 12:58:38.428514  1862 net.cpp:84] Creating Layer pool1
I0910 12:58:38.428530  1862 net.cpp:406] pool1 <- conv1
I0910 12:58:38.428550  1862 net.cpp:380] pool1 -> pool1
I0910 12:58:38.428617  1862 net.cpp:122] Setting up pool1
I0910 12:58:38.428639  1862 net.cpp:129] Top shape: 256 96 27 27 (17915904)
I0910 12:58:38.428655  1862 net.cpp:137] Memory required for data: 1415285760
I0910 12:58:38.428670  1862 layer_factory.hpp:77] Creating layer conv2
I0910 12:58:38.428694  1862 net.cpp:84] Creating Layer conv2
I0910 12:58:38.428710  1862 net.cpp:406] conv2 <- pool1
I0910 12:58:38.428730  1862 net.cpp:380] conv2 -> conv2
I0910 12:58:38.441536  1862 net.cpp:122] Setting up conv2
I0910 12:58:38.441574  1862 net.cpp:129] Top shape: 256 256 27 27 (47775744)
I0910 12:58:38.441593  1862 net.cpp:137] Memory required for data: 1606388736
I0910 12:58:38.441617  1862 layer_factory.hpp:77] Creating layer bn2
I0910 12:58:38.441639  1862 net.cpp:84] Creating Layer bn2
I0910 12:58:38.441658  1862 net.cpp:406] bn2 <- conv2
I0910 12:58:38.441678  1862 net.cpp:367] bn2 -> conv2 (in-place)
I0910 12:58:38.441874  1862 net.cpp:122] Setting up bn2
I0910 12:58:38.441905  1862 net.cpp:129] Top shape: 256 256 27 27 (47775744)
I0910 12:58:38.441932  1862 net.cpp:137] Memory required for data: 1797491712
I0910 12:58:38.441953  1862 layer_factory.hpp:77] Creating layer scale2
I0910 12:58:38.441973  1862 net.cpp:84] Creating Layer scale2
I0910 12:58:38.441992  1862 net.cpp:406] scale2 <- conv2
I0910 12:58:38.442010  1862 net.cpp:367] scale2 -> conv2 (in-place)
I0910 12:58:38.442061  1862 layer_factory.hpp:77] Creating layer scale2
I0910 12:58:38.442189  1862 net.cpp:122] Setting up scale2
I0910 12:58:38.442212  1862 net.cpp:129] Top shape: 256 256 27 27 (47775744)
I0910 12:58:38.442229  1862 net.cpp:137] Memory required for data: 1988594688
I0910 12:58:38.442248  1862 layer_factory.hpp:77] Creating layer relu2
I0910 12:58:38.442267  1862 net.cpp:84] Creating Layer relu2
I0910 12:58:38.442284  1862 net.cpp:406] relu2 <- conv2
I0910 12:58:38.442303  1862 net.cpp:367] relu2 -> conv2 (in-place)
I0910 12:58:38.442323  1862 net.cpp:122] Setting up relu2
I0910 12:58:38.442342  1862 net.cpp:129] Top shape: 256 256 27 27 (47775744)
I0910 12:58:38.442358  1862 net.cpp:137] Memory required for data: 2179697664
I0910 12:58:38.442373  1862 layer_factory.hpp:77] Creating layer pool2
I0910 12:58:38.442392  1862 net.cpp:84] Creating Layer pool2
I0910 12:58:38.442409  1862 net.cpp:406] pool2 <- conv2
I0910 12:58:38.442427  1862 net.cpp:380] pool2 -> pool2
I0910 12:58:38.442482  1862 net.cpp:122] Setting up pool2
I0910 12:58:38.442503  1862 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0910 12:58:38.442519  1862 net.cpp:137] Memory required for data: 2224000000
I0910 12:58:38.442535  1862 layer_factory.hpp:77] Creating layer conv3
I0910 12:58:38.442557  1862 net.cpp:84] Creating Layer conv3
I0910 12:58:38.442574  1862 net.cpp:406] conv3 <- pool2
I0910 12:58:38.442593  1862 net.cpp:380] conv3 -> conv3
I0910 12:58:38.483172  1862 net.cpp:122] Setting up conv3
I0910 12:58:38.483232  1862 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0910 12:58:38.483250  1862 net.cpp:137] Memory required for data: 2290453504
I0910 12:58:38.483273  1862 layer_factory.hpp:77] Creating layer bn3
I0910 12:58:38.483295  1862 net.cpp:84] Creating Layer bn3
I0910 12:58:38.483314  1862 net.cpp:406] bn3 <- conv3
I0910 12:58:38.483335  1862 net.cpp:367] bn3 -> conv3 (in-place)
I0910 12:58:38.483539  1862 net.cpp:122] Setting up bn3
I0910 12:58:38.483563  1862 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0910 12:58:38.483580  1862 net.cpp:137] Memory required for data: 2356907008
I0910 12:58:38.483608  1862 layer_factory.hpp:77] Creating layer scale3
I0910 12:58:38.483629  1862 net.cpp:84] Creating Layer scale3
I0910 12:58:38.483647  1862 net.cpp:406] scale3 <- conv3
I0910 12:58:38.483666  1862 net.cpp:367] scale3 -> conv3 (in-place)
I0910 12:58:38.483719  1862 layer_factory.hpp:77] Creating layer scale3
I0910 12:58:38.483852  1862 net.cpp:122] Setting up scale3
I0910 12:58:38.483875  1862 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0910 12:58:38.483891  1862 net.cpp:137] Memory required for data: 2423360512
I0910 12:58:38.483911  1862 layer_factory.hpp:77] Creating layer relu3
I0910 12:58:38.483933  1862 net.cpp:84] Creating Layer relu3
I0910 12:58:38.483950  1862 net.cpp:406] relu3 <- conv3
I0910 12:58:38.483969  1862 net.cpp:367] relu3 -> conv3 (in-place)
I0910 12:58:38.483989  1862 net.cpp:122] Setting up relu3
I0910 12:58:38.484007  1862 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0910 12:58:38.484024  1862 net.cpp:137] Memory required for data: 2489814016
I0910 12:58:38.484040  1862 layer_factory.hpp:77] Creating layer conv4
I0910 12:58:38.484066  1862 net.cpp:84] Creating Layer conv4
I0910 12:58:38.484083  1862 net.cpp:406] conv4 <- conv3
I0910 12:58:38.484103  1862 net.cpp:380] conv4 -> conv4
I0910 12:58:38.538051  1862 net.cpp:122] Setting up conv4
I0910 12:58:38.544904  1862 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0910 12:58:38.545037  1862 net.cpp:137] Memory required for data: 2556267520
I0910 12:58:38.545203  1862 layer_factory.hpp:77] Creating layer bn4
I0910 12:58:38.545331  1862 net.cpp:84] Creating Layer bn4
I0910 12:58:38.545451  1862 net.cpp:406] bn4 <- conv4
I0910 12:58:38.545572  1862 net.cpp:367] bn4 -> conv4 (in-place)
I0910 12:58:38.545876  1862 net.cpp:122] Setting up bn4
I0910 12:58:38.546557  1862 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0910 12:58:38.546797  1862 net.cpp:137] Memory required for data: 2622721024
I0910 12:58:38.546880  1862 layer_factory.hpp:77] Creating layer scale4
I0910 12:58:38.546932  1862 net.cpp:84] Creating Layer scale4
I0910 12:58:38.546978  1862 net.cpp:406] scale4 <- conv4
I0910 12:58:38.547026  1862 net.cpp:367] scale4 -> conv4 (in-place)
I0910 12:58:38.547132  1862 layer_factory.hpp:77] Creating layer scale4
I0910 12:58:38.547400  1862 net.cpp:122] Setting up scale4
I0910 12:58:38.547632  1862 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0910 12:58:38.547682  1862 net.cpp:137] Memory required for data: 2689174528
I0910 12:58:38.547731  1862 layer_factory.hpp:77] Creating layer relu4
I0910 12:58:38.547809  1862 net.cpp:84] Creating Layer relu4
I0910 12:58:38.547884  1862 net.cpp:406] relu4 <- conv4
I0910 12:58:38.547960  1862 net.cpp:367] relu4 -> conv4 (in-place)
I0910 12:58:38.548054  1862 net.cpp:122] Setting up relu4
I0910 12:58:38.548132  1862 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0910 12:58:38.548199  1862 net.cpp:137] Memory required for data: 2755628032
I0910 12:58:38.548260  1862 layer_factory.hpp:77] Creating layer conv5
I0910 12:58:38.548338  1862 net.cpp:84] Creating Layer conv5
I0910 12:58:38.548565  1862 net.cpp:406] conv5 <- conv4
I0910 12:58:38.548626  1862 net.cpp:380] conv5 -> conv5
I0910 12:58:38.577597  1862 net.cpp:122] Setting up conv5
I0910 12:58:38.586058  1862 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0910 12:58:38.586195  1862 net.cpp:137] Memory required for data: 2799930368
I0910 12:58:38.586278  1862 layer_factory.hpp:77] Creating layer bn5
I0910 12:58:38.586390  1862 net.cpp:84] Creating Layer bn5
I0910 12:58:38.586482  1862 net.cpp:406] bn5 <- conv5
I0910 12:58:38.586555  1862 net.cpp:367] bn5 -> conv5 (in-place)
I0910 12:58:38.586846  1862 net.cpp:122] Setting up bn5
I0910 12:58:38.587354  1862 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0910 12:58:38.587456  1862 net.cpp:137] Memory required for data: 2844232704
I0910 12:58:38.587530  1862 layer_factory.hpp:77] Creating layer scale5
I0910 12:58:38.587626  1862 net.cpp:84] Creating Layer scale5
I0910 12:58:38.587715  1862 net.cpp:406] scale5 <- conv5
I0910 12:58:38.587783  1862 net.cpp:367] scale5 -> conv5 (in-place)
I0910 12:58:38.587908  1862 layer_factory.hpp:77] Creating layer scale5
I0910 12:58:38.588193  1862 net.cpp:122] Setting up scale5
I0910 12:58:38.589220  1862 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0910 12:58:38.589309  1862 net.cpp:137] Memory required for data: 2888535040
I0910 12:58:38.589371  1862 layer_factory.hpp:77] Creating layer relu5
I0910 12:58:38.589426  1862 net.cpp:84] Creating Layer relu5
I0910 12:58:38.589475  1862 net.cpp:406] relu5 <- conv5
I0910 12:58:38.589531  1862 net.cpp:367] relu5 -> conv5 (in-place)
I0910 12:58:38.589583  1862 net.cpp:122] Setting up relu5
I0910 12:58:38.589633  1862 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0910 12:58:38.589680  1862 net.cpp:137] Memory required for data: 2932837376
I0910 12:58:38.589720  1862 layer_factory.hpp:77] Creating layer pool5
I0910 12:58:38.589785  1862 net.cpp:84] Creating Layer pool5
I0910 12:58:38.589829  1862 net.cpp:406] pool5 <- conv5
I0910 12:58:38.589872  1862 net.cpp:380] pool5 -> pool5
I0910 12:58:38.589994  1862 net.cpp:122] Setting up pool5
I0910 12:58:38.590047  1862 net.cpp:129] Top shape: 256 256 6 6 (2359296)
I0910 12:58:38.590090  1862 net.cpp:137] Memory required for data: 2942274560
I0910 12:58:38.590127  1862 layer_factory.hpp:77] Creating layer drop6
I0910 12:58:38.590171  1862 net.cpp:84] Creating Layer drop6
I0910 12:58:38.590211  1862 net.cpp:406] drop6 <- pool5
I0910 12:58:38.590260  1862 net.cpp:367] drop6 -> pool5 (in-place)
I0910 12:58:38.590339  1862 net.cpp:122] Setting up drop6
I0910 12:58:38.590387  1862 net.cpp:129] Top shape: 256 256 6 6 (2359296)
I0910 12:58:38.590456  1862 net.cpp:137] Memory required for data: 2951711744
I0910 12:58:38.590504  1862 layer_factory.hpp:77] Creating layer fc6
I0910 12:58:38.590561  1862 net.cpp:84] Creating Layer fc6
I0910 12:58:38.590607  1862 net.cpp:406] fc6 <- pool5
I0910 12:58:38.590652  1862 net.cpp:380] fc6 -> fc6
I0910 12:58:39.534416  1862 net.cpp:122] Setting up fc6
I0910 12:58:39.534449  1862 net.cpp:129] Top shape: 256 4096 (1048576)
I0910 12:58:39.534454  1862 net.cpp:137] Memory required for data: 2955906048
I0910 12:58:39.534468  1862 layer_factory.hpp:77] Creating layer bn6
I0910 12:58:39.534482  1862 net.cpp:84] Creating Layer bn6
I0910 12:58:39.534487  1862 net.cpp:406] bn6 <- fc6
I0910 12:58:39.534503  1862 net.cpp:367] bn6 -> fc6 (in-place)
I0910 12:58:39.534713  1862 net.cpp:122] Setting up bn6
I0910 12:58:39.534724  1862 net.cpp:129] Top shape: 256 4096 (1048576)
I0910 12:58:39.534729  1862 net.cpp:137] Memory required for data: 2960100352
I0910 12:58:39.534737  1862 layer_factory.hpp:77] Creating layer scale6
I0910 12:58:39.534745  1862 net.cpp:84] Creating Layer scale6
I0910 12:58:39.534750  1862 net.cpp:406] scale6 <- fc6
I0910 12:58:39.534759  1862 net.cpp:367] scale6 -> fc6 (in-place)
I0910 12:58:39.534797  1862 layer_factory.hpp:77] Creating layer scale6
I0910 12:58:39.534924  1862 net.cpp:122] Setting up scale6
I0910 12:58:39.534936  1862 net.cpp:129] Top shape: 256 4096 (1048576)
I0910 12:58:39.534940  1862 net.cpp:137] Memory required for data: 2964294656
I0910 12:58:39.534946  1862 layer_factory.hpp:77] Creating layer relu6
I0910 12:58:39.534953  1862 net.cpp:84] Creating Layer relu6
I0910 12:58:39.534960  1862 net.cpp:406] relu6 <- fc6
I0910 12:58:39.534965  1862 net.cpp:367] relu6 -> fc6 (in-place)
I0910 12:58:39.534971  1862 net.cpp:122] Setting up relu6
I0910 12:58:39.534977  1862 net.cpp:129] Top shape: 256 4096 (1048576)
I0910 12:58:39.534981  1862 net.cpp:137] Memory required for data: 2968488960
I0910 12:58:39.534984  1862 layer_factory.hpp:77] Creating layer drop7
I0910 12:58:39.534992  1862 net.cpp:84] Creating Layer drop7
I0910 12:58:39.534996  1862 net.cpp:406] drop7 <- fc6
I0910 12:58:39.535003  1862 net.cpp:367] drop7 -> fc6 (in-place)
I0910 12:58:39.535022  1862 net.cpp:122] Setting up drop7
I0910 12:58:39.535032  1862 net.cpp:129] Top shape: 256 4096 (1048576)
I0910 12:58:39.535035  1862 net.cpp:137] Memory required for data: 2972683264
I0910 12:58:39.535039  1862 layer_factory.hpp:77] Creating layer fc7
I0910 12:58:39.535049  1862 net.cpp:84] Creating Layer fc7
I0910 12:58:39.535053  1862 net.cpp:406] fc7 <- fc6
I0910 12:58:39.535063  1862 net.cpp:380] fc7 -> fc7
I0910 12:58:40.003401  1862 net.cpp:122] Setting up fc7
I0910 12:58:40.003438  1862 net.cpp:129] Top shape: 256 4096 (1048576)
I0910 12:58:40.003443  1862 net.cpp:137] Memory required for data: 2976877568
I0910 12:58:40.003456  1862 layer_factory.hpp:77] Creating layer bn7
I0910 12:58:40.003475  1862 net.cpp:84] Creating Layer bn7
I0910 12:58:40.003481  1862 net.cpp:406] bn7 <- fc7
I0910 12:58:40.003490  1862 net.cpp:367] bn7 -> fc7 (in-place)
I0910 12:58:40.003697  1862 net.cpp:122] Setting up bn7
I0910 12:58:40.003710  1862 net.cpp:129] Top shape: 256 4096 (1048576)
I0910 12:58:40.003712  1862 net.cpp:137] Memory required for data: 2981071872
I0910 12:58:40.003721  1862 layer_factory.hpp:77] Creating layer scale7
I0910 12:58:40.003731  1862 net.cpp:84] Creating Layer scale7
I0910 12:58:40.003736  1862 net.cpp:406] scale7 <- fc7
I0910 12:58:40.003743  1862 net.cpp:367] scale7 -> fc7 (in-place)
I0910 12:58:40.003782  1862 layer_factory.hpp:77] Creating layer scale7
I0910 12:58:40.003906  1862 net.cpp:122] Setting up scale7
I0910 12:58:40.003918  1862 net.cpp:129] Top shape: 256 4096 (1048576)
I0910 12:58:40.003922  1862 net.cpp:137] Memory required for data: 2985266176
I0910 12:58:40.003929  1862 layer_factory.hpp:77] Creating layer relu7
I0910 12:58:40.003937  1862 net.cpp:84] Creating Layer relu7
I0910 12:58:40.003942  1862 net.cpp:406] relu7 <- fc7
I0910 12:58:40.003947  1862 net.cpp:367] relu7 -> fc7 (in-place)
I0910 12:58:40.003954  1862 net.cpp:122] Setting up relu7
I0910 12:58:40.003986  1862 net.cpp:129] Top shape: 256 4096 (1048576)
I0910 12:58:40.003991  1862 net.cpp:137] Memory required for data: 2989460480
I0910 12:58:40.003994  1862 layer_factory.hpp:77] Creating layer fc8
I0910 12:58:40.004007  1862 net.cpp:84] Creating Layer fc8
I0910 12:58:40.004012  1862 net.cpp:406] fc8 <- fc7
I0910 12:58:40.004022  1862 net.cpp:380] fc8 -> fc8
I0910 12:58:40.155118  1862 net.cpp:122] Setting up fc8
I0910 12:58:40.157148  1862 net.cpp:129] Top shape: 256 1000 (256000)
I0910 12:58:40.157253  1862 net.cpp:137] Memory required for data: 2990484480
I0910 12:58:40.157339  1862 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0910 12:58:40.157435  1862 net.cpp:84] Creating Layer fc8_fc8_0_split
I0910 12:58:40.157507  1862 net.cpp:406] fc8_fc8_0_split <- fc8
I0910 12:58:40.157578  1862 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0910 12:58:40.157662  1862 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0910 12:58:40.157781  1862 net.cpp:122] Setting up fc8_fc8_0_split
I0910 12:58:40.157898  1862 net.cpp:129] Top shape: 256 1000 (256000)
I0910 12:58:40.157989  1862 net.cpp:129] Top shape: 256 1000 (256000)
I0910 12:58:40.158056  1862 net.cpp:137] Memory required for data: 2992532480
I0910 12:58:40.158116  1862 layer_factory.hpp:77] Creating layer accuracy_5_TRAIN
I0910 12:58:40.158185  1862 net.cpp:84] Creating Layer accuracy_5_TRAIN
I0910 12:58:40.158252  1862 net.cpp:406] accuracy_5_TRAIN <- fc8_fc8_0_split_0
I0910 12:58:40.158318  1862 net.cpp:406] accuracy_5_TRAIN <- label_data_1_split_0
I0910 12:58:40.158391  1862 net.cpp:380] accuracy_5_TRAIN -> accuracy_5_TRAIN
I0910 12:58:40.158479  1862 net.cpp:122] Setting up accuracy_5_TRAIN
I0910 12:58:40.158563  1862 net.cpp:129] Top shape: (1)
I0910 12:58:40.158624  1862 net.cpp:137] Memory required for data: 2992532484
I0910 12:58:40.158684  1862 layer_factory.hpp:77] Creating layer loss
I0910 12:58:40.158748  1862 net.cpp:84] Creating Layer loss
I0910 12:58:40.158816  1862 net.cpp:406] loss <- fc8_fc8_0_split_1
I0910 12:58:40.158877  1862 net.cpp:406] loss <- label_data_1_split_1
I0910 12:58:40.158938  1862 net.cpp:380] loss -> loss
I0910 12:58:40.159011  1862 layer_factory.hpp:77] Creating layer loss
I0910 12:58:40.164058  1862 net.cpp:122] Setting up loss
I0910 12:58:40.164419  1862 net.cpp:129] Top shape: (1)
I0910 12:58:40.164512  1862 net.cpp:132]     with loss weight 1
I0910 12:58:40.164620  1862 net.cpp:137] Memory required for data: 2992532488
I0910 12:58:40.164682  1862 net.cpp:198] loss needs backward computation.
I0910 12:58:40.164757  1862 net.cpp:200] accuracy_5_TRAIN does not need backward computation.
I0910 12:58:40.164822  1862 net.cpp:198] fc8_fc8_0_split needs backward computation.
I0910 12:58:40.164893  1862 net.cpp:198] fc8 needs backward computation.
I0910 12:58:40.164955  1862 net.cpp:198] relu7 needs backward computation.
I0910 12:58:40.165015  1862 net.cpp:198] scale7 needs backward computation.
I0910 12:58:40.165071  1862 net.cpp:198] bn7 needs backward computation.
I0910 12:58:40.165124  1862 net.cpp:198] fc7 needs backward computation.
I0910 12:58:40.165182  1862 net.cpp:198] drop7 needs backward computation.
I0910 12:58:40.165246  1862 net.cpp:198] relu6 needs backward computation.
I0910 12:58:40.165303  1862 net.cpp:198] scale6 needs backward computation.
I0910 12:58:40.165385  1862 net.cpp:198] bn6 needs backward computation.
I0910 12:58:40.165447  1862 net.cpp:198] fc6 needs backward computation.
I0910 12:58:40.165508  1862 net.cpp:198] drop6 needs backward computation.
I0910 12:58:40.165562  1862 net.cpp:198] pool5 needs backward computation.
I0910 12:58:40.165621  1862 net.cpp:198] relu5 needs backward computation.
I0910 12:58:40.165683  1862 net.cpp:198] scale5 needs backward computation.
I0910 12:58:40.165740  1862 net.cpp:198] bn5 needs backward computation.
I0910 12:58:40.165796  1862 net.cpp:198] conv5 needs backward computation.
I0910 12:58:40.165850  1862 net.cpp:198] relu4 needs backward computation.
I0910 12:58:40.165921  1862 net.cpp:198] scale4 needs backward computation.
I0910 12:58:40.166012  1862 net.cpp:198] bn4 needs backward computation.
I0910 12:58:40.166071  1862 net.cpp:198] conv4 needs backward computation.
I0910 12:58:40.166129  1862 net.cpp:198] relu3 needs backward computation.
I0910 12:58:40.166183  1862 net.cpp:198] scale3 needs backward computation.
I0910 12:58:40.166239  1862 net.cpp:198] bn3 needs backward computation.
I0910 12:58:40.166293  1862 net.cpp:198] conv3 needs backward computation.
I0910 12:58:40.166347  1862 net.cpp:198] pool2 needs backward computation.
I0910 12:58:40.166409  1862 net.cpp:198] relu2 needs backward computation.
I0910 12:58:40.166472  1862 net.cpp:198] scale2 needs backward computation.
I0910 12:58:40.166532  1862 net.cpp:198] bn2 needs backward computation.
I0910 12:58:40.166587  1862 net.cpp:198] conv2 needs backward computation.
I0910 12:58:40.166642  1862 net.cpp:198] pool1 needs backward computation.
I0910 12:58:40.166707  1862 net.cpp:198] relu1 needs backward computation.
I0910 12:58:40.166770  1862 net.cpp:198] scale1 needs backward computation.
I0910 12:58:40.166824  1862 net.cpp:198] bn1 needs backward computation.
I0910 12:58:40.166879  1862 net.cpp:198] conv1 needs backward computation.
I0910 12:58:40.166936  1862 net.cpp:200] label_data_1_split does not need backward computation.
I0910 12:58:40.166998  1862 net.cpp:200] data does not need backward computation.
I0910 12:58:40.167060  1862 net.cpp:242] This network produces output accuracy_5_TRAIN
I0910 12:58:40.167119  1862 net.cpp:242] This network produces output loss
I0910 12:58:40.167203  1862 net.cpp:255] Network initialization done.
I0910 12:58:40.167732  1862 solver.cpp:193] Creating test net (#0) specified by net file: my/Imagenet/AlexNet-BN/XnorNet_FWN/train_val.prototxt
I0910 12:58:40.168298  1862 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0910 12:58:40.168457  1862 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_5_TRAIN
I0910 12:58:40.168926  1862 net.cpp:51] Initializing net from parameters: 
name: "AlexNet-BN"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 224
    mean_value: 103.939
    mean_value: 116.779
    mean_value: 123.68
  }
  data_param {
    source: "/home/zhengzhe/Data/ilsvrc12/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "BinaryConvolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    pad: 2
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "BinaryConvolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "BinaryConvolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "BinaryConvolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "BinaryConvolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "scale5"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "pool5"
  top: "pool5"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "fc6"
  type: "BinaryInnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn6"
  type: "BatchNorm"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "scale6"
  type: "Scale"
  bottom: "fc6"
  top: "fc6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "fc7"
  type: "BinaryInnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "scale7"
  type: "Scale"
  bottom: "fc7"
  top: "fc7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "fc8"
  type: "BinaryInnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy_5"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy_5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0910 12:58:40.172310  1862 layer_factory.hpp:77] Creating layer data
I0910 12:58:40.212388  1862 db_lmdb.cpp:35] Opened lmdb /home/zhengzhe/Data/ilsvrc12/ilsvrc12_val_lmdb
I0910 12:58:40.212419  1862 net.cpp:84] Creating Layer data
I0910 12:58:40.212430  1862 net.cpp:380] data -> data
I0910 12:58:40.212441  1862 net.cpp:380] data -> label
I0910 12:58:40.212823  1862 data_layer.cpp:45] output data size: 50,3,224,224
I0910 12:58:40.544471  1862 net.cpp:122] Setting up data
I0910 12:58:40.544804  1862 net.cpp:129] Top shape: 50 3 224 224 (7526400)
I0910 12:58:40.544900  1862 net.cpp:129] Top shape: 50 (50)
I0910 12:58:40.544970  1862 net.cpp:137] Memory required for data: 30105800
I0910 12:58:40.545042  1862 layer_factory.hpp:77] Creating layer label_data_1_split
I0910 12:58:40.545131  1862 net.cpp:84] Creating Layer label_data_1_split
I0910 12:58:40.545219  1862 net.cpp:406] label_data_1_split <- label
I0910 12:58:40.545291  1862 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0910 12:58:40.545449  1862 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0910 12:58:40.545558  1862 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0910 12:58:40.545735  1862 net.cpp:122] Setting up label_data_1_split
I0910 12:58:40.545971  1862 net.cpp:129] Top shape: 50 (50)
I0910 12:58:40.546061  1862 net.cpp:129] Top shape: 50 (50)
I0910 12:58:40.546128  1862 net.cpp:129] Top shape: 50 (50)
I0910 12:58:40.546193  1862 net.cpp:137] Memory required for data: 30106400
I0910 12:58:40.546254  1862 layer_factory.hpp:77] Creating layer conv1
I0910 12:58:40.546329  1862 net.cpp:84] Creating Layer conv1
I0910 12:58:40.546419  1862 net.cpp:406] conv1 <- data
I0910 12:58:40.546490  1862 net.cpp:380] conv1 -> conv1
I0910 12:58:40.547389  1862 net.cpp:122] Setting up conv1
I0910 12:58:40.549123  1862 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0910 12:58:40.549216  1862 net.cpp:137] Memory required for data: 88186400
I0910 12:58:40.549289  1862 layer_factory.hpp:77] Creating layer bn1
I0910 12:58:40.549389  1862 net.cpp:84] Creating Layer bn1
I0910 12:58:40.549466  1862 net.cpp:406] bn1 <- conv1
I0910 12:58:40.549535  1862 net.cpp:367] bn1 -> conv1 (in-place)
I0910 12:58:40.553283  1862 net.cpp:122] Setting up bn1
I0910 12:58:40.553367  1862 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0910 12:58:40.553413  1862 net.cpp:137] Memory required for data: 146266400
I0910 12:58:40.553467  1862 layer_factory.hpp:77] Creating layer scale1
I0910 12:58:40.553520  1862 net.cpp:84] Creating Layer scale1
I0910 12:58:40.553561  1862 net.cpp:406] scale1 <- conv1
I0910 12:58:40.553603  1862 net.cpp:367] scale1 -> conv1 (in-place)
I0910 12:58:40.553694  1862 layer_factory.hpp:77] Creating layer scale1
I0910 12:58:40.553884  1862 net.cpp:122] Setting up scale1
I0910 12:58:40.553937  1862 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0910 12:58:40.553982  1862 net.cpp:137] Memory required for data: 204346400
I0910 12:58:40.554029  1862 layer_factory.hpp:77] Creating layer relu1
I0910 12:58:40.554077  1862 net.cpp:84] Creating Layer relu1
I0910 12:58:40.554121  1862 net.cpp:406] relu1 <- conv1
I0910 12:58:40.554163  1862 net.cpp:367] relu1 -> conv1 (in-place)
I0910 12:58:40.554208  1862 net.cpp:122] Setting up relu1
I0910 12:58:40.554251  1862 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0910 12:58:40.554288  1862 net.cpp:137] Memory required for data: 262426400
I0910 12:58:40.554325  1862 layer_factory.hpp:77] Creating layer pool1
I0910 12:58:40.554379  1862 net.cpp:84] Creating Layer pool1
I0910 12:58:40.554443  1862 net.cpp:406] pool1 <- conv1
I0910 12:58:40.554494  1862 net.cpp:380] pool1 -> pool1
I0910 12:58:40.554587  1862 net.cpp:122] Setting up pool1
I0910 12:58:40.554641  1862 net.cpp:129] Top shape: 50 96 27 27 (3499200)
I0910 12:58:40.554682  1862 net.cpp:137] Memory required for data: 276423200
I0910 12:58:40.554721  1862 layer_factory.hpp:77] Creating layer conv2
I0910 12:58:40.554767  1862 net.cpp:84] Creating Layer conv2
I0910 12:58:40.554807  1862 net.cpp:406] conv2 <- pool1
I0910 12:58:40.554850  1862 net.cpp:380] conv2 -> conv2
I0910 12:58:40.575121  1862 net.cpp:122] Setting up conv2
I0910 12:58:40.580340  1862 net.cpp:129] Top shape: 50 256 27 27 (9331200)
I0910 12:58:40.580446  1862 net.cpp:137] Memory required for data: 313748000
I0910 12:58:40.580525  1862 layer_factory.hpp:77] Creating layer bn2
I0910 12:58:40.580624  1862 net.cpp:84] Creating Layer bn2
I0910 12:58:40.580708  1862 net.cpp:406] bn2 <- conv2
I0910 12:58:40.580778  1862 net.cpp:367] bn2 -> conv2 (in-place)
I0910 12:58:40.581073  1862 net.cpp:122] Setting up bn2
I0910 12:58:40.581594  1862 net.cpp:129] Top shape: 50 256 27 27 (9331200)
I0910 12:58:40.581686  1862 net.cpp:137] Memory required for data: 351072800
I0910 12:58:40.581756  1862 layer_factory.hpp:77] Creating layer scale2
I0910 12:58:40.581836  1862 net.cpp:84] Creating Layer scale2
I0910 12:58:40.581909  1862 net.cpp:406] scale2 <- conv2
I0910 12:58:40.581976  1862 net.cpp:367] scale2 -> conv2 (in-place)
I0910 12:58:40.582099  1862 layer_factory.hpp:77] Creating layer scale2
I0910 12:58:40.582401  1862 net.cpp:122] Setting up scale2
I0910 12:58:40.582731  1862 net.cpp:129] Top shape: 50 256 27 27 (9331200)
I0910 12:58:40.582818  1862 net.cpp:137] Memory required for data: 388397600
I0910 12:58:40.582886  1862 layer_factory.hpp:77] Creating layer relu2
I0910 12:58:40.582964  1862 net.cpp:84] Creating Layer relu2
I0910 12:58:40.583034  1862 net.cpp:406] relu2 <- conv2
I0910 12:58:40.583099  1862 net.cpp:367] relu2 -> conv2 (in-place)
I0910 12:58:40.583175  1862 net.cpp:122] Setting up relu2
I0910 12:58:40.583252  1862 net.cpp:129] Top shape: 50 256 27 27 (9331200)
I0910 12:58:40.583318  1862 net.cpp:137] Memory required for data: 425722400
I0910 12:58:40.583379  1862 layer_factory.hpp:77] Creating layer pool2
I0910 12:58:40.583447  1862 net.cpp:84] Creating Layer pool2
I0910 12:58:40.583518  1862 net.cpp:406] pool2 <- conv2
I0910 12:58:40.583578  1862 net.cpp:380] pool2 -> pool2
I0910 12:58:40.583698  1862 net.cpp:122] Setting up pool2
I0910 12:58:40.583873  1862 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0910 12:58:40.583941  1862 net.cpp:137] Memory required for data: 434375200
I0910 12:58:40.584000  1862 layer_factory.hpp:77] Creating layer conv3
I0910 12:58:40.584071  1862 net.cpp:84] Creating Layer conv3
I0910 12:58:40.584151  1862 net.cpp:406] conv3 <- pool2
I0910 12:58:40.584218  1862 net.cpp:380] conv3 -> conv3
I0910 12:58:40.630091  1862 net.cpp:122] Setting up conv3
I0910 12:58:40.632956  1862 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0910 12:58:40.633088  1862 net.cpp:137] Memory required for data: 447354400
I0910 12:58:40.633172  1862 layer_factory.hpp:77] Creating layer bn3
I0910 12:58:40.633293  1862 net.cpp:84] Creating Layer bn3
I0910 12:58:40.633401  1862 net.cpp:406] bn3 <- conv3
I0910 12:58:40.633507  1862 net.cpp:367] bn3 -> conv3 (in-place)
I0910 12:58:40.633849  1862 net.cpp:122] Setting up bn3
I0910 12:58:40.634506  1862 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0910 12:58:40.634624  1862 net.cpp:137] Memory required for data: 460333600
I0910 12:58:40.634690  1862 layer_factory.hpp:77] Creating layer scale3
I0910 12:58:40.634802  1862 net.cpp:84] Creating Layer scale3
I0910 12:58:40.634886  1862 net.cpp:406] scale3 <- conv3
I0910 12:58:40.634953  1862 net.cpp:367] scale3 -> conv3 (in-place)
I0910 12:58:40.635089  1862 layer_factory.hpp:77] Creating layer scale3
I0910 12:58:40.635432  1862 net.cpp:122] Setting up scale3
I0910 12:58:40.635812  1862 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0910 12:58:40.635980  1862 net.cpp:137] Memory required for data: 473312800
I0910 12:58:40.636073  1862 layer_factory.hpp:77] Creating layer relu3
I0910 12:58:40.636147  1862 net.cpp:84] Creating Layer relu3
I0910 12:58:40.636219  1862 net.cpp:406] relu3 <- conv3
I0910 12:58:40.636287  1862 net.cpp:367] relu3 -> conv3 (in-place)
I0910 12:58:40.636368  1862 net.cpp:122] Setting up relu3
I0910 12:58:40.636443  1862 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0910 12:58:40.636507  1862 net.cpp:137] Memory required for data: 486292000
I0910 12:58:40.636567  1862 layer_factory.hpp:77] Creating layer conv4
I0910 12:58:40.636643  1862 net.cpp:84] Creating Layer conv4
I0910 12:58:40.636739  1862 net.cpp:406] conv4 <- conv3
I0910 12:58:40.636806  1862 net.cpp:380] conv4 -> conv4
I0910 12:58:40.676975  1862 net.cpp:122] Setting up conv4
I0910 12:58:40.693806  1862 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0910 12:58:40.693914  1862 net.cpp:137] Memory required for data: 499271200
I0910 12:58:40.693995  1862 layer_factory.hpp:77] Creating layer bn4
I0910 12:58:40.694084  1862 net.cpp:84] Creating Layer bn4
I0910 12:58:40.694169  1862 net.cpp:406] bn4 <- conv4
I0910 12:58:40.694242  1862 net.cpp:367] bn4 -> conv4 (in-place)
I0910 12:58:40.694562  1862 net.cpp:122] Setting up bn4
I0910 12:58:40.695119  1862 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0910 12:58:40.695209  1862 net.cpp:137] Memory required for data: 512250400
I0910 12:58:40.695281  1862 layer_factory.hpp:77] Creating layer scale4
I0910 12:58:40.695366  1862 net.cpp:84] Creating Layer scale4
I0910 12:58:40.695441  1862 net.cpp:406] scale4 <- conv4
I0910 12:58:40.695513  1862 net.cpp:367] scale4 -> conv4 (in-place)
I0910 12:58:40.695638  1862 layer_factory.hpp:77] Creating layer scale4
I0910 12:58:40.695950  1862 net.cpp:122] Setting up scale4
I0910 12:58:40.696310  1862 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0910 12:58:40.696399  1862 net.cpp:137] Memory required for data: 525229600
I0910 12:58:40.696465  1862 layer_factory.hpp:77] Creating layer relu4
I0910 12:58:40.696542  1862 net.cpp:84] Creating Layer relu4
I0910 12:58:40.696591  1862 net.cpp:406] relu4 <- conv4
I0910 12:58:40.696635  1862 net.cpp:367] relu4 -> conv4 (in-place)
I0910 12:58:40.696689  1862 net.cpp:122] Setting up relu4
I0910 12:58:40.696738  1862 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0910 12:58:40.696776  1862 net.cpp:137] Memory required for data: 538208800
I0910 12:58:40.696813  1862 layer_factory.hpp:77] Creating layer conv5
I0910 12:58:40.696862  1862 net.cpp:84] Creating Layer conv5
I0910 12:58:40.696923  1862 net.cpp:406] conv5 <- conv4
I0910 12:58:40.696964  1862 net.cpp:380] conv5 -> conv5
I0910 12:58:40.726685  1862 net.cpp:122] Setting up conv5
I0910 12:58:40.735630  1862 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0910 12:58:40.735685  1862 net.cpp:137] Memory required for data: 546861600
I0910 12:58:40.735731  1862 layer_factory.hpp:77] Creating layer bn5
I0910 12:58:40.735801  1862 net.cpp:84] Creating Layer bn5
I0910 12:58:40.735857  1862 net.cpp:406] bn5 <- conv5
I0910 12:58:40.735896  1862 net.cpp:367] bn5 -> conv5 (in-place)
I0910 12:58:40.736165  1862 net.cpp:122] Setting up bn5
I0910 12:58:40.736660  1862 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0910 12:58:40.736701  1862 net.cpp:137] Memory required for data: 555514400
I0910 12:58:40.736747  1862 layer_factory.hpp:77] Creating layer scale5
I0910 12:58:40.736812  1862 net.cpp:84] Creating Layer scale5
I0910 12:58:40.736860  1862 net.cpp:406] scale5 <- conv5
I0910 12:58:40.736903  1862 net.cpp:367] scale5 -> conv5 (in-place)
I0910 12:58:40.737000  1862 layer_factory.hpp:77] Creating layer scale5
I0910 12:58:40.737274  1862 net.cpp:122] Setting up scale5
I0910 12:58:40.737586  1862 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0910 12:58:40.737629  1862 net.cpp:137] Memory required for data: 564167200
I0910 12:58:40.737669  1862 layer_factory.hpp:77] Creating layer relu5
I0910 12:58:40.737715  1862 net.cpp:84] Creating Layer relu5
I0910 12:58:40.737771  1862 net.cpp:406] relu5 <- conv5
I0910 12:58:40.737852  1862 net.cpp:367] relu5 -> conv5 (in-place)
I0910 12:58:40.737903  1862 net.cpp:122] Setting up relu5
I0910 12:58:40.737956  1862 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0910 12:58:40.737995  1862 net.cpp:137] Memory required for data: 572820000
I0910 12:58:40.738032  1862 layer_factory.hpp:77] Creating layer pool5
I0910 12:58:40.738071  1862 net.cpp:84] Creating Layer pool5
I0910 12:58:40.738114  1862 net.cpp:406] pool5 <- conv5
I0910 12:58:40.738157  1862 net.cpp:380] pool5 -> pool5
I0910 12:58:40.738250  1862 net.cpp:122] Setting up pool5
I0910 12:58:40.738394  1862 net.cpp:129] Top shape: 50 256 6 6 (460800)
I0910 12:58:40.738435  1862 net.cpp:137] Memory required for data: 574663200
I0910 12:58:40.738473  1862 layer_factory.hpp:77] Creating layer drop6
I0910 12:58:40.738519  1862 net.cpp:84] Creating Layer drop6
I0910 12:58:40.738571  1862 net.cpp:406] drop6 <- pool5
I0910 12:58:40.738612  1862 net.cpp:367] drop6 -> pool5 (in-place)
I0910 12:58:40.738685  1862 net.cpp:122] Setting up drop6
I0910 12:58:40.738786  1862 net.cpp:129] Top shape: 50 256 6 6 (460800)
I0910 12:58:40.738828  1862 net.cpp:137] Memory required for data: 576506400
I0910 12:58:40.738863  1862 layer_factory.hpp:77] Creating layer fc6
I0910 12:58:40.738909  1862 net.cpp:84] Creating Layer fc6
I0910 12:58:40.738958  1862 net.cpp:406] fc6 <- pool5
I0910 12:58:40.738997  1862 net.cpp:380] fc6 -> fc6
I0910 12:58:42.806288  1862 net.cpp:122] Setting up fc6
I0910 12:58:42.806479  1862 net.cpp:129] Top shape: 50 4096 (204800)
I0910 12:58:42.806529  1862 net.cpp:137] Memory required for data: 577325600
I0910 12:58:42.806579  1862 layer_factory.hpp:77] Creating layer bn6
I0910 12:58:42.806635  1862 net.cpp:84] Creating Layer bn6
I0910 12:58:42.806680  1862 net.cpp:406] bn6 <- fc6
I0910 12:58:42.806723  1862 net.cpp:367] bn6 -> fc6 (in-place)
I0910 12:58:42.807008  1862 net.cpp:122] Setting up bn6
I0910 12:58:42.807085  1862 net.cpp:129] Top shape: 50 4096 (204800)
I0910 12:58:42.807128  1862 net.cpp:137] Memory required for data: 578144800
I0910 12:58:42.807178  1862 layer_factory.hpp:77] Creating layer scale6
I0910 12:58:42.807227  1862 net.cpp:84] Creating Layer scale6
I0910 12:58:42.807268  1862 net.cpp:406] scale6 <- fc6
I0910 12:58:42.807312  1862 net.cpp:367] scale6 -> fc6 (in-place)
I0910 12:58:42.807405  1862 layer_factory.hpp:77] Creating layer scale6
I0910 12:58:42.807607  1862 net.cpp:122] Setting up scale6
I0910 12:58:42.807677  1862 net.cpp:129] Top shape: 50 4096 (204800)
I0910 12:58:42.807718  1862 net.cpp:137] Memory required for data: 578964000
I0910 12:58:42.807760  1862 layer_factory.hpp:77] Creating layer relu6
I0910 12:58:42.807806  1862 net.cpp:84] Creating Layer relu6
I0910 12:58:42.807844  1862 net.cpp:406] relu6 <- fc6
I0910 12:58:42.807890  1862 net.cpp:367] relu6 -> fc6 (in-place)
I0910 12:58:42.807935  1862 net.cpp:122] Setting up relu6
I0910 12:58:42.807976  1862 net.cpp:129] Top shape: 50 4096 (204800)
I0910 12:58:42.808013  1862 net.cpp:137] Memory required for data: 579783200
I0910 12:58:42.808051  1862 layer_factory.hpp:77] Creating layer drop7
I0910 12:58:42.808092  1862 net.cpp:84] Creating Layer drop7
I0910 12:58:42.808131  1862 net.cpp:406] drop7 <- fc6
I0910 12:58:42.808171  1862 net.cpp:367] drop7 -> fc6 (in-place)
I0910 12:58:42.808243  1862 net.cpp:122] Setting up drop7
I0910 12:58:42.808300  1862 net.cpp:129] Top shape: 50 4096 (204800)
I0910 12:58:42.808344  1862 net.cpp:137] Memory required for data: 580602400
I0910 12:58:42.808383  1862 layer_factory.hpp:77] Creating layer fc7
I0910 12:58:42.808430  1862 net.cpp:84] Creating Layer fc7
I0910 12:58:42.808471  1862 net.cpp:406] fc7 <- fc6
I0910 12:58:42.808516  1862 net.cpp:380] fc7 -> fc7
I0910 12:58:43.522239  1862 net.cpp:122] Setting up fc7
I0910 12:58:43.522491  1862 net.cpp:129] Top shape: 50 4096 (204800)
I0910 12:58:43.522516  1862 net.cpp:137] Memory required for data: 581421600
I0910 12:58:43.522560  1862 layer_factory.hpp:77] Creating layer bn7
I0910 12:58:43.522615  1862 net.cpp:84] Creating Layer bn7
I0910 12:58:43.522637  1862 net.cpp:406] bn7 <- fc7
I0910 12:58:43.522713  1862 net.cpp:367] bn7 -> fc7 (in-place)
I0910 12:58:43.523725  1862 net.cpp:122] Setting up bn7
I0910 12:58:43.523792  1862 net.cpp:129] Top shape: 50 4096 (204800)
I0910 12:58:43.523833  1862 net.cpp:137] Memory required for data: 582240800
I0910 12:58:43.523888  1862 layer_factory.hpp:77] Creating layer scale7
I0910 12:58:43.523943  1862 net.cpp:84] Creating Layer scale7
I0910 12:58:43.523984  1862 net.cpp:406] scale7 <- fc7
I0910 12:58:43.524034  1862 net.cpp:367] scale7 -> fc7 (in-place)
I0910 12:58:43.524271  1862 layer_factory.hpp:77] Creating layer scale7
I0910 12:58:43.524832  1862 net.cpp:122] Setting up scale7
I0910 12:58:43.524893  1862 net.cpp:129] Top shape: 50 4096 (204800)
I0910 12:58:43.524933  1862 net.cpp:137] Memory required for data: 583060000
I0910 12:58:43.524986  1862 layer_factory.hpp:77] Creating layer relu7
I0910 12:58:43.525036  1862 net.cpp:84] Creating Layer relu7
I0910 12:58:43.525075  1862 net.cpp:406] relu7 <- fc7
I0910 12:58:43.525121  1862 net.cpp:367] relu7 -> fc7 (in-place)
I0910 12:58:43.525173  1862 net.cpp:122] Setting up relu7
I0910 12:58:43.525214  1862 net.cpp:129] Top shape: 50 4096 (204800)
I0910 12:58:43.525241  1862 net.cpp:137] Memory required for data: 583879200
I0910 12:58:43.525280  1862 layer_factory.hpp:77] Creating layer fc8
I0910 12:58:43.525352  1862 net.cpp:84] Creating Layer fc8
I0910 12:58:43.525395  1862 net.cpp:406] fc8 <- fc7
I0910 12:58:43.525454  1862 net.cpp:380] fc8 -> fc8
I0910 12:58:43.871373  1862 net.cpp:122] Setting up fc8
I0910 12:58:43.887282  1862 net.cpp:129] Top shape: 50 1000 (50000)
I0910 12:58:43.887712  1862 net.cpp:137] Memory required for data: 584079200
I0910 12:58:43.887917  1862 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0910 12:58:43.888160  1862 net.cpp:84] Creating Layer fc8_fc8_0_split
I0910 12:58:43.888267  1862 net.cpp:406] fc8_fc8_0_split <- fc8
I0910 12:58:43.888432  1862 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0910 12:58:43.888514  1862 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0910 12:58:43.888593  1862 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0910 12:58:43.888854  1862 net.cpp:122] Setting up fc8_fc8_0_split
I0910 12:58:43.889065  1862 net.cpp:129] Top shape: 50 1000 (50000)
I0910 12:58:43.889163  1862 net.cpp:129] Top shape: 50 1000 (50000)
I0910 12:58:43.889305  1862 net.cpp:129] Top shape: 50 1000 (50000)
I0910 12:58:43.889377  1862 net.cpp:137] Memory required for data: 584679200
I0910 12:58:43.889421  1862 layer_factory.hpp:77] Creating layer accuracy
I0910 12:58:43.889473  1862 net.cpp:84] Creating Layer accuracy
I0910 12:58:43.889554  1862 net.cpp:406] accuracy <- fc8_fc8_0_split_0
I0910 12:58:43.889700  1862 net.cpp:406] accuracy <- label_data_1_split_0
I0910 12:58:43.889755  1862 net.cpp:380] accuracy -> accuracy
I0910 12:58:43.889811  1862 net.cpp:122] Setting up accuracy
I0910 12:58:43.889886  1862 net.cpp:129] Top shape: (1)
I0910 12:58:43.890034  1862 net.cpp:137] Memory required for data: 584679204
I0910 12:58:43.890081  1862 layer_factory.hpp:77] Creating layer accuracy_5
I0910 12:58:43.890131  1862 net.cpp:84] Creating Layer accuracy_5
I0910 12:58:43.890182  1862 net.cpp:406] accuracy_5 <- fc8_fc8_0_split_1
I0910 12:58:43.890241  1862 net.cpp:406] accuracy_5 <- label_data_1_split_1
I0910 12:58:43.890399  1862 net.cpp:380] accuracy_5 -> accuracy_5
I0910 12:58:43.890455  1862 net.cpp:122] Setting up accuracy_5
I0910 12:58:43.890504  1862 net.cpp:129] Top shape: (1)
I0910 12:58:43.890560  1862 net.cpp:137] Memory required for data: 584679208
I0910 12:58:43.890708  1862 layer_factory.hpp:77] Creating layer loss
I0910 12:58:43.890758  1862 net.cpp:84] Creating Layer loss
I0910 12:58:43.890803  1862 net.cpp:406] loss <- fc8_fc8_0_split_2
I0910 12:58:43.890848  1862 net.cpp:406] loss <- label_data_1_split_2
I0910 12:58:43.890900  1862 net.cpp:380] loss -> loss
I0910 12:58:43.891057  1862 layer_factory.hpp:77] Creating layer loss
I0910 12:58:43.891327  1862 net.cpp:122] Setting up loss
I0910 12:58:43.891803  1862 net.cpp:129] Top shape: (1)
I0910 12:58:43.891921  1862 net.cpp:132]     with loss weight 1
I0910 12:58:43.892082  1862 net.cpp:137] Memory required for data: 584679212
I0910 12:58:43.892132  1862 net.cpp:198] loss needs backward computation.
I0910 12:58:43.892181  1862 net.cpp:200] accuracy_5 does not need backward computation.
I0910 12:58:43.892333  1862 net.cpp:200] accuracy does not need backward computation.
I0910 12:58:43.892380  1862 net.cpp:198] fc8_fc8_0_split needs backward computation.
I0910 12:58:43.892424  1862 net.cpp:198] fc8 needs backward computation.
I0910 12:58:43.892467  1862 net.cpp:198] relu7 needs backward computation.
I0910 12:58:43.892514  1862 net.cpp:198] scale7 needs backward computation.
I0910 12:58:43.892572  1862 net.cpp:198] bn7 needs backward computation.
I0910 12:58:43.892710  1862 net.cpp:198] fc7 needs backward computation.
I0910 12:58:43.892757  1862 net.cpp:198] drop7 needs backward computation.
I0910 12:58:43.892799  1862 net.cpp:198] relu6 needs backward computation.
I0910 12:58:43.892838  1862 net.cpp:198] scale6 needs backward computation.
I0910 12:58:43.892880  1862 net.cpp:198] bn6 needs backward computation.
I0910 12:58:43.893024  1862 net.cpp:198] fc6 needs backward computation.
I0910 12:58:43.893071  1862 net.cpp:198] drop6 needs backward computation.
I0910 12:58:43.893110  1862 net.cpp:198] pool5 needs backward computation.
I0910 12:58:43.893149  1862 net.cpp:198] relu5 needs backward computation.
I0910 12:58:43.893188  1862 net.cpp:198] scale5 needs backward computation.
I0910 12:58:43.893234  1862 net.cpp:198] bn5 needs backward computation.
I0910 12:58:43.893290  1862 net.cpp:198] conv5 needs backward computation.
I0910 12:58:43.893380  1862 net.cpp:198] relu4 needs backward computation.
I0910 12:58:43.893429  1862 net.cpp:198] scale4 needs backward computation.
I0910 12:58:43.893481  1862 net.cpp:198] bn4 needs backward computation.
I0910 12:58:43.893538  1862 net.cpp:198] conv4 needs backward computation.
I0910 12:58:43.893595  1862 net.cpp:198] relu3 needs backward computation.
I0910 12:58:43.893651  1862 net.cpp:198] scale3 needs backward computation.
I0910 12:58:43.893705  1862 net.cpp:198] bn3 needs backward computation.
I0910 12:58:43.893759  1862 net.cpp:198] conv3 needs backward computation.
I0910 12:58:43.893816  1862 net.cpp:198] pool2 needs backward computation.
I0910 12:58:43.893873  1862 net.cpp:198] relu2 needs backward computation.
I0910 12:58:43.893931  1862 net.cpp:198] scale2 needs backward computation.
I0910 12:58:43.893986  1862 net.cpp:198] bn2 needs backward computation.
I0910 12:58:43.894043  1862 net.cpp:198] conv2 needs backward computation.
I0910 12:58:43.894098  1862 net.cpp:198] pool1 needs backward computation.
I0910 12:58:43.894155  1862 net.cpp:198] relu1 needs backward computation.
I0910 12:58:43.894210  1862 net.cpp:198] scale1 needs backward computation.
I0910 12:58:43.894268  1862 net.cpp:198] bn1 needs backward computation.
I0910 12:58:43.894321  1862 net.cpp:198] conv1 needs backward computation.
I0910 12:58:43.894376  1862 net.cpp:200] label_data_1_split does not need backward computation.
I0910 12:58:43.894436  1862 net.cpp:200] data does not need backward computation.
I0910 12:58:43.894496  1862 net.cpp:242] This network produces output accuracy
I0910 12:58:43.894551  1862 net.cpp:242] This network produces output accuracy_5
I0910 12:58:43.894608  1862 net.cpp:242] This network produces output loss
I0910 12:58:43.894698  1862 net.cpp:255] Network initialization done.
I0910 12:58:43.895370  1862 solver.cpp:57] Solver scaffolding done.
I0910 12:58:43.934321  1862 caffe.cpp:235] Resuming from my/Imagenet/AlexNet-BN/XnorNet_FWN/snapshot/xnor_net_iter_270000.solverstate
I0910 12:58:52.719229  1862 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: my/Imagenet/AlexNet-BN/XnorNet_FWN/snapshot/xnor_net_iter_270000.caffemodel
I0910 12:58:52.719280  1862 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0910 12:58:52.719292  1862 net.cpp:811] net quantization's state : 0
I0910 12:58:56.100960  1862 sgd_solver.cpp:374] SGDSolver: restoring history
I0910 12:58:56.808718  1862 caffe.cpp:239] Starting Optimization
I0910 12:59:03.328382  1922 solver.cpp:193] Creating test net (#0) specified by net file: my/Imagenet/AlexNet-BN/XnorNet_FWN/train_val.prototxt
I0910 12:59:37.264859  1922 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: my/Imagenet/AlexNet-BN/XnorNet_FWN/snapshot/xnor_net_iter_270000.caffemodel
I0910 12:59:37.282450  1922 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0910 12:59:37.282634  1922 net.cpp:811] net quantization's state : 0
I0910 12:59:39.574098  1922 sgd_solver.cpp:374] SGDSolver: restoring history
I0910 12:59:40.841344  1862 solver.cpp:296] Solving AlexNet-BN
I0910 12:59:40.841606  1862 solver.cpp:297] Learning Rate Policy: poly
I0910 12:59:40.841914  1862 solver.cpp:377] Iteration 270000, Testing net (#0)
I0910 12:59:41.217419  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0910 13:10:48.904692  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0910 13:10:51.578860  1862 solver.cpp:445]     Test net output #0: accuracy = 0.36972
I0910 13:10:51.580531  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.61372
I0910 13:10:51.580567  1862 solver.cpp:445]     Test net output #2: loss = 2.99581 (* 1 = 2.99581 loss)
I0910 13:10:51.580685  1862 solver.cpp:456] ================================
I0910 13:10:51.580725  1862 solver.cpp:457]     Test net best accuracy1 is: 0.36972
I0910 13:10:51.580761  1862 solver.cpp:459]     Test net best accuracy5 is: 0.61372
I0910 13:10:53.241461  1862 solver.cpp:242] Iteration 270000 (1.6986e+11 iter/s, 672.355s/200 iters), loss = 2.52716
I0910 13:10:53.241883  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.671875
I0910 13:10:53.242019  1862 solver.cpp:261]     Train net output #1: loss = 2.52716 (* 1 = 2.52716 loss)
I0910 13:10:53.242115  1862 sgd_solver.cpp:122] Iteration 270000, lr = 0.0078125
I0910 13:16:18.998379  1862 solver.cpp:242] Iteration 270200 (0.613976 iter/s, 325.745s/200 iters), loss = 2.20909
I0910 13:16:18.999070  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.746094
I0910 13:16:18.999217  1862 solver.cpp:261]     Train net output #1: loss = 2.20909 (* 1 = 2.20909 loss)
I0910 13:16:18.999315  1862 sgd_solver.cpp:122] Iteration 270200, lr = 0.00778125
I0910 13:21:41.273401  1862 solver.cpp:242] Iteration 270400 (0.62061 iter/s, 322.263s/200 iters), loss = 2.23412
I0910 13:21:41.273785  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.738281
I0910 13:21:41.273872  1862 solver.cpp:261]     Train net output #1: loss = 2.23412 (* 1 = 2.23412 loss)
I0910 13:21:41.273952  1862 sgd_solver.cpp:122] Iteration 270400, lr = 0.00775
I0910 13:27:10.609983  1862 solver.cpp:242] Iteration 270600 (0.607303 iter/s, 329.325s/200 iters), loss = 2.31958
I0910 13:27:10.611085  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.710938
I0910 13:27:10.611166  1862 solver.cpp:261]     Train net output #1: loss = 2.31958 (* 1 = 2.31958 loss)
I0910 13:27:10.611227  1862 sgd_solver.cpp:122] Iteration 270600, lr = 0.00771875
I0910 13:32:40.857405  1862 solver.cpp:242] Iteration 270800 (0.605629 iter/s, 330.235s/200 iters), loss = 2.26714
I0910 13:32:40.857566  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.777344
I0910 13:32:40.857583  1862 solver.cpp:261]     Train net output #1: loss = 2.26714 (* 1 = 2.26714 loss)
I0910 13:32:40.857599  1862 sgd_solver.cpp:122] Iteration 270800, lr = 0.0076875
I0910 13:38:18.757833  1862 solver.cpp:377] Iteration 271000, Testing net (#0)
I0910 13:38:18.764791  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0910 13:49:46.748625  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0910 13:49:48.995693  1862 solver.cpp:445]     Test net output #0: accuracy = 0.37224
I0910 13:49:48.995915  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.619039
I0910 13:49:48.995999  1862 solver.cpp:445]     Test net output #2: loss = 2.98633 (* 1 = 2.98633 loss)
I0910 13:49:48.996050  1862 solver.cpp:456] ================================
I0910 13:49:48.996093  1862 solver.cpp:457]     Test net best accuracy1 is: 0.37224
I0910 13:49:48.996136  1862 solver.cpp:459]     Test net best accuracy5 is: 0.619039
I0910 13:49:50.481437  1862 solver.cpp:242] Iteration 271000 (0.194252 iter/s, 1029.59s/200 iters), loss = 2.18844
I0910 13:49:50.481560  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.734375
I0910 13:49:50.481601  1862 solver.cpp:261]     Train net output #1: loss = 2.18844 (* 1 = 2.18844 loss)
I0910 13:49:50.481643  1862 sgd_solver.cpp:122] Iteration 271000, lr = 0.00765625
I0910 13:55:13.117394  1862 solver.cpp:242] Iteration 271200 (0.619915 iter/s, 322.625s/200 iters), loss = 2.29808
I0910 13:55:13.119591  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.726562
I0910 13:55:13.119642  1862 solver.cpp:261]     Train net output #1: loss = 2.29808 (* 1 = 2.29808 loss)
I0910 13:55:13.119683  1862 sgd_solver.cpp:122] Iteration 271200, lr = 0.007625
I0910 14:00:39.725509  1862 solver.cpp:242] Iteration 271400 (0.612395 iter/s, 326.587s/200 iters), loss = 2.23231
I0910 14:00:39.732416  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.730469
I0910 14:00:39.732434  1862 solver.cpp:261]     Train net output #1: loss = 2.23231 (* 1 = 2.23231 loss)
I0910 14:00:39.732447  1862 sgd_solver.cpp:122] Iteration 271400, lr = 0.00759375
I0910 14:06:57.037398  1862 solver.cpp:242] Iteration 271600 (0.530093 iter/s, 377.292s/200 iters), loss = 2.25504
I0910 14:06:57.038080  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.726562
I0910 14:06:57.038215  1862 solver.cpp:261]     Train net output #1: loss = 2.25504 (* 1 = 2.25504 loss)
I0910 14:06:57.038321  1862 sgd_solver.cpp:122] Iteration 271600, lr = 0.0075625
I0910 14:13:24.349948  1862 solver.cpp:242] Iteration 271800 (0.516397 iter/s, 387.299s/200 iters), loss = 2.28891
I0910 14:13:24.351078  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.722656
I0910 14:13:24.351146  1862 solver.cpp:261]     Train net output #1: loss = 2.28891 (* 1 = 2.28891 loss)
I0910 14:13:24.351205  1862 sgd_solver.cpp:122] Iteration 271800, lr = 0.00753125
I0910 14:19:18.783219  1862 solver.cpp:377] Iteration 272000, Testing net (#0)
I0910 14:19:18.789455  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0910 14:31:37.071127  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0910 14:31:41.116781  1862 solver.cpp:445]     Test net output #0: accuracy = 0.3597
I0910 14:31:41.119988  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.60034
I0910 14:31:41.120306  1862 solver.cpp:445]     Test net output #2: loss = 3.1055 (* 1 = 3.1055 loss)
I0910 14:31:41.120549  1862 solver.cpp:456] ================================
I0910 14:31:41.120751  1862 solver.cpp:457]     Test net best accuracy1 is: 0.37224
I0910 14:31:41.120960  1862 solver.cpp:459]     Test net best accuracy5 is: 0.619039
I0910 14:31:42.766331  1862 solver.cpp:242] Iteration 272000 (0.182087 iter/s, 1098.38s/200 iters), loss = 2.29917
I0910 14:31:42.766403  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.738281
I0910 14:31:42.766420  1862 solver.cpp:261]     Train net output #1: loss = 2.29917 (* 1 = 2.29917 loss)
I0910 14:31:42.799819  1862 sgd_solver.cpp:122] Iteration 272000, lr = 0.0075
I0910 14:38:09.017383  1862 solver.cpp:242] Iteration 272200 (0.517815 iter/s, 386.238s/200 iters), loss = 2.10904
I0910 14:38:09.017820  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.761719
I0910 14:38:09.017894  1862 solver.cpp:261]     Train net output #1: loss = 2.10904 (* 1 = 2.10904 loss)
I0910 14:38:09.017961  1862 sgd_solver.cpp:122] Iteration 272200, lr = 0.00746875
I0910 14:44:06.260015  1862 solver.cpp:242] Iteration 272400 (0.559863 iter/s, 357.23s/200 iters), loss = 2.28092
I0910 14:44:06.260419  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.738281
I0910 14:44:06.260500  1862 solver.cpp:261]     Train net output #1: loss = 2.28092 (* 1 = 2.28092 loss)
I0910 14:44:06.260571  1862 sgd_solver.cpp:122] Iteration 272400, lr = 0.0074375
I0910 14:47:10.735610  1876 data_layer.cpp:73] Restarting data prefetching from start.
I0910 14:50:12.811939  1862 solver.cpp:242] Iteration 272600 (0.545644 iter/s, 366.539s/200 iters), loss = 2.07561
I0910 14:50:12.812263  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.757812
I0910 14:50:12.812341  1862 solver.cpp:261]     Train net output #1: loss = 2.07561 (* 1 = 2.07561 loss)
I0910 14:50:12.837442  1862 sgd_solver.cpp:122] Iteration 272600, lr = 0.00740625
I0910 14:55:38.206988  1862 solver.cpp:242] Iteration 272800 (0.614659 iter/s, 325.384s/200 iters), loss = 2.17849
I0910 14:55:38.207159  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.746094
I0910 14:55:38.207178  1862 solver.cpp:261]     Train net output #1: loss = 2.17849 (* 1 = 2.17849 loss)
I0910 14:55:38.273357  1862 sgd_solver.cpp:122] Iteration 272800, lr = 0.007375
I0910 15:01:09.515399  1862 solver.cpp:377] Iteration 273000, Testing net (#0)
I0910 15:01:09.543143  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0910 15:13:00.879086  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0910 15:13:04.078547  1862 solver.cpp:445]     Test net output #0: accuracy = 0.35216
I0910 15:13:04.078766  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.59888
I0910 15:13:04.078835  1862 solver.cpp:445]     Test net output #2: loss = 3.10726 (* 1 = 3.10726 loss)
I0910 15:13:04.078886  1862 solver.cpp:456] ================================
I0910 15:13:04.078930  1862 solver.cpp:457]     Test net best accuracy1 is: 0.37224
I0910 15:13:04.078974  1862 solver.cpp:459]     Test net best accuracy5 is: 0.619039
I0910 15:13:05.505414  1862 solver.cpp:242] Iteration 273000 (0.190974 iter/s, 1047.26s/200 iters), loss = 2.14008
I0910 15:13:05.505633  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.761719
I0910 15:13:05.505707  1862 solver.cpp:261]     Train net output #1: loss = 2.14008 (* 1 = 2.14008 loss)
I0910 15:13:05.532425  1862 sgd_solver.cpp:122] Iteration 273000, lr = 0.00734375
I0910 15:18:45.907812  1862 solver.cpp:242] Iteration 273200 (0.58756 iter/s, 340.391s/200 iters), loss = 2.3045
I0910 15:18:45.908332  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.714844
I0910 15:18:45.908510  1862 solver.cpp:261]     Train net output #1: loss = 2.3045 (* 1 = 2.3045 loss)
I0910 15:18:45.908620  1862 sgd_solver.cpp:122] Iteration 273200, lr = 0.0073125
I0910 15:24:46.881404  1862 solver.cpp:242] Iteration 273400 (0.554077 iter/s, 360.961s/200 iters), loss = 2.39597
I0910 15:24:46.881878  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.761719
I0910 15:24:46.881988  1862 solver.cpp:261]     Train net output #1: loss = 2.39597 (* 1 = 2.39597 loss)
I0910 15:24:46.882076  1862 sgd_solver.cpp:122] Iteration 273400, lr = 0.00728125
I0910 15:30:40.768824  1862 solver.cpp:242] Iteration 273600 (0.565171 iter/s, 353.875s/200 iters), loss = 2.41927
I0910 15:30:40.769001  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.710938
I0910 15:30:40.769021  1862 solver.cpp:261]     Train net output #1: loss = 2.41927 (* 1 = 2.41927 loss)
I0910 15:30:40.819300  1862 sgd_solver.cpp:122] Iteration 273600, lr = 0.00725
I0910 15:36:25.205374  1862 solver.cpp:242] Iteration 273800 (0.580678 iter/s, 344.425s/200 iters), loss = 2.62956
I0910 15:36:25.205564  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.667969
I0910 15:36:25.205596  1862 solver.cpp:261]     Train net output #1: loss = 2.62956 (* 1 = 2.62956 loss)
I0910 15:36:25.205627  1862 sgd_solver.cpp:122] Iteration 273800, lr = 0.00721875
I0910 15:43:07.846479  1862 solver.cpp:377] Iteration 274000, Testing net (#0)
I0910 15:43:07.846889  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0910 15:56:23.287183  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0910 15:56:25.562696  1862 solver.cpp:445]     Test net output #0: accuracy = 0.3636
I0910 15:56:25.573616  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.60302
I0910 15:56:25.573726  1862 solver.cpp:445]     Test net output #2: loss = 3.06518 (* 1 = 3.06518 loss)
I0910 15:56:25.573794  1862 solver.cpp:456] ================================
I0910 15:56:25.573850  1862 solver.cpp:457]     Test net best accuracy1 is: 0.37224
I0910 15:56:25.573906  1862 solver.cpp:459]     Test net best accuracy5 is: 0.619039
I0910 15:56:27.169625  1862 solver.cpp:242] Iteration 274000 (0.1664 iter/s, 1201.92s/200 iters), loss = 2.22143
I0910 15:56:27.170334  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.761719
I0910 15:56:27.170524  1862 solver.cpp:261]     Train net output #1: loss = 2.22143 (* 1 = 2.22143 loss)
I0910 15:56:27.170670  1862 sgd_solver.cpp:122] Iteration 274000, lr = 0.0071875
I0910 16:02:40.495018  1862 solver.cpp:242] Iteration 274200 (0.535745 iter/s, 373.312s/200 iters), loss = 2.24509
I0910 16:02:40.495712  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.738281
I0910 16:02:40.495734  1862 solver.cpp:261]     Train net output #1: loss = 2.24509 (* 1 = 2.24509 loss)
I0910 16:02:40.495754  1862 sgd_solver.cpp:122] Iteration 274200, lr = 0.00715625
I0910 16:08:41.823981  1862 solver.cpp:242] Iteration 274400 (0.553532 iter/s, 361.316s/200 iters), loss = 2.38706
I0910 16:08:41.824407  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.726562
I0910 16:08:41.824481  1862 solver.cpp:261]     Train net output #1: loss = 2.38706 (* 1 = 2.38706 loss)
I0910 16:08:41.824568  1862 sgd_solver.cpp:122] Iteration 274400, lr = 0.007125
I0910 16:15:00.093397  1862 solver.cpp:242] Iteration 274600 (0.528742 iter/s, 378.256s/200 iters), loss = 2.21821
I0910 16:15:00.093761  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.753906
I0910 16:15:00.093776  1862 solver.cpp:261]     Train net output #1: loss = 2.21821 (* 1 = 2.21821 loss)
I0910 16:15:00.093793  1862 sgd_solver.cpp:122] Iteration 274600, lr = 0.00709375
I0910 16:21:34.113456  1862 solver.cpp:242] Iteration 274800 (0.507606 iter/s, 394.006s/200 iters), loss = 2.21663
I0910 16:21:34.113876  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.722656
I0910 16:21:34.113957  1862 solver.cpp:261]     Train net output #1: loss = 2.21663 (* 1 = 2.21663 loss)
I0910 16:21:34.114040  1862 sgd_solver.cpp:122] Iteration 274800, lr = 0.0070625
I0910 16:28:24.803985  1862 solver.cpp:377] Iteration 275000, Testing net (#0)
I0910 16:28:24.805876  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0910 16:42:20.998559  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0910 16:42:24.882447  1862 solver.cpp:445]     Test net output #0: accuracy = 0.38224
I0910 16:42:24.882757  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.63456
I0910 16:42:24.882863  1862 solver.cpp:445]     Test net output #2: loss = 2.89901 (* 1 = 2.89901 loss)
I0910 16:42:24.882930  1862 solver.cpp:456] ================================
I0910 16:42:24.883002  1862 solver.cpp:457]     Test net best accuracy1 is: 0.38224
I0910 16:42:24.883062  1862 solver.cpp:459]     Test net best accuracy5 is: 0.63456
I0910 16:42:26.505898  1862 solver.cpp:242] Iteration 275000 (0.1597 iter/s, 1252.35s/200 iters), loss = 2.30248
I0910 16:42:26.506095  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.738281
I0910 16:42:26.506144  1862 solver.cpp:261]     Train net output #1: loss = 2.30248 (* 1 = 2.30248 loss)
I0910 16:42:26.552865  1862 sgd_solver.cpp:122] Iteration 275000, lr = 0.00703125
I0910 16:42:27.345966  1876 data_layer.cpp:73] Restarting data prefetching from start.
I0910 16:49:56.651882  1862 solver.cpp:242] Iteration 275200 (0.444316 iter/s, 450.13s/200 iters), loss = 2.15634
I0910 16:49:56.652479  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.777344
I0910 16:49:56.652525  1862 solver.cpp:261]     Train net output #1: loss = 2.15634 (* 1 = 2.15634 loss)
I0910 16:49:56.673892  1862 sgd_solver.cpp:122] Iteration 275200, lr = 0.007
I0910 16:57:10.973683  1862 solver.cpp:242] Iteration 275400 (0.460504 iter/s, 434.306s/200 iters), loss = 2.09873
I0910 16:57:10.973966  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.773438
I0910 16:57:10.974005  1862 solver.cpp:261]     Train net output #1: loss = 2.09873 (* 1 = 2.09873 loss)
I0910 16:57:10.974030  1862 sgd_solver.cpp:122] Iteration 275400, lr = 0.00696875
I0910 17:04:37.535439  1862 solver.cpp:242] Iteration 275600 (0.447882 iter/s, 446.546s/200 iters), loss = 2.2206
I0910 17:04:37.536279  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.742188
I0910 17:04:37.536335  1862 solver.cpp:261]     Train net output #1: loss = 2.2206 (* 1 = 2.2206 loss)
I0910 17:04:37.601460  1862 sgd_solver.cpp:122] Iteration 275600, lr = 0.0069375
I0910 17:12:09.759097  1862 solver.cpp:242] Iteration 275800 (0.442275 iter/s, 452.207s/200 iters), loss = 2.06723
I0910 17:12:09.759268  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.78125
I0910 17:12:09.759284  1862 solver.cpp:261]     Train net output #1: loss = 2.06723 (* 1 = 2.06723 loss)
I0910 17:12:09.777354  1862 sgd_solver.cpp:122] Iteration 275800, lr = 0.00690625
I0910 17:19:06.033924  1862 solver.cpp:377] Iteration 276000, Testing net (#0)
I0910 17:19:06.035841  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0910 17:33:20.189921  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0910 17:33:22.754215  1862 solver.cpp:445]     Test net output #0: accuracy = 0.35776
I0910 17:33:22.758402  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.607259
I0910 17:33:22.758517  1862 solver.cpp:445]     Test net output #2: loss = 3.05197 (* 1 = 3.05197 loss)
I0910 17:33:22.758597  1862 solver.cpp:456] ================================
I0910 17:33:22.758658  1862 solver.cpp:457]     Test net best accuracy1 is: 0.38224
I0910 17:33:22.758719  1862 solver.cpp:459]     Test net best accuracy5 is: 0.63456
I0910 17:33:24.585196  1862 solver.cpp:242] Iteration 276000 (0.156889 iter/s, 1274.78s/200 iters), loss = 2.29338
I0910 17:33:24.585528  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.738281
I0910 17:33:24.585649  1862 solver.cpp:261]     Train net output #1: loss = 2.29338 (* 1 = 2.29338 loss)
I0910 17:33:24.585731  1862 sgd_solver.cpp:122] Iteration 276000, lr = 0.006875
I0910 17:40:56.465428  1862 solver.cpp:242] Iteration 276200 (0.44261 iter/s, 451.865s/200 iters), loss = 2.2768
I0910 17:40:56.466136  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.730469
I0910 17:40:56.466367  1862 solver.cpp:261]     Train net output #1: loss = 2.2768 (* 1 = 2.2768 loss)
I0910 17:40:56.466548  1862 sgd_solver.cpp:122] Iteration 276200, lr = 0.00684375
I0910 17:48:17.503911  1862 solver.cpp:242] Iteration 276400 (0.453491 iter/s, 441.023s/200 iters), loss = 2.32095
I0910 17:48:17.507470  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.710938
I0910 17:48:17.507593  1862 solver.cpp:261]     Train net output #1: loss = 2.32095 (* 1 = 2.32095 loss)
I0910 17:48:17.507670  1862 sgd_solver.cpp:122] Iteration 276400, lr = 0.0068125
I0910 17:55:38.561938  1862 solver.cpp:242] Iteration 276600 (0.453474 iter/s, 441.04s/200 iters), loss = 2.04427
I0910 17:55:38.562782  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.789062
I0910 17:55:38.562804  1862 solver.cpp:261]     Train net output #1: loss = 2.04427 (* 1 = 2.04427 loss)
I0910 17:55:38.562819  1862 sgd_solver.cpp:122] Iteration 276600, lr = 0.00678125
I0910 18:03:00.132401  1862 solver.cpp:242] Iteration 276800 (0.452945 iter/s, 441.555s/200 iters), loss = 2.12462
I0910 18:03:00.132743  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.746094
I0910 18:03:00.132819  1862 solver.cpp:261]     Train net output #1: loss = 2.12462 (* 1 = 2.12462 loss)
I0910 18:03:00.132881  1862 sgd_solver.cpp:122] Iteration 276800, lr = 0.00675
I0910 18:10:16.607611  1862 solver.cpp:377] Iteration 277000, Testing net (#0)
I0910 18:10:16.608808  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0910 18:23:37.052649  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0910 18:23:39.929069  1862 solver.cpp:445]     Test net output #0: accuracy = 0.35514
I0910 18:23:39.929136  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.603159
I0910 18:23:39.929148  1862 solver.cpp:445]     Test net output #2: loss = 3.1012 (* 1 = 3.1012 loss)
I0910 18:23:39.929153  1862 solver.cpp:456] ================================
I0910 18:23:39.929157  1862 solver.cpp:457]     Test net best accuracy1 is: 0.38224
I0910 18:23:39.929162  1862 solver.cpp:459]     Test net best accuracy5 is: 0.63456
I0910 18:23:41.605962  1862 solver.cpp:242] Iteration 277000 (0.161104 iter/s, 1241.43s/200 iters), loss = 2.02918
I0910 18:23:41.606196  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.769531
I0910 18:23:41.606264  1862 solver.cpp:261]     Train net output #1: loss = 2.02918 (* 1 = 2.02918 loss)
I0910 18:23:41.641906  1862 sgd_solver.cpp:122] Iteration 277000, lr = 0.00671875
I0910 18:29:38.151238  1862 solver.cpp:242] Iteration 277200 (0.560958 iter/s, 356.533s/200 iters), loss = 2.04987
I0910 18:29:38.152101  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.765625
I0910 18:29:38.152580  1862 solver.cpp:261]     Train net output #1: loss = 2.04987 (* 1 = 2.04987 loss)
I0910 18:29:38.152775  1862 sgd_solver.cpp:122] Iteration 277200, lr = 0.0066875
I0910 18:35:51.119892  1862 solver.cpp:242] Iteration 277400 (0.536257 iter/s, 372.955s/200 iters), loss = 2.15356
I0910 18:35:51.120419  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.757812
I0910 18:35:51.120535  1862 solver.cpp:261]     Train net output #1: loss = 2.15356 (* 1 = 2.15356 loss)
I0910 18:35:51.120625  1862 sgd_solver.cpp:122] Iteration 277400, lr = 0.00665625
I0910 18:38:54.784873  1876 data_layer.cpp:73] Restarting data prefetching from start.
I0910 18:41:46.237406  1862 solver.cpp:242] Iteration 277600 (0.563214 iter/s, 355.105s/200 iters), loss = 2.11393
I0910 18:41:46.237563  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.765625
I0910 18:41:46.237586  1862 solver.cpp:261]     Train net output #1: loss = 2.11393 (* 1 = 2.11393 loss)
I0910 18:41:46.237602  1862 sgd_solver.cpp:122] Iteration 277600, lr = 0.006625
I0910 18:47:43.389503  1862 solver.cpp:242] Iteration 277800 (0.560005 iter/s, 357.14s/200 iters), loss = 1.98666
I0910 18:47:43.394605  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.753906
I0910 18:47:43.394635  1862 solver.cpp:261]     Train net output #1: loss = 1.98666 (* 1 = 1.98666 loss)
I0910 18:47:43.394655  1862 sgd_solver.cpp:122] Iteration 277800, lr = 0.00659375
I0910 18:53:33.318491  1862 solver.cpp:377] Iteration 278000, Testing net (#0)
I0910 18:53:33.329675  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0910 19:06:33.906044  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0910 19:06:38.133316  1862 solver.cpp:445]     Test net output #0: accuracy = 0.37204
I0910 19:06:38.133649  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.61868
I0910 19:06:38.133744  1862 solver.cpp:445]     Test net output #2: loss = 2.99507 (* 1 = 2.99507 loss)
I0910 19:06:38.133780  1862 solver.cpp:456] ================================
I0910 19:06:38.133812  1862 solver.cpp:457]     Test net best accuracy1 is: 0.38224
I0910 19:06:38.133854  1862 solver.cpp:459]     Test net best accuracy5 is: 0.63456
I0910 19:06:39.959560  1862 solver.cpp:242] Iteration 278000 (0.175975 iter/s, 1136.53s/200 iters), loss = 1.89071
I0910 19:06:39.960091  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.800781
I0910 19:06:39.976265  1862 solver.cpp:261]     Train net output #1: loss = 1.89071 (* 1 = 1.89071 loss)
I0910 19:06:39.977859  1862 sgd_solver.cpp:122] Iteration 278000, lr = 0.0065625
I0910 19:13:01.049279  1862 solver.cpp:242] Iteration 278200 (0.524829 iter/s, 381.076s/200 iters), loss = 2.03567
I0910 19:13:01.056314  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.765625
I0910 19:13:01.056439  1862 solver.cpp:261]     Train net output #1: loss = 2.03567 (* 1 = 2.03567 loss)
I0910 19:13:01.056547  1862 sgd_solver.cpp:122] Iteration 278200, lr = 0.00653125
I0910 19:18:32.053501  1862 solver.cpp:242] Iteration 278400 (0.604255 iter/s, 330.986s/200 iters), loss = 2.25629
I0910 19:18:32.073585  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.722656
I0910 19:18:32.073673  1862 solver.cpp:261]     Train net output #1: loss = 2.25629 (* 1 = 2.25629 loss)
I0910 19:18:32.073736  1862 sgd_solver.cpp:122] Iteration 278400, lr = 0.0065
I0910 19:24:15.158690  1862 solver.cpp:242] Iteration 278600 (0.582966 iter/s, 343.073s/200 iters), loss = 2.48191
I0910 19:24:15.166039  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.71875
I0910 19:24:15.166229  1862 solver.cpp:261]     Train net output #1: loss = 2.48191 (* 1 = 2.48191 loss)
I0910 19:24:15.166296  1862 sgd_solver.cpp:122] Iteration 278600, lr = 0.00646875
I0910 19:29:46.949388  1862 solver.cpp:242] Iteration 278800 (0.602823 iter/s, 331.772s/200 iters), loss = 2.03162
I0910 19:29:46.949717  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.746094
I0910 19:29:46.949795  1862 solver.cpp:261]     Train net output #1: loss = 2.03162 (* 1 = 2.03162 loss)
I0910 19:29:46.949867  1862 sgd_solver.cpp:122] Iteration 278800, lr = 0.0064375
I0910 19:35:09.815572  1862 solver.cpp:377] Iteration 279000, Testing net (#0)
I0910 19:35:09.834240  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0910 19:46:40.063737  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0910 19:46:42.226017  1862 solver.cpp:445]     Test net output #0: accuracy = 0.38652
I0910 19:46:42.226454  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.631259
I0910 19:46:42.226562  1862 solver.cpp:445]     Test net output #2: loss = 2.89094 (* 1 = 2.89094 loss)
I0910 19:46:42.226634  1862 solver.cpp:456] ================================
I0910 19:46:42.226692  1862 solver.cpp:457]     Test net best accuracy1 is: 0.38652
I0910 19:46:42.226753  1862 solver.cpp:459]     Test net best accuracy5 is: 0.631259
I0910 19:46:43.597389  1862 solver.cpp:242] Iteration 279000 (0.196732 iter/s, 1016.61s/200 iters), loss = 2.08268
I0910 19:46:43.597633  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.761719
I0910 19:46:43.597710  1862 solver.cpp:261]     Train net output #1: loss = 2.08268 (* 1 = 2.08268 loss)
I0910 19:46:43.597776  1862 sgd_solver.cpp:122] Iteration 279000, lr = 0.00640625
I0910 19:52:12.696555  1862 solver.cpp:242] Iteration 279200 (0.607741 iter/s, 329.088s/200 iters), loss = 2.06541
I0910 19:52:12.696933  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.78125
I0910 19:52:12.696949  1862 solver.cpp:261]     Train net output #1: loss = 2.06541 (* 1 = 2.06541 loss)
I0910 19:52:12.696966  1862 sgd_solver.cpp:122] Iteration 279200, lr = 0.006375
I0910 19:57:39.225402  1862 solver.cpp:242] Iteration 279400 (0.612525 iter/s, 326.517s/200 iters), loss = 2.27186
I0910 19:57:39.225728  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.71875
I0910 19:57:39.225802  1862 solver.cpp:261]     Train net output #1: loss = 2.27186 (* 1 = 2.27186 loss)
I0910 19:57:39.225868  1862 sgd_solver.cpp:122] Iteration 279400, lr = 0.00634375
I0910 20:03:24.616231  1862 solver.cpp:242] Iteration 279600 (0.579074 iter/s, 345.379s/200 iters), loss = 2.14738
I0910 20:03:24.616840  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.753906
I0910 20:03:24.616858  1862 solver.cpp:261]     Train net output #1: loss = 2.14738 (* 1 = 2.14738 loss)
I0910 20:03:24.616868  1862 sgd_solver.cpp:122] Iteration 279600, lr = 0.0063125
I0910 20:09:14.397374  1862 solver.cpp:242] Iteration 279800 (0.571806 iter/s, 349.769s/200 iters), loss = 2.28343
I0910 20:09:14.397562  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.714844
I0910 20:09:14.397594  1862 solver.cpp:261]     Train net output #1: loss = 2.28343 (* 1 = 2.28343 loss)
I0910 20:09:14.397641  1862 sgd_solver.cpp:122] Iteration 279800, lr = 0.00628125
I0910 20:14:47.945538  1862 solver.cpp:507] Snapshotting to binary proto file my/Imagenet/AlexNet-BN/XnorNet_FWN/snapshot/xnor_net_iter_280000.caffemodel
I0910 20:15:03.822144  1862 sgd_solver.cpp:329] Snapshotting solver state to binary proto file my/Imagenet/AlexNet-BN/XnorNet_FWN/snapshot/xnor_net_iter_280000.solverstate
I0910 20:15:05.341553  1862 solver.cpp:377] Iteration 280000, Testing net (#0)
I0910 20:15:05.341866  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0910 20:27:51.988864  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0910 20:27:55.270457  1862 solver.cpp:445]     Test net output #0: accuracy = 0.37694
I0910 20:27:55.270525  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.623839
I0910 20:27:55.270539  1862 solver.cpp:445]     Test net output #2: loss = 2.95136 (* 1 = 2.95136 loss)
I0910 20:27:55.270545  1862 solver.cpp:456] ================================
I0910 20:27:55.270548  1862 solver.cpp:457]     Test net best accuracy1 is: 0.38652
I0910 20:27:55.270553  1862 solver.cpp:459]     Test net best accuracy5 is: 0.631259
I0910 20:27:56.801425  1862 solver.cpp:242] Iteration 280000 (0.178195 iter/s, 1122.37s/200 iters), loss = 1.96119
I0910 20:27:56.801740  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.792969
I0910 20:27:56.801887  1862 solver.cpp:261]     Train net output #1: loss = 1.96119 (* 1 = 1.96119 loss)
I0910 20:27:56.802027  1862 sgd_solver.cpp:122] Iteration 280000, lr = 0.00625
I0910 20:28:05.905283  1876 data_layer.cpp:73] Restarting data prefetching from start.
I0910 20:33:36.257103  1862 solver.cpp:242] Iteration 280200 (0.589199 iter/s, 339.444s/200 iters), loss = 2.05502
I0910 20:33:36.257829  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.777344
I0910 20:33:36.257983  1862 solver.cpp:261]     Train net output #1: loss = 2.05502 (* 1 = 2.05502 loss)
I0910 20:33:36.258088  1862 sgd_solver.cpp:122] Iteration 280200, lr = 0.00621875
I0910 20:39:31.226408  1862 solver.cpp:242] Iteration 280400 (0.563449 iter/s, 354.957s/200 iters), loss = 1.97515
I0910 20:39:31.233919  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.792969
I0910 20:39:31.233958  1862 solver.cpp:261]     Train net output #1: loss = 1.97515 (* 1 = 1.97515 loss)
I0910 20:39:31.233985  1862 sgd_solver.cpp:122] Iteration 280400, lr = 0.0061875
I0910 20:45:12.517374  1862 solver.cpp:242] Iteration 280600 (0.586043 iter/s, 341.272s/200 iters), loss = 2.17788
I0910 20:45:12.517585  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.746094
I0910 20:45:12.517629  1862 solver.cpp:261]     Train net output #1: loss = 2.17788 (* 1 = 2.17788 loss)
I0910 20:45:12.517664  1862 sgd_solver.cpp:122] Iteration 280600, lr = 0.00615625
I0910 20:50:52.709385  1862 solver.cpp:242] Iteration 280800 (0.587924 iter/s, 340.18s/200 iters), loss = 2.1097
I0910 20:50:52.709555  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.78125
I0910 20:50:52.709580  1862 solver.cpp:261]     Train net output #1: loss = 2.1097 (* 1 = 2.1097 loss)
I0910 20:50:52.709600  1862 sgd_solver.cpp:122] Iteration 280800, lr = 0.006125
I0910 20:56:22.955195  1862 solver.cpp:377] Iteration 281000, Testing net (#0)
I0910 20:56:22.974423  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0910 21:08:57.934270  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0910 21:09:00.931706  1862 solver.cpp:445]     Test net output #0: accuracy = 0.37334
I0910 21:09:00.932045  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.62176
I0910 21:09:00.932165  1862 solver.cpp:445]     Test net output #2: loss = 2.96161 (* 1 = 2.96161 loss)
I0910 21:09:00.932273  1862 solver.cpp:456] ================================
I0910 21:09:00.932343  1862 solver.cpp:457]     Test net best accuracy1 is: 0.38652
I0910 21:09:00.932435  1862 solver.cpp:459]     Test net best accuracy5 is: 0.631259
I0910 21:09:02.641763  1862 solver.cpp:242] Iteration 281000 (0.183504 iter/s, 1089.9s/200 iters), loss = 2.04556
I0910 21:09:02.642441  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.785156
I0910 21:09:02.642738  1862 solver.cpp:261]     Train net output #1: loss = 2.04556 (* 1 = 2.04556 loss)
I0910 21:09:02.643056  1862 sgd_solver.cpp:122] Iteration 281000, lr = 0.00609375
I0910 21:15:08.478870  1862 solver.cpp:242] Iteration 281200 (0.546711 iter/s, 365.824s/200 iters), loss = 1.97698
I0910 21:15:08.485962  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.792969
I0910 21:15:08.486068  1862 solver.cpp:261]     Train net output #1: loss = 1.97698 (* 1 = 1.97698 loss)
I0910 21:15:08.486131  1862 sgd_solver.cpp:122] Iteration 281200, lr = 0.0060625
I0910 21:20:43.113381  1862 solver.cpp:242] Iteration 281400 (0.5977 iter/s, 334.616s/200 iters), loss = 1.98517
I0910 21:20:43.125605  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.804688
I0910 21:20:43.125660  1862 solver.cpp:261]     Train net output #1: loss = 1.98517 (* 1 = 1.98517 loss)
I0910 21:20:43.125695  1862 sgd_solver.cpp:122] Iteration 281400, lr = 0.00603125
I0910 21:26:14.202375  1862 solver.cpp:242] Iteration 281600 (0.60411 iter/s, 331.066s/200 iters), loss = 2.07578
I0910 21:26:14.203352  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.753906
I0910 21:26:14.203371  1862 solver.cpp:261]     Train net output #1: loss = 2.07578 (* 1 = 2.07578 loss)
I0910 21:26:14.250880  1862 sgd_solver.cpp:122] Iteration 281600, lr = 0.006
I0910 21:32:13.469372  1862 solver.cpp:242] Iteration 281800 (0.556709 iter/s, 359.254s/200 iters), loss = 2.00632
I0910 21:32:13.469673  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.773438
I0910 21:32:13.469738  1862 solver.cpp:261]     Train net output #1: loss = 2.00632 (* 1 = 2.00632 loss)
I0910 21:32:13.469799  1862 sgd_solver.cpp:122] Iteration 281800, lr = 0.00596875
I0910 21:38:11.949864  1862 solver.cpp:377] Iteration 282000, Testing net (#0)
I0910 21:38:11.974225  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0910 21:51:27.223750  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0910 21:51:29.605201  1862 solver.cpp:445]     Test net output #0: accuracy = 0.34866
I0910 21:51:29.605446  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.58874
I0910 21:51:29.605509  1862 solver.cpp:445]     Test net output #2: loss = 3.22448 (* 1 = 3.22448 loss)
I0910 21:51:29.605556  1862 solver.cpp:456] ================================
I0910 21:51:29.605602  1862 solver.cpp:457]     Test net best accuracy1 is: 0.38652
I0910 21:51:29.605650  1862 solver.cpp:459]     Test net best accuracy5 is: 0.631259
I0910 21:51:30.761402  1862 solver.cpp:242] Iteration 282000 (0.172823 iter/s, 1157.25s/200 iters), loss = 2.28132
I0910 21:51:30.761767  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.738281
I0910 21:51:30.761893  1862 solver.cpp:261]     Train net output #1: loss = 2.28132 (* 1 = 2.28132 loss)
I0910 21:51:30.762014  1862 sgd_solver.cpp:122] Iteration 282000, lr = 0.0059375
I0910 21:56:56.217399  1862 solver.cpp:242] Iteration 282200 (0.614544 iter/s, 325.445s/200 iters), loss = 2.11501
I0910 21:56:56.217676  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.730469
I0910 21:56:56.217707  1862 solver.cpp:261]     Train net output #1: loss = 2.11501 (* 1 = 2.11501 loss)
I0910 21:56:56.217741  1862 sgd_solver.cpp:122] Iteration 282200, lr = 0.00590625
I0910 22:02:29.849233  1862 solver.cpp:242] Iteration 282400 (0.599484 iter/s, 333.62s/200 iters), loss = 2.05615
I0910 22:02:29.850133  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.765625
I0910 22:02:29.850214  1862 solver.cpp:261]     Train net output #1: loss = 2.05615 (* 1 = 2.05615 loss)
I0910 22:02:29.850275  1862 sgd_solver.cpp:122] Iteration 282400, lr = 0.005875
I0910 22:05:27.090548  1876 data_layer.cpp:73] Restarting data prefetching from start.
I0910 22:08:03.461380  1862 solver.cpp:242] Iteration 282600 (0.59952 iter/s, 333.6s/200 iters), loss = 2.03612
I0910 22:08:03.463541  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.757812
I0910 22:08:03.463707  1862 solver.cpp:261]     Train net output #1: loss = 2.03612 (* 1 = 2.03612 loss)
I0910 22:08:03.463821  1862 sgd_solver.cpp:122] Iteration 282600, lr = 0.00584375
I0910 22:13:35.317392  1862 solver.cpp:242] Iteration 282800 (0.602695 iter/s, 331.843s/200 iters), loss = 2.05109
I0910 22:13:35.317718  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.785156
I0910 22:13:35.317793  1862 solver.cpp:261]     Train net output #1: loss = 2.05109 (* 1 = 2.05109 loss)
I0910 22:13:35.317859  1862 sgd_solver.cpp:122] Iteration 282800, lr = 0.0058125
I0910 22:19:05.661651  1862 solver.cpp:377] Iteration 283000, Testing net (#0)
I0910 22:19:05.662115  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0910 22:30:18.179183  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0910 22:30:20.361037  1862 solver.cpp:445]     Test net output #0: accuracy = 0.39658
I0910 22:30:20.378949  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.645939
I0910 22:30:20.379149  1862 solver.cpp:445]     Test net output #2: loss = 2.82271 (* 1 = 2.82271 loss)
I0910 22:30:20.379248  1862 solver.cpp:456] ================================
I0910 22:30:20.379314  1862 solver.cpp:457]     Test net best accuracy1 is: 0.39658
I0910 22:30:20.379377  1862 solver.cpp:459]     Test net best accuracy5 is: 0.645939
I0910 22:30:22.029390  1862 solver.cpp:242] Iteration 283000 (0.198673 iter/s, 1006.68s/200 iters), loss = 1.85456
I0910 22:30:22.029615  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.816406
I0910 22:30:22.029695  1862 solver.cpp:261]     Train net output #1: loss = 1.85456 (* 1 = 1.85456 loss)
I0910 22:30:22.029758  1862 sgd_solver.cpp:122] Iteration 283000, lr = 0.00578125
I0910 22:35:51.965375  1862 solver.cpp:242] Iteration 283200 (0.606199 iter/s, 329.925s/200 iters), loss = 1.84021
I0910 22:35:51.970122  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.789062
I0910 22:35:51.970201  1862 solver.cpp:261]     Train net output #1: loss = 1.84021 (* 1 = 1.84021 loss)
I0910 22:35:51.970261  1862 sgd_solver.cpp:122] Iteration 283200, lr = 0.00575
I0910 22:41:26.254619  1862 solver.cpp:242] Iteration 283400 (0.598313 iter/s, 334.273s/200 iters), loss = 2.09638
I0910 22:41:26.255270  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.734375
I0910 22:41:26.255287  1862 solver.cpp:261]     Train net output #1: loss = 2.09638 (* 1 = 2.09638 loss)
I0910 22:41:26.255298  1862 sgd_solver.cpp:122] Iteration 283400, lr = 0.00571875
I0910 22:46:55.665403  1862 solver.cpp:242] Iteration 283600 (0.607166 iter/s, 329.399s/200 iters), loss = 1.91721
I0910 22:46:55.665603  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.796875
I0910 22:46:55.665642  1862 solver.cpp:261]     Train net output #1: loss = 1.91721 (* 1 = 1.91721 loss)
I0910 22:46:55.665678  1862 sgd_solver.cpp:122] Iteration 283600, lr = 0.0056875
I0910 22:52:27.060047  1862 solver.cpp:242] Iteration 283800 (0.603531 iter/s, 331.383s/200 iters), loss = 2.14778
I0910 22:52:27.060238  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.753906
I0910 22:52:27.060262  1862 solver.cpp:261]     Train net output #1: loss = 2.14778 (* 1 = 2.14778 loss)
I0910 22:52:27.060279  1862 sgd_solver.cpp:122] Iteration 283800, lr = 0.00565625
I0910 22:57:58.629834  1862 solver.cpp:377] Iteration 284000, Testing net (#0)
I0910 22:57:58.649482  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0910 23:09:57.206454  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0910 23:09:58.748071  1862 solver.cpp:445]     Test net output #0: accuracy = 0.35742
I0910 23:09:58.749951  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.60086
I0910 23:09:58.750057  1862 solver.cpp:445]     Test net output #2: loss = 3.09574 (* 1 = 3.09574 loss)
I0910 23:09:58.750123  1862 solver.cpp:456] ================================
I0910 23:09:58.750178  1862 solver.cpp:457]     Test net best accuracy1 is: 0.39658
I0910 23:09:58.750254  1862 solver.cpp:459]     Test net best accuracy5 is: 0.645939
I0910 23:10:00.017395  1862 solver.cpp:242] Iteration 284000 (0.189948 iter/s, 1052.92s/200 iters), loss = 2.07634
I0910 23:10:00.022146  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.757812
I0910 23:10:00.022271  1862 solver.cpp:261]     Train net output #1: loss = 2.07634 (* 1 = 2.07634 loss)
I0910 23:10:00.022496  1862 sgd_solver.cpp:122] Iteration 284000, lr = 0.005625
I0910 23:15:27.082360  1862 solver.cpp:242] Iteration 284200 (0.611529 iter/s, 327.049s/200 iters), loss = 1.78285
I0910 23:15:27.083758  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.832031
I0910 23:15:27.083784  1862 solver.cpp:261]     Train net output #1: loss = 1.78285 (* 1 = 1.78285 loss)
I0910 23:15:27.083801  1862 sgd_solver.cpp:122] Iteration 284200, lr = 0.00559375
I0910 23:20:58.698175  1862 solver.cpp:242] Iteration 284400 (0.60313 iter/s, 331.603s/200 iters), loss = 1.94726
I0910 23:20:58.698845  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.765625
I0910 23:20:58.698979  1862 solver.cpp:261]     Train net output #1: loss = 1.94726 (* 1 = 1.94726 loss)
I0910 23:20:58.699074  1862 sgd_solver.cpp:122] Iteration 284400, lr = 0.0055625
I0910 23:26:36.285384  1862 solver.cpp:242] Iteration 284600 (0.592461 iter/s, 337.575s/200 iters), loss = 1.99885
I0910 23:26:36.285641  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.78125
I0910 23:26:36.285677  1862 solver.cpp:261]     Train net output #1: loss = 1.99885 (* 1 = 1.99885 loss)
I0910 23:26:36.285701  1862 sgd_solver.cpp:122] Iteration 284600, lr = 0.00553125
I0910 23:32:09.189559  1862 solver.cpp:242] Iteration 284800 (0.600794 iter/s, 332.893s/200 iters), loss = 2.03292
I0910 23:32:09.189944  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.78125
I0910 23:32:09.190004  1862 solver.cpp:261]     Train net output #1: loss = 2.03292 (* 1 = 2.03292 loss)
I0910 23:32:09.190053  1862 sgd_solver.cpp:122] Iteration 284800, lr = 0.0055
I0910 23:37:42.465855  1862 solver.cpp:377] Iteration 285000, Testing net (#0)
I0910 23:37:42.486325  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0910 23:49:19.679303  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0910 23:49:22.623719  1862 solver.cpp:445]     Test net output #0: accuracy = 0.39604
I0910 23:49:22.632480  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.644879
I0910 23:49:22.632589  1862 solver.cpp:445]     Test net output #2: loss = 2.8332 (* 1 = 2.8332 loss)
I0910 23:49:22.632658  1862 solver.cpp:456] ================================
I0910 23:49:22.632714  1862 solver.cpp:457]     Test net best accuracy1 is: 0.39658
I0910 23:49:22.632774  1862 solver.cpp:459]     Test net best accuracy5 is: 0.645939
I0910 23:49:24.006894  1862 solver.cpp:242] Iteration 285000 (0.193277 iter/s, 1034.78s/200 iters), loss = 2.14559
I0910 23:49:24.009503  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.757812
I0910 23:49:24.009722  1862 solver.cpp:261]     Train net output #1: loss = 2.14559 (* 1 = 2.14559 loss)
I0910 23:49:24.011703  1862 sgd_solver.cpp:122] Iteration 285000, lr = 0.00546875
I0910 23:49:38.442322  1876 data_layer.cpp:73] Restarting data prefetching from start.
I0910 23:54:49.173403  1862 solver.cpp:242] Iteration 285200 (0.615095 iter/s, 325.153s/200 iters), loss = 2.02599
I0910 23:54:49.176822  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.761719
I0910 23:54:49.176970  1862 solver.cpp:261]     Train net output #1: loss = 2.02599 (* 1 = 2.02599 loss)
I0910 23:54:49.177124  1862 sgd_solver.cpp:122] Iteration 285200, lr = 0.0054375
I0911 00:00:25.828513  1862 solver.cpp:242] Iteration 285400 (0.594106 iter/s, 336.64s/200 iters), loss = 2.09565
I0911 00:00:25.830150  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.726562
I0911 00:00:25.830549  1862 solver.cpp:261]     Train net output #1: loss = 2.09565 (* 1 = 2.09565 loss)
I0911 00:00:25.830786  1862 sgd_solver.cpp:122] Iteration 285400, lr = 0.00540625
I0911 00:06:15.427788  1862 solver.cpp:242] Iteration 285600 (0.572106 iter/s, 349.586s/200 iters), loss = 2.02423
I0911 00:06:15.428154  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.769531
I0911 00:06:15.428243  1862 solver.cpp:261]     Train net output #1: loss = 2.02423 (* 1 = 2.02423 loss)
I0911 00:06:15.470675  1862 sgd_solver.cpp:122] Iteration 285600, lr = 0.005375
I0911 00:12:22.717419  1862 solver.cpp:242] Iteration 285800 (0.544548 iter/s, 367.277s/200 iters), loss = 1.92724
I0911 00:12:22.731791  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.773438
I0911 00:12:22.731815  1862 solver.cpp:261]     Train net output #1: loss = 1.92724 (* 1 = 1.92724 loss)
I0911 00:12:22.731829  1862 sgd_solver.cpp:122] Iteration 285800, lr = 0.00534375
I0911 00:18:05.078295  1862 solver.cpp:377] Iteration 286000, Testing net (#0)
I0911 00:18:05.105160  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 00:30:07.805989  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 00:30:10.389439  1862 solver.cpp:445]     Test net output #0: accuracy = 0.36716
I0911 00:30:10.390496  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.61896
I0911 00:30:10.390609  1862 solver.cpp:445]     Test net output #2: loss = 2.99221 (* 1 = 2.99221 loss)
I0911 00:30:10.390684  1862 solver.cpp:456] ================================
I0911 00:30:10.390746  1862 solver.cpp:457]     Test net best accuracy1 is: 0.39658
I0911 00:30:10.390811  1862 solver.cpp:459]     Test net best accuracy5 is: 0.645939
I0911 00:30:11.698655  1862 solver.cpp:242] Iteration 286000 (0.187103 iter/s, 1068.93s/200 iters), loss = 2.23989
I0911 00:30:11.698889  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.722656
I0911 00:30:11.698962  1862 solver.cpp:261]     Train net output #1: loss = 2.23989 (* 1 = 2.23989 loss)
I0911 00:30:11.724418  1862 sgd_solver.cpp:122] Iteration 286000, lr = 0.0053125
I0911 00:36:02.383462  1862 solver.cpp:242] Iteration 286200 (0.570332 iter/s, 350.673s/200 iters), loss = 1.97958
I0911 00:36:02.389941  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.765625
I0911 00:36:02.389959  1862 solver.cpp:261]     Train net output #1: loss = 1.97958 (* 1 = 1.97958 loss)
I0911 00:36:02.389971  1862 sgd_solver.cpp:122] Iteration 286200, lr = 0.00528125
I0911 00:41:52.969573  1862 solver.cpp:242] Iteration 286400 (0.570503 iter/s, 350.568s/200 iters), loss = 1.97249
I0911 00:41:52.969846  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.78125
I0911 00:41:52.969884  1862 solver.cpp:261]     Train net output #1: loss = 1.97249 (* 1 = 1.97249 loss)
I0911 00:41:52.988804  1862 sgd_solver.cpp:122] Iteration 286400, lr = 0.00525
I0911 00:47:32.380048  1862 solver.cpp:242] Iteration 286600 (0.589278 iter/s, 339.399s/200 iters), loss = 2.29379
I0911 00:47:32.380230  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.722656
I0911 00:47:32.380246  1862 solver.cpp:261]     Train net output #1: loss = 2.29379 (* 1 = 2.29379 loss)
I0911 00:47:32.397344  1862 sgd_solver.cpp:122] Iteration 286600, lr = 0.00521875
I0911 00:53:22.501391  1862 solver.cpp:242] Iteration 286800 (0.57125 iter/s, 350.109s/200 iters), loss = 2.00944
I0911 00:53:22.502073  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.773438
I0911 00:53:22.502151  1862 solver.cpp:261]     Train net output #1: loss = 2.00944 (* 1 = 2.00944 loss)
I0911 00:53:22.502214  1862 sgd_solver.cpp:122] Iteration 286800, lr = 0.0051875
I0911 00:58:57.477998  1862 solver.cpp:377] Iteration 287000, Testing net (#0)
I0911 00:58:57.487911  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 01:10:50.922992  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 01:10:53.811393  1862 solver.cpp:445]     Test net output #0: accuracy = 0.37484
I0911 01:10:53.817621  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.61976
I0911 01:10:53.817804  1862 solver.cpp:445]     Test net output #2: loss = 2.98111 (* 1 = 2.98111 loss)
I0911 01:10:53.817961  1862 solver.cpp:456] ================================
I0911 01:10:53.818070  1862 solver.cpp:457]     Test net best accuracy1 is: 0.39658
I0911 01:10:53.818181  1862 solver.cpp:459]     Test net best accuracy5 is: 0.645939
I0911 01:10:55.265398  1862 solver.cpp:242] Iteration 287000 (0.189983 iter/s, 1052.73s/200 iters), loss = 2.02786
I0911 01:10:55.265470  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.796875
I0911 01:10:55.265486  1862 solver.cpp:261]     Train net output #1: loss = 2.02786 (* 1 = 2.02786 loss)
I0911 01:10:55.289939  1862 sgd_solver.cpp:122] Iteration 287000, lr = 0.00515625
I0911 01:16:58.291481  1862 solver.cpp:242] Iteration 287200 (0.550943 iter/s, 363.014s/200 iters), loss = 1.89657
I0911 01:16:58.305419  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.820312
I0911 01:16:58.305462  1862 solver.cpp:261]     Train net output #1: loss = 1.89657 (* 1 = 1.89657 loss)
I0911 01:16:58.305495  1862 sgd_solver.cpp:122] Iteration 287200, lr = 0.005125
I0911 01:22:44.382220  1862 solver.cpp:242] Iteration 287400 (0.577926 iter/s, 346.065s/200 iters), loss = 2.02643
I0911 01:22:44.398370  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.777344
I0911 01:22:44.398458  1862 solver.cpp:261]     Train net output #1: loss = 2.02643 (* 1 = 2.02643 loss)
I0911 01:22:44.398526  1862 sgd_solver.cpp:122] Iteration 287400, lr = 0.00509375
I0911 01:25:55.844940  1876 data_layer.cpp:73] Restarting data prefetching from start.
I0911 01:28:27.313163  1862 solver.cpp:242] Iteration 287600 (0.583255 iter/s, 342.903s/200 iters), loss = 1.96998
I0911 01:28:27.314098  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.785156
I0911 01:28:27.314170  1862 solver.cpp:261]     Train net output #1: loss = 1.96998 (* 1 = 1.96998 loss)
I0911 01:28:27.314234  1862 sgd_solver.cpp:122] Iteration 287600, lr = 0.0050625
I0911 01:34:08.614004  1862 solver.cpp:242] Iteration 287800 (0.586015 iter/s, 341.288s/200 iters), loss = 2.15614
I0911 01:34:08.621402  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.78125
I0911 01:34:08.621485  1862 solver.cpp:261]     Train net output #1: loss = 2.15614 (* 1 = 2.15614 loss)
I0911 01:34:08.621539  1862 sgd_solver.cpp:122] Iteration 287800, lr = 0.00503125
I0911 01:39:49.700958  1862 solver.cpp:377] Iteration 288000, Testing net (#0)
I0911 01:39:49.715615  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 01:51:49.898345  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 01:51:52.958591  1862 solver.cpp:445]     Test net output #0: accuracy = 0.3596
I0911 01:51:52.972749  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.60444
I0911 01:51:52.973012  1862 solver.cpp:445]     Test net output #2: loss = 3.08852 (* 1 = 3.08852 loss)
I0911 01:51:52.973121  1862 solver.cpp:456] ================================
I0911 01:51:52.973203  1862 solver.cpp:457]     Test net best accuracy1 is: 0.39658
I0911 01:51:52.973284  1862 solver.cpp:459]     Test net best accuracy5 is: 0.645939
I0911 01:51:54.605398  1862 solver.cpp:242] Iteration 288000 (0.187626 iter/s, 1065.95s/200 iters), loss = 2.04845
I0911 01:51:54.605469  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.757812
I0911 01:51:54.605487  1862 solver.cpp:261]     Train net output #1: loss = 2.04845 (* 1 = 2.04845 loss)
I0911 01:51:54.632568  1862 sgd_solver.cpp:122] Iteration 288000, lr = 0.005
I0911 01:57:29.899998  1862 solver.cpp:242] Iteration 288200 (0.596511 iter/s, 335.283s/200 iters), loss = 1.94528
I0911 01:57:29.900290  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.796875
I0911 01:57:29.900315  1862 solver.cpp:261]     Train net output #1: loss = 1.94528 (* 1 = 1.94528 loss)
I0911 01:57:29.900337  1862 sgd_solver.cpp:122] Iteration 288200, lr = 0.00496875
I0911 02:03:22.005486  1862 solver.cpp:242] Iteration 288400 (0.568031 iter/s, 352.093s/200 iters), loss = 2.01752
I0911 02:03:22.005726  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.796875
I0911 02:03:22.005754  1862 solver.cpp:261]     Train net output #1: loss = 2.01752 (* 1 = 2.01752 loss)
I0911 02:03:22.005779  1862 sgd_solver.cpp:122] Iteration 288400, lr = 0.0049375
I0911 02:09:13.562989  1862 solver.cpp:242] Iteration 288600 (0.568917 iter/s, 351.545s/200 iters), loss = 2.07162
I0911 02:09:13.563166  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.765625
I0911 02:09:13.563185  1862 solver.cpp:261]     Train net output #1: loss = 2.07162 (* 1 = 2.07162 loss)
I0911 02:09:13.607575  1862 sgd_solver.cpp:122] Iteration 288600, lr = 0.00490625
I0911 02:14:49.097818  1862 solver.cpp:242] Iteration 288800 (0.596084 iter/s, 335.523s/200 iters), loss = 2.12376
I0911 02:14:49.098213  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.746094
I0911 02:14:49.098230  1862 solver.cpp:261]     Train net output #1: loss = 2.12376 (* 1 = 2.12376 loss)
I0911 02:14:49.098243  1862 sgd_solver.cpp:122] Iteration 288800, lr = 0.004875
I0911 02:20:27.626495  1862 solver.cpp:377] Iteration 289000, Testing net (#0)
I0911 02:20:27.649487  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 02:32:14.176662  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 02:32:16.228042  1862 solver.cpp:445]     Test net output #0: accuracy = 0.36156
I0911 02:32:16.232916  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.609679
I0911 02:32:16.233036  1862 solver.cpp:445]     Test net output #2: loss = 3.08179 (* 1 = 3.08179 loss)
I0911 02:32:16.233117  1862 solver.cpp:456] ================================
I0911 02:32:16.233177  1862 solver.cpp:457]     Test net best accuracy1 is: 0.39658
I0911 02:32:16.233234  1862 solver.cpp:459]     Test net best accuracy5 is: 0.645939
I0911 02:32:17.420087  1862 solver.cpp:242] Iteration 289000 (0.190787 iter/s, 1048.29s/200 iters), loss = 2.16603
I0911 02:32:17.425158  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.75
I0911 02:32:17.425295  1862 solver.cpp:261]     Train net output #1: loss = 2.16603 (* 1 = 2.16603 loss)
I0911 02:32:17.425384  1862 sgd_solver.cpp:122] Iteration 289000, lr = 0.00484375
I0911 02:38:12.494277  1862 solver.cpp:242] Iteration 289200 (0.56329 iter/s, 355.057s/200 iters), loss = 1.94438
I0911 02:38:12.495553  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.765625
I0911 02:38:12.495717  1862 solver.cpp:261]     Train net output #1: loss = 1.94438 (* 1 = 1.94438 loss)
I0911 02:38:12.495820  1862 sgd_solver.cpp:122] Iteration 289200, lr = 0.0048125
I0911 02:44:08.449390  1862 solver.cpp:242] Iteration 289400 (0.56189 iter/s, 355.942s/200 iters), loss = 1.96703
I0911 02:44:08.449887  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.796875
I0911 02:44:08.449998  1862 solver.cpp:261]     Train net output #1: loss = 1.96703 (* 1 = 1.96703 loss)
I0911 02:44:08.450088  1862 sgd_solver.cpp:122] Iteration 289400, lr = 0.00478125
I0911 02:50:20.853389  1862 solver.cpp:242] Iteration 289600 (0.53707 iter/s, 372.391s/200 iters), loss = 1.92504
I0911 02:50:20.864600  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.792969
I0911 02:50:20.864619  1862 solver.cpp:261]     Train net output #1: loss = 1.92504 (* 1 = 1.92504 loss)
I0911 02:50:20.864637  1862 sgd_solver.cpp:122] Iteration 289600, lr = 0.00475
I0911 02:56:03.037600  1862 solver.cpp:242] Iteration 289800 (0.58452 iter/s, 342.161s/200 iters), loss = 2.14682
I0911 02:56:03.044015  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.746094
I0911 02:56:03.044165  1862 solver.cpp:261]     Train net output #1: loss = 2.14682 (* 1 = 2.14682 loss)
I0911 02:56:03.044261  1862 sgd_solver.cpp:122] Iteration 289800, lr = 0.00471875
I0911 03:01:34.296010  1862 solver.cpp:507] Snapshotting to binary proto file my/Imagenet/AlexNet-BN/XnorNet_FWN/snapshot/xnor_net_iter_290000.caffemodel
I0911 03:01:42.818210  1862 sgd_solver.cpp:329] Snapshotting solver state to binary proto file my/Imagenet/AlexNet-BN/XnorNet_FWN/snapshot/xnor_net_iter_290000.solverstate
I0911 03:01:43.945389  1862 solver.cpp:377] Iteration 290000, Testing net (#0)
I0911 03:01:43.963169  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 03:02:16.189463  1862 blocking_queue.cpp:49] Waiting for data
I0911 03:13:19.841837  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 03:13:21.884302  1862 solver.cpp:445]     Test net output #0: accuracy = 0.37166
I0911 03:13:21.896374  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.617439
I0911 03:13:21.896436  1862 solver.cpp:445]     Test net output #2: loss = 3.02032 (* 1 = 3.02032 loss)
I0911 03:13:21.896473  1862 solver.cpp:456] ================================
I0911 03:13:21.896498  1862 solver.cpp:457]     Test net best accuracy1 is: 0.39658
I0911 03:13:21.896525  1862 solver.cpp:459]     Test net best accuracy5 is: 0.645939
I0911 03:13:23.533370  1862 solver.cpp:242] Iteration 290000 (0.192224 iter/s, 1040.45s/200 iters), loss = 2.10316
I0911 03:13:23.533479  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.773438
I0911 03:13:23.533509  1862 solver.cpp:261]     Train net output #1: loss = 2.10316 (* 1 = 2.10316 loss)
I0911 03:13:23.533542  1862 sgd_solver.cpp:122] Iteration 290000, lr = 0.0046875
I0911 03:13:46.052794  1876 data_layer.cpp:73] Restarting data prefetching from start.
I0911 03:19:01.528491  1862 solver.cpp:242] Iteration 290200 (0.591745 iter/s, 337.984s/200 iters), loss = 2.13945
I0911 03:19:01.528681  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.773438
I0911 03:19:01.528707  1862 solver.cpp:261]     Train net output #1: loss = 2.13945 (* 1 = 2.13945 loss)
I0911 03:19:01.528723  1862 sgd_solver.cpp:122] Iteration 290200, lr = 0.00465625
I0911 03:24:49.492982  1862 solver.cpp:242] Iteration 290400 (0.574791 iter/s, 347.953s/200 iters), loss = 2.26308
I0911 03:24:49.493683  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.730469
I0911 03:24:49.493821  1862 solver.cpp:261]     Train net output #1: loss = 2.26308 (* 1 = 2.26308 loss)
I0911 03:24:49.493922  1862 sgd_solver.cpp:122] Iteration 290400, lr = 0.004625
I0911 03:30:39.933410  1862 solver.cpp:242] Iteration 290600 (0.570731 iter/s, 350.428s/200 iters), loss = 1.74732
I0911 03:30:39.933583  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.828125
I0911 03:30:39.933609  1862 solver.cpp:261]     Train net output #1: loss = 1.74732 (* 1 = 1.74732 loss)
I0911 03:30:39.933622  1862 sgd_solver.cpp:122] Iteration 290600, lr = 0.00459375
I0911 03:36:34.133399  1862 solver.cpp:242] Iteration 290800 (0.564672 iter/s, 354.188s/200 iters), loss = 2.01619
I0911 03:36:34.133641  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.769531
I0911 03:36:34.133674  1862 solver.cpp:261]     Train net output #1: loss = 2.01619 (* 1 = 2.01619 loss)
I0911 03:36:34.133708  1862 sgd_solver.cpp:122] Iteration 290800, lr = 0.0045625
I0911 03:42:21.305869  1862 solver.cpp:377] Iteration 291000, Testing net (#0)
I0911 03:42:21.310607  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 03:54:22.590441  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 03:54:25.717320  1862 solver.cpp:445]     Test net output #0: accuracy = 0.36848
I0911 03:54:25.717591  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.617379
I0911 03:54:25.717653  1862 solver.cpp:445]     Test net output #2: loss = 2.99654 (* 1 = 2.99654 loss)
I0911 03:54:25.717705  1862 solver.cpp:456] ================================
I0911 03:54:25.717754  1862 solver.cpp:457]     Test net best accuracy1 is: 0.39658
I0911 03:54:25.717803  1862 solver.cpp:459]     Test net best accuracy5 is: 0.645939
I0911 03:54:27.070185  1862 solver.cpp:242] Iteration 291000 (0.186411 iter/s, 1072.9s/200 iters), loss = 2.10196
I0911 03:54:27.070390  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.78125
I0911 03:54:27.070462  1862 solver.cpp:261]     Train net output #1: loss = 2.10196 (* 1 = 2.10196 loss)
I0911 03:54:27.070528  1862 sgd_solver.cpp:122] Iteration 291000, lr = 0.00453125
I0911 04:00:10.363029  1862 solver.cpp:242] Iteration 291200 (0.582613 iter/s, 343.281s/200 iters), loss = 2.18033
I0911 04:00:10.363250  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.773438
I0911 04:00:10.363268  1862 solver.cpp:261]     Train net output #1: loss = 2.18033 (* 1 = 2.18033 loss)
I0911 04:00:10.421342  1862 sgd_solver.cpp:122] Iteration 291200, lr = 0.0045
I0911 04:05:59.245375  1862 solver.cpp:242] Iteration 291400 (0.573279 iter/s, 348.87s/200 iters), loss = 1.95965
I0911 04:05:59.248051  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.785156
I0911 04:05:59.248134  1862 solver.cpp:261]     Train net output #1: loss = 1.95965 (* 1 = 1.95965 loss)
I0911 04:05:59.248195  1862 sgd_solver.cpp:122] Iteration 291400, lr = 0.00446875
I0911 04:11:47.938186  1862 solver.cpp:242] Iteration 291600 (0.573595 iter/s, 348.678s/200 iters), loss = 2.02627
I0911 04:11:47.938364  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.773438
I0911 04:11:47.938382  1862 solver.cpp:261]     Train net output #1: loss = 2.02627 (* 1 = 2.02627 loss)
I0911 04:11:47.957350  1862 sgd_solver.cpp:122] Iteration 291600, lr = 0.0044375
I0911 04:17:38.381494  1862 solver.cpp:242] Iteration 291800 (0.570725 iter/s, 350.431s/200 iters), loss = 1.91586
I0911 04:17:38.381779  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.785156
I0911 04:17:38.381845  1862 solver.cpp:261]     Train net output #1: loss = 1.91586 (* 1 = 1.91586 loss)
I0911 04:17:38.381901  1862 sgd_solver.cpp:122] Iteration 291800, lr = 0.00440625
I0911 04:23:17.197877  1862 solver.cpp:377] Iteration 292000, Testing net (#0)
I0911 04:23:17.210882  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 04:34:49.783251  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 04:34:52.499781  1862 solver.cpp:445]     Test net output #0: accuracy = 0.3857
I0911 04:34:52.509910  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.631139
I0911 04:34:52.510059  1862 solver.cpp:445]     Test net output #2: loss = 2.93108 (* 1 = 2.93108 loss)
I0911 04:34:52.510149  1862 solver.cpp:456] ================================
I0911 04:34:52.510217  1862 solver.cpp:457]     Test net best accuracy1 is: 0.39658
I0911 04:34:52.510288  1862 solver.cpp:459]     Test net best accuracy5 is: 0.645939
I0911 04:34:53.845408  1862 solver.cpp:242] Iteration 292000 (0.193157 iter/s, 1035.43s/200 iters), loss = 2.25717
I0911 04:34:53.845479  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.710938
I0911 04:34:53.845495  1862 solver.cpp:261]     Train net output #1: loss = 2.25717 (* 1 = 2.25717 loss)
I0911 04:34:53.873672  1862 sgd_solver.cpp:122] Iteration 292000, lr = 0.004375
I0911 04:40:35.438944  1862 solver.cpp:242] Iteration 292200 (0.585511 iter/s, 341.582s/200 iters), loss = 2.05552
I0911 04:40:35.439733  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.777344
I0911 04:40:35.439836  1862 solver.cpp:261]     Train net output #1: loss = 2.05552 (* 1 = 2.05552 loss)
I0911 04:40:35.441509  1862 sgd_solver.cpp:122] Iteration 292200, lr = 0.00434375
I0911 04:46:11.869397  1862 solver.cpp:242] Iteration 292400 (0.594498 iter/s, 336.418s/200 iters), loss = 1.85103
I0911 04:46:11.874199  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.792969
I0911 04:46:11.874279  1862 solver.cpp:261]     Train net output #1: loss = 1.85103 (* 1 = 1.85103 loss)
I0911 04:46:11.874339  1862 sgd_solver.cpp:122] Iteration 292400, lr = 0.0043125
I0911 04:49:43.253751  1876 data_layer.cpp:73] Restarting data prefetching from start.
I0911 04:52:10.816160  1862 solver.cpp:242] Iteration 292600 (0.557212 iter/s, 358.93s/200 iters), loss = 2.04798
I0911 04:52:10.849514  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.765625
I0911 04:52:10.849611  1862 solver.cpp:261]     Train net output #1: loss = 2.04798 (* 1 = 2.04798 loss)
I0911 04:52:10.849669  1862 sgd_solver.cpp:122] Iteration 292600, lr = 0.00428125
I0911 04:58:06.301391  1862 solver.cpp:242] Iteration 292800 (0.562683 iter/s, 355.44s/200 iters), loss = 1.94393
I0911 04:58:06.303313  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.792969
I0911 04:58:06.303349  1862 solver.cpp:261]     Train net output #1: loss = 1.94393 (* 1 = 1.94393 loss)
I0911 04:58:06.303381  1862 sgd_solver.cpp:122] Iteration 292800, lr = 0.00425
I0911 05:03:53.792500  1862 solver.cpp:377] Iteration 293000, Testing net (#0)
I0911 05:03:53.796116  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 05:15:38.703608  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 05:15:41.033948  1862 solver.cpp:445]     Test net output #0: accuracy = 0.37326
I0911 05:15:41.034013  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.62002
I0911 05:15:41.034024  1862 solver.cpp:445]     Test net output #2: loss = 2.98935 (* 1 = 2.98935 loss)
I0911 05:15:41.034029  1862 solver.cpp:456] ================================
I0911 05:15:41.034034  1862 solver.cpp:457]     Test net best accuracy1 is: 0.39658
I0911 05:15:41.034037  1862 solver.cpp:459]     Test net best accuracy5 is: 0.645939
I0911 05:15:42.473381  1862 solver.cpp:242] Iteration 293000 (0.18937 iter/s, 1056.13s/200 iters), loss = 2.05651
I0911 05:15:42.473595  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.789062
I0911 05:15:42.473665  1862 solver.cpp:261]     Train net output #1: loss = 2.05651 (* 1 = 2.05651 loss)
I0911 05:15:42.473729  1862 sgd_solver.cpp:122] Iteration 293000, lr = 0.00421875
I0911 05:21:29.597424  1862 solver.cpp:242] Iteration 293200 (0.576183 iter/s, 347.112s/200 iters), loss = 1.84276
I0911 05:21:29.597831  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.800781
I0911 05:21:29.597909  1862 solver.cpp:261]     Train net output #1: loss = 1.84276 (* 1 = 1.84276 loss)
I0911 05:21:29.597977  1862 sgd_solver.cpp:122] Iteration 293200, lr = 0.0041875
I0911 05:27:27.362984  1862 solver.cpp:242] Iteration 293400 (0.559045 iter/s, 357.753s/200 iters), loss = 1.80921
I0911 05:27:27.363171  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.796875
I0911 05:27:27.363203  1862 solver.cpp:261]     Train net output #1: loss = 1.80921 (* 1 = 1.80921 loss)
I0911 05:27:27.363230  1862 sgd_solver.cpp:122] Iteration 293400, lr = 0.00415625
I0911 05:33:22.967293  1862 solver.cpp:242] Iteration 293600 (0.562442 iter/s, 355.592s/200 iters), loss = 1.87442
I0911 05:33:22.973738  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.777344
I0911 05:33:22.973763  1862 solver.cpp:261]     Train net output #1: loss = 1.87442 (* 1 = 1.87442 loss)
I0911 05:33:22.973781  1862 sgd_solver.cpp:122] Iteration 293600, lr = 0.004125
I0911 05:39:06.333523  1862 solver.cpp:242] Iteration 293800 (0.582499 iter/s, 343.348s/200 iters), loss = 1.83402
I0911 05:39:06.333868  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.796875
I0911 05:39:06.333941  1862 solver.cpp:261]     Train net output #1: loss = 1.83402 (* 1 = 1.83402 loss)
I0911 05:39:06.334003  1862 sgd_solver.cpp:122] Iteration 293800, lr = 0.00409375
I0911 05:44:41.612608  1862 solver.cpp:377] Iteration 294000, Testing net (#0)
I0911 05:44:41.617557  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 05:56:17.302810  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 05:56:20.155107  1862 solver.cpp:445]     Test net output #0: accuracy = 0.38282
I0911 05:56:20.172449  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.631879
I0911 05:56:20.172752  1862 solver.cpp:445]     Test net output #2: loss = 2.93008 (* 1 = 2.93008 loss)
I0911 05:56:20.172866  1862 solver.cpp:456] ================================
I0911 05:56:20.172948  1862 solver.cpp:457]     Test net best accuracy1 is: 0.39658
I0911 05:56:20.173033  1862 solver.cpp:459]     Test net best accuracy5 is: 0.645939
I0911 05:56:22.193392  1862 solver.cpp:242] Iteration 294000 (0.193083 iter/s, 1035.82s/200 iters), loss = 2.00217
I0911 05:56:22.193611  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.746094
I0911 05:56:22.193706  1862 solver.cpp:261]     Train net output #1: loss = 2.00217 (* 1 = 2.00217 loss)
I0911 05:56:22.193769  1862 sgd_solver.cpp:122] Iteration 294000, lr = 0.0040625
I0911 06:01:58.433390  1862 solver.cpp:242] Iteration 294200 (0.594834 iter/s, 336.228s/200 iters), loss = 1.83631
I0911 06:01:58.452416  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.800781
I0911 06:01:58.452440  1862 solver.cpp:261]     Train net output #1: loss = 1.83631 (* 1 = 1.83631 loss)
I0911 06:01:58.452455  1862 sgd_solver.cpp:122] Iteration 294200, lr = 0.00403125
I0911 06:07:51.245393  1862 solver.cpp:242] Iteration 294400 (0.566924 iter/s, 352.781s/200 iters), loss = 1.87525
I0911 06:07:51.245605  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.78125
I0911 06:07:51.245642  1862 solver.cpp:261]     Train net output #1: loss = 1.87525 (* 1 = 1.87525 loss)
I0911 06:07:51.245679  1862 sgd_solver.cpp:122] Iteration 294400, lr = 0.004
I0911 06:13:34.157413  1862 solver.cpp:242] Iteration 294600 (0.58326 iter/s, 342.9s/200 iters), loss = 1.94779
I0911 06:13:34.157719  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.792969
I0911 06:13:34.157793  1862 solver.cpp:261]     Train net output #1: loss = 1.94779 (* 1 = 1.94779 loss)
I0911 06:13:34.157862  1862 sgd_solver.cpp:122] Iteration 294600, lr = 0.00396875
I0911 06:19:20.217418  1862 solver.cpp:242] Iteration 294800 (0.577954 iter/s, 346.048s/200 iters), loss = 2.1705
I0911 06:19:20.217602  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.734375
I0911 06:19:20.217622  1862 solver.cpp:261]     Train net output #1: loss = 2.1705 (* 1 = 2.1705 loss)
I0911 06:19:20.217660  1862 sgd_solver.cpp:122] Iteration 294800, lr = 0.0039375
I0911 06:25:17.844862  1862 solver.cpp:377] Iteration 295000, Testing net (#0)
I0911 06:25:17.849658  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 06:37:25.070992  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 06:37:27.682636  1862 solver.cpp:445]     Test net output #0: accuracy = 0.39314
I0911 06:37:27.691262  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.639719
I0911 06:37:27.691372  1862 solver.cpp:445]     Test net output #2: loss = 2.8596 (* 1 = 2.8596 loss)
I0911 06:37:27.691439  1862 solver.cpp:456] ================================
I0911 06:37:27.691496  1862 solver.cpp:457]     Test net best accuracy1 is: 0.39658
I0911 06:37:27.691555  1862 solver.cpp:459]     Test net best accuracy5 is: 0.645939
I0911 06:37:29.261425  1862 solver.cpp:242] Iteration 295000 (0.183653 iter/s, 1089.01s/200 iters), loss = 1.91656
I0911 06:37:29.261497  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.789062
I0911 06:37:29.261514  1862 solver.cpp:261]     Train net output #1: loss = 1.91656 (* 1 = 1.91656 loss)
I0911 06:37:29.279606  1862 sgd_solver.cpp:122] Iteration 295000, lr = 0.00390625
I0911 06:37:59.484093  1876 data_layer.cpp:73] Restarting data prefetching from start.
I0911 06:43:21.397459  1862 solver.cpp:242] Iteration 295200 (0.567982 iter/s, 352.124s/200 iters), loss = 1.8663
I0911 06:43:21.397771  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.800781
I0911 06:43:21.397845  1862 solver.cpp:261]     Train net output #1: loss = 1.8663 (* 1 = 1.8663 loss)
I0911 06:43:21.397908  1862 sgd_solver.cpp:122] Iteration 295200, lr = 0.003875
I0911 06:49:25.615530  1862 solver.cpp:242] Iteration 295400 (0.549141 iter/s, 364.205s/200 iters), loss = 1.88387
I0911 06:49:25.615721  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.796875
I0911 06:49:25.615746  1862 solver.cpp:261]     Train net output #1: loss = 1.88387 (* 1 = 1.88387 loss)
I0911 06:49:25.615762  1862 sgd_solver.cpp:122] Iteration 295400, lr = 0.00384375
I0911 06:55:21.649354  1862 solver.cpp:242] Iteration 295600 (0.561764 iter/s, 356.022s/200 iters), loss = 2.09516
I0911 06:55:21.651687  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.765625
I0911 06:55:21.651728  1862 solver.cpp:261]     Train net output #1: loss = 2.09516 (* 1 = 2.09516 loss)
I0911 06:55:21.651747  1862 sgd_solver.cpp:122] Iteration 295600, lr = 0.0038125
I0911 07:01:43.101382  1862 solver.cpp:242] Iteration 295800 (0.524333 iter/s, 381.437s/200 iters), loss = 1.81413
I0911 07:01:43.105861  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.792969
I0911 07:01:43.105904  1862 solver.cpp:261]     Train net output #1: loss = 1.81413 (* 1 = 1.81413 loss)
I0911 07:01:43.105929  1862 sgd_solver.cpp:122] Iteration 295800, lr = 0.00378125
I0911 07:07:35.769867  1862 solver.cpp:377] Iteration 296000, Testing net (#0)
I0911 07:07:35.778849  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 07:19:04.362051  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 07:19:07.500535  1862 solver.cpp:445]     Test net output #0: accuracy = 0.39722
I0911 07:19:07.513237  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.64354
I0911 07:19:07.513480  1862 solver.cpp:445]     Test net output #2: loss = 2.84722 (* 1 = 2.84722 loss)
I0911 07:19:07.513537  1862 solver.cpp:456] ================================
I0911 07:19:07.513573  1862 solver.cpp:457]     Test net best accuracy1 is: 0.39722
I0911 07:19:07.513607  1862 solver.cpp:459]     Test net best accuracy5 is: 0.64354
I0911 07:19:08.965400  1862 solver.cpp:242] Iteration 296000 (0.191237 iter/s, 1045.82s/200 iters), loss = 2.24884
I0911 07:19:08.965615  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.714844
I0911 07:19:08.965682  1862 solver.cpp:261]     Train net output #1: loss = 2.24884 (* 1 = 2.24884 loss)
I0911 07:19:08.965741  1862 sgd_solver.cpp:122] Iteration 296000, lr = 0.00375
I0911 07:24:57.803695  1862 solver.cpp:242] Iteration 296200 (0.573351 iter/s, 348.826s/200 iters), loss = 1.96854
I0911 07:24:57.803874  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.761719
I0911 07:24:57.803896  1862 solver.cpp:261]     Train net output #1: loss = 1.96854 (* 1 = 1.96854 loss)
I0911 07:24:57.803911  1862 sgd_solver.cpp:122] Iteration 296200, lr = 0.00371875
I0911 07:30:41.018795  1862 solver.cpp:242] Iteration 296400 (0.582745 iter/s, 343.203s/200 iters), loss = 1.86442
I0911 07:30:41.019520  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.792969
I0911 07:30:41.019654  1862 solver.cpp:261]     Train net output #1: loss = 1.86442 (* 1 = 1.86442 loss)
I0911 07:30:41.019757  1862 sgd_solver.cpp:122] Iteration 296400, lr = 0.0036875
I0911 07:39:30.168089  1862 solver.cpp:242] Iteration 296600 (0.377978 iter/s, 529.131s/200 iters), loss = 2.06102
I0911 07:39:30.168411  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.785156
I0911 07:39:30.168484  1862 solver.cpp:261]     Train net output #1: loss = 2.06102 (* 1 = 2.06102 loss)
I0911 07:39:30.168546  1862 sgd_solver.cpp:122] Iteration 296600, lr = 0.00365625
I0911 07:46:00.781978  1862 solver.cpp:242] Iteration 296800 (0.512032 iter/s, 390.6s/200 iters), loss = 1.68141
I0911 07:46:00.782500  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.820312
I0911 07:46:00.782606  1862 solver.cpp:261]     Train net output #1: loss = 1.68141 (* 1 = 1.68141 loss)
I0911 07:46:00.782691  1862 sgd_solver.cpp:122] Iteration 296800, lr = 0.003625
I0911 07:52:07.061748  1862 solver.cpp:377] Iteration 297000, Testing net (#0)
I0911 07:52:07.069466  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 08:03:54.584314  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 08:03:58.047502  1862 solver.cpp:445]     Test net output #0: accuracy = 0.40392
I0911 08:03:58.057593  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.655259
I0911 08:03:58.057685  1862 solver.cpp:445]     Test net output #2: loss = 2.79301 (* 1 = 2.79301 loss)
I0911 08:03:58.057734  1862 solver.cpp:456] ================================
I0911 08:03:58.057778  1862 solver.cpp:457]     Test net best accuracy1 is: 0.40392
I0911 08:03:58.057822  1862 solver.cpp:459]     Test net best accuracy5 is: 0.655259
I0911 08:04:00.011687  1862 solver.cpp:242] Iteration 297000 (0.185324 iter/s, 1079.19s/200 iters), loss = 1.84126
I0911 08:04:00.011765  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.808594
I0911 08:04:00.011782  1862 solver.cpp:261]     Train net output #1: loss = 1.84126 (* 1 = 1.84126 loss)
I0911 08:04:00.036661  1862 sgd_solver.cpp:122] Iteration 297000, lr = 0.00359375
I0911 08:09:37.787518  1862 solver.cpp:242] Iteration 297200 (0.592129 iter/s, 337.764s/200 iters), loss = 1.8882
I0911 08:09:37.788141  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.804688
I0911 08:09:37.788254  1862 solver.cpp:261]     Train net output #1: loss = 1.8882 (* 1 = 1.8882 loss)
I0911 08:09:37.788373  1862 sgd_solver.cpp:122] Iteration 297200, lr = 0.0035625
I0911 08:15:41.036006  1862 solver.cpp:242] Iteration 297400 (0.550607 iter/s, 363.236s/200 iters), loss = 1.93541
I0911 08:15:41.060437  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.789062
I0911 08:15:41.060461  1862 solver.cpp:261]     Train net output #1: loss = 1.93541 (* 1 = 1.93541 loss)
I0911 08:15:41.060477  1862 sgd_solver.cpp:122] Iteration 297400, lr = 0.00353125
I0911 08:19:03.241901  1876 data_layer.cpp:73] Restarting data prefetching from start.
I0911 08:21:15.417924  1862 solver.cpp:242] Iteration 297600 (0.598182 iter/s, 334.346s/200 iters), loss = 1.58353
I0911 08:21:15.418087  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.847656
I0911 08:21:15.418105  1862 solver.cpp:261]     Train net output #1: loss = 1.58353 (* 1 = 1.58353 loss)
I0911 08:21:15.459393  1862 sgd_solver.cpp:122] Iteration 297600, lr = 0.0035
I0911 08:26:54.565718  1862 solver.cpp:242] Iteration 297800 (0.589734 iter/s, 339.136s/200 iters), loss = 1.97532
I0911 08:26:54.581342  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.773438
I0911 08:26:54.585392  1862 solver.cpp:261]     Train net output #1: loss = 1.97532 (* 1 = 1.97532 loss)
I0911 08:26:54.585436  1862 sgd_solver.cpp:122] Iteration 297800, lr = 0.00346875
I0911 08:32:45.451025  1862 solver.cpp:377] Iteration 298000, Testing net (#0)
I0911 08:32:45.461261  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 08:44:37.507746  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 08:44:39.978585  1862 solver.cpp:445]     Test net output #0: accuracy = 0.3791
I0911 08:44:39.986855  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.62808
I0911 08:44:39.987049  1862 solver.cpp:445]     Test net output #2: loss = 2.9664 (* 1 = 2.9664 loss)
I0911 08:44:39.987139  1862 solver.cpp:456] ================================
I0911 08:44:39.987203  1862 solver.cpp:457]     Test net best accuracy1 is: 0.40392
I0911 08:44:39.987272  1862 solver.cpp:459]     Test net best accuracy5 is: 0.655259
I0911 08:44:41.045409  1862 solver.cpp:242] Iteration 298000 (0.187542 iter/s, 1066.43s/200 iters), loss = 1.87807
I0911 08:44:41.045635  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.78125
I0911 08:44:41.045704  1862 solver.cpp:261]     Train net output #1: loss = 1.87807 (* 1 = 1.87807 loss)
I0911 08:44:41.069339  1862 sgd_solver.cpp:122] Iteration 298000, lr = 0.0034375
I0911 08:50:14.858813  1862 solver.cpp:242] Iteration 298200 (0.599158 iter/s, 333.802s/200 iters), loss = 2.17857
I0911 08:50:14.859182  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.757812
I0911 08:50:14.859207  1862 solver.cpp:261]     Train net output #1: loss = 2.17857 (* 1 = 2.17857 loss)
I0911 08:50:14.859221  1862 sgd_solver.cpp:122] Iteration 298200, lr = 0.00340625
I0911 08:56:14.362619  1862 solver.cpp:242] Iteration 298400 (0.556342 iter/s, 359.491s/200 iters), loss = 1.86243
I0911 08:56:14.370138  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.796875
I0911 08:56:14.370162  1862 solver.cpp:261]     Train net output #1: loss = 1.86243 (* 1 = 1.86243 loss)
I0911 08:56:14.370177  1862 sgd_solver.cpp:122] Iteration 298400, lr = 0.003375
I0911 09:02:11.223914  1862 solver.cpp:242] Iteration 298600 (0.560473 iter/s, 356.842s/200 iters), loss = 2.08822
I0911 09:02:11.229018  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.742188
I0911 09:02:11.229064  1862 solver.cpp:261]     Train net output #1: loss = 2.08822 (* 1 = 2.08822 loss)
I0911 09:02:11.229094  1862 sgd_solver.cpp:122] Iteration 298600, lr = 0.00334375
I0911 09:08:07.224617  1862 solver.cpp:242] Iteration 298800 (0.561824 iter/s, 355.983s/200 iters), loss = 1.95328
I0911 09:08:07.224804  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.765625
I0911 09:08:07.224824  1862 solver.cpp:261]     Train net output #1: loss = 1.95328 (* 1 = 1.95328 loss)
I0911 09:08:07.240423  1862 sgd_solver.cpp:122] Iteration 298800, lr = 0.0033125
I0911 09:13:38.561851  1862 solver.cpp:377] Iteration 299000, Testing net (#0)
I0911 09:13:38.568940  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 09:25:10.932880  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 09:25:14.088246  1862 solver.cpp:445]     Test net output #0: accuracy = 0.40152
I0911 09:25:14.090441  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.65158
I0911 09:25:14.090515  1862 solver.cpp:445]     Test net output #2: loss = 2.8069 (* 1 = 2.8069 loss)
I0911 09:25:14.090556  1862 solver.cpp:456] ================================
I0911 09:25:14.090627  1862 solver.cpp:457]     Test net best accuracy1 is: 0.40392
I0911 09:25:14.090652  1862 solver.cpp:459]     Test net best accuracy5 is: 0.655259
I0911 09:25:15.455114  1862 solver.cpp:242] Iteration 299000 (0.194515 iter/s, 1028.2s/200 iters), loss = 1.91808
I0911 09:25:15.462159  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.789062
I0911 09:25:15.462235  1862 solver.cpp:261]     Train net output #1: loss = 1.91808 (* 1 = 1.91808 loss)
I0911 09:25:15.462285  1862 sgd_solver.cpp:122] Iteration 299000, lr = 0.00328125
I0911 09:31:19.525379  1862 solver.cpp:242] Iteration 299200 (0.549374 iter/s, 364.051s/200 iters), loss = 1.95477
I0911 09:31:19.541463  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.796875
I0911 09:31:19.541510  1862 solver.cpp:261]     Train net output #1: loss = 1.95477 (* 1 = 1.95477 loss)
I0911 09:31:19.541548  1862 sgd_solver.cpp:122] Iteration 299200, lr = 0.00325
I0911 09:37:01.787354  1862 solver.cpp:242] Iteration 299400 (0.584395 iter/s, 342.234s/200 iters), loss = 1.73593
I0911 09:37:01.797468  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.792969
I0911 09:37:01.797608  1862 solver.cpp:261]     Train net output #1: loss = 1.73593 (* 1 = 1.73593 loss)
I0911 09:37:01.797703  1862 sgd_solver.cpp:122] Iteration 299400, lr = 0.00321875
I0911 09:43:02.565390  1862 solver.cpp:242] Iteration 299600 (0.554392 iter/s, 360.756s/200 iters), loss = 1.82534
I0911 09:43:02.565948  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.808594
I0911 09:43:02.565984  1862 solver.cpp:261]     Train net output #1: loss = 1.82534 (* 1 = 1.82534 loss)
I0911 09:43:02.566016  1862 sgd_solver.cpp:122] Iteration 299600, lr = 0.0031875
I0911 09:49:01.411931  1862 solver.cpp:242] Iteration 299800 (0.557361 iter/s, 358.834s/200 iters), loss = 2.07779
I0911 09:49:01.412109  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.78125
I0911 09:49:01.412127  1862 solver.cpp:261]     Train net output #1: loss = 2.07779 (* 1 = 2.07779 loss)
I0911 09:49:01.412139  1862 sgd_solver.cpp:122] Iteration 299800, lr = 0.00315625
I0911 09:54:55.916357  1862 solver.cpp:507] Snapshotting to binary proto file my/Imagenet/AlexNet-BN/XnorNet_FWN/snapshot/xnor_net_iter_300000.caffemodel
I0911 09:55:11.255724  1862 sgd_solver.cpp:329] Snapshotting solver state to binary proto file my/Imagenet/AlexNet-BN/XnorNet_FWN/snapshot/xnor_net_iter_300000.solverstate
I0911 09:55:12.836076  1862 solver.cpp:377] Iteration 300000, Testing net (#0)
I0911 09:55:12.836400  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 10:07:13.728106  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 10:07:15.903914  1862 solver.cpp:445]     Test net output #0: accuracy = 0.38888
I0911 10:07:15.908001  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.63494
I0911 10:07:15.908136  1862 solver.cpp:445]     Test net output #2: loss = 2.91396 (* 1 = 2.91396 loss)
I0911 10:07:15.908224  1862 solver.cpp:456] ================================
I0911 10:07:15.908290  1862 solver.cpp:457]     Test net best accuracy1 is: 0.40392
I0911 10:07:15.908358  1862 solver.cpp:459]     Test net best accuracy5 is: 0.655259
I0911 10:07:17.491300  1862 solver.cpp:242] Iteration 300000 (0.182475 iter/s, 1096.04s/200 iters), loss = 1.9713
I0911 10:07:17.491884  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.765625
I0911 10:07:17.492043  1862 solver.cpp:261]     Train net output #1: loss = 1.9713 (* 1 = 1.9713 loss)
I0911 10:07:17.493047  1862 sgd_solver.cpp:122] Iteration 300000, lr = 0.003125
I0911 10:07:58.313271  1876 data_layer.cpp:73] Restarting data prefetching from start.
I0911 10:13:08.192577  1862 solver.cpp:242] Iteration 300200 (0.570306 iter/s, 350.689s/200 iters), loss = 1.92876
I0911 10:13:08.202797  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.777344
I0911 10:13:08.203167  1862 solver.cpp:261]     Train net output #1: loss = 1.92876 (* 1 = 1.92876 loss)
I0911 10:13:08.203426  1862 sgd_solver.cpp:122] Iteration 300200, lr = 0.00309375
I0911 10:18:55.266118  1862 solver.cpp:242] Iteration 300400 (0.576283 iter/s, 347.052s/200 iters), loss = 2.15704
I0911 10:18:55.266508  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.753906
I0911 10:18:55.266582  1862 solver.cpp:261]     Train net output #1: loss = 2.15704 (* 1 = 2.15704 loss)
I0911 10:18:55.266643  1862 sgd_solver.cpp:122] Iteration 300400, lr = 0.0030625
I0911 10:24:47.413379  1862 solver.cpp:242] Iteration 300600 (0.567964 iter/s, 352.135s/200 iters), loss = 1.97214
I0911 10:24:47.413547  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.765625
I0911 10:24:47.413568  1862 solver.cpp:261]     Train net output #1: loss = 1.97214 (* 1 = 1.97214 loss)
I0911 10:24:47.413588  1862 sgd_solver.cpp:122] Iteration 300600, lr = 0.00303125
I0911 10:30:41.111280  1862 solver.cpp:242] Iteration 300800 (0.565474 iter/s, 353.686s/200 iters), loss = 1.76214
I0911 10:30:41.118058  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.804688
I0911 10:30:41.118084  1862 solver.cpp:261]     Train net output #1: loss = 1.76214 (* 1 = 1.76214 loss)
I0911 10:30:41.141080  1862 sgd_solver.cpp:122] Iteration 300800, lr = 0.003
I0911 10:36:38.021816  1862 solver.cpp:377] Iteration 301000, Testing net (#0)
I0911 10:36:38.026922  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 10:48:18.299628  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 10:48:20.854043  1862 solver.cpp:445]     Test net output #0: accuracy = 0.3833
I0911 10:48:20.854110  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.631879
I0911 10:48:20.854120  1862 solver.cpp:445]     Test net output #2: loss = 2.9617 (* 1 = 2.9617 loss)
I0911 10:48:20.854125  1862 solver.cpp:456] ================================
I0911 10:48:20.854128  1862 solver.cpp:457]     Test net best accuracy1 is: 0.40392
I0911 10:48:20.854133  1862 solver.cpp:459]     Test net best accuracy5 is: 0.655259
I0911 10:48:22.421378  1862 solver.cpp:242] Iteration 301000 (0.188454 iter/s, 1061.27s/200 iters), loss = 1.91144
I0911 10:48:22.421572  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.769531
I0911 10:48:22.421630  1862 solver.cpp:261]     Train net output #1: loss = 1.91144 (* 1 = 1.91144 loss)
I0911 10:48:22.421679  1862 sgd_solver.cpp:122] Iteration 301000, lr = 0.00296875
I0911 10:54:21.518743  1862 solver.cpp:242] Iteration 301200 (0.556971 iter/s, 359.085s/200 iters), loss = 1.90292
I0911 10:54:21.518936  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.78125
I0911 10:54:21.518960  1862 solver.cpp:261]     Train net output #1: loss = 1.90292 (* 1 = 1.90292 loss)
I0911 10:54:21.518977  1862 sgd_solver.cpp:122] Iteration 301200, lr = 0.0029375
I0911 11:00:17.529917  1862 solver.cpp:242] Iteration 301400 (0.561799 iter/s, 355.999s/200 iters), loss = 1.80203
I0911 11:00:17.549569  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.824219
I0911 11:00:17.549651  1862 solver.cpp:261]     Train net output #1: loss = 1.80203 (* 1 = 1.80203 loss)
I0911 11:00:17.549717  1862 sgd_solver.cpp:122] Iteration 301400, lr = 0.00290625
I0911 11:06:05.921500  1862 solver.cpp:242] Iteration 301600 (0.574119 iter/s, 348.36s/200 iters), loss = 1.79818
I0911 11:06:05.921702  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.808594
I0911 11:06:05.921741  1862 solver.cpp:261]     Train net output #1: loss = 1.79818 (* 1 = 1.79818 loss)
I0911 11:06:05.921771  1862 sgd_solver.cpp:122] Iteration 301600, lr = 0.002875
I0911 11:11:57.546648  1862 solver.cpp:242] Iteration 301800 (0.568807 iter/s, 351.613s/200 iters), loss = 1.77451
I0911 11:11:57.552556  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.777344
I0911 11:11:57.552578  1862 solver.cpp:261]     Train net output #1: loss = 1.77451 (* 1 = 1.77451 loss)
I0911 11:11:57.552594  1862 sgd_solver.cpp:122] Iteration 301800, lr = 0.00284375
I0911 11:18:03.511694  1862 solver.cpp:377] Iteration 302000, Testing net (#0)
I0911 11:18:03.520378  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 11:30:04.134264  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 11:30:06.950320  1862 solver.cpp:445]     Test net output #0: accuracy = 0.41576
I0911 11:30:06.950528  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.66484
I0911 11:30:06.950588  1862 solver.cpp:445]     Test net output #2: loss = 2.76129 (* 1 = 2.76129 loss)
I0911 11:30:06.950636  1862 solver.cpp:456] ================================
I0911 11:30:06.950686  1862 solver.cpp:457]     Test net best accuracy1 is: 0.41576
I0911 11:30:06.950731  1862 solver.cpp:459]     Test net best accuracy5 is: 0.66484
I0911 11:30:08.765383  1862 solver.cpp:242] Iteration 302000 (0.183288 iter/s, 1091.18s/200 iters), loss = 1.74877
I0911 11:30:08.765463  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.8125
I0911 11:30:08.765478  1862 solver.cpp:261]     Train net output #1: loss = 1.74877 (* 1 = 1.74877 loss)
I0911 11:30:08.791708  1862 sgd_solver.cpp:122] Iteration 302000, lr = 0.0028125
I0911 11:36:02.555233  1862 solver.cpp:242] Iteration 302200 (0.565327 iter/s, 353.778s/200 iters), loss = 1.80366
I0911 11:36:02.555410  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.804688
I0911 11:36:02.555433  1862 solver.cpp:261]     Train net output #1: loss = 1.80366 (* 1 = 1.80366 loss)
I0911 11:36:02.555452  1862 sgd_solver.cpp:122] Iteration 302200, lr = 0.00278125
I0911 11:41:50.256042  1862 solver.cpp:242] Iteration 302400 (0.575227 iter/s, 347.689s/200 iters), loss = 2.03143
I0911 11:41:50.262639  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.777344
I0911 11:41:50.262668  1862 solver.cpp:261]     Train net output #1: loss = 2.03143 (* 1 = 2.03143 loss)
I0911 11:41:50.262686  1862 sgd_solver.cpp:122] Iteration 302400, lr = 0.00275
I0911 11:45:40.632937  1876 data_layer.cpp:73] Restarting data prefetching from start.
I0911 11:47:52.181352  1862 solver.cpp:242] Iteration 302600 (0.55263 iter/s, 361.906s/200 iters), loss = 1.811
I0911 11:47:52.181668  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.832031
I0911 11:47:52.181741  1862 solver.cpp:261]     Train net output #1: loss = 1.811 (* 1 = 1.811 loss)
I0911 11:47:52.181804  1862 sgd_solver.cpp:122] Iteration 302600, lr = 0.00271875
I0911 11:53:39.882974  1862 solver.cpp:242] Iteration 302800 (0.575226 iter/s, 347.69s/200 iters), loss = 1.82555
I0911 11:53:39.883159  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.785156
I0911 11:53:39.883175  1862 solver.cpp:261]     Train net output #1: loss = 1.82555 (* 1 = 1.82555 loss)
I0911 11:53:39.901342  1862 sgd_solver.cpp:122] Iteration 302800, lr = 0.0026875
I0911 11:59:14.199353  1862 solver.cpp:377] Iteration 303000, Testing net (#0)
I0911 11:59:14.207850  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 12:11:01.091881  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 12:11:03.233000  1862 solver.cpp:445]     Test net output #0: accuracy = 0.41788
I0911 12:11:03.233220  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.665379
I0911 12:11:03.233294  1862 solver.cpp:445]     Test net output #2: loss = 2.73711 (* 1 = 2.73711 loss)
I0911 12:11:03.233362  1862 solver.cpp:456] ================================
I0911 12:11:03.233408  1862 solver.cpp:457]     Test net best accuracy1 is: 0.41788
I0911 12:11:03.233453  1862 solver.cpp:459]     Test net best accuracy5 is: 0.665379
I0911 12:11:04.821398  1862 solver.cpp:242] Iteration 303000 (0.191405 iter/s, 1044.9s/200 iters), loss = 1.71845
I0911 12:11:04.821468  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.8125
I0911 12:11:04.821483  1862 solver.cpp:261]     Train net output #1: loss = 1.71845 (* 1 = 1.71845 loss)
I0911 12:11:04.841349  1862 sgd_solver.cpp:122] Iteration 303000, lr = 0.00265625
I0911 12:16:48.835654  1862 solver.cpp:242] Iteration 303200 (0.581391 iter/s, 344.003s/200 iters), loss = 1.74986
I0911 12:16:48.836169  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.828125
I0911 12:16:48.836271  1862 solver.cpp:261]     Train net output #1: loss = 1.74986 (* 1 = 1.74986 loss)
I0911 12:16:48.836352  1862 sgd_solver.cpp:122] Iteration 303200, lr = 0.002625
I0911 12:22:40.120379  1862 solver.cpp:242] Iteration 303400 (0.569359 iter/s, 351.272s/200 iters), loss = 1.62644
I0911 12:22:40.121075  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.832031
I0911 12:22:40.121155  1862 solver.cpp:261]     Train net output #1: loss = 1.62644 (* 1 = 1.62644 loss)
I0911 12:22:40.121214  1862 sgd_solver.cpp:122] Iteration 303400, lr = 0.00259375
I0911 12:28:35.013243  1862 solver.cpp:242] Iteration 303600 (0.563571 iter/s, 354.88s/200 iters), loss = 1.84285
I0911 12:28:35.013445  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.804688
I0911 12:28:35.013471  1862 solver.cpp:261]     Train net output #1: loss = 1.84285 (* 1 = 1.84285 loss)
I0911 12:28:35.013491  1862 sgd_solver.cpp:122] Iteration 303600, lr = 0.0025625
I0911 12:34:18.707235  1862 solver.cpp:242] Iteration 303800 (0.581933 iter/s, 343.682s/200 iters), loss = 1.71893
I0911 12:34:18.707578  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.820312
I0911 12:34:18.707653  1862 solver.cpp:261]     Train net output #1: loss = 1.71893 (* 1 = 1.71893 loss)
I0911 12:34:18.707713  1862 sgd_solver.cpp:122] Iteration 303800, lr = 0.00253125
I0911 12:40:04.453861  1862 solver.cpp:377] Iteration 304000, Testing net (#0)
I0911 12:40:04.469489  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 12:52:00.366873  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 12:52:03.281266  1862 solver.cpp:445]     Test net output #0: accuracy = 0.41122
I0911 12:52:03.287286  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.656339
I0911 12:52:03.287462  1862 solver.cpp:445]     Test net output #2: loss = 2.78425 (* 1 = 2.78425 loss)
I0911 12:52:03.287547  1862 solver.cpp:456] ================================
I0911 12:52:03.287612  1862 solver.cpp:457]     Test net best accuracy1 is: 0.41788
I0911 12:52:03.287683  1862 solver.cpp:459]     Test net best accuracy5 is: 0.665379
I0911 12:52:04.985395  1862 solver.cpp:242] Iteration 304000 (0.187575 iter/s, 1066.24s/200 iters), loss = 1.83302
I0911 12:52:04.985605  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.835938
I0911 12:52:04.985678  1862 solver.cpp:261]     Train net output #1: loss = 1.83302 (* 1 = 1.83302 loss)
I0911 12:52:04.985744  1862 sgd_solver.cpp:122] Iteration 304000, lr = 0.0025
I0911 12:57:34.665474  1862 solver.cpp:242] Iteration 304200 (0.60667 iter/s, 329.669s/200 iters), loss = 1.78179
I0911 12:57:34.671178  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.773438
I0911 12:57:34.671305  1862 solver.cpp:261]     Train net output #1: loss = 1.78179 (* 1 = 1.78179 loss)
I0911 12:57:34.671408  1862 sgd_solver.cpp:122] Iteration 304200, lr = 0.00246875
I0911 13:03:35.358711  1862 solver.cpp:242] Iteration 304400 (0.554515 iter/s, 360.675s/200 iters), loss = 1.85814
I0911 13:03:35.372256  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.773438
I0911 13:03:35.372282  1862 solver.cpp:261]     Train net output #1: loss = 1.85814 (* 1 = 1.85814 loss)
I0911 13:03:35.372298  1862 sgd_solver.cpp:122] Iteration 304400, lr = 0.0024375
I0911 13:09:15.796262  1862 solver.cpp:242] Iteration 304600 (0.587523 iter/s, 340.412s/200 iters), loss = 1.87178
I0911 13:09:15.797147  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.808594
I0911 13:09:15.797315  1862 solver.cpp:261]     Train net output #1: loss = 1.87178 (* 1 = 1.87178 loss)
I0911 13:09:15.797454  1862 sgd_solver.cpp:122] Iteration 304600, lr = 0.00240625
I0911 13:15:01.425323  1862 solver.cpp:242] Iteration 304800 (0.578676 iter/s, 345.616s/200 iters), loss = 1.85595
I0911 13:15:01.433163  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.777344
I0911 13:15:01.433396  1862 solver.cpp:261]     Train net output #1: loss = 1.85595 (* 1 = 1.85595 loss)
I0911 13:15:01.433549  1862 sgd_solver.cpp:122] Iteration 304800, lr = 0.002375
I0911 13:20:45.732697  1862 solver.cpp:377] Iteration 305000, Testing net (#0)
I0911 13:20:45.761529  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 13:32:25.418061  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 13:32:28.019150  1862 solver.cpp:445]     Test net output #0: accuracy = 0.41184
I0911 13:32:28.019371  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.65626
I0911 13:32:28.019431  1862 solver.cpp:445]     Test net output #2: loss = 2.78524 (* 1 = 2.78524 loss)
I0911 13:32:28.019482  1862 solver.cpp:456] ================================
I0911 13:32:28.019528  1862 solver.cpp:457]     Test net best accuracy1 is: 0.41788
I0911 13:32:28.019572  1862 solver.cpp:459]     Test net best accuracy5 is: 0.665379
I0911 13:32:29.065975  1862 solver.cpp:242] Iteration 305000 (0.190913 iter/s, 1047.6s/200 iters), loss = 1.67474
I0911 13:32:29.070720  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.832031
I0911 13:32:29.070842  1862 solver.cpp:261]     Train net output #1: loss = 1.67474 (* 1 = 1.67474 loss)
I0911 13:32:29.090436  1862 sgd_solver.cpp:122] Iteration 305000, lr = 0.00234375
I0911 13:33:17.312265  1876 data_layer.cpp:73] Restarting data prefetching from start.
I0911 13:38:23.753371  1862 solver.cpp:242] Iteration 305200 (0.563903 iter/s, 354.671s/200 iters), loss = 1.93651
I0911 13:38:23.753674  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.796875
I0911 13:38:23.753751  1862 solver.cpp:261]     Train net output #1: loss = 1.93651 (* 1 = 1.93651 loss)
I0911 13:38:23.753823  1862 sgd_solver.cpp:122] Iteration 305200, lr = 0.0023125
I0911 13:44:24.868192  1862 solver.cpp:242] Iteration 305400 (0.55386 iter/s, 361.102s/200 iters), loss = 1.789
I0911 13:44:24.868538  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.789062
I0911 13:44:24.868611  1862 solver.cpp:261]     Train net output #1: loss = 1.789 (* 1 = 1.789 loss)
I0911 13:44:24.868672  1862 sgd_solver.cpp:122] Iteration 305400, lr = 0.00228125
I0911 13:50:25.894372  1862 solver.cpp:242] Iteration 305600 (0.553996 iter/s, 361.014s/200 iters), loss = 1.6569
I0911 13:50:25.894558  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.839844
I0911 13:50:25.894582  1862 solver.cpp:261]     Train net output #1: loss = 1.6569 (* 1 = 1.6569 loss)
I0911 13:50:25.894599  1862 sgd_solver.cpp:122] Iteration 305600, lr = 0.00225
I0911 13:56:19.014123  1862 solver.cpp:242] Iteration 305800 (0.5664 iter/s, 353.108s/200 iters), loss = 1.59585
I0911 13:56:19.042387  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.832031
I0911 13:56:19.042611  1862 solver.cpp:261]     Train net output #1: loss = 1.59585 (* 1 = 1.59585 loss)
I0911 13:56:19.042758  1862 sgd_solver.cpp:122] Iteration 305800, lr = 0.00221875
I0911 14:02:06.882148  1862 solver.cpp:377] Iteration 306000, Testing net (#0)
I0911 14:02:06.882792  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 14:13:49.164880  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 14:13:51.916184  1862 solver.cpp:445]     Test net output #0: accuracy = 0.4095
I0911 14:13:51.919850  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.658919
I0911 14:13:51.919970  1862 solver.cpp:445]     Test net output #2: loss = 2.779 (* 1 = 2.779 loss)
I0911 14:13:51.920020  1862 solver.cpp:456] ================================
I0911 14:13:51.920053  1862 solver.cpp:457]     Test net best accuracy1 is: 0.41788
I0911 14:13:51.920085  1862 solver.cpp:459]     Test net best accuracy5 is: 0.665379
I0911 14:13:53.354769  1862 solver.cpp:242] Iteration 306000 (0.189703 iter/s, 1054.28s/200 iters), loss = 1.80315
I0911 14:13:53.355232  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.835938
I0911 14:13:53.355391  1862 solver.cpp:261]     Train net output #1: loss = 1.80315 (* 1 = 1.80315 loss)
I0911 14:13:53.355520  1862 sgd_solver.cpp:122] Iteration 306000, lr = 0.0021875
I0911 14:19:33.879706  1862 solver.cpp:242] Iteration 306200 (0.587349 iter/s, 340.513s/200 iters), loss = 1.97199
I0911 14:19:33.880542  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.769531
I0911 14:19:33.880684  1862 solver.cpp:261]     Train net output #1: loss = 1.97199 (* 1 = 1.97199 loss)
I0911 14:19:33.898181  1862 sgd_solver.cpp:122] Iteration 306200, lr = 0.00215625
I0911 14:25:11.528436  1862 solver.cpp:242] Iteration 306400 (0.592353 iter/s, 337.636s/200 iters), loss = 1.55481
I0911 14:25:11.534106  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.832031
I0911 14:25:11.534124  1862 solver.cpp:261]     Train net output #1: loss = 1.55481 (* 1 = 1.55481 loss)
I0911 14:25:11.534137  1862 sgd_solver.cpp:122] Iteration 306400, lr = 0.002125
I0911 14:30:41.387198  1862 solver.cpp:242] Iteration 306600 (0.606351 iter/s, 329.842s/200 iters), loss = 1.95148
I0911 14:30:41.387409  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.78125
I0911 14:30:41.387446  1862 solver.cpp:261]     Train net output #1: loss = 1.95148 (* 1 = 1.95148 loss)
I0911 14:30:41.427389  1862 sgd_solver.cpp:122] Iteration 306600, lr = 0.00209375
I0911 14:36:13.708894  1862 solver.cpp:242] Iteration 306800 (0.601847 iter/s, 332.31s/200 iters), loss = 1.8198
I0911 14:36:13.709233  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.792969
I0911 14:36:13.709307  1862 solver.cpp:261]     Train net output #1: loss = 1.8198 (* 1 = 1.8198 loss)
I0911 14:36:13.709379  1862 sgd_solver.cpp:122] Iteration 306800, lr = 0.0020625
I0911 14:41:41.974525  1862 solver.cpp:377] Iteration 307000, Testing net (#0)
I0911 14:41:41.983057  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 14:52:59.098850  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 14:53:01.471493  1862 solver.cpp:445]     Test net output #0: accuracy = 0.39794
I0911 14:53:01.471913  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.64574
I0911 14:53:01.472016  1862 solver.cpp:445]     Test net output #2: loss = 2.87476 (* 1 = 2.87476 loss)
I0911 14:53:01.472084  1862 solver.cpp:456] ================================
I0911 14:53:01.472139  1862 solver.cpp:457]     Test net best accuracy1 is: 0.41788
I0911 14:53:01.472196  1862 solver.cpp:459]     Test net best accuracy5 is: 0.665379
I0911 14:53:03.122344  1862 solver.cpp:242] Iteration 307000 (0.197798 iter/s, 1011.13s/200 iters), loss = 2.04858
I0911 14:53:03.122406  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.777344
I0911 14:53:03.122418  1862 solver.cpp:261]     Train net output #1: loss = 2.04858 (* 1 = 2.04858 loss)
I0911 14:53:03.122436  1862 sgd_solver.cpp:122] Iteration 307000, lr = 0.00203125
I0911 14:58:35.102352  1862 solver.cpp:242] Iteration 307200 (0.602465 iter/s, 331.969s/200 iters), loss = 1.71314
I0911 14:58:35.119081  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.832031
I0911 14:58:35.119101  1862 solver.cpp:261]     Train net output #1: loss = 1.71314 (* 1 = 1.71314 loss)
I0911 14:58:35.119113  1862 sgd_solver.cpp:122] Iteration 307200, lr = 0.002
I0911 15:04:34.962633  1862 solver.cpp:242] Iteration 307400 (0.555814 iter/s, 359.832s/200 iters), loss = 1.84644
I0911 15:04:34.962950  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.789062
I0911 15:04:34.963057  1862 solver.cpp:261]     Train net output #1: loss = 1.84644 (* 1 = 1.84644 loss)
I0911 15:04:34.978292  1862 sgd_solver.cpp:122] Iteration 307400, lr = 0.00196875
I0911 15:08:18.295917  1876 data_layer.cpp:73] Restarting data prefetching from start.
I0911 15:10:13.196139  1862 solver.cpp:242] Iteration 307600 (0.591325 iter/s, 338.223s/200 iters), loss = 1.60607
I0911 15:10:13.201099  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.847656
I0911 15:10:13.201238  1862 solver.cpp:261]     Train net output #1: loss = 1.60607 (* 1 = 1.60607 loss)
I0911 15:10:13.201339  1862 sgd_solver.cpp:122] Iteration 307600, lr = 0.0019375
I0911 15:15:48.665024  1862 solver.cpp:242] Iteration 307800 (0.59621 iter/s, 335.452s/200 iters), loss = 1.69617
I0911 15:15:48.665344  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.804688
I0911 15:15:48.665422  1862 solver.cpp:261]     Train net output #1: loss = 1.69617 (* 1 = 1.69617 loss)
I0911 15:15:48.674633  1862 sgd_solver.cpp:122] Iteration 307800, lr = 0.00190625
I0911 15:21:19.996909  1862 solver.cpp:377] Iteration 308000, Testing net (#0)
I0911 15:21:19.997284  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 15:33:18.812686  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 15:33:21.962272  1862 solver.cpp:445]     Test net output #0: accuracy = 0.4215
I0911 15:33:21.963989  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.66808
I0911 15:33:21.964092  1862 solver.cpp:445]     Test net output #2: loss = 2.72909 (* 1 = 2.72909 loss)
I0911 15:33:21.964160  1862 solver.cpp:456] ================================
I0911 15:33:21.964222  1862 solver.cpp:457]     Test net best accuracy1 is: 0.4215
I0911 15:33:21.964282  1862 solver.cpp:459]     Test net best accuracy5 is: 0.66808
I0911 15:33:23.568290  1862 solver.cpp:242] Iteration 308000 (0.189597 iter/s, 1054.87s/200 iters), loss = 1.87424
I0911 15:33:23.568505  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.804688
I0911 15:33:23.568583  1862 solver.cpp:261]     Train net output #1: loss = 1.87424 (* 1 = 1.87424 loss)
I0911 15:33:23.568645  1862 sgd_solver.cpp:122] Iteration 308000, lr = 0.001875
I0911 15:38:54.022974  1862 solver.cpp:242] Iteration 308200 (0.605244 iter/s, 330.445s/200 iters), loss = 1.8565
I0911 15:38:54.023306  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.777344
I0911 15:38:54.023386  1862 solver.cpp:261]     Train net output #1: loss = 1.8565 (* 1 = 1.8565 loss)
I0911 15:38:54.023448  1862 sgd_solver.cpp:122] Iteration 308200, lr = 0.00184375
I0911 15:45:05.570336  1862 solver.cpp:242] Iteration 308400 (0.538306 iter/s, 371.536s/200 iters), loss = 1.76936
I0911 15:45:05.570642  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.808594
I0911 15:45:05.570719  1862 solver.cpp:261]     Train net output #1: loss = 1.76936 (* 1 = 1.76936 loss)
I0911 15:45:05.570780  1862 sgd_solver.cpp:122] Iteration 308400, lr = 0.0018125
I0911 15:51:24.487133  1862 solver.cpp:242] Iteration 308600 (0.527837 iter/s, 378.905s/200 iters), loss = 1.67744
I0911 15:51:24.487754  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.851562
I0911 15:51:24.487830  1862 solver.cpp:261]     Train net output #1: loss = 1.67744 (* 1 = 1.67744 loss)
I0911 15:51:24.487896  1862 sgd_solver.cpp:122] Iteration 308600, lr = 0.00178125
I0911 15:57:45.482998  1862 solver.cpp:242] Iteration 308800 (0.524957 iter/s, 380.983s/200 iters), loss = 1.59847
I0911 15:57:45.509882  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.832031
I0911 15:57:45.511174  1862 solver.cpp:261]     Train net output #1: loss = 1.59847 (* 1 = 1.59847 loss)
I0911 15:57:45.512483  1862 sgd_solver.cpp:122] Iteration 308800, lr = 0.00175
I0911 16:03:58.045882  1862 solver.cpp:377] Iteration 309000, Testing net (#0)
I0911 16:03:58.062393  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 16:16:59.901955  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 16:17:02.790074  1862 solver.cpp:445]     Test net output #0: accuracy = 0.4217
I0911 16:17:02.799623  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.667519
I0911 16:17:02.799649  1862 solver.cpp:445]     Test net output #2: loss = 2.7437 (* 1 = 2.7437 loss)
I0911 16:17:02.799655  1862 solver.cpp:456] ================================
I0911 16:17:02.799659  1862 solver.cpp:457]     Test net best accuracy1 is: 0.4217
I0911 16:17:02.799664  1862 solver.cpp:459]     Test net best accuracy5 is: 0.667519
I0911 16:17:04.521041  1862 solver.cpp:242] Iteration 309000 (0.172566 iter/s, 1158.98s/200 iters), loss = 1.80118
I0911 16:17:04.526010  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.832031
I0911 16:17:04.526147  1862 solver.cpp:261]     Train net output #1: loss = 1.80118 (* 1 = 1.80118 loss)
I0911 16:17:04.526233  1862 sgd_solver.cpp:122] Iteration 309000, lr = 0.00171875
I0911 16:23:26.814038  1862 solver.cpp:242] Iteration 309200 (0.523182 iter/s, 382.276s/200 iters), loss = 1.86628
I0911 16:23:26.814368  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.78125
I0911 16:23:26.814395  1862 solver.cpp:261]     Train net output #1: loss = 1.86628 (* 1 = 1.86628 loss)
I0911 16:23:26.814420  1862 sgd_solver.cpp:122] Iteration 309200, lr = 0.0016875
I0911 16:29:51.165432  1862 solver.cpp:242] Iteration 309400 (0.520373 iter/s, 384.339s/200 iters), loss = 1.47988
I0911 16:29:51.165613  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.863281
I0911 16:29:51.165629  1862 solver.cpp:261]     Train net output #1: loss = 1.47988 (* 1 = 1.47988 loss)
I0911 16:29:51.230303  1862 sgd_solver.cpp:122] Iteration 309400, lr = 0.00165625
I0911 16:36:11.190239  1862 solver.cpp:242] Iteration 309600 (0.526298 iter/s, 380.013s/200 iters), loss = 1.58975
I0911 16:36:11.190910  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.828125
I0911 16:36:11.191015  1862 solver.cpp:261]     Train net output #1: loss = 1.58975 (* 1 = 1.58975 loss)
I0911 16:36:11.191095  1862 sgd_solver.cpp:122] Iteration 309600, lr = 0.001625
I0911 16:42:20.880079  1862 solver.cpp:242] Iteration 309800 (0.541011 iter/s, 369.678s/200 iters), loss = 1.78038
I0911 16:42:20.898316  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.8125
I0911 16:42:20.898351  1862 solver.cpp:261]     Train net output #1: loss = 1.78038 (* 1 = 1.78038 loss)
I0911 16:42:20.898373  1862 sgd_solver.cpp:122] Iteration 309800, lr = 0.00159375
I0911 16:49:06.037001  1862 solver.cpp:507] Snapshotting to binary proto file my/Imagenet/AlexNet-BN/XnorNet_FWN/snapshot/xnor_net_iter_310000.caffemodel
I0911 16:50:03.985846  1862 sgd_solver.cpp:329] Snapshotting solver state to binary proto file my/Imagenet/AlexNet-BN/XnorNet_FWN/snapshot/xnor_net_iter_310000.solverstate
I0911 16:50:05.677484  1862 solver.cpp:377] Iteration 310000, Testing net (#0)
I0911 16:50:05.677798  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 17:04:22.740325  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 17:04:26.394626  1862 solver.cpp:445]     Test net output #0: accuracy = 0.41386
I0911 17:04:26.394989  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.660119
I0911 17:04:26.395141  1862 solver.cpp:445]     Test net output #2: loss = 2.77668 (* 1 = 2.77668 loss)
I0911 17:04:26.395237  1862 solver.cpp:456] ================================
I0911 17:04:26.395315  1862 solver.cpp:457]     Test net best accuracy1 is: 0.4217
I0911 17:04:26.395400  1862 solver.cpp:459]     Test net best accuracy5 is: 0.667519
I0911 17:04:28.530313  1862 solver.cpp:242] Iteration 310000 (0.150649 iter/s, 1327.59s/200 iters), loss = 1.78119
I0911 17:04:28.530522  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.796875
I0911 17:04:28.530596  1862 solver.cpp:261]     Train net output #1: loss = 1.78119 (* 1 = 1.78119 loss)
I0911 17:04:28.530658  1862 sgd_solver.cpp:122] Iteration 310000, lr = 0.0015625
I0911 17:05:33.665197  1876 data_layer.cpp:73] Restarting data prefetching from start.
I0911 17:11:30.376369  1862 solver.cpp:242] Iteration 310200 (0.47412 iter/s, 421.834s/200 iters), loss = 1.60968
I0911 17:11:30.376543  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.824219
I0911 17:11:30.376559  1862 solver.cpp:261]     Train net output #1: loss = 1.60968 (* 1 = 1.60968 loss)
I0911 17:11:30.416057  1862 sgd_solver.cpp:122] Iteration 310200, lr = 0.00153125
I0911 17:18:38.198691  1862 solver.cpp:242] Iteration 310400 (0.467496 iter/s, 427.811s/200 iters), loss = 1.70156
I0911 17:18:38.198947  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.835938
I0911 17:18:38.198963  1862 solver.cpp:261]     Train net output #1: loss = 1.70156 (* 1 = 1.70156 loss)
I0911 17:18:38.199846  1862 sgd_solver.cpp:122] Iteration 310400, lr = 0.0015
I0911 17:25:44.155493  1862 solver.cpp:242] Iteration 310600 (0.469545 iter/s, 425.944s/200 iters), loss = 1.56484
I0911 17:25:44.155946  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.84375
I0911 17:25:44.156015  1862 solver.cpp:261]     Train net output #1: loss = 1.56484 (* 1 = 1.56484 loss)
I0911 17:25:44.171023  1862 sgd_solver.cpp:122] Iteration 310600, lr = 0.00146875
I0911 17:32:56.082515  1862 solver.cpp:242] Iteration 310800 (0.463055 iter/s, 431.914s/200 iters), loss = 1.61325
I0911 17:32:56.083789  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.847656
I0911 17:32:56.083885  1862 solver.cpp:261]     Train net output #1: loss = 1.61325 (* 1 = 1.61325 loss)
I0911 17:32:56.083955  1862 sgd_solver.cpp:122] Iteration 310800, lr = 0.0014375
I0911 17:40:08.844918  1862 solver.cpp:377] Iteration 311000, Testing net (#0)
I0911 17:40:08.845182  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 17:53:17.144712  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 17:53:19.076261  1862 solver.cpp:445]     Test net output #0: accuracy = 0.4208
I0911 17:53:19.078145  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.667999
I0911 17:53:19.078248  1862 solver.cpp:445]     Test net output #2: loss = 2.7262 (* 1 = 2.7262 loss)
I0911 17:53:19.078335  1862 solver.cpp:456] ================================
I0911 17:53:19.078399  1862 solver.cpp:457]     Test net best accuracy1 is: 0.4217
I0911 17:53:19.078459  1862 solver.cpp:459]     Test net best accuracy5 is: 0.667519
I0911 17:53:20.874334  1862 solver.cpp:242] Iteration 311000 (0.163298 iter/s, 1224.75s/200 iters), loss = 1.78347
I0911 17:53:20.874397  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.785156
I0911 17:53:20.874409  1862 solver.cpp:261]     Train net output #1: loss = 1.78347 (* 1 = 1.78347 loss)
I0911 17:53:20.874428  1862 sgd_solver.cpp:122] Iteration 311000, lr = 0.00140625
I0911 17:58:58.940001  1862 solver.cpp:242] Iteration 311200 (0.591619 iter/s, 338.055s/200 iters), loss = 1.72548
I0911 17:58:58.940407  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.8125
I0911 17:58:58.940487  1862 solver.cpp:261]     Train net output #1: loss = 1.72548 (* 1 = 1.72548 loss)
I0911 17:58:58.952029  1862 sgd_solver.cpp:122] Iteration 311200, lr = 0.001375
I0911 18:04:40.159309  1862 solver.cpp:242] Iteration 311400 (0.586152 iter/s, 341.209s/200 iters), loss = 1.66627
I0911 18:04:40.159629  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.84375
I0911 18:04:40.159698  1862 solver.cpp:261]     Train net output #1: loss = 1.66627 (* 1 = 1.66627 loss)
I0911 18:04:40.159759  1862 sgd_solver.cpp:122] Iteration 311400, lr = 0.00134375
I0911 18:10:21.016296  1862 solver.cpp:242] Iteration 311600 (0.586775 iter/s, 340.846s/200 iters), loss = 1.51952
I0911 18:10:21.016526  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.855469
I0911 18:10:21.016551  1862 solver.cpp:261]     Train net output #1: loss = 1.51952 (* 1 = 1.51952 loss)
I0911 18:10:21.016571  1862 sgd_solver.cpp:122] Iteration 311600, lr = 0.0013125
I0911 18:16:00.666326  1862 solver.cpp:242] Iteration 311800 (0.588859 iter/s, 339.64s/200 iters), loss = 1.73561
I0911 18:16:00.702082  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.789062
I0911 18:16:00.702111  1862 solver.cpp:261]     Train net output #1: loss = 1.73561 (* 1 = 1.73561 loss)
I0911 18:16:00.702126  1862 sgd_solver.cpp:122] Iteration 311800, lr = 0.00128125
I0911 18:21:37.958755  1862 solver.cpp:377] Iteration 312000, Testing net (#0)
I0911 18:21:37.972129  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 18:33:09.074877  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 18:33:12.169214  1862 solver.cpp:445]     Test net output #0: accuracy = 0.42236
I0911 18:33:12.182101  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.668399
I0911 18:33:12.182219  1862 solver.cpp:445]     Test net output #2: loss = 2.71068 (* 1 = 2.71068 loss)
I0911 18:33:12.182297  1862 solver.cpp:456] ================================
I0911 18:33:12.182364  1862 solver.cpp:457]     Test net best accuracy1 is: 0.42236
I0911 18:33:12.182430  1862 solver.cpp:459]     Test net best accuracy5 is: 0.668399
I0911 18:33:13.818328  1862 solver.cpp:242] Iteration 312000 (0.193595 iter/s, 1033.09s/200 iters), loss = 1.53918
I0911 18:33:13.818399  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.839844
I0911 18:33:13.818413  1862 solver.cpp:261]     Train net output #1: loss = 1.53918 (* 1 = 1.53918 loss)
I0911 18:33:13.818429  1862 sgd_solver.cpp:122] Iteration 312000, lr = 0.00125
I0911 18:38:48.663571  1862 solver.cpp:242] Iteration 312200 (0.597308 iter/s, 334.835s/200 iters), loss = 1.85165
I0911 18:38:48.674703  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.792969
I0911 18:38:48.674734  1862 solver.cpp:261]     Train net output #1: loss = 1.85165 (* 1 = 1.85165 loss)
I0911 18:38:48.674752  1862 sgd_solver.cpp:122] Iteration 312200, lr = 0.00121875
I0911 18:44:26.396276  1862 solver.cpp:242] Iteration 312400 (0.592221 iter/s, 337.712s/200 iters), loss = 1.65333
I0911 18:44:26.396456  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.824219
I0911 18:44:26.396476  1862 solver.cpp:261]     Train net output #1: loss = 1.65333 (* 1 = 1.65333 loss)
I0911 18:44:26.411770  1862 sgd_solver.cpp:122] Iteration 312400, lr = 0.0011875
I0911 18:48:14.933709  1876 data_layer.cpp:73] Restarting data prefetching from start.
I0911 18:50:06.856385  1862 solver.cpp:242] Iteration 312600 (0.587458 iter/s, 340.45s/200 iters), loss = 1.73319
I0911 18:50:06.856737  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.808594
I0911 18:50:06.856806  1862 solver.cpp:261]     Train net output #1: loss = 1.73319 (* 1 = 1.73319 loss)
I0911 18:50:06.866358  1862 sgd_solver.cpp:122] Iteration 312600, lr = 0.00115625
I0911 18:55:58.442414  1862 solver.cpp:242] Iteration 312800 (0.56887 iter/s, 351.574s/200 iters), loss = 1.59079
I0911 18:55:58.449569  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.828125
I0911 18:55:58.449645  1862 solver.cpp:261]     Train net output #1: loss = 1.59079 (* 1 = 1.59079 loss)
I0911 18:55:58.449707  1862 sgd_solver.cpp:122] Iteration 312800, lr = 0.001125
I0911 19:01:38.762197  1862 solver.cpp:377] Iteration 313000, Testing net (#0)
I0911 19:01:38.764195  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 19:12:58.467262  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 19:13:01.699664  1862 solver.cpp:445]     Test net output #0: accuracy = 0.42956
I0911 19:13:01.702625  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.675339
I0911 19:13:01.702805  1862 solver.cpp:445]     Test net output #2: loss = 2.67432 (* 1 = 2.67432 loss)
I0911 19:13:01.702950  1862 solver.cpp:456] ================================
I0911 19:13:01.703045  1862 solver.cpp:457]     Test net best accuracy1 is: 0.42956
I0911 19:13:01.703138  1862 solver.cpp:459]     Test net best accuracy5 is: 0.675339
I0911 19:13:03.021775  1862 solver.cpp:242] Iteration 313000 (0.19521 iter/s, 1024.54s/200 iters), loss = 1.68334
I0911 19:13:03.021874  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.839844
I0911 19:13:03.021904  1862 solver.cpp:261]     Train net output #1: loss = 1.68334 (* 1 = 1.68334 loss)
I0911 19:13:03.021932  1862 sgd_solver.cpp:122] Iteration 313000, lr = 0.00109375
I0911 19:18:46.194335  1862 solver.cpp:242] Iteration 313200 (0.582815 iter/s, 343.162s/200 iters), loss = 1.73723
I0911 19:18:46.194694  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.796875
I0911 19:18:46.194779  1862 solver.cpp:261]     Train net output #1: loss = 1.73723 (* 1 = 1.73723 loss)
I0911 19:18:46.194844  1862 sgd_solver.cpp:122] Iteration 313200, lr = 0.0010625
I0911 19:24:34.794073  1862 solver.cpp:242] Iteration 313400 (0.573742 iter/s, 348.589s/200 iters), loss = 1.3275
I0911 19:24:34.810546  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.882812
I0911 19:24:34.810644  1862 solver.cpp:261]     Train net output #1: loss = 1.3275 (* 1 = 1.3275 loss)
I0911 19:24:34.810719  1862 sgd_solver.cpp:122] Iteration 313400, lr = 0.00103125
I0911 19:30:25.462319  1862 solver.cpp:242] Iteration 313600 (0.570383 iter/s, 350.642s/200 iters), loss = 1.52138
I0911 19:30:25.462620  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.839844
I0911 19:30:25.462697  1862 solver.cpp:261]     Train net output #1: loss = 1.52138 (* 1 = 1.52138 loss)
I0911 19:30:25.462760  1862 sgd_solver.cpp:122] Iteration 313600, lr = 0.000999999
I0911 19:36:05.694340  1862 solver.cpp:242] Iteration 313800 (0.587852 iter/s, 340.222s/200 iters), loss = 1.64145
I0911 19:36:05.694882  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.824219
I0911 19:36:05.694900  1862 solver.cpp:261]     Train net output #1: loss = 1.64145 (* 1 = 1.64145 loss)
I0911 19:36:05.694911  1862 sgd_solver.cpp:122] Iteration 313800, lr = 0.000968751
I0911 19:41:42.562932  1862 solver.cpp:377] Iteration 314000, Testing net (#0)
I0911 19:41:42.565977  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 19:53:20.168499  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 19:53:23.338991  1862 solver.cpp:445]     Test net output #0: accuracy = 0.4396
I0911 19:53:23.341038  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.685879
I0911 19:53:23.341188  1862 solver.cpp:445]     Test net output #2: loss = 2.6165 (* 1 = 2.6165 loss)
I0911 19:53:23.341272  1862 solver.cpp:456] ================================
I0911 19:53:23.341336  1862 solver.cpp:457]     Test net best accuracy1 is: 0.4396
I0911 19:53:23.341406  1862 solver.cpp:459]     Test net best accuracy5 is: 0.685879
I0911 19:53:24.475597  1862 solver.cpp:242] Iteration 314000 (0.192539 iter/s, 1038.75s/200 iters), loss = 1.67615
I0911 19:53:24.475822  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.8125
I0911 19:53:24.475899  1862 solver.cpp:261]     Train net output #1: loss = 1.67615 (* 1 = 1.67615 loss)
I0911 19:53:24.487643  1862 sgd_solver.cpp:122] Iteration 314000, lr = 0.000937501
I0911 19:59:00.810959  1862 solver.cpp:242] Iteration 314200 (0.594663 iter/s, 336.325s/200 iters), loss = 1.39732
I0911 19:59:00.811156  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.855469
I0911 19:59:00.811175  1862 solver.cpp:261]     Train net output #1: loss = 1.39732 (* 1 = 1.39732 loss)
I0911 19:59:00.830945  1862 sgd_solver.cpp:122] Iteration 314200, lr = 0.00090625
I0911 20:05:03.292419  1862 solver.cpp:242] Iteration 314400 (0.551767 iter/s, 362.472s/200 iters), loss = 1.42562
I0911 20:05:03.292652  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.863281
I0911 20:05:03.292675  1862 solver.cpp:261]     Train net output #1: loss = 1.42562 (* 1 = 1.42562 loss)
I0911 20:05:03.292707  1862 sgd_solver.cpp:122] Iteration 314400, lr = 0.000874999
I0911 20:11:12.519981  1862 solver.cpp:242] Iteration 314600 (0.541686 iter/s, 369.217s/200 iters), loss = 1.5901
I0911 20:11:12.520323  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.835938
I0911 20:11:12.520397  1862 solver.cpp:261]     Train net output #1: loss = 1.5901 (* 1 = 1.5901 loss)
I0911 20:11:12.520467  1862 sgd_solver.cpp:122] Iteration 314600, lr = 0.000843751
I0911 20:16:48.154317  1862 solver.cpp:242] Iteration 314800 (0.595904 iter/s, 335.625s/200 iters), loss = 1.43698
I0911 20:16:48.154497  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.867188
I0911 20:16:48.154521  1862 solver.cpp:261]     Train net output #1: loss = 1.43698 (* 1 = 1.43698 loss)
I0911 20:16:48.154543  1862 sgd_solver.cpp:122] Iteration 314800, lr = 0.000812501
I0911 20:22:26.242800  1862 solver.cpp:377] Iteration 315000, Testing net (#0)
I0911 20:22:26.246779  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 20:34:08.341154  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 20:34:10.826894  1862 solver.cpp:445]     Test net output #0: accuracy = 0.41706
I0911 20:34:10.827008  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.660099
I0911 20:34:10.827036  1862 solver.cpp:445]     Test net output #2: loss = 2.79595 (* 1 = 2.79595 loss)
I0911 20:34:10.827055  1862 solver.cpp:456] ================================
I0911 20:34:10.827072  1862 solver.cpp:457]     Test net best accuracy1 is: 0.4396
I0911 20:34:10.827090  1862 solver.cpp:459]     Test net best accuracy5 is: 0.685879
I0911 20:34:12.362100  1862 solver.cpp:242] Iteration 315000 (0.191538 iter/s, 1044.18s/200 iters), loss = 1.7261
I0911 20:34:12.362226  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.828125
I0911 20:34:12.362262  1862 solver.cpp:261]     Train net output #1: loss = 1.7261 (* 1 = 1.7261 loss)
I0911 20:34:12.408380  1862 sgd_solver.cpp:122] Iteration 315000, lr = 0.00078125
I0911 20:35:11.771428  1876 data_layer.cpp:73] Restarting data prefetching from start.
I0911 20:39:47.426386  1862 solver.cpp:242] Iteration 315200 (0.596918 iter/s, 335.054s/200 iters), loss = 1.50508
I0911 20:39:47.427754  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.859375
I0911 20:39:47.427822  1862 solver.cpp:261]     Train net output #1: loss = 1.50508 (* 1 = 1.50508 loss)
I0911 20:39:47.429706  1862 sgd_solver.cpp:122] Iteration 315200, lr = 0.000749999
I0911 20:45:29.850313  1862 solver.cpp:242] Iteration 315400 (0.584091 iter/s, 342.413s/200 iters), loss = 1.48187
I0911 20:45:29.850924  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.851562
I0911 20:45:29.850958  1862 solver.cpp:261]     Train net output #1: loss = 1.48187 (* 1 = 1.48187 loss)
I0911 20:45:29.850989  1862 sgd_solver.cpp:122] Iteration 315400, lr = 0.000718749
I0911 20:51:09.495138  1862 solver.cpp:242] Iteration 315600 (0.588869 iter/s, 339.634s/200 iters), loss = 1.50508
I0911 20:51:09.502192  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.855469
I0911 20:51:09.502233  1862 solver.cpp:261]     Train net output #1: loss = 1.50508 (* 1 = 1.50508 loss)
I0911 20:51:09.502264  1862 sgd_solver.cpp:122] Iteration 315600, lr = 0.000687501
I0911 20:57:01.329210  1862 solver.cpp:242] Iteration 315800 (0.568478 iter/s, 351.817s/200 iters), loss = 1.36253
I0911 20:57:01.329582  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.867188
I0911 20:57:01.329643  1862 solver.cpp:261]     Train net output #1: loss = 1.36253 (* 1 = 1.36253 loss)
I0911 20:57:01.329691  1862 sgd_solver.cpp:122] Iteration 315800, lr = 0.00065625
I0911 21:02:41.474148  1862 solver.cpp:377] Iteration 316000, Testing net (#0)
I0911 21:02:41.504494  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 21:14:44.459890  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 21:14:46.654175  1862 solver.cpp:445]     Test net output #0: accuracy = 0.44622
I0911 21:14:46.670281  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.693339
I0911 21:14:46.670383  1862 solver.cpp:445]     Test net output #2: loss = 2.58235 (* 1 = 2.58235 loss)
I0911 21:14:46.670431  1862 solver.cpp:456] ================================
I0911 21:14:46.670475  1862 solver.cpp:457]     Test net best accuracy1 is: 0.44622
I0911 21:14:46.670519  1862 solver.cpp:459]     Test net best accuracy5 is: 0.693339
I0911 21:14:48.169463  1862 solver.cpp:242] Iteration 316000 (0.187475 iter/s, 1066.81s/200 iters), loss = 1.58904
I0911 21:14:48.169685  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.863281
I0911 21:14:48.169752  1862 solver.cpp:261]     Train net output #1: loss = 1.58904 (* 1 = 1.58904 loss)
I0911 21:14:48.182781  1862 sgd_solver.cpp:122] Iteration 316000, lr = 0.000624999
I0911 21:20:38.914501  1862 solver.cpp:242] Iteration 316200 (0.570234 iter/s, 350.733s/200 iters), loss = 1.42505
I0911 21:20:38.935413  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.835938
I0911 21:20:38.935533  1862 solver.cpp:261]     Train net output #1: loss = 1.42505 (* 1 = 1.42505 loss)
I0911 21:20:38.935586  1862 sgd_solver.cpp:122] Iteration 316200, lr = 0.000593749
I0911 21:26:41.542352  1862 solver.cpp:242] Iteration 316400 (0.551579 iter/s, 362.596s/200 iters), loss = 1.27832
I0911 21:26:41.542675  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.90625
I0911 21:26:41.542740  1862 solver.cpp:261]     Train net output #1: loss = 1.27832 (* 1 = 1.27832 loss)
I0911 21:26:41.542804  1862 sgd_solver.cpp:122] Iteration 316400, lr = 0.000562501
I0911 21:32:44.586917  1862 solver.cpp:242] Iteration 316600 (0.550914 iter/s, 363.033s/200 iters), loss = 1.86104
I0911 21:32:44.587105  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.800781
I0911 21:32:44.587121  1862 solver.cpp:261]     Train net output #1: loss = 1.86104 (* 1 = 1.86104 loss)
I0911 21:32:44.587133  1862 sgd_solver.cpp:122] Iteration 316600, lr = 0.00053125
I0911 21:38:34.302330  1862 solver.cpp:242] Iteration 316800 (0.571911 iter/s, 349.705s/200 iters), loss = 1.54694
I0911 21:38:34.303030  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.84375
I0911 21:38:34.303752  1862 solver.cpp:261]     Train net output #1: loss = 1.54694 (* 1 = 1.54694 loss)
I0911 21:38:34.303844  1862 sgd_solver.cpp:122] Iteration 316800, lr = 0.0005
I0911 21:44:15.726752  1862 solver.cpp:377] Iteration 317000, Testing net (#0)
I0911 21:44:15.746457  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 21:55:47.471072  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 21:55:50.876294  1862 solver.cpp:445]     Test net output #0: accuracy = 0.45922
I0911 21:55:50.878775  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.701899
I0911 21:55:50.878865  1862 solver.cpp:445]     Test net output #2: loss = 2.50936 (* 1 = 2.50936 loss)
I0911 21:55:50.878916  1862 solver.cpp:456] ================================
I0911 21:55:50.878959  1862 solver.cpp:457]     Test net best accuracy1 is: 0.45922
I0911 21:55:50.879004  1862 solver.cpp:459]     Test net best accuracy5 is: 0.701899
I0911 21:55:52.302351  1862 solver.cpp:242] Iteration 317000 (0.192684 iter/s, 1037.97s/200 iters), loss = 1.44073
I0911 21:55:52.302585  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.847656
I0911 21:55:52.302655  1862 solver.cpp:261]     Train net output #1: loss = 1.44073 (* 1 = 1.44073 loss)
I0911 21:55:52.302726  1862 sgd_solver.cpp:122] Iteration 317000, lr = 0.000468749
I0911 22:01:39.758404  1862 solver.cpp:242] Iteration 317200 (0.57563 iter/s, 347.445s/200 iters), loss = 1.5162
I0911 22:01:39.758709  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.851562
I0911 22:01:39.758744  1862 solver.cpp:261]     Train net output #1: loss = 1.5162 (* 1 = 1.5162 loss)
I0911 22:01:39.758777  1862 sgd_solver.cpp:122] Iteration 317200, lr = 0.000437501
I0911 22:07:29.202491  1862 solver.cpp:242] Iteration 317400 (0.572355 iter/s, 349.433s/200 iters), loss = 1.51774
I0911 22:07:29.205173  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.839844
I0911 22:07:29.205198  1862 solver.cpp:261]     Train net output #1: loss = 1.51774 (* 1 = 1.51774 loss)
I0911 22:07:29.205216  1862 sgd_solver.cpp:122] Iteration 317400, lr = 0.00040625
I0911 22:11:23.966742  1876 data_layer.cpp:73] Restarting data prefetching from start.
I0911 22:13:04.836277  1862 solver.cpp:242] Iteration 317600 (0.59591 iter/s, 335.621s/200 iters), loss = 1.42403
I0911 22:13:04.836750  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.855469
I0911 22:13:04.836828  1862 solver.cpp:261]     Train net output #1: loss = 1.42403 (* 1 = 1.42403 loss)
I0911 22:13:04.877492  1862 sgd_solver.cpp:122] Iteration 317600, lr = 0.000375
I0911 22:18:44.310998  1862 solver.cpp:242] Iteration 317800 (0.589188 iter/s, 339.45s/200 iters), loss = 1.51845
I0911 22:18:44.323551  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.84375
I0911 22:18:44.323953  1862 solver.cpp:261]     Train net output #1: loss = 1.51845 (* 1 = 1.51845 loss)
I0911 22:18:44.324158  1862 sgd_solver.cpp:122] Iteration 317800, lr = 0.000343749
I0911 22:24:39.996606  1862 solver.cpp:377] Iteration 318000, Testing net (#0)
I0911 22:24:39.997066  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 22:36:33.174098  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 22:36:36.510282  1862 solver.cpp:445]     Test net output #0: accuracy = 0.460521
I0911 22:36:36.514643  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.70354
I0911 22:36:36.514757  1862 solver.cpp:445]     Test net output #2: loss = 2.50949 (* 1 = 2.50949 loss)
I0911 22:36:36.514825  1862 solver.cpp:456] ================================
I0911 22:36:36.514883  1862 solver.cpp:457]     Test net best accuracy1 is: 0.460521
I0911 22:36:36.514940  1862 solver.cpp:459]     Test net best accuracy5 is: 0.70354
I0911 22:36:38.090335  1862 solver.cpp:242] Iteration 318000 (0.186266 iter/s, 1073.74s/200 iters), loss = 1.35251
I0911 22:36:38.090548  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.867188
I0911 22:36:38.090621  1862 solver.cpp:261]     Train net output #1: loss = 1.35251 (* 1 = 1.35251 loss)
I0911 22:36:38.090687  1862 sgd_solver.cpp:122] Iteration 318000, lr = 0.000312501
I0911 22:42:23.831336  1862 solver.cpp:242] Iteration 318200 (0.578485 iter/s, 345.731s/200 iters), loss = 1.42669
I0911 22:42:23.831532  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.863281
I0911 22:42:23.831547  1862 solver.cpp:261]     Train net output #1: loss = 1.42669 (* 1 = 1.42669 loss)
I0911 22:42:23.850293  1862 sgd_solver.cpp:122] Iteration 318200, lr = 0.00028125
I0911 22:48:09.010640  1862 solver.cpp:242] Iteration 318400 (0.579427 iter/s, 345.169s/200 iters), loss = 1.16602
I0911 22:48:09.011345  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.902344
I0911 22:48:09.011365  1862 solver.cpp:261]     Train net output #1: loss = 1.16602 (* 1 = 1.16602 loss)
I0911 22:48:09.011379  1862 sgd_solver.cpp:122] Iteration 318400, lr = 0.00025
I0911 22:53:55.959265  1862 solver.cpp:242] Iteration 318600 (0.576473 iter/s, 346.937s/200 iters), loss = 1.38949
I0911 22:53:55.960008  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.871094
I0911 22:53:55.960115  1862 solver.cpp:261]     Train net output #1: loss = 1.38949 (* 1 = 1.38949 loss)
I0911 22:53:55.983286  1862 sgd_solver.cpp:122] Iteration 318600, lr = 0.000218749
I0911 22:59:43.570341  1862 solver.cpp:242] Iteration 318800 (0.575374 iter/s, 347.6s/200 iters), loss = 1.26861
I0911 22:59:43.570545  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.898438
I0911 22:59:43.570582  1862 solver.cpp:261]     Train net output #1: loss = 1.26861 (* 1 = 1.26861 loss)
I0911 22:59:43.570618  1862 sgd_solver.cpp:122] Iteration 318800, lr = 0.000187501
I0911 23:05:35.678800  1862 solver.cpp:377] Iteration 319000, Testing net (#0)
I0911 23:05:35.689993  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 23:17:34.742909  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 23:17:37.729660  1862 solver.cpp:445]     Test net output #0: accuracy = 0.47466
I0911 23:17:37.730016  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.717139
I0911 23:17:37.730134  1862 solver.cpp:445]     Test net output #2: loss = 2.44017 (* 1 = 2.44017 loss)
I0911 23:17:37.730229  1862 solver.cpp:456] ================================
I0911 23:17:37.730324  1862 solver.cpp:457]     Test net best accuracy1 is: 0.47466
I0911 23:17:37.730402  1862 solver.cpp:459]     Test net best accuracy5 is: 0.717139
I0911 23:17:39.571564  1862 solver.cpp:242] Iteration 319000 (0.185879 iter/s, 1075.97s/200 iters), loss = 1.43041
I0911 23:17:39.576838  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.859375
I0911 23:17:39.576967  1862 solver.cpp:261]     Train net output #1: loss = 1.43041 (* 1 = 1.43041 loss)
I0911 23:17:39.577039  1862 sgd_solver.cpp:122] Iteration 319000, lr = 0.000156251
I0911 23:23:18.204108  1862 solver.cpp:242] Iteration 319200 (0.590637 iter/s, 338.617s/200 iters), loss = 1.43371
I0911 23:23:18.204334  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.863281
I0911 23:23:18.204372  1862 solver.cpp:261]     Train net output #1: loss = 1.43371 (* 1 = 1.43371 loss)
I0911 23:23:18.228621  1862 sgd_solver.cpp:122] Iteration 319200, lr = 0.000125
I0911 23:29:08.942325  1862 solver.cpp:242] Iteration 319400 (0.570244 iter/s, 350.727s/200 iters), loss = 1.51978
I0911 23:29:08.942723  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.839844
I0911 23:29:08.942802  1862 solver.cpp:261]     Train net output #1: loss = 1.51978 (* 1 = 1.51978 loss)
I0911 23:29:08.942867  1862 sgd_solver.cpp:122] Iteration 319400, lr = 9.37492e-05
I0911 23:34:53.826324  1862 solver.cpp:242] Iteration 319600 (0.579924 iter/s, 344.873s/200 iters), loss = 1.28004
I0911 23:34:53.826748  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.898438
I0911 23:34:53.826786  1862 solver.cpp:261]     Train net output #1: loss = 1.28004 (* 1 = 1.28004 loss)
I0911 23:34:53.826820  1862 sgd_solver.cpp:122] Iteration 319600, lr = 6.25014e-05
I0911 23:40:49.875852  1862 solver.cpp:242] Iteration 319800 (0.561738 iter/s, 356.038s/200 iters), loss = 1.38882
I0911 23:40:49.876068  1862 solver.cpp:261]     Train net output #0: accuracy_5_TRAIN = 0.875
I0911 23:40:49.876101  1862 solver.cpp:261]     Train net output #1: loss = 1.38882 (* 1 = 1.38882 loss)
I0911 23:40:49.898146  1862 sgd_solver.cpp:122] Iteration 319800, lr = 3.12507e-05
I0911 23:46:50.828441  1862 solver.cpp:507] Snapshotting to binary proto file my/Imagenet/AlexNet-BN/XnorNet_FWN/snapshot/xnor_net_iter_320000.caffemodel
I0911 23:47:00.578012  1862 sgd_solver.cpp:329] Snapshotting solver state to binary proto file my/Imagenet/AlexNet-BN/XnorNet_FWN/snapshot/xnor_net_iter_320000.solverstate
I0911 23:47:02.118134  1862 solver.cpp:332] Quantization completed!
I0911 23:47:03.215831  1862 solver.cpp:357] Iteration 320000, loss = 1.24059
I0911 23:47:03.220393  1862 solver.cpp:377] Iteration 320000, Testing net (#0)
I0911 23:47:03.220638  1862 net.cpp:676] Ignoring source layer accuracy_5_TRAIN
I0911 23:59:04.262115  1877 data_layer.cpp:73] Restarting data prefetching from start.
I0911 23:59:07.371722  1862 solver.cpp:445]     Test net output #0: accuracy = 0.49016
I0911 23:59:07.371784  1862 solver.cpp:445]     Test net output #1: accuracy_5 = 0.7308
I0911 23:59:07.371796  1862 solver.cpp:445]     Test net output #2: loss = 2.34331 (* 1 = 2.34331 loss)
I0911 23:59:07.371801  1862 solver.cpp:456] ================================
I0911 23:59:07.371806  1862 solver.cpp:457]     Test net best accuracy1 is: 0.49016
I0911 23:59:07.371811  1862 solver.cpp:459]     Test net best accuracy5 is: 0.7308
I0911 23:59:07.371815  1862 solver.cpp:362] Optimization Done.
I0911 23:59:18.361416  1862 caffe.cpp:250] Optimization Done.
