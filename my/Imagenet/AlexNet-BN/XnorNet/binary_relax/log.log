I0128 16:57:30.345324 46007 upgrade_proto.cpp:1113] snapshot_prefix was a directory and is replaced to snapshot/solver
I0128 16:57:30.346751 46007 caffe.cpp:204] Using GPUs 6
I0128 16:57:30.476531 46007 caffe.cpp:209] GPU 6: GeForce GTX 1080 Ti
I0128 16:57:32.789152 46007 solver.cpp:45] Initializing solver from parameters: 
test_iter: 1000
test_interval: 1000
display: 200
max_iter: 350000
lr_policy: "modified_lr"
momentum: 0.9
snapshot: 10000
snapshot_prefix: "snapshot/solver"
solver_mode: GPU
device_id: 6
net: "train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
momentum2: 0.999
type: "Adam"
modified_lr {
  stepvalue: 125000
  stepvalue: 160000
  stepvalue: 270000
  stepvalue: 300000
  stepvalue: 350000
  mlr: 0.001
  mlr: 0.0001
  mlr: 1e-05
  mlr: 1e-06
  mlr: 1e-06
  weight_decay: 1e-05
  weight_decay: 1e-05
  weight_decay: 1e-05
  weight_decay: 1e-05
  weight_decay: 1e-05
}
I0128 16:57:32.932648 46007 solver.cpp:105] Creating training net from net file: train_test.prototxt
I0128 16:57:32.961616 46007 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0128 16:57:32.961858 46007 net.cpp:51] Initializing net from parameters: 
name: "AlexNet-BN"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/zhengzhe/Data/imagenet_shrt256/ilsvrc12_train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 96
    bias_term: false
    pad: 2
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "pool1"
  top: "pool1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive1"
  type: "BinActive"
  bottom: "pool1"
  top: "binactive1"
}
layer {
  name: "conv2"
  type: "BinaryConvolution"
  bottom: "binactive1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: false
    binary_relax: true
    update_lamda: 2500
    phase1_iter: 300000
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "pool2"
  top: "pool2"
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "pool2"
  top: "pool2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive2"
  type: "BinActive"
  bottom: "pool2"
  top: "binactive2"
}
layer {
  name: "conv3"
  type: "BinaryConvolution"
  bottom: "binactive2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: false
    binary_relax: true
    update_lamda: 2500
    phase1_iter: 300000
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive3"
  type: "BinActive"
  bottom: "conv3"
  top: "binactive3"
}
layer {
  name: "conv4"
  type: "BinaryConvolution"
  bottom: "binactive3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: false
    binary_relax: true
    update_lamda: 2500
    phase1_iter: 300000
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "scale5"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive4"
  type: "BinActive"
  bottom: "conv4"
  top: "binactive4"
}
layer {
  name: "conv5"
  type: "BinaryConvolution"
  bottom: "binactive4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: false
    binary_relax: true
    update_lamda: 2500
    phase1_iter: 300000
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "bn6"
  type: "BatchNorm"
  bottom: "pool5"
  top: "pool5"
}
layer {
  name: "scale6"
  type: "Scale"
  bottom: "pool5"
  top: "pool5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive5"
  type: "BinActive"
  bottom: "pool5"
  top: "binactive5"
}
layer {
  name: "fc6"
  type: "BinaryInnerProduct"
  bottom: "binactive5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4096
    bias_term: false
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: false
    binary_relax: true
    update_lamda: 2500
    phase1_iter: 300000
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "scale7"
  type: "Scale"
  bottom: "fc6"
  top: "fc6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive6"
  type: "BinActive"
  bottom: "fc6"
  top: "binactive6"
}
layer {
  name: "fc7"
  type: "BinaryInnerProduct"
  bottom: "binactive6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4096
    bias_term: false
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: false
    binary_relax: true
    update_lamda: 2500
    phase1_iter: 300000
  }
}
layer {
  name: "bn8"
  type: "BatchNorm"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "scale8"
  type: "Scale"
  bottom: "fc7"
  top: "fc7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "accuracy_5"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy_5"
  accuracy_param {
    top_k: 5
  }
}
I0128 16:57:32.962568 46007 layer_factory.hpp:78] Creating layer data
I0128 16:57:32.963028 46007 db_lmdb.cpp:35] Opened lmdb /home/zhengzhe/Data/imagenet_shrt256/ilsvrc12_train_lmdb
I0128 16:57:32.976205 46007 net.cpp:84] Creating Layer data
I0128 16:57:32.976246 46007 net.cpp:380] data -> data
I0128 16:57:32.976426 46007 net.cpp:380] data -> label
I0128 16:57:32.983953 46007 data_layer.cpp:45] output data size: 256,3,224,224
I0128 16:57:34.170974 46007 base_data_layer.cpp:72] Initializing prefetch
I0128 16:57:34.171762 46007 base_data_layer.cpp:75] Prefetch initialized.
I0128 16:57:34.171813 46007 net.cpp:122] Setting up data
I0128 16:57:34.171869 46007 net.cpp:129] Top shape: 256 3 224 224 (38535168)
I0128 16:57:34.171885 46007 net.cpp:129] Top shape: 256 (256)
I0128 16:57:34.171890 46007 net.cpp:137] Memory required for data: 154141696
I0128 16:57:34.171953 46007 layer_factory.hpp:78] Creating layer label_data_1_split
I0128 16:57:34.172022 46007 net.cpp:84] Creating Layer label_data_1_split
I0128 16:57:34.172053 46007 net.cpp:406] label_data_1_split <- label
I0128 16:57:34.172118 46007 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0128 16:57:34.172168 46007 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0128 16:57:34.172188 46007 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0128 16:57:34.172297 46007 net.cpp:122] Setting up label_data_1_split
I0128 16:57:34.172314 46007 net.cpp:129] Top shape: 256 (256)
I0128 16:57:34.172329 46007 net.cpp:129] Top shape: 256 (256)
I0128 16:57:34.172354 46007 net.cpp:129] Top shape: 256 (256)
I0128 16:57:34.172360 46007 net.cpp:137] Memory required for data: 154144768
I0128 16:57:34.172367 46007 layer_factory.hpp:78] Creating layer conv1
I0128 16:57:34.179158 46007 net.cpp:84] Creating Layer conv1
I0128 16:57:34.179180 46007 net.cpp:406] conv1 <- data
I0128 16:57:34.179215 46007 net.cpp:380] conv1 -> conv1
I0128 16:57:41.073526 46007 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 127416
I0128 16:57:41.074038 46007 net.cpp:122] Setting up conv1
I0128 16:57:41.074086 46007 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0128 16:57:41.074095 46007 net.cpp:137] Memory required for data: 451514368
I0128 16:57:41.074232 46007 layer_factory.hpp:78] Creating layer bn1
I0128 16:57:41.074299 46007 net.cpp:84] Creating Layer bn1
I0128 16:57:41.074322 46007 net.cpp:406] bn1 <- conv1
I0128 16:57:41.074385 46007 net.cpp:367] bn1 -> conv1 (in-place)
I0128 16:57:41.078542 46007 net.cpp:122] Setting up bn1
I0128 16:57:41.078596 46007 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0128 16:57:41.078604 46007 net.cpp:137] Memory required for data: 748883968
I0128 16:57:41.078727 46007 layer_factory.hpp:78] Creating layer scale1
I0128 16:57:41.078810 46007 net.cpp:84] Creating Layer scale1
I0128 16:57:41.078843 46007 net.cpp:406] scale1 <- conv1
I0128 16:57:41.078884 46007 net.cpp:367] scale1 -> conv1 (in-place)
I0128 16:57:41.079083 46007 layer_factory.hpp:78] Creating layer scale1
I0128 16:57:41.079591 46007 net.cpp:122] Setting up scale1
I0128 16:57:41.079618 46007 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0128 16:57:41.079627 46007 net.cpp:137] Memory required for data: 1046253568
I0128 16:57:41.079677 46007 layer_factory.hpp:78] Creating layer relu1
I0128 16:57:41.079730 46007 net.cpp:84] Creating Layer relu1
I0128 16:57:41.079747 46007 net.cpp:406] relu1 <- conv1
I0128 16:57:41.079783 46007 net.cpp:367] relu1 -> conv1 (in-place)
I0128 16:57:41.081157 46007 net.cpp:122] Setting up relu1
I0128 16:57:41.081185 46007 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0128 16:57:41.081193 46007 net.cpp:137] Memory required for data: 1343623168
I0128 16:57:41.081209 46007 layer_factory.hpp:78] Creating layer pool1
I0128 16:57:41.081274 46007 net.cpp:84] Creating Layer pool1
I0128 16:57:41.081290 46007 net.cpp:406] pool1 <- conv1
I0128 16:57:41.081329 46007 net.cpp:380] pool1 -> pool1
I0128 16:57:41.081527 46007 net.cpp:122] Setting up pool1
I0128 16:57:41.081557 46007 net.cpp:129] Top shape: 256 96 27 27 (17915904)
I0128 16:57:41.081567 46007 net.cpp:137] Memory required for data: 1415286784
I0128 16:57:41.081581 46007 layer_factory.hpp:78] Creating layer bn2
I0128 16:57:41.081612 46007 net.cpp:84] Creating Layer bn2
I0128 16:57:41.081626 46007 net.cpp:406] bn2 <- pool1
I0128 16:57:41.081656 46007 net.cpp:367] bn2 -> pool1 (in-place)
I0128 16:57:41.084337 46007 net.cpp:122] Setting up bn2
I0128 16:57:41.084379 46007 net.cpp:129] Top shape: 256 96 27 27 (17915904)
I0128 16:57:41.084389 46007 net.cpp:137] Memory required for data: 1486950400
I0128 16:57:41.084466 46007 layer_factory.hpp:78] Creating layer scale2
I0128 16:57:41.084519 46007 net.cpp:84] Creating Layer scale2
I0128 16:57:41.084538 46007 net.cpp:406] scale2 <- pool1
I0128 16:57:41.084573 46007 net.cpp:367] scale2 -> pool1 (in-place)
I0128 16:57:41.084715 46007 layer_factory.hpp:78] Creating layer scale2
I0128 16:57:41.085135 46007 net.cpp:122] Setting up scale2
I0128 16:57:41.085162 46007 net.cpp:129] Top shape: 256 96 27 27 (17915904)
I0128 16:57:41.085170 46007 net.cpp:137] Memory required for data: 1558614016
I0128 16:57:41.085203 46007 layer_factory.hpp:78] Creating layer binactive1
I0128 16:57:41.085240 46007 net.cpp:84] Creating Layer binactive1
I0128 16:57:41.085256 46007 net.cpp:406] binactive1 <- pool1
I0128 16:57:41.085289 46007 net.cpp:380] binactive1 -> binactive1
I0128 16:57:41.085399 46007 net.cpp:122] Setting up binactive1
I0128 16:57:41.085425 46007 net.cpp:129] Top shape: 256 96 27 27 (17915904)
I0128 16:57:41.085435 46007 net.cpp:137] Memory required for data: 1630277632
I0128 16:57:41.085448 46007 layer_factory.hpp:78] Creating layer conv2
I0128 16:57:41.085520 46007 net.cpp:84] Creating Layer conv2
I0128 16:57:41.085539 46007 net.cpp:406] conv2 <- binactive1
I0128 16:57:41.085585 46007 net.cpp:380] conv2 -> conv2
I0128 16:57:41.187023 46007 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 19668
I0128 16:57:41.187083 46007 net.cpp:122] Setting up conv2
I0128 16:57:41.187110 46007 net.cpp:129] Top shape: 256 256 27 27 (47775744)
I0128 16:57:41.187115 46007 net.cpp:137] Memory required for data: 1821380608
I0128 16:57:41.187155 46007 layer_factory.hpp:78] Creating layer pool2
I0128 16:57:41.187213 46007 net.cpp:84] Creating Layer pool2
I0128 16:57:41.187234 46007 net.cpp:406] pool2 <- conv2
I0128 16:57:41.187271 46007 net.cpp:380] pool2 -> pool2
I0128 16:57:41.187379 46007 net.cpp:122] Setting up pool2
I0128 16:57:41.187397 46007 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0128 16:57:41.187403 46007 net.cpp:137] Memory required for data: 1865682944
I0128 16:57:41.187412 46007 layer_factory.hpp:78] Creating layer bn3
I0128 16:57:41.187431 46007 net.cpp:84] Creating Layer bn3
I0128 16:57:41.187439 46007 net.cpp:406] bn3 <- pool2
I0128 16:57:41.187460 46007 net.cpp:367] bn3 -> pool2 (in-place)
I0128 16:57:41.187765 46007 net.cpp:122] Setting up bn3
I0128 16:57:41.187779 46007 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0128 16:57:41.187783 46007 net.cpp:137] Memory required for data: 1909985280
I0128 16:57:41.187811 46007 layer_factory.hpp:78] Creating layer scale3
I0128 16:57:41.187841 46007 net.cpp:84] Creating Layer scale3
I0128 16:57:41.187850 46007 net.cpp:406] scale3 <- pool2
I0128 16:57:41.187868 46007 net.cpp:367] scale3 -> pool2 (in-place)
I0128 16:57:41.187953 46007 layer_factory.hpp:78] Creating layer scale3
I0128 16:57:41.188163 46007 net.cpp:122] Setting up scale3
I0128 16:57:41.188184 46007 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0128 16:57:41.188189 46007 net.cpp:137] Memory required for data: 1954287616
I0128 16:57:41.188223 46007 layer_factory.hpp:78] Creating layer binactive2
I0128 16:57:41.188246 46007 net.cpp:84] Creating Layer binactive2
I0128 16:57:41.188256 46007 net.cpp:406] binactive2 <- pool2
I0128 16:57:41.188274 46007 net.cpp:380] binactive2 -> binactive2
I0128 16:57:41.188321 46007 net.cpp:122] Setting up binactive2
I0128 16:57:41.188336 46007 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0128 16:57:41.188352 46007 net.cpp:137] Memory required for data: 1998589952
I0128 16:57:41.188359 46007 layer_factory.hpp:78] Creating layer conv3
I0128 16:57:41.188403 46007 net.cpp:84] Creating Layer conv3
I0128 16:57:41.188413 46007 net.cpp:406] conv3 <- binactive2
I0128 16:57:41.188436 46007 net.cpp:380] conv3 -> conv3
I0128 16:57:41.291766 46007 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 18874368
I0128 16:57:41.293021 46007 net.cpp:122] Setting up conv3
I0128 16:57:41.293083 46007 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0128 16:57:41.293093 46007 net.cpp:137] Memory required for data: 2065043456
I0128 16:57:41.293141 46007 layer_factory.hpp:78] Creating layer bn4
I0128 16:57:41.293207 46007 net.cpp:84] Creating Layer bn4
I0128 16:57:41.293231 46007 net.cpp:406] bn4 <- conv3
I0128 16:57:41.293275 46007 net.cpp:367] bn4 -> conv3 (in-place)
I0128 16:57:41.293844 46007 net.cpp:122] Setting up bn4
I0128 16:57:41.293901 46007 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0128 16:57:41.293910 46007 net.cpp:137] Memory required for data: 2131496960
I0128 16:57:41.293980 46007 layer_factory.hpp:78] Creating layer scale4
I0128 16:57:41.294034 46007 net.cpp:84] Creating Layer scale4
I0128 16:57:41.294050 46007 net.cpp:406] scale4 <- conv3
I0128 16:57:41.294095 46007 net.cpp:367] scale4 -> conv3 (in-place)
I0128 16:57:41.294234 46007 layer_factory.hpp:78] Creating layer scale4
I0128 16:57:41.294612 46007 net.cpp:122] Setting up scale4
I0128 16:57:41.294639 46007 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0128 16:57:41.294647 46007 net.cpp:137] Memory required for data: 2197950464
I0128 16:57:41.294678 46007 layer_factory.hpp:78] Creating layer binactive3
I0128 16:57:41.294708 46007 net.cpp:84] Creating Layer binactive3
I0128 16:57:41.294724 46007 net.cpp:406] binactive3 <- conv3
I0128 16:57:41.294755 46007 net.cpp:380] binactive3 -> binactive3
I0128 16:57:41.294833 46007 net.cpp:122] Setting up binactive3
I0128 16:57:41.294862 46007 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0128 16:57:41.294870 46007 net.cpp:137] Memory required for data: 2264403968
I0128 16:57:41.294883 46007 layer_factory.hpp:78] Creating layer conv4
I0128 16:57:41.294948 46007 net.cpp:84] Creating Layer conv4
I0128 16:57:41.294966 46007 net.cpp:406] conv4 <- binactive3
I0128 16:57:41.295011 46007 net.cpp:380] conv4 -> conv4
I0128 16:57:41.475028 46007 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 9840
I0128 16:57:41.475113 46007 net.cpp:122] Setting up conv4
I0128 16:57:41.475143 46007 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0128 16:57:41.475149 46007 net.cpp:137] Memory required for data: 2330857472
I0128 16:57:41.475199 46007 layer_factory.hpp:78] Creating layer bn5
I0128 16:57:41.475247 46007 net.cpp:84] Creating Layer bn5
I0128 16:57:41.475267 46007 net.cpp:406] bn5 <- conv4
I0128 16:57:41.475317 46007 net.cpp:367] bn5 -> conv4 (in-place)
I0128 16:57:41.475728 46007 net.cpp:122] Setting up bn5
I0128 16:57:41.475754 46007 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0128 16:57:41.475760 46007 net.cpp:137] Memory required for data: 2397310976
I0128 16:57:41.475797 46007 layer_factory.hpp:78] Creating layer scale5
I0128 16:57:41.475833 46007 net.cpp:84] Creating Layer scale5
I0128 16:57:41.475845 46007 net.cpp:406] scale5 <- conv4
I0128 16:57:41.475868 46007 net.cpp:367] scale5 -> conv4 (in-place)
I0128 16:57:41.475975 46007 layer_factory.hpp:78] Creating layer scale5
I0128 16:57:41.476243 46007 net.cpp:122] Setting up scale5
I0128 16:57:41.476266 46007 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0128 16:57:41.476274 46007 net.cpp:137] Memory required for data: 2463764480
I0128 16:57:41.476297 46007 layer_factory.hpp:78] Creating layer binactive4
I0128 16:57:41.476318 46007 net.cpp:84] Creating Layer binactive4
I0128 16:57:41.476330 46007 net.cpp:406] binactive4 <- conv4
I0128 16:57:41.476361 46007 net.cpp:380] binactive4 -> binactive4
I0128 16:57:41.476424 46007 net.cpp:122] Setting up binactive4
I0128 16:57:41.476442 46007 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0128 16:57:41.476449 46007 net.cpp:137] Memory required for data: 2530217984
I0128 16:57:41.476459 46007 layer_factory.hpp:78] Creating layer conv5
I0128 16:57:41.476508 46007 net.cpp:84] Creating Layer conv5
I0128 16:57:41.476521 46007 net.cpp:406] conv5 <- binactive4
I0128 16:57:41.476550 46007 net.cpp:380] conv5 -> conv5
I0128 16:57:41.582090 46007 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 18874368
I0128 16:57:41.582471 46007 net.cpp:122] Setting up conv5
I0128 16:57:41.582499 46007 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0128 16:57:41.582504 46007 net.cpp:137] Memory required for data: 2574520320
I0128 16:57:41.582535 46007 layer_factory.hpp:78] Creating layer pool5
I0128 16:57:41.582584 46007 net.cpp:84] Creating Layer pool5
I0128 16:57:41.582602 46007 net.cpp:406] pool5 <- conv5
I0128 16:57:41.582633 46007 net.cpp:380] pool5 -> pool5
I0128 16:57:41.582726 46007 net.cpp:122] Setting up pool5
I0128 16:57:41.582763 46007 net.cpp:129] Top shape: 256 256 6 6 (2359296)
I0128 16:57:41.582768 46007 net.cpp:137] Memory required for data: 2583957504
I0128 16:57:41.582777 46007 layer_factory.hpp:78] Creating layer bn6
I0128 16:57:41.582792 46007 net.cpp:84] Creating Layer bn6
I0128 16:57:41.582801 46007 net.cpp:406] bn6 <- pool5
I0128 16:57:41.582816 46007 net.cpp:367] bn6 -> pool5 (in-place)
I0128 16:57:41.583075 46007 net.cpp:122] Setting up bn6
I0128 16:57:41.583086 46007 net.cpp:129] Top shape: 256 256 6 6 (2359296)
I0128 16:57:41.583089 46007 net.cpp:137] Memory required for data: 2593394688
I0128 16:57:41.583127 46007 layer_factory.hpp:78] Creating layer scale6
I0128 16:57:41.583153 46007 net.cpp:84] Creating Layer scale6
I0128 16:57:41.583161 46007 net.cpp:406] scale6 <- pool5
I0128 16:57:41.583176 46007 net.cpp:367] scale6 -> pool5 (in-place)
I0128 16:57:41.583248 46007 layer_factory.hpp:78] Creating layer scale6
I0128 16:57:41.583431 46007 net.cpp:122] Setting up scale6
I0128 16:57:41.583444 46007 net.cpp:129] Top shape: 256 256 6 6 (2359296)
I0128 16:57:41.583448 46007 net.cpp:137] Memory required for data: 2602831872
I0128 16:57:41.583463 46007 layer_factory.hpp:78] Creating layer binactive5
I0128 16:57:41.583478 46007 net.cpp:84] Creating Layer binactive5
I0128 16:57:41.583487 46007 net.cpp:406] binactive5 <- pool5
I0128 16:57:41.583505 46007 net.cpp:380] binactive5 -> binactive5
I0128 16:57:41.583545 46007 net.cpp:122] Setting up binactive5
I0128 16:57:41.583555 46007 net.cpp:129] Top shape: 256 256 6 6 (2359296)
I0128 16:57:41.583562 46007 net.cpp:137] Memory required for data: 2612269056
I0128 16:57:41.583567 46007 layer_factory.hpp:78] Creating layer fc6
I0128 16:57:41.583603 46007 net.cpp:84] Creating Layer fc6
I0128 16:57:41.583612 46007 net.cpp:406] fc6 <- binactive5
I0128 16:57:41.583634 46007 net.cpp:380] fc6 -> fc6
I0128 16:57:45.505950 46007 net.cpp:122] Setting up fc6
I0128 16:57:45.506032 46007 net.cpp:129] Top shape: 256 4096 (1048576)
I0128 16:57:45.506038 46007 net.cpp:137] Memory required for data: 2616463360
I0128 16:57:45.506079 46007 layer_factory.hpp:78] Creating layer bn7
I0128 16:57:45.506124 46007 net.cpp:84] Creating Layer bn7
I0128 16:57:45.506145 46007 net.cpp:406] bn7 <- fc6
I0128 16:57:45.506188 46007 net.cpp:367] bn7 -> fc6 (in-place)
I0128 16:57:45.506484 46007 net.cpp:122] Setting up bn7
I0128 16:57:45.506500 46007 net.cpp:129] Top shape: 256 4096 (1048576)
I0128 16:57:45.506502 46007 net.cpp:137] Memory required for data: 2620657664
I0128 16:57:45.506525 46007 layer_factory.hpp:78] Creating layer scale7
I0128 16:57:45.506551 46007 net.cpp:84] Creating Layer scale7
I0128 16:57:45.506559 46007 net.cpp:406] scale7 <- fc6
I0128 16:57:45.506574 46007 net.cpp:367] scale7 -> fc6 (in-place)
I0128 16:57:45.506670 46007 layer_factory.hpp:78] Creating layer scale7
I0128 16:57:45.506860 46007 net.cpp:122] Setting up scale7
I0128 16:57:45.506875 46007 net.cpp:129] Top shape: 256 4096 (1048576)
I0128 16:57:45.506878 46007 net.cpp:137] Memory required for data: 2624851968
I0128 16:57:45.506894 46007 layer_factory.hpp:78] Creating layer binactive6
I0128 16:57:45.506912 46007 net.cpp:84] Creating Layer binactive6
I0128 16:57:45.506919 46007 net.cpp:406] binactive6 <- fc6
I0128 16:57:45.506937 46007 net.cpp:380] binactive6 -> binactive6
I0128 16:57:45.506980 46007 net.cpp:122] Setting up binactive6
I0128 16:57:45.506992 46007 net.cpp:129] Top shape: 256 4096 (1048576)
I0128 16:57:45.506996 46007 net.cpp:137] Memory required for data: 2629046272
I0128 16:57:45.507002 46007 layer_factory.hpp:78] Creating layer fc7
I0128 16:57:45.507040 46007 net.cpp:84] Creating Layer fc7
I0128 16:57:45.507050 46007 net.cpp:406] fc7 <- binactive6
I0128 16:57:45.507069 46007 net.cpp:380] fc7 -> fc7
I0128 16:57:47.353384 46007 net.cpp:122] Setting up fc7
I0128 16:57:47.353451 46007 net.cpp:129] Top shape: 256 4096 (1048576)
I0128 16:57:47.353456 46007 net.cpp:137] Memory required for data: 2633240576
I0128 16:57:47.353492 46007 layer_factory.hpp:78] Creating layer bn8
I0128 16:57:47.353536 46007 net.cpp:84] Creating Layer bn8
I0128 16:57:47.353579 46007 net.cpp:406] bn8 <- fc7
I0128 16:57:47.353610 46007 net.cpp:367] bn8 -> fc7 (in-place)
I0128 16:57:47.353935 46007 net.cpp:122] Setting up bn8
I0128 16:57:47.353963 46007 net.cpp:129] Top shape: 256 4096 (1048576)
I0128 16:57:47.353982 46007 net.cpp:137] Memory required for data: 2637434880
I0128 16:57:47.354008 46007 layer_factory.hpp:78] Creating layer scale8
I0128 16:57:47.354038 46007 net.cpp:84] Creating Layer scale8
I0128 16:57:47.354044 46007 net.cpp:406] scale8 <- fc7
I0128 16:57:47.354059 46007 net.cpp:367] scale8 -> fc7 (in-place)
I0128 16:57:47.354141 46007 layer_factory.hpp:78] Creating layer scale8
I0128 16:57:47.354393 46007 net.cpp:122] Setting up scale8
I0128 16:57:47.354408 46007 net.cpp:129] Top shape: 256 4096 (1048576)
I0128 16:57:47.354411 46007 net.cpp:137] Memory required for data: 2641629184
I0128 16:57:47.354426 46007 layer_factory.hpp:78] Creating layer relu7
I0128 16:57:47.354449 46007 net.cpp:84] Creating Layer relu7
I0128 16:57:47.354456 46007 net.cpp:406] relu7 <- fc7
I0128 16:57:47.354471 46007 net.cpp:367] relu7 -> fc7 (in-place)
I0128 16:57:47.355497 46007 net.cpp:122] Setting up relu7
I0128 16:57:47.355512 46007 net.cpp:129] Top shape: 256 4096 (1048576)
I0128 16:57:47.355531 46007 net.cpp:137] Memory required for data: 2645823488
I0128 16:57:47.355538 46007 layer_factory.hpp:78] Creating layer fc8
I0128 16:57:47.355577 46007 net.cpp:84] Creating Layer fc8
I0128 16:57:47.355587 46007 net.cpp:406] fc8 <- fc7
I0128 16:57:47.355610 46007 net.cpp:380] fc8 -> fc8
I0128 16:57:47.833254 46007 net.cpp:122] Setting up fc8
I0128 16:57:47.833324 46007 net.cpp:129] Top shape: 256 1000 (256000)
I0128 16:57:47.833330 46007 net.cpp:137] Memory required for data: 2646847488
I0128 16:57:47.833380 46007 layer_factory.hpp:78] Creating layer fc8_fc8_0_split
I0128 16:57:47.833431 46007 net.cpp:84] Creating Layer fc8_fc8_0_split
I0128 16:57:47.833451 46007 net.cpp:406] fc8_fc8_0_split <- fc8
I0128 16:57:47.833487 46007 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0128 16:57:47.833521 46007 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0128 16:57:47.833539 46007 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0128 16:57:47.833631 46007 net.cpp:122] Setting up fc8_fc8_0_split
I0128 16:57:47.833645 46007 net.cpp:129] Top shape: 256 1000 (256000)
I0128 16:57:47.833652 46007 net.cpp:129] Top shape: 256 1000 (256000)
I0128 16:57:47.833658 46007 net.cpp:129] Top shape: 256 1000 (256000)
I0128 16:57:47.833662 46007 net.cpp:137] Memory required for data: 2649919488
I0128 16:57:47.833670 46007 layer_factory.hpp:78] Creating layer loss
I0128 16:57:47.833701 46007 net.cpp:84] Creating Layer loss
I0128 16:57:47.833710 46007 net.cpp:406] loss <- fc8_fc8_0_split_0
I0128 16:57:47.833724 46007 net.cpp:406] loss <- label_data_1_split_0
I0128 16:57:47.833740 46007 net.cpp:380] loss -> loss
I0128 16:57:47.833773 46007 layer_factory.hpp:78] Creating layer loss
I0128 16:57:47.837648 46007 net.cpp:122] Setting up loss
I0128 16:57:47.837669 46007 net.cpp:129] Top shape: (1)
I0128 16:57:47.837687 46007 net.cpp:132]     with loss weight 1
I0128 16:57:47.837760 46007 net.cpp:137] Memory required for data: 2649919492
I0128 16:57:47.837769 46007 layer_factory.hpp:78] Creating layer accuracy
I0128 16:57:47.837812 46007 net.cpp:84] Creating Layer accuracy
I0128 16:57:47.837822 46007 net.cpp:406] accuracy <- fc8_fc8_0_split_1
I0128 16:57:47.837841 46007 net.cpp:406] accuracy <- label_data_1_split_1
I0128 16:57:47.837858 46007 net.cpp:380] accuracy -> accuracy
I0128 16:57:47.837891 46007 net.cpp:122] Setting up accuracy
I0128 16:57:47.837904 46007 net.cpp:129] Top shape: (1)
I0128 16:57:47.837910 46007 net.cpp:137] Memory required for data: 2649919496
I0128 16:57:47.837916 46007 layer_factory.hpp:78] Creating layer accuracy_5
I0128 16:57:47.837934 46007 net.cpp:84] Creating Layer accuracy_5
I0128 16:57:47.837941 46007 net.cpp:406] accuracy_5 <- fc8_fc8_0_split_2
I0128 16:57:47.837954 46007 net.cpp:406] accuracy_5 <- label_data_1_split_2
I0128 16:57:47.837968 46007 net.cpp:380] accuracy_5 -> accuracy_5
I0128 16:57:47.838021 46007 net.cpp:122] Setting up accuracy_5
I0128 16:57:47.838034 46007 net.cpp:129] Top shape: (1)
I0128 16:57:47.838039 46007 net.cpp:137] Memory required for data: 2649919500
I0128 16:57:47.838048 46007 net.cpp:200] accuracy_5 does not need backward computation.
I0128 16:57:47.838057 46007 net.cpp:200] accuracy does not need backward computation.
I0128 16:57:47.838063 46007 net.cpp:198] loss needs backward computation.
I0128 16:57:47.838070 46007 net.cpp:198] fc8_fc8_0_split needs backward computation.
I0128 16:57:47.838076 46007 net.cpp:198] fc8 needs backward computation.
I0128 16:57:47.838083 46007 net.cpp:198] relu7 needs backward computation.
I0128 16:57:47.838089 46007 net.cpp:198] scale8 needs backward computation.
I0128 16:57:47.838094 46007 net.cpp:198] bn8 needs backward computation.
I0128 16:57:47.838101 46007 net.cpp:198] fc7 needs backward computation.
I0128 16:57:47.838107 46007 net.cpp:198] binactive6 needs backward computation.
I0128 16:57:47.838112 46007 net.cpp:198] scale7 needs backward computation.
I0128 16:57:47.838121 46007 net.cpp:198] bn7 needs backward computation.
I0128 16:57:47.838126 46007 net.cpp:198] fc6 needs backward computation.
I0128 16:57:47.838133 46007 net.cpp:198] binactive5 needs backward computation.
I0128 16:57:47.838140 46007 net.cpp:198] scale6 needs backward computation.
I0128 16:57:47.838146 46007 net.cpp:198] bn6 needs backward computation.
I0128 16:57:47.838150 46007 net.cpp:198] pool5 needs backward computation.
I0128 16:57:47.838157 46007 net.cpp:198] conv5 needs backward computation.
I0128 16:57:47.838171 46007 net.cpp:198] binactive4 needs backward computation.
I0128 16:57:47.838178 46007 net.cpp:198] scale5 needs backward computation.
I0128 16:57:47.838184 46007 net.cpp:198] bn5 needs backward computation.
I0128 16:57:47.838191 46007 net.cpp:198] conv4 needs backward computation.
I0128 16:57:47.838198 46007 net.cpp:198] binactive3 needs backward computation.
I0128 16:57:47.838207 46007 net.cpp:198] scale4 needs backward computation.
I0128 16:57:47.838215 46007 net.cpp:198] bn4 needs backward computation.
I0128 16:57:47.838222 46007 net.cpp:198] conv3 needs backward computation.
I0128 16:57:47.838227 46007 net.cpp:198] binactive2 needs backward computation.
I0128 16:57:47.838234 46007 net.cpp:198] scale3 needs backward computation.
I0128 16:57:47.838243 46007 net.cpp:198] bn3 needs backward computation.
I0128 16:57:47.838248 46007 net.cpp:198] pool2 needs backward computation.
I0128 16:57:47.838258 46007 net.cpp:198] conv2 needs backward computation.
I0128 16:57:47.838264 46007 net.cpp:198] binactive1 needs backward computation.
I0128 16:57:47.838279 46007 net.cpp:198] scale2 needs backward computation.
I0128 16:57:47.838285 46007 net.cpp:198] bn2 needs backward computation.
I0128 16:57:47.838291 46007 net.cpp:198] pool1 needs backward computation.
I0128 16:57:47.838299 46007 net.cpp:198] relu1 needs backward computation.
I0128 16:57:47.838304 46007 net.cpp:198] scale1 needs backward computation.
I0128 16:57:47.838310 46007 net.cpp:198] bn1 needs backward computation.
I0128 16:57:47.838315 46007 net.cpp:198] conv1 needs backward computation.
I0128 16:57:47.838325 46007 net.cpp:200] label_data_1_split does not need backward computation.
I0128 16:57:47.838333 46007 net.cpp:200] data does not need backward computation.
I0128 16:57:47.838352 46007 net.cpp:242] This network produces output accuracy
I0128 16:57:47.838363 46007 net.cpp:242] This network produces output accuracy_5
I0128 16:57:47.838371 46007 net.cpp:242] This network produces output loss
I0128 16:57:47.838443 46007 net.cpp:255] Network initialization done.
I0128 16:57:47.839476 46007 solver.cpp:193] Creating test net (#0) specified by net file: train_test.prototxt
I0128 16:57:47.839623 46007 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0128 16:57:47.839884 46007 net.cpp:51] Initializing net from parameters: 
name: "AlexNet-BN"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 224
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/zhengzhe/Data/imagenet_shrt256/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 96
    bias_term: false
    pad: 2
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "pool1"
  top: "pool1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive1"
  type: "BinActive"
  bottom: "pool1"
  top: "binactive1"
}
layer {
  name: "conv2"
  type: "BinaryConvolution"
  bottom: "binactive1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: false
    binary_relax: true
    update_lamda: 2500
    phase1_iter: 300000
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "pool2"
  top: "pool2"
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "pool2"
  top: "pool2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive2"
  type: "BinActive"
  bottom: "pool2"
  top: "binactive2"
}
layer {
  name: "conv3"
  type: "BinaryConvolution"
  bottom: "binactive2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: false
    binary_relax: true
    update_lamda: 2500
    phase1_iter: 300000
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive3"
  type: "BinActive"
  bottom: "conv3"
  top: "binactive3"
}
layer {
  name: "conv4"
  type: "BinaryConvolution"
  bottom: "binactive3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: false
    binary_relax: true
    update_lamda: 2500
    phase1_iter: 300000
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "scale5"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive4"
  type: "BinActive"
  bottom: "conv4"
  top: "binactive4"
}
layer {
  name: "conv5"
  type: "BinaryConvolution"
  bottom: "binactive4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: false
    binary_relax: true
    update_lamda: 2500
    phase1_iter: 300000
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "bn6"
  type: "BatchNorm"
  bottom: "pool5"
  top: "pool5"
}
layer {
  name: "scale6"
  type: "Scale"
  bottom: "pool5"
  top: "pool5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive5"
  type: "BinActive"
  bottom: "pool5"
  top: "binactive5"
}
layer {
  name: "fc6"
  type: "BinaryInnerProduct"
  bottom: "binactive5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4096
    bias_term: false
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: false
    binary_relax: true
    update_lamda: 2500
    phase1_iter: 300000
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "scale7"
  type: "Scale"
  bottom: "fc6"
  top: "fc6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive6"
  type: "BinActive"
  bottom: "fc6"
  top: "binactive6"
}
layer {
  name: "fc7"
  type: "BinaryInnerProduct"
  bottom: "binactive6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4096
    bias_term: false
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: false
    binary_relax: true
    update_lamda: 2500
    phase1_iter: 300000
  }
}
layer {
  name: "bn8"
  type: "BatchNorm"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "scale8"
  type: "Scale"
  bottom: "fc7"
  top: "fc7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "accuracy_5"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy_5"
  accuracy_param {
    top_k: 5
  }
}
I0128 16:57:47.840337 46007 layer_factory.hpp:78] Creating layer data
I0128 16:57:47.840446 46007 db_lmdb.cpp:35] Opened lmdb /home/zhengzhe/Data/imagenet_shrt256/ilsvrc12_val_lmdb
I0128 16:57:47.840492 46007 net.cpp:84] Creating Layer data
I0128 16:57:47.840512 46007 net.cpp:380] data -> data
I0128 16:57:47.840548 46007 net.cpp:380] data -> label
I0128 16:57:47.841331 46007 data_layer.cpp:45] output data size: 50,3,224,224
I0128 16:57:48.277482 46007 base_data_layer.cpp:72] Initializing prefetch
I0128 16:57:48.277705 46007 base_data_layer.cpp:75] Prefetch initialized.
I0128 16:57:48.277720 46007 net.cpp:122] Setting up data
I0128 16:57:48.277788 46007 net.cpp:129] Top shape: 50 3 224 224 (7526400)
I0128 16:57:48.277801 46007 net.cpp:129] Top shape: 50 (50)
I0128 16:57:48.277807 46007 net.cpp:137] Memory required for data: 30105800
I0128 16:57:48.277840 46007 layer_factory.hpp:78] Creating layer label_data_1_split
I0128 16:57:48.277909 46007 net.cpp:84] Creating Layer label_data_1_split
I0128 16:57:48.277928 46007 net.cpp:406] label_data_1_split <- label
I0128 16:57:48.277971 46007 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0128 16:57:48.278014 46007 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0128 16:57:48.278031 46007 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0128 16:57:48.278417 46007 net.cpp:122] Setting up label_data_1_split
I0128 16:57:48.278435 46007 net.cpp:129] Top shape: 50 (50)
I0128 16:57:48.278442 46007 net.cpp:129] Top shape: 50 (50)
I0128 16:57:48.278448 46007 net.cpp:129] Top shape: 50 (50)
I0128 16:57:48.278452 46007 net.cpp:137] Memory required for data: 30106400
I0128 16:57:48.278460 46007 layer_factory.hpp:78] Creating layer conv1
I0128 16:57:48.278511 46007 net.cpp:84] Creating Layer conv1
I0128 16:57:48.278520 46007 net.cpp:406] conv1 <- data
I0128 16:57:48.278553 46007 net.cpp:380] conv1 -> conv1
I0128 16:57:48.288403 46007 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 127416
I0128 16:57:48.288491 46007 net.cpp:122] Setting up conv1
I0128 16:57:48.288527 46007 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0128 16:57:48.288534 46007 net.cpp:137] Memory required for data: 88186400
I0128 16:57:48.288568 46007 layer_factory.hpp:78] Creating layer bn1
I0128 16:57:48.288597 46007 net.cpp:84] Creating Layer bn1
I0128 16:57:48.288607 46007 net.cpp:406] bn1 <- conv1
I0128 16:57:48.288626 46007 net.cpp:367] bn1 -> conv1 (in-place)
I0128 16:57:48.289046 46007 net.cpp:122] Setting up bn1
I0128 16:57:48.289060 46007 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0128 16:57:48.289065 46007 net.cpp:137] Memory required for data: 146266400
I0128 16:57:48.289104 46007 layer_factory.hpp:78] Creating layer scale1
I0128 16:57:48.289137 46007 net.cpp:84] Creating Layer scale1
I0128 16:57:48.289147 46007 net.cpp:406] scale1 <- conv1
I0128 16:57:48.289165 46007 net.cpp:367] scale1 -> conv1 (in-place)
I0128 16:57:48.289255 46007 layer_factory.hpp:78] Creating layer scale1
I0128 16:57:48.289579 46007 net.cpp:122] Setting up scale1
I0128 16:57:48.289595 46007 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0128 16:57:48.289599 46007 net.cpp:137] Memory required for data: 204346400
I0128 16:57:48.289629 46007 layer_factory.hpp:78] Creating layer relu1
I0128 16:57:48.289650 46007 net.cpp:84] Creating Layer relu1
I0128 16:57:48.289659 46007 net.cpp:406] relu1 <- conv1
I0128 16:57:48.289680 46007 net.cpp:367] relu1 -> conv1 (in-place)
I0128 16:57:48.290412 46007 net.cpp:122] Setting up relu1
I0128 16:57:48.290427 46007 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0128 16:57:48.290433 46007 net.cpp:137] Memory required for data: 262426400
I0128 16:57:48.290441 46007 layer_factory.hpp:78] Creating layer pool1
I0128 16:57:48.290464 46007 net.cpp:84] Creating Layer pool1
I0128 16:57:48.290488 46007 net.cpp:406] pool1 <- conv1
I0128 16:57:48.290513 46007 net.cpp:380] pool1 -> pool1
I0128 16:57:48.290606 46007 net.cpp:122] Setting up pool1
I0128 16:57:48.290621 46007 net.cpp:129] Top shape: 50 96 27 27 (3499200)
I0128 16:57:48.290627 46007 net.cpp:137] Memory required for data: 276423200
I0128 16:57:48.290632 46007 layer_factory.hpp:78] Creating layer bn2
I0128 16:57:48.290654 46007 net.cpp:84] Creating Layer bn2
I0128 16:57:48.290663 46007 net.cpp:406] bn2 <- pool1
I0128 16:57:48.290680 46007 net.cpp:367] bn2 -> pool1 (in-place)
I0128 16:57:48.291062 46007 net.cpp:122] Setting up bn2
I0128 16:57:48.291076 46007 net.cpp:129] Top shape: 50 96 27 27 (3499200)
I0128 16:57:48.291080 46007 net.cpp:137] Memory required for data: 290420000
I0128 16:57:48.291126 46007 layer_factory.hpp:78] Creating layer scale2
I0128 16:57:48.291152 46007 net.cpp:84] Creating Layer scale2
I0128 16:57:48.291162 46007 net.cpp:406] scale2 <- pool1
I0128 16:57:48.291182 46007 net.cpp:367] scale2 -> pool1 (in-place)
I0128 16:57:48.291276 46007 layer_factory.hpp:78] Creating layer scale2
I0128 16:57:48.291541 46007 net.cpp:122] Setting up scale2
I0128 16:57:48.291556 46007 net.cpp:129] Top shape: 50 96 27 27 (3499200)
I0128 16:57:48.291561 46007 net.cpp:137] Memory required for data: 304416800
I0128 16:57:48.291580 46007 layer_factory.hpp:78] Creating layer binactive1
I0128 16:57:48.291601 46007 net.cpp:84] Creating Layer binactive1
I0128 16:57:48.291610 46007 net.cpp:406] binactive1 <- pool1
I0128 16:57:48.291628 46007 net.cpp:380] binactive1 -> binactive1
I0128 16:57:48.291678 46007 net.cpp:122] Setting up binactive1
I0128 16:57:48.291692 46007 net.cpp:129] Top shape: 50 96 27 27 (3499200)
I0128 16:57:48.291697 46007 net.cpp:137] Memory required for data: 318413600
I0128 16:57:48.291703 46007 layer_factory.hpp:78] Creating layer conv2
I0128 16:57:48.291736 46007 net.cpp:84] Creating Layer conv2
I0128 16:57:48.291746 46007 net.cpp:406] conv2 <- binactive1
I0128 16:57:48.291769 46007 net.cpp:380] conv2 -> conv2
I0128 16:57:48.356747 46007 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 19668
I0128 16:57:48.356806 46007 net.cpp:122] Setting up conv2
I0128 16:57:48.356825 46007 net.cpp:129] Top shape: 50 256 27 27 (9331200)
I0128 16:57:48.356829 46007 net.cpp:137] Memory required for data: 355738400
I0128 16:57:48.356875 46007 layer_factory.hpp:78] Creating layer pool2
I0128 16:57:48.356921 46007 net.cpp:84] Creating Layer pool2
I0128 16:57:48.356936 46007 net.cpp:406] pool2 <- conv2
I0128 16:57:48.356966 46007 net.cpp:380] pool2 -> pool2
I0128 16:57:48.357045 46007 net.cpp:122] Setting up pool2
I0128 16:57:48.357061 46007 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0128 16:57:48.357066 46007 net.cpp:137] Memory required for data: 364391200
I0128 16:57:48.357072 46007 layer_factory.hpp:78] Creating layer bn3
I0128 16:57:48.357087 46007 net.cpp:84] Creating Layer bn3
I0128 16:57:48.357095 46007 net.cpp:406] bn3 <- pool2
I0128 16:57:48.357110 46007 net.cpp:367] bn3 -> pool2 (in-place)
I0128 16:57:48.357405 46007 net.cpp:122] Setting up bn3
I0128 16:57:48.357420 46007 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0128 16:57:48.357424 46007 net.cpp:137] Memory required for data: 373044000
I0128 16:57:48.357446 46007 layer_factory.hpp:78] Creating layer scale3
I0128 16:57:48.357467 46007 net.cpp:84] Creating Layer scale3
I0128 16:57:48.357475 46007 net.cpp:406] scale3 <- pool2
I0128 16:57:48.357491 46007 net.cpp:367] scale3 -> pool2 (in-place)
I0128 16:57:48.357575 46007 layer_factory.hpp:78] Creating layer scale3
I0128 16:57:48.357753 46007 net.cpp:122] Setting up scale3
I0128 16:57:48.357769 46007 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0128 16:57:48.357772 46007 net.cpp:137] Memory required for data: 381696800
I0128 16:57:48.357800 46007 layer_factory.hpp:78] Creating layer binactive2
I0128 16:57:48.357816 46007 net.cpp:84] Creating Layer binactive2
I0128 16:57:48.357825 46007 net.cpp:406] binactive2 <- pool2
I0128 16:57:48.357841 46007 net.cpp:380] binactive2 -> binactive2
I0128 16:57:48.357887 46007 net.cpp:122] Setting up binactive2
I0128 16:57:48.357899 46007 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0128 16:57:48.357903 46007 net.cpp:137] Memory required for data: 390349600
I0128 16:57:48.357908 46007 layer_factory.hpp:78] Creating layer conv3
I0128 16:57:48.357940 46007 net.cpp:84] Creating Layer conv3
I0128 16:57:48.357949 46007 net.cpp:406] conv3 <- binactive2
I0128 16:57:48.357973 46007 net.cpp:380] conv3 -> conv3
I0128 16:57:48.443645 46007 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 18874368
I0128 16:57:48.444237 46007 net.cpp:122] Setting up conv3
I0128 16:57:48.444281 46007 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0128 16:57:48.444303 46007 net.cpp:137] Memory required for data: 403328800
I0128 16:57:48.444361 46007 layer_factory.hpp:78] Creating layer bn4
I0128 16:57:48.444449 46007 net.cpp:84] Creating Layer bn4
I0128 16:57:48.444473 46007 net.cpp:406] bn4 <- conv3
I0128 16:57:48.444526 46007 net.cpp:367] bn4 -> conv3 (in-place)
I0128 16:57:48.445143 46007 net.cpp:122] Setting up bn4
I0128 16:57:48.445166 46007 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0128 16:57:48.445174 46007 net.cpp:137] Memory required for data: 416308000
I0128 16:57:48.445225 46007 layer_factory.hpp:78] Creating layer scale4
I0128 16:57:48.445274 46007 net.cpp:84] Creating Layer scale4
I0128 16:57:48.445291 46007 net.cpp:406] scale4 <- conv3
I0128 16:57:48.445340 46007 net.cpp:367] scale4 -> conv3 (in-place)
I0128 16:57:48.445505 46007 layer_factory.hpp:78] Creating layer scale4
I0128 16:57:48.445904 46007 net.cpp:122] Setting up scale4
I0128 16:57:48.445928 46007 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0128 16:57:48.445936 46007 net.cpp:137] Memory required for data: 429287200
I0128 16:57:48.445966 46007 layer_factory.hpp:78] Creating layer binactive3
I0128 16:57:48.446003 46007 net.cpp:84] Creating Layer binactive3
I0128 16:57:48.446020 46007 net.cpp:406] binactive3 <- conv3
I0128 16:57:48.446059 46007 net.cpp:380] binactive3 -> binactive3
I0128 16:57:48.446156 46007 net.cpp:122] Setting up binactive3
I0128 16:57:48.446180 46007 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0128 16:57:48.446189 46007 net.cpp:137] Memory required for data: 442266400
I0128 16:57:48.446202 46007 layer_factory.hpp:78] Creating layer conv4
I0128 16:57:48.446265 46007 net.cpp:84] Creating Layer conv4
I0128 16:57:48.446317 46007 net.cpp:406] conv4 <- binactive3
I0128 16:57:48.446400 46007 net.cpp:380] conv4 -> conv4
I0128 16:57:48.624553 46007 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 9840
I0128 16:57:48.624604 46007 net.cpp:122] Setting up conv4
I0128 16:57:48.624631 46007 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0128 16:57:48.624636 46007 net.cpp:137] Memory required for data: 455245600
I0128 16:57:48.624670 46007 layer_factory.hpp:78] Creating layer bn5
I0128 16:57:48.624708 46007 net.cpp:84] Creating Layer bn5
I0128 16:57:48.624722 46007 net.cpp:406] bn5 <- conv4
I0128 16:57:48.624750 46007 net.cpp:367] bn5 -> conv4 (in-place)
I0128 16:57:48.625090 46007 net.cpp:122] Setting up bn5
I0128 16:57:48.625115 46007 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0128 16:57:48.625120 46007 net.cpp:137] Memory required for data: 468224800
I0128 16:57:48.625146 46007 layer_factory.hpp:78] Creating layer scale5
I0128 16:57:48.625171 46007 net.cpp:84] Creating Layer scale5
I0128 16:57:48.625182 46007 net.cpp:406] scale5 <- conv4
I0128 16:57:48.625200 46007 net.cpp:367] scale5 -> conv4 (in-place)
I0128 16:57:48.625291 46007 layer_factory.hpp:78] Creating layer scale5
I0128 16:57:48.625525 46007 net.cpp:122] Setting up scale5
I0128 16:57:48.625540 46007 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0128 16:57:48.625545 46007 net.cpp:137] Memory required for data: 481204000
I0128 16:57:48.625562 46007 layer_factory.hpp:78] Creating layer binactive4
I0128 16:57:48.625579 46007 net.cpp:84] Creating Layer binactive4
I0128 16:57:48.625587 46007 net.cpp:406] binactive4 <- conv4
I0128 16:57:48.625622 46007 net.cpp:380] binactive4 -> binactive4
I0128 16:57:48.625676 46007 net.cpp:122] Setting up binactive4
I0128 16:57:48.625694 46007 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0128 16:57:48.625699 46007 net.cpp:137] Memory required for data: 494183200
I0128 16:57:48.625705 46007 layer_factory.hpp:78] Creating layer conv5
I0128 16:57:48.625761 46007 net.cpp:84] Creating Layer conv5
I0128 16:57:48.625771 46007 net.cpp:406] conv5 <- binactive4
I0128 16:57:48.625792 46007 net.cpp:380] conv5 -> conv5
I0128 16:57:48.729179 46007 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 18874368
I0128 16:57:48.729585 46007 net.cpp:122] Setting up conv5
I0128 16:57:48.729625 46007 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0128 16:57:48.729631 46007 net.cpp:137] Memory required for data: 502836000
I0128 16:57:48.729673 46007 layer_factory.hpp:78] Creating layer pool5
I0128 16:57:48.729732 46007 net.cpp:84] Creating Layer pool5
I0128 16:57:48.729750 46007 net.cpp:406] pool5 <- conv5
I0128 16:57:48.729792 46007 net.cpp:380] pool5 -> pool5
I0128 16:57:48.729907 46007 net.cpp:122] Setting up pool5
I0128 16:57:48.729926 46007 net.cpp:129] Top shape: 50 256 6 6 (460800)
I0128 16:57:48.729931 46007 net.cpp:137] Memory required for data: 504679200
I0128 16:57:48.729940 46007 layer_factory.hpp:78] Creating layer bn6
I0128 16:57:48.729962 46007 net.cpp:84] Creating Layer bn6
I0128 16:57:48.729971 46007 net.cpp:406] bn6 <- pool5
I0128 16:57:48.729990 46007 net.cpp:367] bn6 -> pool5 (in-place)
I0128 16:57:48.730410 46007 net.cpp:122] Setting up bn6
I0128 16:57:48.730425 46007 net.cpp:129] Top shape: 50 256 6 6 (460800)
I0128 16:57:48.730429 46007 net.cpp:137] Memory required for data: 506522400
I0128 16:57:48.730474 46007 layer_factory.hpp:78] Creating layer scale6
I0128 16:57:48.730501 46007 net.cpp:84] Creating Layer scale6
I0128 16:57:48.730511 46007 net.cpp:406] scale6 <- pool5
I0128 16:57:48.730530 46007 net.cpp:367] scale6 -> pool5 (in-place)
I0128 16:57:48.730630 46007 layer_factory.hpp:78] Creating layer scale6
I0128 16:57:48.730844 46007 net.cpp:122] Setting up scale6
I0128 16:57:48.730859 46007 net.cpp:129] Top shape: 50 256 6 6 (460800)
I0128 16:57:48.730864 46007 net.cpp:137] Memory required for data: 508365600
I0128 16:57:48.730880 46007 layer_factory.hpp:78] Creating layer binactive5
I0128 16:57:48.730898 46007 net.cpp:84] Creating Layer binactive5
I0128 16:57:48.730933 46007 net.cpp:406] binactive5 <- pool5
I0128 16:57:48.730976 46007 net.cpp:380] binactive5 -> binactive5
I0128 16:57:48.731037 46007 net.cpp:122] Setting up binactive5
I0128 16:57:48.731051 46007 net.cpp:129] Top shape: 50 256 6 6 (460800)
I0128 16:57:48.731058 46007 net.cpp:137] Memory required for data: 510208800
I0128 16:57:48.731065 46007 layer_factory.hpp:78] Creating layer fc6
I0128 16:57:48.731094 46007 net.cpp:84] Creating Layer fc6
I0128 16:57:48.731102 46007 net.cpp:406] fc6 <- binactive5
I0128 16:57:48.731125 46007 net.cpp:380] fc6 -> fc6
I0128 16:57:52.568923 46007 net.cpp:122] Setting up fc6
I0128 16:57:52.568990 46007 net.cpp:129] Top shape: 50 4096 (204800)
I0128 16:57:52.568996 46007 net.cpp:137] Memory required for data: 511028000
I0128 16:57:52.569041 46007 layer_factory.hpp:78] Creating layer bn7
I0128 16:57:52.569094 46007 net.cpp:84] Creating Layer bn7
I0128 16:57:52.569113 46007 net.cpp:406] bn7 <- fc6
I0128 16:57:52.569154 46007 net.cpp:367] bn7 -> fc6 (in-place)
I0128 16:57:52.569525 46007 net.cpp:122] Setting up bn7
I0128 16:57:52.569540 46007 net.cpp:129] Top shape: 50 4096 (204800)
I0128 16:57:52.569543 46007 net.cpp:137] Memory required for data: 511847200
I0128 16:57:52.569568 46007 layer_factory.hpp:78] Creating layer scale7
I0128 16:57:52.569597 46007 net.cpp:84] Creating Layer scale7
I0128 16:57:52.569607 46007 net.cpp:406] scale7 <- fc6
I0128 16:57:52.569624 46007 net.cpp:367] scale7 -> fc6 (in-place)
I0128 16:57:52.569763 46007 layer_factory.hpp:78] Creating layer scale7
I0128 16:57:52.570000 46007 net.cpp:122] Setting up scale7
I0128 16:57:52.570016 46007 net.cpp:129] Top shape: 50 4096 (204800)
I0128 16:57:52.570020 46007 net.cpp:137] Memory required for data: 512666400
I0128 16:57:52.570039 46007 layer_factory.hpp:78] Creating layer binactive6
I0128 16:57:52.570058 46007 net.cpp:84] Creating Layer binactive6
I0128 16:57:52.570067 46007 net.cpp:406] binactive6 <- fc6
I0128 16:57:52.570089 46007 net.cpp:380] binactive6 -> binactive6
I0128 16:57:52.570143 46007 net.cpp:122] Setting up binactive6
I0128 16:57:52.570161 46007 net.cpp:129] Top shape: 50 4096 (204800)
I0128 16:57:52.570165 46007 net.cpp:137] Memory required for data: 513485600
I0128 16:57:52.570173 46007 layer_factory.hpp:78] Creating layer fc7
I0128 16:57:52.570210 46007 net.cpp:84] Creating Layer fc7
I0128 16:57:52.570220 46007 net.cpp:406] fc7 <- binactive6
I0128 16:57:52.570241 46007 net.cpp:380] fc7 -> fc7
I0128 16:57:54.345037 46007 net.cpp:122] Setting up fc7
I0128 16:57:54.345103 46007 net.cpp:129] Top shape: 50 4096 (204800)
I0128 16:57:54.345108 46007 net.cpp:137] Memory required for data: 514304800
I0128 16:57:54.345178 46007 layer_factory.hpp:78] Creating layer bn8
I0128 16:57:54.345224 46007 net.cpp:84] Creating Layer bn8
I0128 16:57:54.345242 46007 net.cpp:406] bn8 <- fc7
I0128 16:57:54.345275 46007 net.cpp:367] bn8 -> fc7 (in-place)
I0128 16:57:54.345675 46007 net.cpp:122] Setting up bn8
I0128 16:57:54.345688 46007 net.cpp:129] Top shape: 50 4096 (204800)
I0128 16:57:54.345691 46007 net.cpp:137] Memory required for data: 515124000
I0128 16:57:54.345715 46007 layer_factory.hpp:78] Creating layer scale8
I0128 16:57:54.345739 46007 net.cpp:84] Creating Layer scale8
I0128 16:57:54.345747 46007 net.cpp:406] scale8 <- fc7
I0128 16:57:54.345762 46007 net.cpp:367] scale8 -> fc7 (in-place)
I0128 16:57:54.345942 46007 layer_factory.hpp:78] Creating layer scale8
I0128 16:57:54.346145 46007 net.cpp:122] Setting up scale8
I0128 16:57:54.346158 46007 net.cpp:129] Top shape: 50 4096 (204800)
I0128 16:57:54.346163 46007 net.cpp:137] Memory required for data: 515943200
I0128 16:57:54.346177 46007 layer_factory.hpp:78] Creating layer relu7
I0128 16:57:54.346196 46007 net.cpp:84] Creating Layer relu7
I0128 16:57:54.346204 46007 net.cpp:406] relu7 <- fc7
I0128 16:57:54.346218 46007 net.cpp:367] relu7 -> fc7 (in-place)
I0128 16:57:54.347769 46007 net.cpp:122] Setting up relu7
I0128 16:57:54.347785 46007 net.cpp:129] Top shape: 50 4096 (204800)
I0128 16:57:54.347790 46007 net.cpp:137] Memory required for data: 516762400
I0128 16:57:54.347820 46007 layer_factory.hpp:78] Creating layer fc8
I0128 16:57:54.347848 46007 net.cpp:84] Creating Layer fc8
I0128 16:57:54.347856 46007 net.cpp:406] fc8 <- fc7
I0128 16:57:54.347880 46007 net.cpp:380] fc8 -> fc8
I0128 16:57:54.800134 46007 net.cpp:122] Setting up fc8
I0128 16:57:54.800181 46007 net.cpp:129] Top shape: 50 1000 (50000)
I0128 16:57:54.800186 46007 net.cpp:137] Memory required for data: 516962400
I0128 16:57:54.800218 46007 layer_factory.hpp:78] Creating layer fc8_fc8_0_split
I0128 16:57:54.800261 46007 net.cpp:84] Creating Layer fc8_fc8_0_split
I0128 16:57:54.800277 46007 net.cpp:406] fc8_fc8_0_split <- fc8
I0128 16:57:54.800305 46007 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0128 16:57:54.800333 46007 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0128 16:57:54.800352 46007 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0128 16:57:54.800451 46007 net.cpp:122] Setting up fc8_fc8_0_split
I0128 16:57:54.800464 46007 net.cpp:129] Top shape: 50 1000 (50000)
I0128 16:57:54.800470 46007 net.cpp:129] Top shape: 50 1000 (50000)
I0128 16:57:54.800475 46007 net.cpp:129] Top shape: 50 1000 (50000)
I0128 16:57:54.800478 46007 net.cpp:137] Memory required for data: 517562400
I0128 16:57:54.800485 46007 layer_factory.hpp:78] Creating layer loss
I0128 16:57:54.800503 46007 net.cpp:84] Creating Layer loss
I0128 16:57:54.800510 46007 net.cpp:406] loss <- fc8_fc8_0_split_0
I0128 16:57:54.800523 46007 net.cpp:406] loss <- label_data_1_split_0
I0128 16:57:54.800541 46007 net.cpp:380] loss -> loss
I0128 16:57:54.800563 46007 layer_factory.hpp:78] Creating layer loss
I0128 16:57:54.801730 46007 net.cpp:122] Setting up loss
I0128 16:57:54.801748 46007 net.cpp:129] Top shape: (1)
I0128 16:57:54.801751 46007 net.cpp:132]     with loss weight 1
I0128 16:57:54.801764 46007 net.cpp:137] Memory required for data: 517562404
I0128 16:57:54.801771 46007 layer_factory.hpp:78] Creating layer accuracy
I0128 16:57:54.801789 46007 net.cpp:84] Creating Layer accuracy
I0128 16:57:54.801800 46007 net.cpp:406] accuracy <- fc8_fc8_0_split_1
I0128 16:57:54.801813 46007 net.cpp:406] accuracy <- label_data_1_split_1
I0128 16:57:54.801826 46007 net.cpp:380] accuracy -> accuracy
I0128 16:57:54.801851 46007 net.cpp:122] Setting up accuracy
I0128 16:57:54.801859 46007 net.cpp:129] Top shape: (1)
I0128 16:57:54.801863 46007 net.cpp:137] Memory required for data: 517562408
I0128 16:57:54.801868 46007 layer_factory.hpp:78] Creating layer accuracy_5
I0128 16:57:54.801882 46007 net.cpp:84] Creating Layer accuracy_5
I0128 16:57:54.801892 46007 net.cpp:406] accuracy_5 <- fc8_fc8_0_split_2
I0128 16:57:54.801903 46007 net.cpp:406] accuracy_5 <- label_data_1_split_2
I0128 16:57:54.801916 46007 net.cpp:380] accuracy_5 -> accuracy_5
I0128 16:57:54.801936 46007 net.cpp:122] Setting up accuracy_5
I0128 16:57:54.801947 46007 net.cpp:129] Top shape: (1)
I0128 16:57:54.801950 46007 net.cpp:137] Memory required for data: 517562412
I0128 16:57:54.801957 46007 net.cpp:200] accuracy_5 does not need backward computation.
I0128 16:57:54.801964 46007 net.cpp:200] accuracy does not need backward computation.
I0128 16:57:54.801968 46007 net.cpp:198] loss needs backward computation.
I0128 16:57:54.801973 46007 net.cpp:198] fc8_fc8_0_split needs backward computation.
I0128 16:57:54.801977 46007 net.cpp:198] fc8 needs backward computation.
I0128 16:57:54.801981 46007 net.cpp:198] relu7 needs backward computation.
I0128 16:57:54.801985 46007 net.cpp:198] scale8 needs backward computation.
I0128 16:57:54.801990 46007 net.cpp:198] bn8 needs backward computation.
I0128 16:57:54.801995 46007 net.cpp:198] fc7 needs backward computation.
I0128 16:57:54.802000 46007 net.cpp:198] binactive6 needs backward computation.
I0128 16:57:54.802006 46007 net.cpp:198] scale7 needs backward computation.
I0128 16:57:54.802011 46007 net.cpp:198] bn7 needs backward computation.
I0128 16:57:54.802014 46007 net.cpp:198] fc6 needs backward computation.
I0128 16:57:54.802021 46007 net.cpp:198] binactive5 needs backward computation.
I0128 16:57:54.802026 46007 net.cpp:198] scale6 needs backward computation.
I0128 16:57:54.802052 46007 net.cpp:198] bn6 needs backward computation.
I0128 16:57:54.802057 46007 net.cpp:198] pool5 needs backward computation.
I0128 16:57:54.802063 46007 net.cpp:198] conv5 needs backward computation.
I0128 16:57:54.802075 46007 net.cpp:198] binactive4 needs backward computation.
I0128 16:57:54.802088 46007 net.cpp:198] scale5 needs backward computation.
I0128 16:57:54.802094 46007 net.cpp:198] bn5 needs backward computation.
I0128 16:57:54.802100 46007 net.cpp:198] conv4 needs backward computation.
I0128 16:57:54.802107 46007 net.cpp:198] binactive3 needs backward computation.
I0128 16:57:54.802112 46007 net.cpp:198] scale4 needs backward computation.
I0128 16:57:54.802117 46007 net.cpp:198] bn4 needs backward computation.
I0128 16:57:54.802122 46007 net.cpp:198] conv3 needs backward computation.
I0128 16:57:54.802126 46007 net.cpp:198] binactive2 needs backward computation.
I0128 16:57:54.802132 46007 net.cpp:198] scale3 needs backward computation.
I0128 16:57:54.802137 46007 net.cpp:198] bn3 needs backward computation.
I0128 16:57:54.802142 46007 net.cpp:198] pool2 needs backward computation.
I0128 16:57:54.802148 46007 net.cpp:198] conv2 needs backward computation.
I0128 16:57:54.802153 46007 net.cpp:198] binactive1 needs backward computation.
I0128 16:57:54.802157 46007 net.cpp:198] scale2 needs backward computation.
I0128 16:57:54.802161 46007 net.cpp:198] bn2 needs backward computation.
I0128 16:57:54.802166 46007 net.cpp:198] pool1 needs backward computation.
I0128 16:57:54.802172 46007 net.cpp:198] relu1 needs backward computation.
I0128 16:57:54.802177 46007 net.cpp:198] scale1 needs backward computation.
I0128 16:57:54.802183 46007 net.cpp:198] bn1 needs backward computation.
I0128 16:57:54.802192 46007 net.cpp:198] conv1 needs backward computation.
I0128 16:57:54.802207 46007 net.cpp:200] label_data_1_split does not need backward computation.
I0128 16:57:54.802215 46007 net.cpp:200] data does not need backward computation.
I0128 16:57:54.802219 46007 net.cpp:242] This network produces output accuracy
I0128 16:57:54.802227 46007 net.cpp:242] This network produces output accuracy_5
I0128 16:57:54.802232 46007 net.cpp:242] This network produces output loss
I0128 16:57:54.802284 46007 net.cpp:255] Network initialization done.
I0128 16:57:54.802500 46007 solver.cpp:57] Solver scaffolding done.
I0128 16:57:54.805557 46007 caffe.cpp:235] Resuming from snapshot/solver_iter_300000.solverstate
I0128 16:58:09.227195 46007 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: snapshot/solver_iter_300000.caffemodel
I0128 16:58:09.227278 46007 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0128 16:58:09.227303 46007 net.cpp:825] Copying source layer data
I0128 16:58:09.227310 46007 net.cpp:825] Copying source layer label_data_1_split
I0128 16:58:09.227315 46007 net.cpp:825] Copying source layer conv1
I0128 16:58:09.228243 46007 net.cpp:825] Copying source layer bn1
I0128 16:58:09.228504 46007 net.cpp:825] Copying source layer scale1
I0128 16:58:09.228557 46007 net.cpp:825] Copying source layer relu1
I0128 16:58:09.228564 46007 net.cpp:825] Copying source layer pool1
I0128 16:58:09.228567 46007 net.cpp:825] Copying source layer bn2
I0128 16:58:09.228626 46007 net.cpp:825] Copying source layer scale2
I0128 16:58:09.228677 46007 net.cpp:825] Copying source layer binactive1
I0128 16:58:09.228683 46007 net.cpp:825] Copying source layer conv2
I0128 16:58:09.238456 46007 net.cpp:825] Copying source layer pool2
I0128 16:58:09.238474 46007 net.cpp:825] Copying source layer bn3
I0128 16:58:09.238580 46007 net.cpp:825] Copying source layer scale3
I0128 16:58:09.238633 46007 net.cpp:825] Copying source layer binactive2
I0128 16:58:09.238641 46007 net.cpp:825] Copying source layer conv3
I0128 16:58:09.252544 46007 net.cpp:825] Copying source layer bn4
I0128 16:58:09.252758 46007 net.cpp:825] Copying source layer scale4
I0128 16:58:09.252806 46007 net.cpp:825] Copying source layer binactive3
I0128 16:58:09.252820 46007 net.cpp:825] Copying source layer conv4
I0128 16:58:09.272034 46007 net.cpp:825] Copying source layer bn5
I0128 16:58:09.272208 46007 net.cpp:825] Copying source layer scale5
I0128 16:58:09.272261 46007 net.cpp:825] Copying source layer binactive4
I0128 16:58:09.272269 46007 net.cpp:825] Copying source layer conv5
I0128 16:58:09.285152 46007 net.cpp:825] Copying source layer pool5
I0128 16:58:09.285174 46007 net.cpp:825] Copying source layer bn6
I0128 16:58:09.285296 46007 net.cpp:825] Copying source layer scale6
I0128 16:58:09.285353 46007 net.cpp:825] Copying source layer binactive5
I0128 16:58:09.285360 46007 net.cpp:825] Copying source layer fc6
I0128 16:58:10.313434 46007 net.cpp:825] Copying source layer bn7
I0128 16:58:10.313798 46007 net.cpp:825] Copying source layer scale7
I0128 16:58:10.313987 46007 net.cpp:825] Copying source layer binactive6
I0128 16:58:10.313997 46007 net.cpp:825] Copying source layer fc7
I0128 16:58:10.601230 46007 net.cpp:825] Copying source layer bn8
I0128 16:58:10.601595 46007 net.cpp:825] Copying source layer scale8
I0128 16:58:10.601775 46007 net.cpp:825] Copying source layer relu7
I0128 16:58:10.601785 46007 net.cpp:825] Copying source layer fc8
I0128 16:58:10.674193 46007 net.cpp:825] Copying source layer fc8_fc8_0_split
I0128 16:58:10.674226 46007 net.cpp:825] Copying source layer loss
I0128 16:58:10.674232 46007 net.cpp:825] Copying source layer accuracy
I0128 16:58:10.674247 46007 net.cpp:825] Copying source layer accuracy_5
I0128 16:58:10.703289 46007 sgd_solver.cpp:356] SGDSolver: restoring history
I0128 16:58:13.871129 46007 caffe.cpp:239] Starting Optimization
I0128 16:58:13.871184 46007 solver.cpp:300] Solving AlexNet-BN
I0128 16:58:13.871203 46007 solver.cpp:301] Learning Rate Policy: modified_lr
I0128 16:58:13.889397 46007 solver.cpp:385] Iteration 300000, Testing net (#0)
I0128 16:58:14.233428 46007 blocking_queue.cpp:49] Waiting for data
I0128 17:00:11.075567 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0128 17:00:11.129490 46007 solver.cpp:454]     Test net output #0: accuracy = 0.4667
I0128 17:00:11.129549 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.712079
I0128 17:00:11.129566 46007 solver.cpp:454]     Test net output #2: loss = 2.435 (* 1 = 2.435 loss)
I0128 17:00:11.129593 46007 solver.cpp:468] snapshoting best accuracy model ...
I0128 17:00:11.129621 46007 net.cpp:929] Serializing 41 layers
I0128 17:00:17.867808 46007 solver.cpp:472] snapshoting best accuracy model done.
I0128 17:00:17.902261 46007 solver.cpp:474] ================================
I0128 17:00:17.902284 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4667
I0128 17:00:17.902300 46007 solver.cpp:477]     Test net best accuracy5 is: 0.712079
I0128 17:00:18.621333 46007 solver.cpp:243] Iteration 300000 (2404.89 iter/s, 124.746s/200 iters), loss = 2.30176
I0128 17:00:18.621421 46007 solver.cpp:262]     Train net output #0: accuracy = 0.449219
I0128 17:00:18.621433 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.726562
I0128 17:00:18.621450 46007 solver.cpp:262]     Train net output #2: loss = 2.30176 (* 1 = 2.30176 loss)
I0128 17:00:18.621472 46007 sgd_solver.cpp:37] Modified_lr Status: Iteration 300000, step = 4
I0128 17:00:18.621479 46007 sgd_solver.cpp:122] Iteration 300000, lr = 1e-06
I0128 17:00:26.963205 46007 blocking_queue.cpp:49] Waiting for data
I0128 17:02:54.613715 46007 solver.cpp:243] Iteration 300200 (1.28216 iter/s, 155.987s/200 iters), loss = 1.49018
I0128 17:02:54.613806 46007 solver.cpp:262]     Train net output #0: accuracy = 0.671875
I0128 17:02:54.613816 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.863281
I0128 17:02:54.613828 46007 solver.cpp:262]     Train net output #2: loss = 1.49018 (* 1 = 1.49018 loss)
I0128 17:02:54.613837 46007 sgd_solver.cpp:122] Iteration 300200, lr = 1e-06
I0128 17:05:39.819207 46007 solver.cpp:243] Iteration 300400 (1.21066 iter/s, 165.199s/200 iters), loss = 1.79443
I0128 17:05:39.819346 46007 solver.cpp:262]     Train net output #0: accuracy = 0.585938
I0128 17:05:39.819365 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.820312
I0128 17:05:39.819391 46007 solver.cpp:262]     Train net output #2: loss = 1.79443 (* 1 = 1.79443 loss)
I0128 17:05:39.819402 46007 sgd_solver.cpp:122] Iteration 300400, lr = 1e-06
I0128 17:08:07.033113 46007 solver.cpp:243] Iteration 300600 (1.35862 iter/s, 147.208s/200 iters), loss = 1.82973
I0128 17:08:07.045155 46007 solver.cpp:262]     Train net output #0: accuracy = 0.601562
I0128 17:08:07.045178 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.789062
I0128 17:08:07.045225 46007 solver.cpp:262]     Train net output #2: loss = 1.82973 (* 1 = 1.82973 loss)
I0128 17:08:07.045236 46007 sgd_solver.cpp:122] Iteration 300600, lr = 1e-06
I0128 17:10:26.497208 46007 solver.cpp:243] Iteration 300800 (1.43424 iter/s, 139.447s/200 iters), loss = 2.02879
I0128 17:10:26.509510 46007 solver.cpp:262]     Train net output #0: accuracy = 0.535156
I0128 17:10:26.509539 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.746094
I0128 17:10:26.509570 46007 solver.cpp:262]     Train net output #2: loss = 2.02879 (* 1 = 2.02879 loss)
I0128 17:10:26.509586 46007 sgd_solver.cpp:122] Iteration 300800, lr = 1e-06
I0128 17:12:43.389014 46007 solver.cpp:385] Iteration 301000, Testing net (#0)
I0128 17:13:59.090643 46007 blocking_queue.cpp:49] Waiting for data
I0128 17:14:45.228126 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0128 17:14:45.277894 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46412
I0128 17:14:45.277951 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.708339
I0128 17:14:45.277969 46007 solver.cpp:454]     Test net output #2: loss = 2.44437 (* 1 = 2.44437 loss)
I0128 17:14:45.277982 46007 solver.cpp:474] ================================
I0128 17:14:45.277988 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4667
I0128 17:14:45.277994 46007 solver.cpp:477]     Test net best accuracy5 is: 0.712079
I0128 17:14:45.932579 46007 solver.cpp:243] Iteration 301000 (0.77097 iter/s, 259.414s/200 iters), loss = 1.76896
I0128 17:14:45.934901 46007 solver.cpp:262]     Train net output #0: accuracy = 0.5625
I0128 17:14:45.934928 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.816406
I0128 17:14:45.934949 46007 solver.cpp:262]     Train net output #2: loss = 1.76896 (* 1 = 1.76896 loss)
I0128 17:14:45.934964 46007 sgd_solver.cpp:122] Iteration 301000, lr = 1e-06
I0128 17:17:00.672668 46007 solver.cpp:243] Iteration 301200 (1.48442 iter/s, 134.733s/200 iters), loss = 1.92052
I0128 17:17:00.684432 46007 solver.cpp:262]     Train net output #0: accuracy = 0.570312
I0128 17:17:00.684468 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.796875
I0128 17:17:00.684495 46007 solver.cpp:262]     Train net output #2: loss = 1.92052 (* 1 = 1.92052 loss)
I0128 17:17:00.684506 46007 sgd_solver.cpp:122] Iteration 301200, lr = 1e-06
I0128 17:19:15.820413 46007 solver.cpp:243] Iteration 301400 (1.48005 iter/s, 135.131s/200 iters), loss = 1.79065
I0128 17:19:15.832260 46007 solver.cpp:262]     Train net output #0: accuracy = 0.59375
I0128 17:19:15.832281 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.824219
I0128 17:19:15.832317 46007 solver.cpp:262]     Train net output #2: loss = 1.79065 (* 1 = 1.79065 loss)
I0128 17:19:15.832329 46007 sgd_solver.cpp:122] Iteration 301400, lr = 1e-06
I0128 17:21:31.881191 46007 solver.cpp:243] Iteration 301600 (1.47011 iter/s, 136.044s/200 iters), loss = 1.77371
I0128 17:21:31.893414 46007 solver.cpp:262]     Train net output #0: accuracy = 0.574219
I0128 17:21:31.893436 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.804688
I0128 17:21:31.893456 46007 solver.cpp:262]     Train net output #2: loss = 1.77371 (* 1 = 1.77371 loss)
I0128 17:21:31.893470 46007 sgd_solver.cpp:122] Iteration 301600, lr = 1e-06
I0128 17:23:48.443267 46007 solver.cpp:243] Iteration 301800 (1.46472 iter/s, 136.545s/200 iters), loss = 1.78583
I0128 17:23:48.455296 46007 solver.cpp:262]     Train net output #0: accuracy = 0.574219
I0128 17:23:48.455318 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.785156
I0128 17:23:48.455338 46007 solver.cpp:262]     Train net output #2: loss = 1.78583 (* 1 = 1.78583 loss)
I0128 17:23:48.455358 46007 sgd_solver.cpp:122] Iteration 301800, lr = 1e-06
I0128 17:26:03.193913 46007 solver.cpp:385] Iteration 302000, Testing net (#0)
I0128 17:27:08.914090 46007 blocking_queue.cpp:49] Waiting for data
I0128 17:27:58.173655 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0128 17:27:58.223575 46007 solver.cpp:454]     Test net output #0: accuracy = 0.4631
I0128 17:27:58.223629 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.70856
I0128 17:27:58.223659 46007 solver.cpp:454]     Test net output #2: loss = 2.44784 (* 1 = 2.44784 loss)
I0128 17:27:58.223667 46007 solver.cpp:474] ================================
I0128 17:27:58.223672 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4667
I0128 17:27:58.223678 46007 solver.cpp:477]     Test net best accuracy5 is: 0.712079
I0128 17:27:58.879689 46007 solver.cpp:243] Iteration 302000 (0.798674 iter/s, 250.415s/200 iters), loss = 1.81152
I0128 17:27:58.882020 46007 solver.cpp:262]     Train net output #0: accuracy = 0.574219
I0128 17:27:58.882051 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.804688
I0128 17:27:58.882082 46007 solver.cpp:262]     Train net output #2: loss = 1.81152 (* 1 = 1.81152 loss)
I0128 17:27:58.882097 46007 sgd_solver.cpp:122] Iteration 302000, lr = 1e-06
I0128 17:30:14.391166 46007 solver.cpp:243] Iteration 302200 (1.47597 iter/s, 135.504s/200 iters), loss = 1.78029
I0128 17:30:14.402979 46007 solver.cpp:262]     Train net output #0: accuracy = 0.554688
I0128 17:30:14.402995 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.808594
I0128 17:30:14.403010 46007 solver.cpp:262]     Train net output #2: loss = 1.78029 (* 1 = 1.78029 loss)
I0128 17:30:14.403021 46007 sgd_solver.cpp:122] Iteration 302200, lr = 1e-06
I0128 17:32:30.733451 46007 solver.cpp:243] Iteration 302400 (1.46708 iter/s, 136.325s/200 iters), loss = 1.63328
I0128 17:32:30.745173 46007 solver.cpp:262]     Train net output #0: accuracy = 0.605469
I0128 17:32:30.745190 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.832031
I0128 17:32:30.745220 46007 solver.cpp:262]     Train net output #2: loss = 1.63328 (* 1 = 1.63328 loss)
I0128 17:32:30.745234 46007 sgd_solver.cpp:122] Iteration 302400, lr = 1e-06
I0128 17:34:47.685083 46007 solver.cpp:243] Iteration 302600 (1.46055 iter/s, 136.935s/200 iters), loss = 1.57392
I0128 17:34:47.697042 46007 solver.cpp:262]     Train net output #0: accuracy = 0.632812
I0128 17:34:47.697059 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.820312
I0128 17:34:47.697093 46007 solver.cpp:262]     Train net output #2: loss = 1.57392 (* 1 = 1.57392 loss)
I0128 17:34:47.697106 46007 sgd_solver.cpp:122] Iteration 302600, lr = 1e-06
I0128 17:37:04.582244 46007 solver.cpp:243] Iteration 302800 (1.46113 iter/s, 136.88s/200 iters), loss = 1.49482
I0128 17:37:04.593991 46007 solver.cpp:262]     Train net output #0: accuracy = 0.625
I0128 17:37:04.594004 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.84375
I0128 17:37:04.594044 46007 solver.cpp:262]     Train net output #2: loss = 1.49482 (* 1 = 1.49482 loss)
I0128 17:37:04.594058 46007 sgd_solver.cpp:122] Iteration 302800, lr = 1e-06
I0128 17:39:20.827798 46007 solver.cpp:385] Iteration 303000, Testing net (#0)
I0128 17:40:23.612203 46007 blocking_queue.cpp:49] Waiting for data
I0128 17:41:14.160960 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0128 17:41:14.211235 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46274
I0128 17:41:14.211284 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.709899
I0128 17:41:14.211298 46007 solver.cpp:454]     Test net output #2: loss = 2.44748 (* 1 = 2.44748 loss)
I0128 17:41:14.211307 46007 solver.cpp:474] ================================
I0128 17:41:14.211310 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4667
I0128 17:41:14.211315 46007 solver.cpp:477]     Test net best accuracy5 is: 0.712079
I0128 17:41:14.870332 46007 solver.cpp:243] Iteration 303000 (0.799147 iter/s, 250.267s/200 iters), loss = 1.7099
I0128 17:41:14.872720 46007 solver.cpp:262]     Train net output #0: accuracy = 0.613281
I0128 17:41:14.872747 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.820312
I0128 17:41:14.872776 46007 solver.cpp:262]     Train net output #2: loss = 1.7099 (* 1 = 1.7099 loss)
I0128 17:41:14.872789 46007 sgd_solver.cpp:122] Iteration 303000, lr = 1e-06
I0128 17:43:31.146731 46007 solver.cpp:243] Iteration 303200 (1.46769 iter/s, 136.269s/200 iters), loss = 1.8749
I0128 17:43:31.158588 46007 solver.cpp:262]     Train net output #0: accuracy = 0.570312
I0128 17:43:31.158602 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.777344
I0128 17:43:31.158633 46007 solver.cpp:262]     Train net output #2: loss = 1.8749 (* 1 = 1.8749 loss)
I0128 17:43:31.158645 46007 sgd_solver.cpp:122] Iteration 303200, lr = 1e-06
I0128 17:45:47.746100 46007 solver.cpp:243] Iteration 303400 (1.46432 iter/s, 136.582s/200 iters), loss = 1.62119
I0128 17:45:47.758594 46007 solver.cpp:262]     Train net output #0: accuracy = 0.621094
I0128 17:45:47.758618 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.824219
I0128 17:45:47.758641 46007 solver.cpp:262]     Train net output #2: loss = 1.62119 (* 1 = 1.62119 loss)
I0128 17:45:47.758656 46007 sgd_solver.cpp:122] Iteration 303400, lr = 1e-06
I0128 17:48:04.282315 46007 solver.cpp:243] Iteration 303600 (1.465 iter/s, 136.519s/200 iters), loss = 1.47975
I0128 17:48:04.294358 46007 solver.cpp:262]     Train net output #0: accuracy = 0.632812
I0128 17:48:04.294375 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.871094
I0128 17:48:04.294394 46007 solver.cpp:262]     Train net output #2: loss = 1.47975 (* 1 = 1.47975 loss)
I0128 17:48:04.294404 46007 sgd_solver.cpp:122] Iteration 303600, lr = 1e-06
I0128 17:50:21.203750 46007 solver.cpp:243] Iteration 303800 (1.46087 iter/s, 136.904s/200 iters), loss = 1.62753
I0128 17:50:21.215523 46007 solver.cpp:262]     Train net output #0: accuracy = 0.597656
I0128 17:50:21.215545 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.828125
I0128 17:50:21.215572 46007 solver.cpp:262]     Train net output #2: loss = 1.62753 (* 1 = 1.62753 loss)
I0128 17:50:21.215582 46007 sgd_solver.cpp:122] Iteration 303800, lr = 1e-06
I0128 17:52:38.186456 46007 solver.cpp:385] Iteration 304000, Testing net (#0)
I0128 17:53:37.317008 46007 blocking_queue.cpp:49] Waiting for data
I0128 17:54:27.753408 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0128 17:54:27.803663 46007 solver.cpp:454]     Test net output #0: accuracy = 0.4677
I0128 17:54:27.803733 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.71252
I0128 17:54:27.803752 46007 solver.cpp:454]     Test net output #2: loss = 2.41907 (* 1 = 2.41907 loss)
I0128 17:54:27.803772 46007 solver.cpp:468] snapshoting best accuracy model ...
I0128 17:54:27.814781 46007 net.cpp:929] Serializing 41 layers
I0128 17:54:32.952481 46007 solver.cpp:472] snapshoting best accuracy model done.
I0128 17:54:32.974375 46007 solver.cpp:474] ================================
I0128 17:54:32.974396 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0128 17:54:32.974409 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0128 17:54:33.676321 46007 solver.cpp:243] Iteration 304000 (0.792232 iter/s, 252.451s/200 iters), loss = 1.75279
I0128 17:54:33.676403 46007 solver.cpp:262]     Train net output #0: accuracy = 0.628906
I0128 17:54:33.676414 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.820312
I0128 17:54:33.676434 46007 solver.cpp:262]     Train net output #2: loss = 1.75279 (* 1 = 1.75279 loss)
I0128 17:54:33.676446 46007 sgd_solver.cpp:122] Iteration 304000, lr = 1e-06
I0128 17:56:50.472704 46007 solver.cpp:243] Iteration 304200 (1.46208 iter/s, 136.791s/200 iters), loss = 1.6275
I0128 17:56:50.484645 46007 solver.cpp:262]     Train net output #0: accuracy = 0.621094
I0128 17:56:50.484660 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.824219
I0128 17:56:50.484699 46007 solver.cpp:262]     Train net output #2: loss = 1.6275 (* 1 = 1.6275 loss)
I0128 17:56:50.484710 46007 sgd_solver.cpp:122] Iteration 304200, lr = 1e-06
I0128 17:59:08.427779 46007 solver.cpp:243] Iteration 304400 (1.44993 iter/s, 137.938s/200 iters), loss = 1.71955
I0128 17:59:08.439709 46007 solver.cpp:262]     Train net output #0: accuracy = 0.589844
I0128 17:59:08.439725 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.8125
I0128 17:59:08.439748 46007 solver.cpp:262]     Train net output #2: loss = 1.71955 (* 1 = 1.71955 loss)
I0128 17:59:08.439760 46007 sgd_solver.cpp:122] Iteration 304400, lr = 1e-06
I0128 18:01:26.585170 46007 solver.cpp:243] Iteration 304600 (1.4478 iter/s, 138.14s/200 iters), loss = 1.74183
I0128 18:01:26.597210 46007 solver.cpp:262]     Train net output #0: accuracy = 0.582031
I0128 18:01:26.597239 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.820312
I0128 18:01:26.597265 46007 solver.cpp:262]     Train net output #2: loss = 1.74183 (* 1 = 1.74183 loss)
I0128 18:01:26.597275 46007 sgd_solver.cpp:122] Iteration 304600, lr = 1e-06
I0128 18:03:44.859978 46007 solver.cpp:243] Iteration 304800 (1.44658 iter/s, 138.258s/200 iters), loss = 1.71656
I0128 18:03:44.871698 46007 solver.cpp:262]     Train net output #0: accuracy = 0.601562
I0128 18:03:44.871733 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.832031
I0128 18:03:44.871778 46007 solver.cpp:262]     Train net output #2: loss = 1.71656 (* 1 = 1.71656 loss)
I0128 18:03:44.871793 46007 sgd_solver.cpp:122] Iteration 304800, lr = 1e-06
I0128 18:06:01.103262 46007 solver.cpp:385] Iteration 305000, Testing net (#0)
I0128 18:06:46.068218 46007 blocking_queue.cpp:49] Waiting for data
I0128 18:07:48.723464 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0128 18:07:48.773829 46007 solver.cpp:454]     Test net output #0: accuracy = 0.4663
I0128 18:07:48.773872 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.709899
I0128 18:07:48.773895 46007 solver.cpp:454]     Test net output #2: loss = 2.43846 (* 1 = 2.43846 loss)
I0128 18:07:48.773902 46007 solver.cpp:474] ================================
I0128 18:07:48.773907 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0128 18:07:48.773912 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0128 18:07:49.429388 46007 solver.cpp:243] Iteration 305000 (0.817833 iter/s, 244.549s/200 iters), loss = 1.83253
I0128 18:07:49.431727 46007 solver.cpp:262]     Train net output #0: accuracy = 0.554688
I0128 18:07:49.431742 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.796875
I0128 18:07:49.431771 46007 solver.cpp:262]     Train net output #2: loss = 1.83253 (* 1 = 1.83253 loss)
I0128 18:07:49.431785 46007 sgd_solver.cpp:122] Iteration 305000, lr = 1e-06
I0128 18:07:49.925772 46077 data_layer.cpp:73] Restarting data prefetching from start.
I0128 18:10:07.059075 46007 solver.cpp:243] Iteration 305200 (1.45325 iter/s, 137.622s/200 iters), loss = 1.60933
I0128 18:10:07.070874 46007 solver.cpp:262]     Train net output #0: accuracy = 0.613281
I0128 18:10:07.070924 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.824219
I0128 18:10:07.070950 46007 solver.cpp:262]     Train net output #2: loss = 1.60933 (* 1 = 1.60933 loss)
I0128 18:10:07.070967 46007 sgd_solver.cpp:122] Iteration 305200, lr = 1e-06
I0128 18:12:23.777297 46007 solver.cpp:243] Iteration 305400 (1.46304 iter/s, 136.701s/200 iters), loss = 1.76281
I0128 18:12:23.789176 46007 solver.cpp:262]     Train net output #0: accuracy = 0.59375
I0128 18:12:23.789191 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.773438
I0128 18:12:23.789224 46007 solver.cpp:262]     Train net output #2: loss = 1.76281 (* 1 = 1.76281 loss)
I0128 18:12:23.789235 46007 sgd_solver.cpp:122] Iteration 305400, lr = 1e-06
I0128 18:14:40.962231 46007 solver.cpp:243] Iteration 305600 (1.45807 iter/s, 137.168s/200 iters), loss = 1.82256
I0128 18:14:40.974098 46007 solver.cpp:262]     Train net output #0: accuracy = 0.605469
I0128 18:14:40.974114 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.792969
I0128 18:14:40.974153 46007 solver.cpp:262]     Train net output #2: loss = 1.82256 (* 1 = 1.82256 loss)
I0128 18:14:40.974162 46007 sgd_solver.cpp:122] Iteration 305600, lr = 1e-06
I0128 18:16:58.039739 46007 solver.cpp:243] Iteration 305800 (1.45921 iter/s, 137.061s/200 iters), loss = 1.91278
I0128 18:16:58.051529 46007 solver.cpp:262]     Train net output #0: accuracy = 0.554688
I0128 18:16:58.051553 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.789062
I0128 18:16:58.051576 46007 solver.cpp:262]     Train net output #2: loss = 1.91278 (* 1 = 1.91278 loss)
I0128 18:16:58.051587 46007 sgd_solver.cpp:122] Iteration 305800, lr = 1e-06
I0128 18:19:14.385924 46007 solver.cpp:385] Iteration 306000, Testing net (#0)
I0128 18:19:53.203627 46007 blocking_queue.cpp:49] Waiting for data
I0128 18:21:23.951745 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0128 18:21:24.001783 46007 solver.cpp:454]     Test net output #0: accuracy = 0.463741
I0128 18:21:24.001821 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.708399
I0128 18:21:24.001844 46007 solver.cpp:454]     Test net output #2: loss = 2.44242 (* 1 = 2.44242 loss)
I0128 18:21:24.001854 46007 solver.cpp:474] ================================
I0128 18:21:24.001858 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0128 18:21:24.001864 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0128 18:21:24.659603 46007 solver.cpp:243] Iteration 306000 (0.750193 iter/s, 266.598s/200 iters), loss = 1.67697
I0128 18:21:24.661964 46007 solver.cpp:262]     Train net output #0: accuracy = 0.605469
I0128 18:21:24.661995 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.816406
I0128 18:21:24.662036 46007 solver.cpp:262]     Train net output #2: loss = 1.67697 (* 1 = 1.67697 loss)
I0128 18:21:24.662060 46007 sgd_solver.cpp:122] Iteration 306000, lr = 1e-06
I0128 18:23:41.423346 46007 solver.cpp:243] Iteration 306200 (1.46246 iter/s, 136.756s/200 iters), loss = 1.62594
I0128 18:23:41.435129 46007 solver.cpp:262]     Train net output #0: accuracy = 0.617188
I0128 18:23:41.435148 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.84375
I0128 18:23:41.435186 46007 solver.cpp:262]     Train net output #2: loss = 1.62594 (* 1 = 1.62594 loss)
I0128 18:23:41.435199 46007 sgd_solver.cpp:122] Iteration 306200, lr = 1e-06
I0128 18:25:58.356904 46007 solver.cpp:243] Iteration 306400 (1.46074 iter/s, 136.917s/200 iters), loss = 1.71445
I0128 18:25:58.368834 46007 solver.cpp:262]     Train net output #0: accuracy = 0.578125
I0128 18:25:58.368857 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.8125
I0128 18:25:58.368898 46007 solver.cpp:262]     Train net output #2: loss = 1.71445 (* 1 = 1.71445 loss)
I0128 18:25:58.368911 46007 sgd_solver.cpp:122] Iteration 306400, lr = 1e-06
I0128 18:28:15.068101 46007 solver.cpp:243] Iteration 306600 (1.46312 iter/s, 136.694s/200 iters), loss = 1.84676
I0128 18:28:15.079962 46007 solver.cpp:262]     Train net output #0: accuracy = 0.5625
I0128 18:28:15.079985 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.796875
I0128 18:28:15.080010 46007 solver.cpp:262]     Train net output #2: loss = 1.84676 (* 1 = 1.84676 loss)
I0128 18:28:15.080021 46007 sgd_solver.cpp:122] Iteration 306600, lr = 1e-06
I0128 18:30:32.047344 46007 solver.cpp:243] Iteration 306800 (1.46026 iter/s, 136.962s/200 iters), loss = 1.84942
I0128 18:30:32.059119 46007 solver.cpp:262]     Train net output #0: accuracy = 0.613281
I0128 18:30:32.059134 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.824219
I0128 18:30:32.059170 46007 solver.cpp:262]     Train net output #2: loss = 1.84942 (* 1 = 1.84942 loss)
I0128 18:30:32.059180 46007 sgd_solver.cpp:122] Iteration 306800, lr = 1e-06
I0128 18:32:48.608001 46007 solver.cpp:385] Iteration 307000, Testing net (#0)
I0128 18:33:49.904309 46007 blocking_queue.cpp:49] Waiting for data
I0128 18:35:48.753157 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0128 18:35:48.803135 46007 solver.cpp:454]     Test net output #0: accuracy = 0.4655
I0128 18:35:48.803182 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.709159
I0128 18:35:48.803205 46007 solver.cpp:454]     Test net output #2: loss = 2.43661 (* 1 = 2.43661 loss)
I0128 18:35:48.803215 46007 solver.cpp:474] ================================
I0128 18:35:48.803220 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0128 18:35:48.803225 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0128 18:35:49.450412 46007 solver.cpp:243] Iteration 307000 (0.630161 iter/s, 317.379s/200 iters), loss = 2.00792
I0128 18:35:49.452834 46007 solver.cpp:262]     Train net output #0: accuracy = 0.503906
I0128 18:35:49.452859 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.769531
I0128 18:35:49.452877 46007 solver.cpp:262]     Train net output #2: loss = 2.00792 (* 1 = 2.00792 loss)
I0128 18:35:49.452890 46007 sgd_solver.cpp:122] Iteration 307000, lr = 1e-06
I0128 18:38:12.289372 46007 solver.cpp:243] Iteration 307200 (1.40027 iter/s, 142.83s/200 iters), loss = 1.51434
I0128 18:38:12.299619 46007 solver.cpp:262]     Train net output #0: accuracy = 0.660156
I0128 18:38:12.299633 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.855469
I0128 18:38:12.299669 46007 solver.cpp:262]     Train net output #2: loss = 1.51434 (* 1 = 1.51434 loss)
I0128 18:38:12.299679 46007 sgd_solver.cpp:122] Iteration 307200, lr = 1e-06
I0128 18:40:28.778540 46007 solver.cpp:243] Iteration 307400 (1.46548 iter/s, 136.474s/200 iters), loss = 1.52444
I0128 18:40:28.778647 46007 solver.cpp:262]     Train net output #0: accuracy = 0.648438
I0128 18:40:28.778659 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.847656
I0128 18:40:28.778677 46007 solver.cpp:262]     Train net output #2: loss = 1.52444 (* 1 = 1.52444 loss)
I0128 18:40:28.778688 46007 sgd_solver.cpp:122] Iteration 307400, lr = 1e-06
I0128 18:42:45.911371 46007 solver.cpp:243] Iteration 307600 (1.4585 iter/s, 137.128s/200 iters), loss = 1.94647
I0128 18:42:45.923287 46007 solver.cpp:262]     Train net output #0: accuracy = 0.523438
I0128 18:42:45.923310 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.769531
I0128 18:42:45.923358 46007 solver.cpp:262]     Train net output #2: loss = 1.94647 (* 1 = 1.94647 loss)
I0128 18:42:45.923370 46007 sgd_solver.cpp:122] Iteration 307600, lr = 1e-06
I0128 18:45:02.671772 46007 solver.cpp:243] Iteration 307800 (1.46259 iter/s, 136.743s/200 iters), loss = 1.66587
I0128 18:45:02.683799 46007 solver.cpp:262]     Train net output #0: accuracy = 0.613281
I0128 18:45:02.683842 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.847656
I0128 18:45:02.683897 46007 solver.cpp:262]     Train net output #2: loss = 1.66587 (* 1 = 1.66587 loss)
I0128 18:45:02.683920 46007 sgd_solver.cpp:122] Iteration 307800, lr = 1e-06
I0128 18:47:19.041697 46007 solver.cpp:385] Iteration 308000, Testing net (#0)
I0128 18:48:03.346591 46007 blocking_queue.cpp:49] Waiting for data
I0128 18:50:23.274498 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0128 18:50:23.324357 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46458
I0128 18:50:23.324400 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.710919
I0128 18:50:23.324424 46007 solver.cpp:454]     Test net output #2: loss = 2.43749 (* 1 = 2.43749 loss)
I0128 18:50:23.324432 46007 solver.cpp:474] ================================
I0128 18:50:23.324437 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0128 18:50:23.324442 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0128 18:50:23.972158 46007 solver.cpp:243] Iteration 308000 (0.622517 iter/s, 321.276s/200 iters), loss = 1.56807
I0128 18:50:23.974555 46007 solver.cpp:262]     Train net output #0: accuracy = 0.605469
I0128 18:50:23.974584 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.863281
I0128 18:50:23.974622 46007 solver.cpp:262]     Train net output #2: loss = 1.56807 (* 1 = 1.56807 loss)
I0128 18:50:23.974634 46007 sgd_solver.cpp:122] Iteration 308000, lr = 1e-06
I0128 18:52:41.098600 46007 solver.cpp:243] Iteration 308200 (1.45859 iter/s, 137.119s/200 iters), loss = 1.59335
I0128 18:52:41.110373 46007 solver.cpp:262]     Train net output #0: accuracy = 0.628906
I0128 18:52:41.110394 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.820312
I0128 18:52:41.110431 46007 solver.cpp:262]     Train net output #2: loss = 1.59335 (* 1 = 1.59335 loss)
I0128 18:52:41.110440 46007 sgd_solver.cpp:122] Iteration 308200, lr = 1e-06
I0128 18:55:00.008133 46007 solver.cpp:243] Iteration 308400 (1.43996 iter/s, 138.893s/200 iters), loss = 1.67335
I0128 18:55:00.020161 46007 solver.cpp:262]     Train net output #0: accuracy = 0.632812
I0128 18:55:00.020184 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.824219
I0128 18:55:00.020220 46007 solver.cpp:262]     Train net output #2: loss = 1.67335 (* 1 = 1.67335 loss)
I0128 18:55:00.020232 46007 sgd_solver.cpp:122] Iteration 308400, lr = 1e-06
I0128 18:57:20.726277 46007 solver.cpp:243] Iteration 308600 (1.42146 iter/s, 140.701s/200 iters), loss = 1.7507
I0128 18:57:20.738090 46007 solver.cpp:262]     Train net output #0: accuracy = 0.554688
I0128 18:57:20.738116 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.847656
I0128 18:57:20.738139 46007 solver.cpp:262]     Train net output #2: loss = 1.7507 (* 1 = 1.7507 loss)
I0128 18:57:20.738150 46007 sgd_solver.cpp:122] Iteration 308600, lr = 1e-06
I0128 18:59:38.484745 46007 solver.cpp:243] Iteration 308800 (1.452 iter/s, 137.741s/200 iters), loss = 1.61248
I0128 18:59:38.496749 46007 solver.cpp:262]     Train net output #0: accuracy = 0.613281
I0128 18:59:38.496773 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.804688
I0128 18:59:38.496811 46007 solver.cpp:262]     Train net output #2: loss = 1.61248 (* 1 = 1.61248 loss)
I0128 18:59:38.496824 46007 sgd_solver.cpp:122] Iteration 308800, lr = 1e-06
I0128 19:01:56.735357 46007 solver.cpp:385] Iteration 309000, Testing net (#0)
I0128 19:02:10.770256 46007 blocking_queue.cpp:49] Waiting for data
I0128 19:05:11.927418 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0128 19:05:11.977151 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46606
I0128 19:05:11.977203 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.709839
I0128 19:05:11.977231 46007 solver.cpp:454]     Test net output #2: loss = 2.43303 (* 1 = 2.43303 loss)
I0128 19:05:11.977241 46007 solver.cpp:474] ================================
I0128 19:05:11.977246 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0128 19:05:11.977252 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0128 19:05:12.623019 46007 solver.cpp:243] Iteration 309000 (0.598598 iter/s, 334.114s/200 iters), loss = 1.58738
I0128 19:05:12.625388 46007 solver.cpp:262]     Train net output #0: accuracy = 0.574219
I0128 19:05:12.625413 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.859375
I0128 19:05:12.625442 46007 solver.cpp:262]     Train net output #2: loss = 1.58738 (* 1 = 1.58738 loss)
I0128 19:05:12.625454 46007 sgd_solver.cpp:122] Iteration 309000, lr = 1e-06
I0128 19:07:29.283010 46007 solver.cpp:243] Iteration 309200 (1.46357 iter/s, 136.653s/200 iters), loss = 1.83128
I0128 19:07:29.294780 46007 solver.cpp:262]     Train net output #0: accuracy = 0.554688
I0128 19:07:29.294819 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.78125
I0128 19:07:29.294858 46007 solver.cpp:262]     Train net output #2: loss = 1.83128 (* 1 = 1.83128 loss)
I0128 19:07:29.294875 46007 sgd_solver.cpp:122] Iteration 309200, lr = 1e-06
I0128 19:09:47.078522 46007 solver.cpp:243] Iteration 309400 (1.4516 iter/s, 137.779s/200 iters), loss = 1.692
I0128 19:09:47.090399 46007 solver.cpp:262]     Train net output #0: accuracy = 0.574219
I0128 19:09:47.090415 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.792969
I0128 19:09:47.090447 46007 solver.cpp:262]     Train net output #2: loss = 1.692 (* 1 = 1.692 loss)
I0128 19:09:47.090458 46007 sgd_solver.cpp:122] Iteration 309400, lr = 1e-06
I0128 19:12:04.989567 46007 solver.cpp:243] Iteration 309600 (1.45039 iter/s, 137.894s/200 iters), loss = 1.67848
I0128 19:12:05.001471 46007 solver.cpp:262]     Train net output #0: accuracy = 0.601562
I0128 19:12:05.001487 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.824219
I0128 19:12:05.001524 46007 solver.cpp:262]     Train net output #2: loss = 1.67848 (* 1 = 1.67848 loss)
I0128 19:12:05.001535 46007 sgd_solver.cpp:122] Iteration 309600, lr = 1e-06
I0128 19:13:10.043768 46007 blocking_queue.cpp:49] Waiting for data
I0128 19:14:22.284854 46007 solver.cpp:243] Iteration 309800 (1.4569 iter/s, 137.278s/200 iters), loss = 1.57035
I0128 19:14:22.296587 46007 solver.cpp:262]     Train net output #0: accuracy = 0.648438
I0128 19:14:22.296602 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.828125
I0128 19:14:22.296639 46007 solver.cpp:262]     Train net output #2: loss = 1.57035 (* 1 = 1.57035 loss)
I0128 19:14:22.296648 46007 sgd_solver.cpp:122] Iteration 309800, lr = 1e-06
I0128 19:16:41.448837 46007 solver.cpp:525] Snapshotting to binary proto file snapshot/solver_iter_310000.caffemodel
I0128 19:16:41.448940 46007 net.cpp:929] Serializing 41 layers
I0128 19:16:54.307967 46007 sgd_solver.cpp:311] Snapshotting solver state to binary proto file snapshot/solver_iter_310000.solverstate
I0128 19:16:58.151413 46007 solver.cpp:385] Iteration 310000, Testing net (#0)
I0128 19:20:06.444331 46007 blocking_queue.cpp:49] Waiting for data
I0128 19:20:16.277245 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0128 19:20:16.326879 46007 solver.cpp:454]     Test net output #0: accuracy = 0.4637
I0128 19:20:16.326913 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.70906
I0128 19:20:16.326927 46007 solver.cpp:454]     Test net output #2: loss = 2.44456 (* 1 = 2.44456 loss)
I0128 19:20:16.326936 46007 solver.cpp:474] ================================
I0128 19:20:16.326939 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0128 19:20:16.326944 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0128 19:20:16.969182 46007 solver.cpp:243] Iteration 310000 (0.563921 iter/s, 354.659s/200 iters), loss = 1.89173
I0128 19:20:16.969266 46007 solver.cpp:262]     Train net output #0: accuracy = 0.53125
I0128 19:20:16.969280 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.761719
I0128 19:20:16.969303 46007 solver.cpp:262]     Train net output #2: loss = 1.89173 (* 1 = 1.89173 loss)
I0128 19:20:16.969334 46007 sgd_solver.cpp:122] Iteration 310000, lr = 1e-06
I0128 19:20:21.099546 46077 data_layer.cpp:73] Restarting data prefetching from start.
I0128 19:22:35.709156 46007 solver.cpp:243] Iteration 310200 (1.4416 iter/s, 138.735s/200 iters), loss = 1.80608
I0128 19:22:35.721071 46007 solver.cpp:262]     Train net output #0: accuracy = 0.539062
I0128 19:22:35.721094 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.796875
I0128 19:22:35.721120 46007 solver.cpp:262]     Train net output #2: loss = 1.80608 (* 1 = 1.80608 loss)
I0128 19:22:35.721132 46007 sgd_solver.cpp:122] Iteration 310200, lr = 1e-06
I0128 19:24:52.964287 46007 solver.cpp:243] Iteration 310400 (1.45732 iter/s, 137.238s/200 iters), loss = 1.72184
I0128 19:24:52.976063 46007 solver.cpp:262]     Train net output #0: accuracy = 0.570312
I0128 19:24:52.976084 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.824219
I0128 19:24:52.976110 46007 solver.cpp:262]     Train net output #2: loss = 1.72184 (* 1 = 1.72184 loss)
I0128 19:24:52.976120 46007 sgd_solver.cpp:122] Iteration 310400, lr = 1e-06
I0128 19:27:12.325309 46007 solver.cpp:243] Iteration 310600 (1.4353 iter/s, 139.344s/200 iters), loss = 1.8232
I0128 19:27:12.337218 46007 solver.cpp:262]     Train net output #0: accuracy = 0.546875
I0128 19:27:12.337254 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.773438
I0128 19:27:12.337293 46007 solver.cpp:262]     Train net output #2: loss = 1.8232 (* 1 = 1.8232 loss)
I0128 19:27:12.337309 46007 sgd_solver.cpp:122] Iteration 310600, lr = 1e-06
I0128 19:29:29.785611 46007 solver.cpp:243] Iteration 310800 (1.45515 iter/s, 137.443s/200 iters), loss = 1.65128
I0128 19:29:29.797538 46007 solver.cpp:262]     Train net output #0: accuracy = 0.601562
I0128 19:29:29.797554 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.847656
I0128 19:29:29.797574 46007 solver.cpp:262]     Train net output #2: loss = 1.65128 (* 1 = 1.65128 loss)
I0128 19:29:29.797585 46007 sgd_solver.cpp:122] Iteration 310800, lr = 1e-06
I0128 19:31:46.188505 46007 solver.cpp:385] Iteration 311000, Testing net (#0)
I0128 19:33:42.762856 46007 blocking_queue.cpp:49] Waiting for data
I0128 19:33:58.472873 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0128 19:33:58.522869 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46384
I0128 19:33:58.522924 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.70816
I0128 19:33:58.522938 46007 solver.cpp:454]     Test net output #2: loss = 2.44911 (* 1 = 2.44911 loss)
I0128 19:33:58.522945 46007 solver.cpp:474] ================================
I0128 19:33:58.522949 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0128 19:33:58.522954 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0128 19:33:59.177093 46007 solver.cpp:243] Iteration 311000 (0.742474 iter/s, 269.37s/200 iters), loss = 1.42774
I0128 19:33:59.179456 46007 solver.cpp:262]     Train net output #0: accuracy = 0.664062
I0128 19:33:59.179479 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.859375
I0128 19:33:59.179503 46007 solver.cpp:262]     Train net output #2: loss = 1.42774 (* 1 = 1.42774 loss)
I0128 19:33:59.179514 46007 sgd_solver.cpp:122] Iteration 311000, lr = 1e-06
I0128 19:36:17.682633 46007 solver.cpp:243] Iteration 311200 (1.44406 iter/s, 138.498s/200 iters), loss = 1.7386
I0128 19:36:17.694629 46007 solver.cpp:262]     Train net output #0: accuracy = 0.59375
I0128 19:36:17.694670 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.804688
I0128 19:36:17.694727 46007 solver.cpp:262]     Train net output #2: loss = 1.7386 (* 1 = 1.7386 loss)
I0128 19:36:17.694761 46007 sgd_solver.cpp:122] Iteration 311200, lr = 1e-06
I0128 19:38:35.825398 46007 solver.cpp:243] Iteration 311400 (1.44796 iter/s, 138.126s/200 iters), loss = 1.62407
I0128 19:38:35.837214 46007 solver.cpp:262]     Train net output #0: accuracy = 0.589844
I0128 19:38:35.837249 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.847656
I0128 19:38:35.837276 46007 solver.cpp:262]     Train net output #2: loss = 1.62407 (* 1 = 1.62407 loss)
I0128 19:38:35.837290 46007 sgd_solver.cpp:122] Iteration 311400, lr = 1e-06
I0128 19:40:56.590888 46007 solver.cpp:243] Iteration 311600 (1.42097 iter/s, 140.748s/200 iters), loss = 1.66412
I0128 19:40:56.602810 46007 solver.cpp:262]     Train net output #0: accuracy = 0.566406
I0128 19:40:56.602836 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.820312
I0128 19:40:56.602859 46007 solver.cpp:262]     Train net output #2: loss = 1.66412 (* 1 = 1.66412 loss)
I0128 19:40:56.602870 46007 sgd_solver.cpp:122] Iteration 311600, lr = 1e-06
I0128 19:43:15.889472 46007 solver.cpp:243] Iteration 311800 (1.43594 iter/s, 139.281s/200 iters), loss = 1.62529
I0128 19:43:15.901242 46007 solver.cpp:262]     Train net output #0: accuracy = 0.59375
I0128 19:43:15.901271 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.851562
I0128 19:43:15.901298 46007 solver.cpp:262]     Train net output #2: loss = 1.62529 (* 1 = 1.62529 loss)
I0128 19:43:15.901309 46007 sgd_solver.cpp:122] Iteration 311800, lr = 1e-06
I0128 19:45:36.644228 46007 solver.cpp:385] Iteration 312000, Testing net (#0)
I0128 19:47:24.133698 46007 blocking_queue.cpp:49] Waiting for data
I0128 19:48:13.792098 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0128 19:48:13.842325 46007 solver.cpp:454]     Test net output #0: accuracy = 0.4649
I0128 19:48:13.842389 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.71082
I0128 19:48:13.842417 46007 solver.cpp:454]     Test net output #2: loss = 2.43397 (* 1 = 2.43397 loss)
I0128 19:48:13.842427 46007 solver.cpp:474] ================================
I0128 19:48:13.842432 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0128 19:48:13.842439 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0128 19:48:14.506160 46007 solver.cpp:243] Iteration 312000 (0.669806 iter/s, 298.594s/200 iters), loss = 1.71823
I0128 19:48:14.508484 46007 solver.cpp:262]     Train net output #0: accuracy = 0.558594
I0128 19:48:14.508509 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.824219
I0128 19:48:14.508529 46007 solver.cpp:262]     Train net output #2: loss = 1.71823 (* 1 = 1.71823 loss)
I0128 19:48:14.508543 46007 sgd_solver.cpp:122] Iteration 312000, lr = 1e-06
I0128 19:50:31.717730 46007 solver.cpp:243] Iteration 312200 (1.45768 iter/s, 137.204s/200 iters), loss = 1.55817
I0128 19:50:31.729511 46007 solver.cpp:262]     Train net output #0: accuracy = 0.617188
I0128 19:50:31.729526 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.855469
I0128 19:50:31.729565 46007 solver.cpp:262]     Train net output #2: loss = 1.55817 (* 1 = 1.55817 loss)
I0128 19:50:31.729576 46007 sgd_solver.cpp:122] Iteration 312200, lr = 1e-06
I0128 19:52:49.750538 46007 solver.cpp:243] Iteration 312400 (1.44911 iter/s, 138.016s/200 iters), loss = 1.60346
I0128 19:52:49.762271 46007 solver.cpp:262]     Train net output #0: accuracy = 0.65625
I0128 19:52:49.762289 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.824219
I0128 19:52:49.762311 46007 solver.cpp:262]     Train net output #2: loss = 1.60346 (* 1 = 1.60346 loss)
I0128 19:52:49.762323 46007 sgd_solver.cpp:122] Iteration 312400, lr = 1e-06
I0128 19:55:12.175297 46007 solver.cpp:243] Iteration 312600 (1.40442 iter/s, 142.408s/200 iters), loss = 1.75494
I0128 19:55:12.175417 46007 solver.cpp:262]     Train net output #0: accuracy = 0.582031
I0128 19:55:12.175431 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.816406
I0128 19:55:12.175451 46007 solver.cpp:262]     Train net output #2: loss = 1.75494 (* 1 = 1.75494 loss)
I0128 19:55:12.175462 46007 sgd_solver.cpp:122] Iteration 312600, lr = 1e-06
I0128 19:57:31.879016 46007 solver.cpp:243] Iteration 312800 (1.43166 iter/s, 139.698s/200 iters), loss = 1.6885
I0128 19:57:31.890947 46007 solver.cpp:262]     Train net output #0: accuracy = 0.628906
I0128 19:57:31.891010 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.796875
I0128 19:57:31.891078 46007 solver.cpp:262]     Train net output #2: loss = 1.6885 (* 1 = 1.6885 loss)
I0128 19:57:31.891095 46007 sgd_solver.cpp:122] Iteration 312800, lr = 1e-06
I0128 19:59:48.411725 46007 solver.cpp:385] Iteration 313000, Testing net (#0)
I0128 20:00:37.175576 46007 blocking_queue.cpp:49] Waiting for data
I0128 20:01:36.997283 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0128 20:01:37.047621 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46172
I0128 20:01:37.047686 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.70888
I0128 20:01:37.047701 46007 solver.cpp:454]     Test net output #2: loss = 2.44856 (* 1 = 2.44856 loss)
I0128 20:01:37.047710 46007 solver.cpp:474] ================================
I0128 20:01:37.047715 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0128 20:01:37.047721 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0128 20:01:37.698400 46007 solver.cpp:243] Iteration 313000 (0.813675 iter/s, 245.798s/200 iters), loss = 1.63248
I0128 20:01:37.700726 46007 solver.cpp:262]     Train net output #0: accuracy = 0.609375
I0128 20:01:37.700752 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.8125
I0128 20:01:37.700779 46007 solver.cpp:262]     Train net output #2: loss = 1.63248 (* 1 = 1.63248 loss)
I0128 20:01:37.700794 46007 sgd_solver.cpp:122] Iteration 313000, lr = 1e-06
I0128 20:03:54.931833 46007 solver.cpp:243] Iteration 313200 (1.45745 iter/s, 137.226s/200 iters), loss = 1.70097
I0128 20:03:54.943573 46007 solver.cpp:262]     Train net output #0: accuracy = 0.582031
I0128 20:03:54.943604 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.820312
I0128 20:03:54.943629 46007 solver.cpp:262]     Train net output #2: loss = 1.70097 (* 1 = 1.70097 loss)
I0128 20:03:54.943641 46007 sgd_solver.cpp:122] Iteration 313200, lr = 1e-06
I0128 20:06:11.740257 46007 solver.cpp:243] Iteration 313400 (1.46211 iter/s, 136.789s/200 iters), loss = 1.70495
I0128 20:06:11.752159 46007 solver.cpp:262]     Train net output #0: accuracy = 0.578125
I0128 20:06:11.752189 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.820312
I0128 20:06:11.752216 46007 solver.cpp:262]     Train net output #2: loss = 1.70495 (* 1 = 1.70495 loss)
I0128 20:06:11.752228 46007 sgd_solver.cpp:122] Iteration 313400, lr = 1e-06
I0128 20:08:28.868024 46007 solver.cpp:243] Iteration 313600 (1.45872 iter/s, 137.107s/200 iters), loss = 1.48551
I0128 20:08:28.879987 46007 solver.cpp:262]     Train net output #0: accuracy = 0.648438
I0128 20:08:28.880012 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.859375
I0128 20:08:28.880035 46007 solver.cpp:262]     Train net output #2: loss = 1.48551 (* 1 = 1.48551 loss)
I0128 20:08:28.880048 46007 sgd_solver.cpp:122] Iteration 313600, lr = 1e-06
I0128 20:10:47.442399 46007 solver.cpp:243] Iteration 313800 (1.44349 iter/s, 138.553s/200 iters), loss = 1.68013
I0128 20:10:47.454193 46007 solver.cpp:262]     Train net output #0: accuracy = 0.597656
I0128 20:10:47.454216 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.832031
I0128 20:10:47.454238 46007 solver.cpp:262]     Train net output #2: loss = 1.68013 (* 1 = 1.68013 loss)
I0128 20:10:47.454248 46007 sgd_solver.cpp:122] Iteration 313800, lr = 1e-06
I0128 20:13:03.108621 46007 solver.cpp:385] Iteration 314000, Testing net (#0)
I0128 20:14:04.382972 46007 blocking_queue.cpp:49] Waiting for data
I0128 20:15:16.066818 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0128 20:15:16.116730 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46446
I0128 20:15:16.116823 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.710499
I0128 20:15:16.116847 46007 solver.cpp:454]     Test net output #2: loss = 2.43103 (* 1 = 2.43103 loss)
I0128 20:15:16.116863 46007 solver.cpp:474] ================================
I0128 20:15:16.116873 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0128 20:15:16.116883 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0128 20:15:16.773797 46007 solver.cpp:243] Iteration 314000 (0.742644 iter/s, 269.308s/200 iters), loss = 1.60442
I0128 20:15:16.776123 46007 solver.cpp:262]     Train net output #0: accuracy = 0.601562
I0128 20:15:16.776149 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.84375
I0128 20:15:16.776175 46007 solver.cpp:262]     Train net output #2: loss = 1.60442 (* 1 = 1.60442 loss)
I0128 20:15:16.776187 46007 sgd_solver.cpp:122] Iteration 314000, lr = 1e-06
I0128 20:17:33.253465 46007 solver.cpp:243] Iteration 314200 (1.4655 iter/s, 136.472s/200 iters), loss = 1.6785
I0128 20:17:33.265329 46007 solver.cpp:262]     Train net output #0: accuracy = 0.628906
I0128 20:17:33.267848 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.800781
I0128 20:17:33.267876 46007 solver.cpp:262]     Train net output #2: loss = 1.6785 (* 1 = 1.6785 loss)
I0128 20:17:33.267890 46007 sgd_solver.cpp:122] Iteration 314200, lr = 1e-06
I0128 20:19:53.311331 46007 solver.cpp:243] Iteration 314400 (1.42815 iter/s, 140.041s/200 iters), loss = 1.63759
I0128 20:19:53.323374 46007 solver.cpp:262]     Train net output #0: accuracy = 0.597656
I0128 20:19:53.323398 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.84375
I0128 20:19:53.323441 46007 solver.cpp:262]     Train net output #2: loss = 1.63759 (* 1 = 1.63759 loss)
I0128 20:19:53.323452 46007 sgd_solver.cpp:122] Iteration 314400, lr = 1e-06
I0128 20:22:11.816363 46007 solver.cpp:243] Iteration 314600 (1.44417 iter/s, 138.488s/200 iters), loss = 1.43146
I0128 20:22:11.828122 46007 solver.cpp:262]     Train net output #0: accuracy = 0.621094
I0128 20:22:11.828137 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.863281
I0128 20:22:11.828171 46007 solver.cpp:262]     Train net output #2: loss = 1.43146 (* 1 = 1.43146 loss)
I0128 20:22:11.828181 46007 sgd_solver.cpp:122] Iteration 314600, lr = 1e-06
I0128 20:24:34.935613 46007 solver.cpp:243] Iteration 314800 (1.39761 iter/s, 143.102s/200 iters), loss = 1.77297
I0128 20:24:34.947456 46007 solver.cpp:262]     Train net output #0: accuracy = 0.582031
I0128 20:24:34.947482 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.785156
I0128 20:24:34.947508 46007 solver.cpp:262]     Train net output #2: loss = 1.77297 (* 1 = 1.77297 loss)
I0128 20:24:34.947521 46007 sgd_solver.cpp:122] Iteration 314800, lr = 1e-06
I0128 20:26:53.237831 46007 solver.cpp:385] Iteration 315000, Testing net (#0)
I0128 20:27:06.699108 46007 blocking_queue.cpp:49] Waiting for data
I0128 20:28:41.066469 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0128 20:28:41.116963 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46212
I0128 20:28:41.117007 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.706439
I0128 20:28:41.117035 46007 solver.cpp:454]     Test net output #2: loss = 2.45741 (* 1 = 2.45741 loss)
I0128 20:28:41.117044 46007 solver.cpp:474] ================================
I0128 20:28:41.117049 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0128 20:28:41.117055 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0128 20:28:41.772256 46007 solver.cpp:243] Iteration 315000 (0.810325 iter/s, 246.815s/200 iters), loss = 1.69369
I0128 20:28:41.774647 46007 solver.cpp:262]     Train net output #0: accuracy = 0.601562
I0128 20:28:41.774673 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.820312
I0128 20:28:41.774699 46007 solver.cpp:262]     Train net output #2: loss = 1.69369 (* 1 = 1.69369 loss)
I0128 20:28:41.774713 46007 sgd_solver.cpp:122] Iteration 315000, lr = 1e-06
I0128 20:28:49.708159 46077 data_layer.cpp:73] Restarting data prefetching from start.
I0128 20:30:58.746132 46007 solver.cpp:243] Iteration 315200 (1.46022 iter/s, 136.966s/200 iters), loss = 1.52565
I0128 20:30:58.758044 46007 solver.cpp:262]     Train net output #0: accuracy = 0.660156
I0128 20:30:58.758088 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.851562
I0128 20:30:58.758136 46007 solver.cpp:262]     Train net output #2: loss = 1.52565 (* 1 = 1.52565 loss)
I0128 20:30:58.758167 46007 sgd_solver.cpp:122] Iteration 315200, lr = 1e-06
I0128 20:33:17.538575 46007 solver.cpp:243] Iteration 315400 (1.44118 iter/s, 138.775s/200 iters), loss = 1.73102
I0128 20:33:17.550377 46007 solver.cpp:262]     Train net output #0: accuracy = 0.59375
I0128 20:33:17.550400 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.820312
I0128 20:33:17.550424 46007 solver.cpp:262]     Train net output #2: loss = 1.73102 (* 1 = 1.73102 loss)
I0128 20:33:17.550436 46007 sgd_solver.cpp:122] Iteration 315400, lr = 1e-06
I0128 20:35:34.670176 46007 solver.cpp:243] Iteration 315600 (1.45864 iter/s, 137.114s/200 iters), loss = 1.81149
I0128 20:35:34.681970 46007 solver.cpp:262]     Train net output #0: accuracy = 0.597656
I0128 20:35:34.681993 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.800781
I0128 20:35:34.682032 46007 solver.cpp:262]     Train net output #2: loss = 1.81149 (* 1 = 1.81149 loss)
I0128 20:35:34.682041 46007 sgd_solver.cpp:122] Iteration 315600, lr = 1e-06
I0128 20:37:52.183044 46007 solver.cpp:243] Iteration 315800 (1.45459 iter/s, 137.496s/200 iters), loss = 1.87319
I0128 20:37:52.183164 46007 solver.cpp:262]     Train net output #0: accuracy = 0.550781
I0128 20:37:52.183177 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.789062
I0128 20:37:52.183197 46007 solver.cpp:262]     Train net output #2: loss = 1.87319 (* 1 = 1.87319 loss)
I0128 20:37:52.183210 46007 sgd_solver.cpp:122] Iteration 315800, lr = 1e-06
I0128 20:40:09.167693 46007 solver.cpp:385] Iteration 316000, Testing net (#0)
I0128 20:40:10.205370 46007 blocking_queue.cpp:49] Waiting for data
I0128 20:41:58.604372 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0128 20:41:58.654659 46007 solver.cpp:454]     Test net output #0: accuracy = 0.4613
I0128 20:41:58.654719 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.70816
I0128 20:41:58.654742 46007 solver.cpp:454]     Test net output #2: loss = 2.45906 (* 1 = 2.45906 loss)
I0128 20:41:58.654752 46007 solver.cpp:474] ================================
I0128 20:41:58.654758 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0128 20:41:58.654764 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0128 20:41:59.304155 46007 solver.cpp:243] Iteration 316000 (0.80935 iter/s, 247.112s/200 iters), loss = 1.72451
I0128 20:41:59.306515 46007 solver.cpp:262]     Train net output #0: accuracy = 0.570312
I0128 20:41:59.306557 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.828125
I0128 20:41:59.306599 46007 solver.cpp:262]     Train net output #2: loss = 1.72451 (* 1 = 1.72451 loss)
I0128 20:41:59.306618 46007 sgd_solver.cpp:122] Iteration 316000, lr = 1e-06
I0128 20:44:15.772143 46007 solver.cpp:243] Iteration 316200 (1.46562 iter/s, 136.461s/200 iters), loss = 1.85792
I0128 20:44:15.784056 46007 solver.cpp:262]     Train net output #0: accuracy = 0.566406
I0128 20:44:15.784080 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.792969
I0128 20:44:15.784104 46007 solver.cpp:262]     Train net output #2: loss = 1.85792 (* 1 = 1.85792 loss)
I0128 20:44:15.784116 46007 sgd_solver.cpp:122] Iteration 316200, lr = 1e-06
I0128 20:45:16.353363 46007 blocking_queue.cpp:49] Waiting for data
I0128 20:46:33.417732 46007 solver.cpp:243] Iteration 316400 (1.45319 iter/s, 137.629s/200 iters), loss = 1.62706
I0128 20:46:33.429630 46007 solver.cpp:262]     Train net output #0: accuracy = 0.578125
I0128 20:46:33.429651 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.859375
I0128 20:46:33.429672 46007 solver.cpp:262]     Train net output #2: loss = 1.62706 (* 1 = 1.62706 loss)
I0128 20:46:33.429684 46007 sgd_solver.cpp:122] Iteration 316400, lr = 1e-06
I0128 20:48:50.752950 46007 solver.cpp:243] Iteration 316600 (1.45647 iter/s, 137.318s/200 iters), loss = 1.90407
I0128 20:48:50.764686 46007 solver.cpp:262]     Train net output #0: accuracy = 0.558594
I0128 20:48:50.764700 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.816406
I0128 20:48:50.764736 46007 solver.cpp:262]     Train net output #2: loss = 1.90407 (* 1 = 1.90407 loss)
I0128 20:48:50.764745 46007 sgd_solver.cpp:122] Iteration 316600, lr = 1e-06
I0128 20:51:09.760617 46007 solver.cpp:243] Iteration 316800 (1.43894 iter/s, 138.991s/200 iters), loss = 1.77931
I0128 20:51:09.772481 46007 solver.cpp:262]     Train net output #0: accuracy = 0.585938
I0128 20:51:09.772505 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.785156
I0128 20:51:09.772531 46007 solver.cpp:262]     Train net output #2: loss = 1.77931 (* 1 = 1.77931 loss)
I0128 20:51:09.772542 46007 sgd_solver.cpp:122] Iteration 316800, lr = 1e-06
I0128 20:53:33.912298 46007 solver.cpp:385] Iteration 317000, Testing net (#0)
I0128 20:55:07.035586 46007 blocking_queue.cpp:49] Waiting for data
I0128 20:55:23.584141 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0128 20:55:23.634310 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46422
I0128 20:55:23.634366 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.711859
I0128 20:55:23.634379 46007 solver.cpp:454]     Test net output #2: loss = 2.43227 (* 1 = 2.43227 loss)
I0128 20:55:23.634385 46007 solver.cpp:474] ================================
I0128 20:55:23.634389 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0128 20:55:23.634393 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0128 20:55:24.301678 46007 solver.cpp:243] Iteration 317000 (0.785793 iter/s, 254.52s/200 iters), loss = 1.7097
I0128 20:55:24.304016 46007 solver.cpp:262]     Train net output #0: accuracy = 0.597656
I0128 20:55:24.304049 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.789062
I0128 20:55:24.304085 46007 solver.cpp:262]     Train net output #2: loss = 1.7097 (* 1 = 1.7097 loss)
I0128 20:55:24.304105 46007 sgd_solver.cpp:122] Iteration 317000, lr = 1e-06
I0128 20:57:44.550205 46007 solver.cpp:243] Iteration 317200 (1.42612 iter/s, 140.241s/200 iters), loss = 1.99674
I0128 20:57:44.550334 46007 solver.cpp:262]     Train net output #0: accuracy = 0.554688
I0128 20:57:44.550350 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.789062
I0128 20:57:44.550374 46007 solver.cpp:262]     Train net output #2: loss = 1.99674 (* 1 = 1.99674 loss)
I0128 20:57:44.550386 46007 sgd_solver.cpp:122] Iteration 317200, lr = 1e-06
I0128 21:00:03.062845 46007 solver.cpp:243] Iteration 317400 (1.44397 iter/s, 138.507s/200 iters), loss = 1.89023
I0128 21:00:03.062952 46007 solver.cpp:262]     Train net output #0: accuracy = 0.570312
I0128 21:00:03.062965 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.773438
I0128 21:00:03.062988 46007 solver.cpp:262]     Train net output #2: loss = 1.89023 (* 1 = 1.89023 loss)
I0128 21:00:03.063001 46007 sgd_solver.cpp:122] Iteration 317400, lr = 1e-06
I0128 21:02:22.981513 46007 solver.cpp:243] Iteration 317600 (1.42945 iter/s, 139.913s/200 iters), loss = 1.71199
I0128 21:02:22.993360 46007 solver.cpp:262]     Train net output #0: accuracy = 0.5625
I0128 21:02:22.993376 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.859375
I0128 21:02:22.993402 46007 solver.cpp:262]     Train net output #2: loss = 1.71199 (* 1 = 1.71199 loss)
I0128 21:02:22.993414 46007 sgd_solver.cpp:122] Iteration 317600, lr = 1e-06
I0128 21:04:43.122582 46007 solver.cpp:243] Iteration 317800 (1.42731 iter/s, 140.124s/200 iters), loss = 1.81543
I0128 21:04:43.136281 46007 solver.cpp:262]     Train net output #0: accuracy = 0.585938
I0128 21:04:43.136312 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.789062
I0128 21:04:43.136348 46007 solver.cpp:262]     Train net output #2: loss = 1.81543 (* 1 = 1.81543 loss)
I0128 21:04:43.136366 46007 sgd_solver.cpp:122] Iteration 317800, lr = 1e-06
I0128 21:07:05.604127 46007 solver.cpp:385] Iteration 318000, Testing net (#0)
I0128 21:08:35.274161 46007 blocking_queue.cpp:49] Waiting for data
I0128 21:09:41.874430 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0128 21:09:41.924968 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46466
I0128 21:09:41.925034 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.709599
I0128 21:09:41.925052 46007 solver.cpp:454]     Test net output #2: loss = 2.44318 (* 1 = 2.44318 loss)
I0128 21:09:41.925065 46007 solver.cpp:474] ================================
I0128 21:09:41.925071 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0128 21:09:41.925076 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0128 21:09:42.584239 46007 solver.cpp:243] Iteration 318000 (0.667921 iter/s, 299.437s/200 iters), loss = 1.77074
I0128 21:09:42.584345 46007 solver.cpp:262]     Train net output #0: accuracy = 0.570312
I0128 21:09:42.584367 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.804688
I0128 21:09:42.584394 46007 solver.cpp:262]     Train net output #2: loss = 1.77074 (* 1 = 1.77074 loss)
I0128 21:09:42.584410 46007 sgd_solver.cpp:122] Iteration 318000, lr = 1e-06
I0128 21:12:06.695219 46007 solver.cpp:243] Iteration 318200 (1.38787 iter/s, 144.106s/200 iters), loss = 1.65729
I0128 21:12:06.707015 46007 solver.cpp:262]     Train net output #0: accuracy = 0.625
I0128 21:12:06.707037 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.8125
I0128 21:12:06.707060 46007 solver.cpp:262]     Train net output #2: loss = 1.65729 (* 1 = 1.65729 loss)
I0128 21:12:06.707072 46007 sgd_solver.cpp:122] Iteration 318200, lr = 1e-06
I0128 21:14:31.940481 46007 solver.cpp:243] Iteration 318400 (1.37714 iter/s, 145.228s/200 iters), loss = 1.72054
I0128 21:14:31.952304 46007 solver.cpp:262]     Train net output #0: accuracy = 0.570312
I0128 21:14:31.952325 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.839844
I0128 21:14:31.952368 46007 solver.cpp:262]     Train net output #2: loss = 1.72054 (* 1 = 1.72054 loss)
I0128 21:14:31.952379 46007 sgd_solver.cpp:122] Iteration 318400, lr = 1e-06
I0128 21:16:52.963114 46007 solver.cpp:243] Iteration 318600 (1.41838 iter/s, 141.006s/200 iters), loss = 1.64801
I0128 21:16:52.975071 46007 solver.cpp:262]     Train net output #0: accuracy = 0.597656
I0128 21:16:52.975093 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.828125
I0128 21:16:52.975131 46007 solver.cpp:262]     Train net output #2: loss = 1.64801 (* 1 = 1.64801 loss)
I0128 21:16:52.975142 46007 sgd_solver.cpp:122] Iteration 318600, lr = 1e-06
I0128 21:19:14.090404 46007 solver.cpp:243] Iteration 318800 (1.41733 iter/s, 141.11s/200 iters), loss = 1.68606
I0128 21:19:14.102218 46007 solver.cpp:262]     Train net output #0: accuracy = 0.59375
I0128 21:19:14.102238 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.820312
I0128 21:19:14.102264 46007 solver.cpp:262]     Train net output #2: loss = 1.68606 (* 1 = 1.68606 loss)
I0128 21:19:14.102275 46007 sgd_solver.cpp:122] Iteration 318800, lr = 1e-06
I0128 21:21:32.944989 46007 solver.cpp:385] Iteration 319000, Testing net (#0)
I0128 21:21:48.841158 46007 blocking_queue.cpp:49] Waiting for data
I0128 21:23:24.396304 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0128 21:23:24.446625 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46386
I0128 21:23:24.446674 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.70928
I0128 21:23:24.446696 46007 solver.cpp:454]     Test net output #2: loss = 2.43933 (* 1 = 2.43933 loss)
I0128 21:23:24.446713 46007 solver.cpp:474] ================================
I0128 21:23:24.446718 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0128 21:23:24.446723 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0128 21:23:25.108892 46007 solver.cpp:243] Iteration 319000 (0.796821 iter/s, 250.998s/200 iters), loss = 1.56858
I0128 21:23:25.111328 46007 solver.cpp:262]     Train net output #0: accuracy = 0.625
I0128 21:23:25.111364 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.832031
I0128 21:23:25.111403 46007 solver.cpp:262]     Train net output #2: loss = 1.56858 (* 1 = 1.56858 loss)
I0128 21:23:25.111415 46007 sgd_solver.cpp:122] Iteration 319000, lr = 1e-06
I0128 21:25:45.190702 46007 solver.cpp:243] Iteration 319200 (1.42781 iter/s, 140.074s/200 iters), loss = 1.70912
I0128 21:25:45.202579 46007 solver.cpp:262]     Train net output #0: accuracy = 0.597656
I0128 21:25:45.202603 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.796875
I0128 21:25:45.202625 46007 solver.cpp:262]     Train net output #2: loss = 1.70912 (* 1 = 1.70912 loss)
I0128 21:25:45.202636 46007 sgd_solver.cpp:122] Iteration 319200, lr = 1e-06
I0128 21:27:41.962388 46007 blocking_queue.cpp:49] Waiting for data
I0128 21:28:09.669679 46007 solver.cpp:243] Iteration 319400 (1.38445 iter/s, 144.462s/200 iters), loss = 1.51717
I0128 21:28:09.669781 46007 solver.cpp:262]     Train net output #0: accuracy = 0.640625
I0128 21:28:09.669792 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.8125
I0128 21:28:09.669812 46007 solver.cpp:262]     Train net output #2: loss = 1.51717 (* 1 = 1.51717 loss)
I0128 21:28:09.669824 46007 sgd_solver.cpp:122] Iteration 319400, lr = 1e-06
I0128 21:30:30.778031 46007 solver.cpp:243] Iteration 319600 (1.4174 iter/s, 141.103s/200 iters), loss = 1.70978
I0128 21:30:30.790014 46007 solver.cpp:262]     Train net output #0: accuracy = 0.589844
I0128 21:30:30.790037 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.808594
I0128 21:30:30.790060 46007 solver.cpp:262]     Train net output #2: loss = 1.70978 (* 1 = 1.70978 loss)
I0128 21:30:30.790071 46007 sgd_solver.cpp:122] Iteration 319600, lr = 1e-06
I0128 21:32:54.257484 46007 solver.cpp:243] Iteration 319800 (1.39409 iter/s, 143.462s/200 iters), loss = 1.53344
I0128 21:32:54.269379 46007 solver.cpp:262]     Train net output #0: accuracy = 0.636719
I0128 21:32:54.269402 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.863281
I0128 21:32:54.269441 46007 solver.cpp:262]     Train net output #2: loss = 1.53344 (* 1 = 1.53344 loss)
I0128 21:32:54.269453 46007 sgd_solver.cpp:122] Iteration 319800, lr = 1e-06
I0128 21:35:18.771056 46007 solver.cpp:525] Snapshotting to binary proto file snapshot/solver_iter_320000.caffemodel
I0128 21:35:18.771124 46007 net.cpp:929] Serializing 41 layers
I0128 21:35:32.192507 46007 sgd_solver.cpp:311] Snapshotting solver state to binary proto file snapshot/solver_iter_320000.solverstate
I0128 21:35:35.639816 46007 solver.cpp:385] Iteration 320000, Testing net (#0)
I0128 21:37:24.299813 46007 blocking_queue.cpp:49] Waiting for data
I0128 21:38:07.054555 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0128 21:38:07.104734 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46498
I0128 21:38:07.104790 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.70958
I0128 21:38:07.104818 46007 solver.cpp:454]     Test net output #2: loss = 2.44027 (* 1 = 2.44027 loss)
I0128 21:38:07.104828 46007 solver.cpp:474] ================================
I0128 21:38:07.104835 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0128 21:38:07.104841 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0128 21:38:07.759881 46007 solver.cpp:243] Iteration 320000 (0.638001 iter/s, 313.479s/200 iters), loss = 1.92679
I0128 21:38:07.762287 46007 solver.cpp:262]     Train net output #0: accuracy = 0.519531
I0128 21:38:07.762313 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.773438
I0128 21:38:07.762358 46007 solver.cpp:262]     Train net output #2: loss = 1.92679 (* 1 = 1.92679 loss)
I0128 21:38:07.762373 46007 sgd_solver.cpp:122] Iteration 320000, lr = 1e-06
I0128 21:38:18.734815 46077 data_layer.cpp:73] Restarting data prefetching from start.
I0128 21:40:28.952786 46007 solver.cpp:243] Iteration 320200 (1.41658 iter/s, 141.185s/200 iters), loss = 1.81033
I0128 21:40:28.964627 46007 solver.cpp:262]     Train net output #0: accuracy = 0.574219
I0128 21:40:28.964650 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.804688
I0128 21:40:28.964689 46007 solver.cpp:262]     Train net output #2: loss = 1.81033 (* 1 = 1.81033 loss)
I0128 21:40:28.964701 46007 sgd_solver.cpp:122] Iteration 320200, lr = 1e-06
I0128 21:42:51.570395 46007 solver.cpp:243] Iteration 320400 (1.40252 iter/s, 142.6s/200 iters), loss = 1.58819
I0128 21:42:51.570489 46007 solver.cpp:262]     Train net output #0: accuracy = 0.59375
I0128 21:42:51.570502 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.875
I0128 21:42:51.570523 46007 solver.cpp:262]     Train net output #2: loss = 1.58819 (* 1 = 1.58819 loss)
I0128 21:42:51.570535 46007 sgd_solver.cpp:122] Iteration 320400, lr = 1e-06
I0128 21:45:10.739120 46007 solver.cpp:243] Iteration 320600 (1.43716 iter/s, 139.163s/200 iters), loss = 1.6919
I0128 21:45:10.751296 46007 solver.cpp:262]     Train net output #0: accuracy = 0.585938
I0128 21:45:10.751322 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.828125
I0128 21:45:10.751350 46007 solver.cpp:262]     Train net output #2: loss = 1.6919 (* 1 = 1.6919 loss)
I0128 21:45:10.751372 46007 sgd_solver.cpp:122] Iteration 320600, lr = 1e-06
I0128 21:47:33.740942 46007 solver.cpp:243] Iteration 320800 (1.39875 iter/s, 142.984s/200 iters), loss = 1.71354
I0128 21:47:33.752722 46007 solver.cpp:262]     Train net output #0: accuracy = 0.566406
I0128 21:47:33.752737 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.835938
I0128 21:47:33.752774 46007 solver.cpp:262]     Train net output #2: loss = 1.71354 (* 1 = 1.71354 loss)
I0128 21:47:33.752784 46007 sgd_solver.cpp:122] Iteration 320800, lr = 1e-06
I0128 21:49:53.762042 46007 solver.cpp:385] Iteration 321000, Testing net (#0)
I0128 21:50:55.119271 46007 blocking_queue.cpp:49] Waiting for data
I0128 21:52:59.814242 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0128 21:52:59.864531 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46128
I0128 21:52:59.864564 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.70914
I0128 21:52:59.864576 46007 solver.cpp:454]     Test net output #2: loss = 2.44565 (* 1 = 2.44565 loss)
I0128 21:52:59.864583 46007 solver.cpp:474] ================================
I0128 21:52:59.864586 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0128 21:52:59.864590 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0128 21:53:00.519485 46007 solver.cpp:243] Iteration 321000 (0.61208 iter/s, 326.755s/200 iters), loss = 1.81751
I0128 21:53:00.521848 46007 solver.cpp:262]     Train net output #0: accuracy = 0.523438
I0128 21:53:00.521875 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.828125
I0128 21:53:00.521901 46007 solver.cpp:262]     Train net output #2: loss = 1.81751 (* 1 = 1.81751 loss)
I0128 21:53:00.521925 46007 sgd_solver.cpp:122] Iteration 321000, lr = 1e-06
I0128 21:55:18.751606 46007 solver.cpp:243] Iteration 321200 (1.44692 iter/s, 138.225s/200 iters), loss = 1.67543
I0128 21:55:18.763414 46007 solver.cpp:262]     Train net output #0: accuracy = 0.605469
I0128 21:55:18.763438 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.816406
I0128 21:55:18.763461 46007 solver.cpp:262]     Train net output #2: loss = 1.67543 (* 1 = 1.67543 loss)
I0128 21:55:18.763473 46007 sgd_solver.cpp:122] Iteration 321200, lr = 1e-06
I0128 21:57:39.136166 46007 solver.cpp:243] Iteration 321400 (1.42483 iter/s, 140.368s/200 iters), loss = 1.58621
I0128 21:57:39.136253 46007 solver.cpp:262]     Train net output #0: accuracy = 0.617188
I0128 21:57:39.136265 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.84375
I0128 21:57:39.136286 46007 solver.cpp:262]     Train net output #2: loss = 1.58621 (* 1 = 1.58621 loss)
I0128 21:57:39.136299 46007 sgd_solver.cpp:122] Iteration 321400, lr = 1e-06
I0128 22:00:00.945380 46007 solver.cpp:243] Iteration 321600 (1.41039 iter/s, 141.805s/200 iters), loss = 1.88938
I0128 22:00:00.957126 46007 solver.cpp:262]     Train net output #0: accuracy = 0.566406
I0128 22:00:00.957141 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.761719
I0128 22:00:00.957177 46007 solver.cpp:262]     Train net output #2: loss = 1.88938 (* 1 = 1.88938 loss)
I0128 22:00:00.957188 46007 sgd_solver.cpp:122] Iteration 321600, lr = 1e-06
I0128 22:02:20.475041 46007 solver.cpp:243] Iteration 321800 (1.43355 iter/s, 139.513s/200 iters), loss = 1.71179
I0128 22:02:20.486861 46007 solver.cpp:262]     Train net output #0: accuracy = 0.585938
I0128 22:02:20.486876 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.785156
I0128 22:02:20.486912 46007 solver.cpp:262]     Train net output #2: loss = 1.71179 (* 1 = 1.71179 loss)
I0128 22:02:20.486922 46007 sgd_solver.cpp:122] Iteration 321800, lr = 1e-06
I0128 22:04:16.931293 46007 blocking_queue.cpp:49] Waiting for data
I0128 22:04:41.333339 46007 solver.cpp:385] Iteration 322000, Testing net (#0)
I0128 22:06:31.705030 46007 blocking_queue.cpp:49] Waiting for data
I0128 22:06:33.011498 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0128 22:06:33.061759 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46298
I0128 22:06:33.061807 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.71188
I0128 22:06:33.061825 46007 solver.cpp:454]     Test net output #2: loss = 2.43587 (* 1 = 2.43587 loss)
I0128 22:06:33.061833 46007 solver.cpp:474] ================================
I0128 22:06:33.061838 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0128 22:06:33.061843 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0128 22:06:33.726047 46007 solver.cpp:243] Iteration 322000 (0.789792 iter/s, 253.231s/200 iters), loss = 1.89539
I0128 22:06:33.728633 46007 solver.cpp:262]     Train net output #0: accuracy = 0.574219
I0128 22:06:33.728659 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.785156
I0128 22:06:33.728685 46007 solver.cpp:262]     Train net output #2: loss = 1.89539 (* 1 = 1.89539 loss)
I0128 22:06:33.728698 46007 sgd_solver.cpp:122] Iteration 322000, lr = 1e-06
I0128 22:08:58.930311 46007 solver.cpp:243] Iteration 322200 (1.37744 iter/s, 145.197s/200 iters), loss = 1.54595
I0128 22:08:58.930457 46007 solver.cpp:262]     Train net output #0: accuracy = 0.613281
I0128 22:08:58.930470 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.878906
I0128 22:08:58.930490 46007 solver.cpp:262]     Train net output #2: loss = 1.54595 (* 1 = 1.54595 loss)
I0128 22:08:58.930501 46007 sgd_solver.cpp:122] Iteration 322200, lr = 1e-06
I0128 22:11:22.141155 46007 solver.cpp:243] Iteration 322400 (1.39659 iter/s, 143.206s/200 iters), loss = 1.53582
I0128 22:11:22.152899 46007 solver.cpp:262]     Train net output #0: accuracy = 0.621094
I0128 22:11:22.152926 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.851562
I0128 22:11:22.152952 46007 solver.cpp:262]     Train net output #2: loss = 1.53582 (* 1 = 1.53582 loss)
I0128 22:11:22.152961 46007 sgd_solver.cpp:122] Iteration 322400, lr = 1e-06
I0128 22:13:45.321144 46007 solver.cpp:243] Iteration 322600 (1.397 iter/s, 143.163s/200 iters), loss = 1.69304
I0128 22:13:45.332901 46007 solver.cpp:262]     Train net output #0: accuracy = 0.582031
I0128 22:13:45.332957 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.824219
I0128 22:13:45.332980 46007 solver.cpp:262]     Train net output #2: loss = 1.69304 (* 1 = 1.69304 loss)
I0128 22:13:45.332994 46007 sgd_solver.cpp:122] Iteration 322600, lr = 1e-06
I0128 22:16:11.286641 46007 solver.cpp:243] Iteration 322800 (1.37035 iter/s, 145.948s/200 iters), loss = 1.7358
I0128 22:16:11.298401 46007 solver.cpp:262]     Train net output #0: accuracy = 0.597656
I0128 22:16:11.298429 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.835938
I0128 22:16:11.298470 46007 solver.cpp:262]     Train net output #2: loss = 1.7358 (* 1 = 1.7358 loss)
I0128 22:16:11.298487 46007 sgd_solver.cpp:122] Iteration 322800, lr = 1e-06
I0128 22:18:28.740659 46007 solver.cpp:385] Iteration 323000, Testing net (#0)
I0128 22:21:04.359174 46007 blocking_queue.cpp:49] Waiting for data
I0128 22:22:34.349367 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0128 22:22:34.399278 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46478
I0128 22:22:34.399324 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.710579
I0128 22:22:34.399336 46007 solver.cpp:454]     Test net output #2: loss = 2.43504 (* 1 = 2.43504 loss)
I0128 22:22:34.399345 46007 solver.cpp:474] ================================
I0128 22:22:34.399349 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0128 22:22:34.399353 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0128 22:22:35.054330 46007 solver.cpp:243] Iteration 323000 (0.521184 iter/s, 383.742s/200 iters), loss = 1.67333
I0128 22:22:35.056792 46007 solver.cpp:262]     Train net output #0: accuracy = 0.605469
I0128 22:22:35.056819 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.8125
I0128 22:22:35.056843 46007 solver.cpp:262]     Train net output #2: loss = 1.67333 (* 1 = 1.67333 loss)
I0128 22:22:35.056857 46007 sgd_solver.cpp:122] Iteration 323000, lr = 1e-06
I0128 22:24:53.806061 46007 solver.cpp:243] Iteration 323200 (1.4415 iter/s, 138.744s/200 iters), loss = 1.66204
I0128 22:24:53.817845 46007 solver.cpp:262]     Train net output #0: accuracy = 0.609375
I0128 22:24:53.817883 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.84375
I0128 22:24:53.817924 46007 solver.cpp:262]     Train net output #2: loss = 1.66204 (* 1 = 1.66204 loss)
I0128 22:24:53.817939 46007 sgd_solver.cpp:122] Iteration 323200, lr = 1e-06
I0128 22:27:17.984266 46007 solver.cpp:243] Iteration 323400 (1.38734 iter/s, 144.161s/200 iters), loss = 1.70847
I0128 22:27:17.984374 46007 solver.cpp:262]     Train net output #0: accuracy = 0.601562
I0128 22:27:17.984390 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.816406
I0128 22:27:17.984411 46007 solver.cpp:262]     Train net output #2: loss = 1.70847 (* 1 = 1.70847 loss)
I0128 22:27:17.984423 46007 sgd_solver.cpp:122] Iteration 323400, lr = 1e-06
I0128 22:29:36.870857 46007 solver.cpp:243] Iteration 323600 (1.44008 iter/s, 138.881s/200 iters), loss = 1.65967
I0128 22:29:36.870968 46007 solver.cpp:262]     Train net output #0: accuracy = 0.636719
I0128 22:29:36.870980 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.816406
I0128 22:29:36.871008 46007 solver.cpp:262]     Train net output #2: loss = 1.65967 (* 1 = 1.65967 loss)
I0128 22:29:36.871021 46007 sgd_solver.cpp:122] Iteration 323600, lr = 1e-06
I0128 22:31:56.354621 46007 solver.cpp:243] Iteration 323800 (1.43391 iter/s, 139.478s/200 iters), loss = 1.64657
I0128 22:31:56.366441 46007 solver.cpp:262]     Train net output #0: accuracy = 0.621094
I0128 22:31:56.366463 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.824219
I0128 22:31:56.366490 46007 solver.cpp:262]     Train net output #2: loss = 1.64657 (* 1 = 1.64657 loss)
I0128 22:31:56.366503 46007 sgd_solver.cpp:122] Iteration 323800, lr = 1e-06
I0128 22:34:16.032572 46007 solver.cpp:385] Iteration 324000, Testing net (#0)
I0128 22:35:31.911970 46007 blocking_queue.cpp:49] Waiting for data
I0128 22:38:18.992743 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0128 22:38:19.042333 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46616
I0128 22:38:19.042399 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.709239
I0128 22:38:19.042418 46007 solver.cpp:454]     Test net output #2: loss = 2.43715 (* 1 = 2.43715 loss)
I0128 22:38:19.042428 46007 solver.cpp:474] ================================
I0128 22:38:19.042433 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0128 22:38:19.042438 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0128 22:38:19.699041 46007 solver.cpp:243] Iteration 324000 (0.521759 iter/s, 383.319s/200 iters), loss = 1.65281
I0128 22:38:19.701362 46007 solver.cpp:262]     Train net output #0: accuracy = 0.578125
I0128 22:38:19.701388 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.816406
I0128 22:38:19.701414 46007 solver.cpp:262]     Train net output #2: loss = 1.65281 (* 1 = 1.65281 loss)
I0128 22:38:19.701431 46007 sgd_solver.cpp:122] Iteration 324000, lr = 1e-06
I0128 22:40:35.288375 46007 solver.cpp:243] Iteration 324200 (1.47512 iter/s, 135.582s/200 iters), loss = 1.77985
I0128 22:40:35.288471 46007 solver.cpp:262]     Train net output #0: accuracy = 0.542969
I0128 22:40:35.288482 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.796875
I0128 22:40:35.288496 46007 solver.cpp:262]     Train net output #2: loss = 1.77985 (* 1 = 1.77985 loss)
I0128 22:40:35.288507 46007 sgd_solver.cpp:122] Iteration 324200, lr = 1e-06
I0128 22:42:53.176872 46007 solver.cpp:243] Iteration 324400 (1.4505 iter/s, 137.883s/200 iters), loss = 1.59286
I0128 22:42:53.188771 46007 solver.cpp:262]     Train net output #0: accuracy = 0.617188
I0128 22:42:53.188798 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.847656
I0128 22:42:53.188830 46007 solver.cpp:262]     Train net output #2: loss = 1.59286 (* 1 = 1.59286 loss)
I0128 22:42:53.188845 46007 sgd_solver.cpp:122] Iteration 324400, lr = 1e-06
I0128 22:45:11.336844 46007 solver.cpp:243] Iteration 324600 (1.44778 iter/s, 138.143s/200 iters), loss = 1.69152
I0128 22:45:11.348678 46007 solver.cpp:262]     Train net output #0: accuracy = 0.585938
I0128 22:45:11.348703 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.839844
I0128 22:45:11.348729 46007 solver.cpp:262]     Train net output #2: loss = 1.69152 (* 1 = 1.69152 loss)
I0128 22:45:11.348740 46007 sgd_solver.cpp:122] Iteration 324600, lr = 1e-06
I0128 22:47:31.781428 46007 solver.cpp:243] Iteration 324800 (1.42422 iter/s, 140.428s/200 iters), loss = 1.76609
I0128 22:47:31.793275 46007 solver.cpp:262]     Train net output #0: accuracy = 0.617188
I0128 22:47:31.793292 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.84375
I0128 22:47:31.793315 46007 solver.cpp:262]     Train net output #2: loss = 1.76609 (* 1 = 1.76609 loss)
I0128 22:47:31.793326 46007 sgd_solver.cpp:122] Iteration 324800, lr = 1e-06
I0128 22:49:47.714071 46007 solver.cpp:385] Iteration 325000, Testing net (#0)
I0128 22:50:28.138437 46007 blocking_queue.cpp:49] Waiting for data
I0128 22:53:49.782136 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0128 22:53:49.840277 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46306
I0128 22:53:49.840330 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.706899
I0128 22:53:49.840351 46007 solver.cpp:454]     Test net output #2: loss = 2.45385 (* 1 = 2.45385 loss)
I0128 22:53:49.840361 46007 solver.cpp:474] ================================
I0128 22:53:49.840368 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0128 22:53:49.840375 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0128 22:53:50.493430 46007 solver.cpp:243] Iteration 325000 (0.528142 iter/s, 378.686s/200 iters), loss = 1.65153
I0128 22:53:50.495725 46007 solver.cpp:262]     Train net output #0: accuracy = 0.613281
I0128 22:53:50.495751 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.828125
I0128 22:53:50.495787 46007 solver.cpp:262]     Train net output #2: loss = 1.65153 (* 1 = 1.65153 loss)
I0128 22:53:50.495803 46007 sgd_solver.cpp:122] Iteration 325000, lr = 1e-06
I0128 22:54:03.116760 46077 data_layer.cpp:73] Restarting data prefetching from start.
I0128 22:56:10.380726 46007 solver.cpp:243] Iteration 325200 (1.4298 iter/s, 139.88s/200 iters), loss = 1.83429
I0128 22:56:10.380842 46007 solver.cpp:262]     Train net output #0: accuracy = 0.535156
I0128 22:56:10.380859 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.800781
I0128 22:56:10.380893 46007 solver.cpp:262]     Train net output #2: loss = 1.83429 (* 1 = 1.83429 loss)
I0128 22:56:10.380914 46007 sgd_solver.cpp:122] Iteration 325200, lr = 1e-06
I0128 22:57:50.557587 46007 blocking_queue.cpp:49] Waiting for data
I0128 22:58:42.297014 46007 solver.cpp:243] Iteration 325400 (1.31656 iter/s, 151.911s/200 iters), loss = 1.82507
I0128 22:58:42.308790 46007 solver.cpp:262]     Train net output #0: accuracy = 0.546875
I0128 22:58:42.308832 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.808594
I0128 22:58:42.308892 46007 solver.cpp:262]     Train net output #2: loss = 1.82507 (* 1 = 1.82507 loss)
I0128 22:58:42.308908 46007 sgd_solver.cpp:122] Iteration 325400, lr = 1e-06
I0128 23:01:21.228022 46007 solver.cpp:243] Iteration 325600 (1.25855 iter/s, 158.913s/200 iters), loss = 1.66728
I0128 23:01:21.239780 46007 solver.cpp:262]     Train net output #0: accuracy = 0.597656
I0128 23:01:21.239830 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.839844
I0128 23:01:21.239861 46007 solver.cpp:262]     Train net output #2: loss = 1.66728 (* 1 = 1.66728 loss)
I0128 23:01:21.239874 46007 sgd_solver.cpp:122] Iteration 325600, lr = 1e-06
I0128 23:03:46.188231 46007 solver.cpp:243] Iteration 325800 (1.37985 iter/s, 144.943s/200 iters), loss = 1.91411
I0128 23:03:46.200008 46007 solver.cpp:262]     Train net output #0: accuracy = 0.539062
I0128 23:03:46.200040 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.785156
I0128 23:03:46.200083 46007 solver.cpp:262]     Train net output #2: loss = 1.91411 (* 1 = 1.91411 loss)
I0128 23:03:46.200095 46007 sgd_solver.cpp:122] Iteration 325800, lr = 1e-06
I0128 23:06:13.602443 46007 solver.cpp:385] Iteration 326000, Testing net (#0)
I0128 23:09:20.230268 46007 blocking_queue.cpp:49] Waiting for data
I0128 23:10:22.205754 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0128 23:10:22.255964 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46426
I0128 23:10:22.256014 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.70848
I0128 23:10:22.256042 46007 solver.cpp:454]     Test net output #2: loss = 2.44269 (* 1 = 2.44269 loss)
I0128 23:10:22.256052 46007 solver.cpp:474] ================================
I0128 23:10:22.256057 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0128 23:10:22.256063 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0128 23:10:22.904878 46007 solver.cpp:243] Iteration 326000 (0.504172 iter/s, 396.69s/200 iters), loss = 1.75108
I0128 23:10:22.907238 46007 solver.cpp:262]     Train net output #0: accuracy = 0.589844
I0128 23:10:22.907265 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.828125
I0128 23:10:22.907284 46007 solver.cpp:262]     Train net output #2: loss = 1.75108 (* 1 = 1.75108 loss)
I0128 23:10:22.907297 46007 sgd_solver.cpp:122] Iteration 326000, lr = 1e-06
I0128 23:12:38.885952 46007 solver.cpp:243] Iteration 326200 (1.47087 iter/s, 135.974s/200 iters), loss = 1.78149
I0128 23:12:38.897869 46007 solver.cpp:262]     Train net output #0: accuracy = 0.589844
I0128 23:12:38.897892 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.789062
I0128 23:12:38.897918 46007 solver.cpp:262]     Train net output #2: loss = 1.78149 (* 1 = 1.78149 loss)
I0128 23:12:38.897930 46007 sgd_solver.cpp:122] Iteration 326200, lr = 1e-06
I0128 23:15:03.683076 46007 solver.cpp:243] Iteration 326400 (1.38141 iter/s, 144.78s/200 iters), loss = 1.87069
I0128 23:15:03.683169 46007 solver.cpp:262]     Train net output #0: accuracy = 0.578125
I0128 23:15:03.683182 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.804688
I0128 23:15:03.683202 46007 solver.cpp:262]     Train net output #2: loss = 1.87069 (* 1 = 1.87069 loss)
I0128 23:15:03.683212 46007 sgd_solver.cpp:122] Iteration 326400, lr = 1e-06
I0128 23:17:26.390637 46007 solver.cpp:243] Iteration 326600 (1.40152 iter/s, 142.702s/200 iters), loss = 1.44915
I0128 23:17:26.402416 46007 solver.cpp:262]     Train net output #0: accuracy = 0.660156
I0128 23:17:26.402432 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.875
I0128 23:17:26.402456 46007 solver.cpp:262]     Train net output #2: loss = 1.44915 (* 1 = 1.44915 loss)
I0128 23:17:26.402467 46007 sgd_solver.cpp:122] Iteration 326600, lr = 1e-06
I0128 23:19:51.499974 46007 solver.cpp:243] Iteration 326800 (1.37843 iter/s, 145.092s/200 iters), loss = 1.91579
I0128 23:19:51.500087 46007 solver.cpp:262]     Train net output #0: accuracy = 0.542969
I0128 23:19:51.500100 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.769531
I0128 23:19:51.500126 46007 solver.cpp:262]     Train net output #2: loss = 1.91579 (* 1 = 1.91579 loss)
I0128 23:19:51.500145 46007 sgd_solver.cpp:122] Iteration 326800, lr = 1e-06
I0128 23:22:14.979409 46007 solver.cpp:385] Iteration 327000, Testing net (#0)
I0128 23:24:24.028337 46007 blocking_queue.cpp:49] Waiting for data
I0128 23:26:12.431085 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0128 23:26:12.481182 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46074
I0128 23:26:12.481227 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.70758
I0128 23:26:12.481246 46007 solver.cpp:454]     Test net output #2: loss = 2.44986 (* 1 = 2.44986 loss)
I0128 23:26:12.481256 46007 solver.cpp:474] ================================
I0128 23:26:12.481262 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0128 23:26:12.481269 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0128 23:26:13.137598 46007 solver.cpp:243] Iteration 327000 (0.524077 iter/s, 381.623s/200 iters), loss = 1.7484
I0128 23:26:13.137671 46007 solver.cpp:262]     Train net output #0: accuracy = 0.589844
I0128 23:26:13.137683 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.828125
I0128 23:26:13.137706 46007 solver.cpp:262]     Train net output #2: loss = 1.7484 (* 1 = 1.7484 loss)
I0128 23:26:13.137720 46007 sgd_solver.cpp:122] Iteration 327000, lr = 1e-06
I0128 23:28:29.100216 46007 solver.cpp:243] Iteration 327200 (1.47105 iter/s, 135.957s/200 iters), loss = 1.60897
I0128 23:28:29.111977 46007 solver.cpp:262]     Train net output #0: accuracy = 0.589844
I0128 23:28:29.112001 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.828125
I0128 23:28:29.112032 46007 solver.cpp:262]     Train net output #2: loss = 1.60897 (* 1 = 1.60897 loss)
I0128 23:28:29.112051 46007 sgd_solver.cpp:122] Iteration 327200, lr = 1e-06
I0128 23:30:48.953337 46007 solver.cpp:243] Iteration 327400 (1.43025 iter/s, 139.836s/200 iters), loss = 1.77487
I0128 23:30:48.965258 46007 solver.cpp:262]     Train net output #0: accuracy = 0.585938
I0128 23:30:48.965272 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.816406
I0128 23:30:48.965288 46007 solver.cpp:262]     Train net output #2: loss = 1.77487 (* 1 = 1.77487 loss)
I0128 23:30:48.965298 46007 sgd_solver.cpp:122] Iteration 327400, lr = 1e-06
I0128 23:33:12.462188 46007 solver.cpp:243] Iteration 327600 (1.39381 iter/s, 143.491s/200 iters), loss = 1.73501
I0128 23:33:12.474020 46007 solver.cpp:262]     Train net output #0: accuracy = 0.546875
I0128 23:33:12.474035 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.796875
I0128 23:33:12.474071 46007 solver.cpp:262]     Train net output #2: loss = 1.73501 (* 1 = 1.73501 loss)
I0128 23:33:12.474099 46007 sgd_solver.cpp:122] Iteration 327600, lr = 1e-06
I0128 23:35:41.950800 46007 solver.cpp:243] Iteration 327800 (1.33805 iter/s, 149.471s/200 iters), loss = 1.68609
I0128 23:35:41.950898 46007 solver.cpp:262]     Train net output #0: accuracy = 0.601562
I0128 23:35:41.950913 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.808594
I0128 23:35:41.950939 46007 solver.cpp:262]     Train net output #2: loss = 1.68609 (* 1 = 1.68609 loss)
I0128 23:35:41.950950 46007 sgd_solver.cpp:122] Iteration 327800, lr = 1e-06
I0128 23:38:10.240725 46007 solver.cpp:385] Iteration 328000, Testing net (#0)
I0128 23:38:30.118572 46007 blocking_queue.cpp:49] Waiting for data
I0128 23:42:29.601706 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0128 23:42:29.673743 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46232
I0128 23:42:29.673776 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.708419
I0128 23:42:29.673787 46007 solver.cpp:454]     Test net output #2: loss = 2.44971 (* 1 = 2.44971 loss)
I0128 23:42:29.673792 46007 solver.cpp:474] ================================
I0128 23:42:29.673795 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0128 23:42:29.673799 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0128 23:42:30.327029 46007 solver.cpp:243] Iteration 328000 (0.489763 iter/s, 408.361s/200 iters), loss = 1.41879
I0128 23:42:30.327105 46007 solver.cpp:262]     Train net output #0: accuracy = 0.679688
I0128 23:42:30.327116 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.863281
I0128 23:42:30.327132 46007 solver.cpp:262]     Train net output #2: loss = 1.41879 (* 1 = 1.41879 loss)
I0128 23:42:30.327144 46007 sgd_solver.cpp:122] Iteration 328000, lr = 1e-06
I0128 23:44:46.626500 46007 solver.cpp:243] Iteration 328200 (1.46741 iter/s, 136.294s/200 iters), loss = 1.59999
I0128 23:44:46.638396 46007 solver.cpp:262]     Train net output #0: accuracy = 0.648438
I0128 23:44:46.638450 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.820312
I0128 23:44:46.638495 46007 solver.cpp:262]     Train net output #2: loss = 1.59999 (* 1 = 1.59999 loss)
I0128 23:44:46.638515 46007 sgd_solver.cpp:122] Iteration 328200, lr = 1e-06
I0128 23:47:03.609194 46007 solver.cpp:243] Iteration 328400 (1.46022 iter/s, 136.966s/200 iters), loss = 1.70228
I0128 23:47:03.609333 46007 solver.cpp:262]     Train net output #0: accuracy = 0.578125
I0128 23:47:03.609360 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.847656
I0128 23:47:03.609438 46007 solver.cpp:262]     Train net output #2: loss = 1.70228 (* 1 = 1.70228 loss)
I0128 23:47:03.609463 46007 sgd_solver.cpp:122] Iteration 328400, lr = 1e-06
I0128 23:49:22.725845 46007 solver.cpp:243] Iteration 328600 (1.4377 iter/s, 139.111s/200 iters), loss = 1.84997
I0128 23:49:22.737685 46007 solver.cpp:262]     Train net output #0: accuracy = 0.566406
I0128 23:49:22.737711 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.75
I0128 23:49:22.737733 46007 solver.cpp:262]     Train net output #2: loss = 1.84997 (* 1 = 1.84997 loss)
I0128 23:49:22.737745 46007 sgd_solver.cpp:122] Iteration 328600, lr = 1e-06
I0128 23:50:29.345798 46007 blocking_queue.cpp:49] Waiting for data
I0128 23:51:53.163894 46007 solver.cpp:243] Iteration 328800 (1.32961 iter/s, 150.421s/200 iters), loss = 1.77198
I0128 23:51:53.163992 46007 solver.cpp:262]     Train net output #0: accuracy = 0.566406
I0128 23:51:53.164006 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.816406
I0128 23:51:53.164031 46007 solver.cpp:262]     Train net output #2: loss = 1.77198 (* 1 = 1.77198 loss)
I0128 23:51:53.164047 46007 sgd_solver.cpp:122] Iteration 328800, lr = 1e-06
I0128 23:54:12.967025 46007 solver.cpp:385] Iteration 329000, Testing net (#0)
I0128 23:57:58.373874 46007 blocking_queue.cpp:49] Waiting for data
I0128 23:58:16.169979 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0128 23:58:16.220059 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46042
I0128 23:58:16.220124 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.70828
I0128 23:58:16.220141 46007 solver.cpp:454]     Test net output #2: loss = 2.45562 (* 1 = 2.45562 loss)
I0128 23:58:16.220155 46007 solver.cpp:474] ================================
I0128 23:58:16.220160 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0128 23:58:16.220166 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0128 23:58:16.884416 46007 solver.cpp:243] Iteration 329000 (0.521232 iter/s, 383.706s/200 iters), loss = 1.85605
I0128 23:58:16.886750 46007 solver.cpp:262]     Train net output #0: accuracy = 0.585938
I0128 23:58:16.886778 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.800781
I0128 23:58:16.886807 46007 solver.cpp:262]     Train net output #2: loss = 1.85605 (* 1 = 1.85605 loss)
I0128 23:58:16.886819 46007 sgd_solver.cpp:122] Iteration 329000, lr = 1e-06
I0129 00:00:50.321725 46007 solver.cpp:243] Iteration 329200 (1.30353 iter/s, 153.43s/200 iters), loss = 1.72237
I0129 00:00:50.333439 46007 solver.cpp:262]     Train net output #0: accuracy = 0.601562
I0129 00:00:50.333467 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.816406
I0129 00:00:50.333493 46007 solver.cpp:262]     Train net output #2: loss = 1.72237 (* 1 = 1.72237 loss)
I0129 00:00:50.333504 46007 sgd_solver.cpp:122] Iteration 329200, lr = 1e-06
I0129 00:03:34.003414 46007 solver.cpp:243] Iteration 329400 (1.22201 iter/s, 163.664s/200 iters), loss = 1.78679
I0129 00:03:34.003535 46007 solver.cpp:262]     Train net output #0: accuracy = 0.609375
I0129 00:03:34.003548 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.832031
I0129 00:03:34.003618 46007 solver.cpp:262]     Train net output #2: loss = 1.78679 (* 1 = 1.78679 loss)
I0129 00:03:34.003638 46007 sgd_solver.cpp:122] Iteration 329400, lr = 1e-06
I0129 00:06:13.030110 46007 solver.cpp:243] Iteration 329600 (1.2577 iter/s, 159.021s/200 iters), loss = 1.31085
I0129 00:06:13.042089 46007 solver.cpp:262]     Train net output #0: accuracy = 0.648438
I0129 00:06:13.042115 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.902344
I0129 00:06:13.042140 46007 solver.cpp:262]     Train net output #2: loss = 1.31085 (* 1 = 1.31085 loss)
I0129 00:06:13.042152 46007 sgd_solver.cpp:122] Iteration 329600, lr = 1e-06
I0129 00:08:45.310187 46007 solver.cpp:243] Iteration 329800 (1.31352 iter/s, 152.263s/200 iters), loss = 1.62856
I0129 00:08:45.310281 46007 solver.cpp:262]     Train net output #0: accuracy = 0.613281
I0129 00:08:45.310292 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.828125
I0129 00:08:45.310313 46007 solver.cpp:262]     Train net output #2: loss = 1.62856 (* 1 = 1.62856 loss)
I0129 00:08:45.310324 46007 sgd_solver.cpp:122] Iteration 329800, lr = 1e-06
I0129 00:11:26.943590 46007 solver.cpp:525] Snapshotting to binary proto file snapshot/solver_iter_330000.caffemodel
I0129 00:11:26.943683 46007 net.cpp:929] Serializing 41 layers
I0129 00:11:40.899621 46007 sgd_solver.cpp:311] Snapshotting solver state to binary proto file snapshot/solver_iter_330000.solverstate
I0129 00:11:44.476379 46007 solver.cpp:385] Iteration 330000, Testing net (#0)
I0129 00:12:20.898579 46007 blocking_queue.cpp:49] Waiting for data
I0129 00:15:14.022770 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0129 00:15:14.073408 46007 solver.cpp:454]     Test net output #0: accuracy = 0.464621
I0129 00:15:14.073470 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.707019
I0129 00:15:14.073488 46007 solver.cpp:454]     Test net output #2: loss = 2.44954 (* 1 = 2.44954 loss)
I0129 00:15:14.073499 46007 solver.cpp:474] ================================
I0129 00:15:14.073505 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0129 00:15:14.073511 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0129 00:15:14.733196 46007 solver.cpp:243] Iteration 330000 (0.513599 iter/s, 389.409s/200 iters), loss = 1.9695
I0129 00:15:14.735519 46007 solver.cpp:262]     Train net output #0: accuracy = 0.492188
I0129 00:15:14.735548 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.785156
I0129 00:15:14.735581 46007 solver.cpp:262]     Train net output #2: loss = 1.9695 (* 1 = 1.9695 loss)
I0129 00:15:14.735594 46007 sgd_solver.cpp:122] Iteration 330000, lr = 1e-06
I0129 00:15:34.360347 46077 data_layer.cpp:73] Restarting data prefetching from start.
I0129 00:17:44.920437 46007 solver.cpp:243] Iteration 330200 (1.33174 iter/s, 150.179s/200 iters), loss = 1.69055
I0129 00:17:44.920564 46007 solver.cpp:262]     Train net output #0: accuracy = 0.613281
I0129 00:17:44.920580 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.808594
I0129 00:17:44.920620 46007 solver.cpp:262]     Train net output #2: loss = 1.69055 (* 1 = 1.69055 loss)
I0129 00:17:44.920637 46007 sgd_solver.cpp:122] Iteration 330200, lr = 1e-06
I0129 00:20:11.575903 46007 solver.cpp:243] Iteration 330400 (1.36379 iter/s, 146.65s/200 iters), loss = 1.72641
I0129 00:20:11.587646 46007 solver.cpp:262]     Train net output #0: accuracy = 0.554688
I0129 00:20:11.587673 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.804688
I0129 00:20:11.587707 46007 solver.cpp:262]     Train net output #2: loss = 1.72641 (* 1 = 1.72641 loss)
I0129 00:20:11.587721 46007 sgd_solver.cpp:122] Iteration 330400, lr = 1e-06
I0129 00:20:14.298266 46007 blocking_queue.cpp:49] Waiting for data
I0129 00:22:42.710321 46007 solver.cpp:243] Iteration 330600 (1.32348 iter/s, 151.117s/200 iters), loss = 1.73937
I0129 00:22:42.710435 46007 solver.cpp:262]     Train net output #0: accuracy = 0.5625
I0129 00:22:42.710450 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.800781
I0129 00:22:42.710477 46007 solver.cpp:262]     Train net output #2: loss = 1.73937 (* 1 = 1.73937 loss)
I0129 00:22:42.710507 46007 sgd_solver.cpp:122] Iteration 330600, lr = 1e-06
I0129 00:25:18.740751 46007 solver.cpp:243] Iteration 330800 (1.28185 iter/s, 156.024s/200 iters), loss = 1.70205
I0129 00:25:18.740882 46007 solver.cpp:262]     Train net output #0: accuracy = 0.578125
I0129 00:25:18.740903 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.800781
I0129 00:25:18.740989 46007 solver.cpp:262]     Train net output #2: loss = 1.70205 (* 1 = 1.70205 loss)
I0129 00:25:18.741011 46007 sgd_solver.cpp:122] Iteration 330800, lr = 1e-06
I0129 00:27:45.357841 46007 solver.cpp:385] Iteration 331000, Testing net (#0)
I0129 00:30:23.564988 46007 blocking_queue.cpp:49] Waiting for data
I0129 00:31:12.698926 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0129 00:31:12.760362 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46602
I0129 00:31:12.760416 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.70854
I0129 00:31:12.760429 46007 solver.cpp:454]     Test net output #2: loss = 2.43635 (* 1 = 2.43635 loss)
I0129 00:31:12.760437 46007 solver.cpp:474] ================================
I0129 00:31:12.760442 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0129 00:31:12.760445 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0129 00:31:13.408905 46007 solver.cpp:243] Iteration 331000 (0.563929 iter/s, 354.655s/200 iters), loss = 1.84567
I0129 00:31:13.411270 46007 solver.cpp:262]     Train net output #0: accuracy = 0.601562
I0129 00:31:13.411293 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.808594
I0129 00:31:13.411334 46007 solver.cpp:262]     Train net output #2: loss = 1.84567 (* 1 = 1.84567 loss)
I0129 00:31:13.411355 46007 sgd_solver.cpp:122] Iteration 331000, lr = 1e-06
I0129 00:33:34.604064 46007 solver.cpp:243] Iteration 331200 (1.41656 iter/s, 141.188s/200 iters), loss = 1.74986
I0129 00:33:34.604187 46007 solver.cpp:262]     Train net output #0: accuracy = 0.574219
I0129 00:33:34.604200 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.816406
I0129 00:33:34.604223 46007 solver.cpp:262]     Train net output #2: loss = 1.74986 (* 1 = 1.74986 loss)
I0129 00:33:34.604233 46007 sgd_solver.cpp:122] Iteration 331200, lr = 1e-06
I0129 00:36:03.604943 46007 solver.cpp:243] Iteration 331400 (1.34233 iter/s, 148.995s/200 iters), loss = 1.43195
I0129 00:36:03.605042 46007 solver.cpp:262]     Train net output #0: accuracy = 0.671875
I0129 00:36:03.605057 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.863281
I0129 00:36:03.605079 46007 solver.cpp:262]     Train net output #2: loss = 1.43195 (* 1 = 1.43195 loss)
I0129 00:36:03.605093 46007 sgd_solver.cpp:122] Iteration 331400, lr = 1e-06
I0129 00:38:33.933730 46007 solver.cpp:243] Iteration 331600 (1.33047 iter/s, 150.323s/200 iters), loss = 1.90993
I0129 00:38:33.933831 46007 solver.cpp:262]     Train net output #0: accuracy = 0.535156
I0129 00:38:33.933843 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.769531
I0129 00:38:33.933868 46007 solver.cpp:262]     Train net output #2: loss = 1.90993 (* 1 = 1.90993 loss)
I0129 00:38:33.933884 46007 sgd_solver.cpp:122] Iteration 331600, lr = 1e-06
I0129 00:41:04.056309 46007 solver.cpp:243] Iteration 331800 (1.3323 iter/s, 150.117s/200 iters), loss = 1.69002
I0129 00:41:04.068050 46007 solver.cpp:262]     Train net output #0: accuracy = 0.574219
I0129 00:41:04.068070 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.839844
I0129 00:41:04.068091 46007 solver.cpp:262]     Train net output #2: loss = 1.69002 (* 1 = 1.69002 loss)
I0129 00:41:04.068100 46007 sgd_solver.cpp:122] Iteration 331800, lr = 1e-06
I0129 00:43:33.024281 46007 solver.cpp:385] Iteration 332000, Testing net (#0)
I0129 00:44:17.526535 46007 blocking_queue.cpp:49] Waiting for data
I0129 00:46:40.685734 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0129 00:46:40.735592 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46128
I0129 00:46:40.735651 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.707579
I0129 00:46:40.735669 46007 solver.cpp:454]     Test net output #2: loss = 2.45396 (* 1 = 2.45396 loss)
I0129 00:46:40.735680 46007 solver.cpp:474] ================================
I0129 00:46:40.735688 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0129 00:46:40.735694 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0129 00:46:41.390427 46007 solver.cpp:243] Iteration 332000 (0.592927 iter/s, 337.31s/200 iters), loss = 1.95504
I0129 00:46:41.392769 46007 solver.cpp:262]     Train net output #0: accuracy = 0.535156
I0129 00:46:41.392802 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.773438
I0129 00:46:41.392832 46007 solver.cpp:262]     Train net output #2: loss = 1.95504 (* 1 = 1.95504 loss)
I0129 00:46:41.392845 46007 sgd_solver.cpp:122] Iteration 332000, lr = 1e-06
I0129 00:49:09.705808 46007 solver.cpp:243] Iteration 332200 (1.34855 iter/s, 148.307s/200 iters), loss = 1.79204
I0129 00:49:09.717525 46007 solver.cpp:262]     Train net output #0: accuracy = 0.574219
I0129 00:49:09.717541 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.796875
I0129 00:49:09.717566 46007 solver.cpp:262]     Train net output #2: loss = 1.79204 (* 1 = 1.79204 loss)
I0129 00:49:09.717579 46007 sgd_solver.cpp:122] Iteration 332200, lr = 1e-06
I0129 00:51:37.036058 46007 solver.cpp:243] Iteration 332400 (1.35765 iter/s, 147.313s/200 iters), loss = 1.74241
I0129 00:51:37.047852 46007 solver.cpp:262]     Train net output #0: accuracy = 0.601562
I0129 00:51:37.047886 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.828125
I0129 00:51:37.047955 46007 solver.cpp:262]     Train net output #2: loss = 1.74241 (* 1 = 1.74241 loss)
I0129 00:51:37.047973 46007 sgd_solver.cpp:122] Iteration 332400, lr = 1e-06
I0129 00:52:30.466464 46007 blocking_queue.cpp:49] Waiting for data
I0129 00:54:10.773375 46007 solver.cpp:243] Iteration 332600 (1.30107 iter/s, 153.72s/200 iters), loss = 1.89327
I0129 00:54:10.785142 46007 solver.cpp:262]     Train net output #0: accuracy = 0.585938
I0129 00:54:10.785161 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.792969
I0129 00:54:10.785187 46007 solver.cpp:262]     Train net output #2: loss = 1.89327 (* 1 = 1.89327 loss)
I0129 00:54:10.785197 46007 sgd_solver.cpp:122] Iteration 332600, lr = 1e-06
I0129 00:56:41.488358 46007 solver.cpp:243] Iteration 332800 (1.32716 iter/s, 150.698s/200 iters), loss = 1.69017
I0129 00:56:41.500092 46007 solver.cpp:262]     Train net output #0: accuracy = 0.601562
I0129 00:56:41.500116 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.828125
I0129 00:56:41.500144 46007 solver.cpp:262]     Train net output #2: loss = 1.69017 (* 1 = 1.69017 loss)
I0129 00:56:41.500154 46007 sgd_solver.cpp:122] Iteration 332800, lr = 1e-06
I0129 00:59:12.988035 46007 solver.cpp:385] Iteration 333000, Testing net (#0)
I0129 01:02:08.167186 46007 blocking_queue.cpp:49] Waiting for data
I0129 01:02:57.359496 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0129 01:02:57.410126 46007 solver.cpp:454]     Test net output #0: accuracy = 0.467501
I0129 01:02:57.410187 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.712019
I0129 01:02:57.410203 46007 solver.cpp:454]     Test net output #2: loss = 2.43 (* 1 = 2.43 loss)
I0129 01:02:57.410212 46007 solver.cpp:474] ================================
I0129 01:02:57.410218 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0129 01:02:57.410223 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0129 01:02:58.068500 46007 solver.cpp:243] Iteration 333000 (0.531132 iter/s, 376.554s/200 iters), loss = 1.57728
I0129 01:02:58.068586 46007 solver.cpp:262]     Train net output #0: accuracy = 0.59375
I0129 01:02:58.068599 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.847656
I0129 01:02:58.068619 46007 solver.cpp:262]     Train net output #2: loss = 1.57728 (* 1 = 1.57728 loss)
I0129 01:02:58.068631 46007 sgd_solver.cpp:122] Iteration 333000, lr = 1e-06
I0129 01:05:25.405668 46007 solver.cpp:243] Iteration 333200 (1.35748 iter/s, 147.332s/200 iters), loss = 1.61439
I0129 01:05:25.417425 46007 solver.cpp:262]     Train net output #0: accuracy = 0.582031
I0129 01:05:25.417446 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.851562
I0129 01:05:25.417488 46007 solver.cpp:262]     Train net output #2: loss = 1.61439 (* 1 = 1.61439 loss)
I0129 01:05:25.417500 46007 sgd_solver.cpp:122] Iteration 333200, lr = 1e-06
I0129 01:07:58.134415 46007 solver.cpp:243] Iteration 333400 (1.30967 iter/s, 152.71s/200 iters), loss = 1.65324
I0129 01:07:58.145190 46007 solver.cpp:262]     Train net output #0: accuracy = 0.550781
I0129 01:07:58.145233 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.839844
I0129 01:07:58.145258 46007 solver.cpp:262]     Train net output #2: loss = 1.65324 (* 1 = 1.65324 loss)
I0129 01:07:58.145270 46007 sgd_solver.cpp:122] Iteration 333400, lr = 1e-06
I0129 01:10:45.075311 46007 solver.cpp:243] Iteration 333600 (1.19815 iter/s, 166.924s/200 iters), loss = 1.51008
I0129 01:10:45.075443 46007 solver.cpp:262]     Train net output #0: accuracy = 0.636719
I0129 01:10:45.075459 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.867188
I0129 01:10:45.075485 46007 solver.cpp:262]     Train net output #2: loss = 1.51008 (* 1 = 1.51008 loss)
I0129 01:10:45.075497 46007 sgd_solver.cpp:122] Iteration 333600, lr = 1e-06
I0129 01:13:39.454813 46007 solver.cpp:243] Iteration 333800 (1.14697 iter/s, 174.373s/200 iters), loss = 1.7558
I0129 01:13:39.454970 46007 solver.cpp:262]     Train net output #0: accuracy = 0.566406
I0129 01:13:39.454984 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.828125
I0129 01:13:39.455008 46007 solver.cpp:262]     Train net output #2: loss = 1.7558 (* 1 = 1.7558 loss)
I0129 01:13:39.455022 46007 sgd_solver.cpp:122] Iteration 333800, lr = 1e-06
I0129 01:16:38.543655 46007 solver.cpp:385] Iteration 334000, Testing net (#0)
I0129 01:17:10.186306 46007 blocking_queue.cpp:49] Waiting for data
I0129 01:19:02.533852 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0129 01:19:02.589890 46007 solver.cpp:454]     Test net output #0: accuracy = 0.4631
I0129 01:19:02.589964 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.70888
I0129 01:19:02.589982 46007 solver.cpp:454]     Test net output #2: loss = 2.45101 (* 1 = 2.45101 loss)
I0129 01:19:02.589990 46007 solver.cpp:474] ================================
I0129 01:19:02.589996 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0129 01:19:02.590003 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0129 01:19:03.276805 46007 solver.cpp:243] Iteration 334000 (0.617647 iter/s, 323.81s/200 iters), loss = 1.8103
I0129 01:19:03.279155 46007 solver.cpp:262]     Train net output #0: accuracy = 0.582031
I0129 01:19:03.279197 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.78125
I0129 01:19:03.279229 46007 solver.cpp:262]     Train net output #2: loss = 1.8103 (* 1 = 1.8103 loss)
I0129 01:19:03.279248 46007 sgd_solver.cpp:122] Iteration 334000, lr = 1e-06
I0129 01:21:45.401110 46007 solver.cpp:243] Iteration 334200 (1.23369 iter/s, 162.116s/200 iters), loss = 1.59004
I0129 01:21:45.412921 46007 solver.cpp:262]     Train net output #0: accuracy = 0.628906
I0129 01:21:45.412943 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.828125
I0129 01:21:45.412966 46007 solver.cpp:262]     Train net output #2: loss = 1.59004 (* 1 = 1.59004 loss)
I0129 01:21:45.412977 46007 sgd_solver.cpp:122] Iteration 334200, lr = 1e-06
I0129 01:24:55.365181 46007 solver.cpp:243] Iteration 334400 (1.05294 iter/s, 189.945s/200 iters), loss = 1.6536
I0129 01:24:55.365286 46007 solver.cpp:262]     Train net output #0: accuracy = 0.613281
I0129 01:24:55.365299 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.832031
I0129 01:24:55.365315 46007 solver.cpp:262]     Train net output #2: loss = 1.6536 (* 1 = 1.6536 loss)
I0129 01:24:55.365324 46007 sgd_solver.cpp:122] Iteration 334400, lr = 1e-06
I0129 01:27:48.241752 46007 solver.cpp:243] Iteration 334600 (1.15694 iter/s, 172.87s/200 iters), loss = 1.86253
I0129 01:27:48.253486 46007 solver.cpp:262]     Train net output #0: accuracy = 0.597656
I0129 01:27:48.253501 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.816406
I0129 01:27:48.253521 46007 solver.cpp:262]     Train net output #2: loss = 1.86253 (* 1 = 1.86253 loss)
I0129 01:27:48.253532 46007 sgd_solver.cpp:122] Iteration 334600, lr = 1e-06
I0129 01:30:42.627732 46007 solver.cpp:243] Iteration 334800 (1.147 iter/s, 174.367s/200 iters), loss = 1.60975
I0129 01:30:42.639657 46007 solver.cpp:262]     Train net output #0: accuracy = 0.652344
I0129 01:30:42.639703 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.855469
I0129 01:30:42.639746 46007 solver.cpp:262]     Train net output #2: loss = 1.60975 (* 1 = 1.60975 loss)
I0129 01:30:42.639757 46007 sgd_solver.cpp:122] Iteration 334800, lr = 1e-06
I0129 01:30:49.682252 46007 blocking_queue.cpp:49] Waiting for data
I0129 01:33:36.593868 46007 solver.cpp:385] Iteration 335000, Testing net (#0)
I0129 01:35:45.173177 46007 blocking_queue.cpp:49] Waiting for data
I0129 01:35:48.593142 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0129 01:35:48.653182 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46496
I0129 01:35:48.653246 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.709939
I0129 01:35:48.653262 46007 solver.cpp:454]     Test net output #2: loss = 2.44016 (* 1 = 2.44016 loss)
I0129 01:35:48.653271 46007 solver.cpp:474] ================================
I0129 01:35:48.653276 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0129 01:35:48.653281 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0129 01:35:49.436139 46007 solver.cpp:243] Iteration 335000 (0.651924 iter/s, 306.784s/200 iters), loss = 1.54643
I0129 01:35:49.438540 46007 solver.cpp:262]     Train net output #0: accuracy = 0.632812
I0129 01:35:49.438587 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.847656
I0129 01:35:49.438652 46007 solver.cpp:262]     Train net output #2: loss = 1.54643 (* 1 = 1.54643 loss)
I0129 01:35:49.438671 46007 sgd_solver.cpp:122] Iteration 335000, lr = 1e-06
I0129 01:36:13.104449 46077 data_layer.cpp:73] Restarting data prefetching from start.
I0129 01:38:37.558559 46007 solver.cpp:243] Iteration 335200 (1.18967 iter/s, 168.113s/200 iters), loss = 1.87437
I0129 01:38:37.570384 46007 solver.cpp:262]     Train net output #0: accuracy = 0.613281
I0129 01:38:37.570407 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.773438
I0129 01:38:37.570447 46007 solver.cpp:262]     Train net output #2: loss = 1.87437 (* 1 = 1.87437 loss)
I0129 01:38:37.570458 46007 sgd_solver.cpp:122] Iteration 335200, lr = 1e-06
I0129 01:41:27.047587 46007 solver.cpp:243] Iteration 335400 (1.18015 iter/s, 169.47s/200 iters), loss = 1.9117
I0129 01:41:27.059376 46007 solver.cpp:262]     Train net output #0: accuracy = 0.539062
I0129 01:41:27.059401 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.761719
I0129 01:41:27.059442 46007 solver.cpp:262]     Train net output #2: loss = 1.9117 (* 1 = 1.9117 loss)
I0129 01:41:27.059453 46007 sgd_solver.cpp:122] Iteration 335400, lr = 1e-06
I0129 01:44:13.568385 46007 solver.cpp:243] Iteration 335600 (1.20119 iter/s, 166.502s/200 iters), loss = 1.9119
I0129 01:44:13.580147 46007 solver.cpp:262]     Train net output #0: accuracy = 0.566406
I0129 01:44:13.580163 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.761719
I0129 01:44:13.580188 46007 solver.cpp:262]     Train net output #2: loss = 1.9119 (* 1 = 1.9119 loss)
I0129 01:44:13.580197 46007 sgd_solver.cpp:122] Iteration 335600, lr = 1e-06
I0129 01:47:05.455530 46007 solver.cpp:243] Iteration 335800 (1.16368 iter/s, 171.868s/200 iters), loss = 1.74664
I0129 01:47:05.455654 46007 solver.cpp:262]     Train net output #0: accuracy = 0.589844
I0129 01:47:05.455668 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.820312
I0129 01:47:05.455691 46007 solver.cpp:262]     Train net output #2: loss = 1.74664 (* 1 = 1.74664 loss)
I0129 01:47:05.455703 46007 sgd_solver.cpp:122] Iteration 335800, lr = 1e-06
I0129 01:49:57.392120 46007 solver.cpp:385] Iteration 336000, Testing net (#0)
I0129 01:52:48.267278 46007 blocking_queue.cpp:49] Waiting for data
I0129 01:54:04.561471 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0129 01:54:04.650203 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46668
I0129 01:54:04.650297 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.71122
I0129 01:54:04.650316 46007 solver.cpp:454]     Test net output #2: loss = 2.43331 (* 1 = 2.43331 loss)
I0129 01:54:04.650326 46007 solver.cpp:474] ================================
I0129 01:54:04.650331 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0129 01:54:04.650336 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0129 01:54:05.317183 46007 solver.cpp:243] Iteration 336000 (0.476368 iter/s, 419.843s/200 iters), loss = 1.77347
I0129 01:54:05.319535 46007 solver.cpp:262]     Train net output #0: accuracy = 0.582031
I0129 01:54:05.319578 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.8125
I0129 01:54:05.319619 46007 solver.cpp:262]     Train net output #2: loss = 1.77347 (* 1 = 1.77347 loss)
I0129 01:54:05.319640 46007 sgd_solver.cpp:122] Iteration 336000, lr = 1e-06
I0129 01:56:37.442543 46007 solver.cpp:243] Iteration 336200 (1.31478 iter/s, 152.116s/200 iters), loss = 1.85849
I0129 01:56:37.454258 46007 solver.cpp:262]     Train net output #0: accuracy = 0.554688
I0129 01:56:37.454280 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.800781
I0129 01:56:37.454319 46007 solver.cpp:262]     Train net output #2: loss = 1.85849 (* 1 = 1.85849 loss)
I0129 01:56:37.454329 46007 sgd_solver.cpp:122] Iteration 336200, lr = 1e-06
I0129 01:59:35.071444 46007 solver.cpp:243] Iteration 336400 (1.12607 iter/s, 177.609s/200 iters), loss = 1.6839
I0129 01:59:35.083194 46007 solver.cpp:262]     Train net output #0: accuracy = 0.578125
I0129 01:59:35.083214 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.824219
I0129 01:59:35.083256 46007 solver.cpp:262]     Train net output #2: loss = 1.6839 (* 1 = 1.6839 loss)
I0129 01:59:35.083266 46007 sgd_solver.cpp:122] Iteration 336400, lr = 1e-06
I0129 02:02:33.246917 46007 solver.cpp:243] Iteration 336600 (1.12261 iter/s, 178.157s/200 iters), loss = 1.66467
I0129 02:02:33.247035 46007 solver.cpp:262]     Train net output #0: accuracy = 0.566406
I0129 02:02:33.247050 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.84375
I0129 02:02:33.247092 46007 solver.cpp:262]     Train net output #2: loss = 1.66467 (* 1 = 1.66467 loss)
I0129 02:02:33.247108 46007 sgd_solver.cpp:122] Iteration 336600, lr = 1e-06
I0129 02:05:34.370605 46007 solver.cpp:243] Iteration 336800 (1.10426 iter/s, 181.117s/200 iters), loss = 1.65115
I0129 02:05:34.382395 46007 solver.cpp:262]     Train net output #0: accuracy = 0.605469
I0129 02:05:34.382426 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.824219
I0129 02:05:34.382475 46007 solver.cpp:262]     Train net output #2: loss = 1.65115 (* 1 = 1.65115 loss)
I0129 02:05:34.382488 46007 sgd_solver.cpp:122] Iteration 336800, lr = 1e-06
I0129 02:08:37.035934 46007 solver.cpp:385] Iteration 337000, Testing net (#0)
I0129 02:10:36.677669 46007 blocking_queue.cpp:49] Waiting for data
I0129 02:11:42.839869 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0129 02:11:42.897965 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46358
I0129 02:11:42.898015 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.708079
I0129 02:11:42.898042 46007 solver.cpp:454]     Test net output #2: loss = 2.44433 (* 1 = 2.44433 loss)
I0129 02:11:42.898052 46007 solver.cpp:474] ================================
I0129 02:11:42.898057 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0129 02:11:42.898063 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0129 02:11:43.652796 46007 solver.cpp:243] Iteration 337000 (0.541629 iter/s, 369.257s/200 iters), loss = 1.66967
I0129 02:11:43.655117 46007 solver.cpp:262]     Train net output #0: accuracy = 0.625
I0129 02:11:43.655143 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.816406
I0129 02:11:43.655170 46007 solver.cpp:262]     Train net output #2: loss = 1.66967 (* 1 = 1.66967 loss)
I0129 02:11:43.655182 46007 sgd_solver.cpp:122] Iteration 337000, lr = 1e-06
I0129 02:14:14.466133 46007 solver.cpp:243] Iteration 337200 (1.32621 iter/s, 150.805s/200 iters), loss = 1.61574
I0129 02:14:14.466243 46007 solver.cpp:262]     Train net output #0: accuracy = 0.617188
I0129 02:14:14.466254 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.824219
I0129 02:14:14.466275 46007 solver.cpp:262]     Train net output #2: loss = 1.61574 (* 1 = 1.61574 loss)
I0129 02:14:14.466287 46007 sgd_solver.cpp:122] Iteration 337200, lr = 1e-06
I0129 02:16:56.983530 46007 solver.cpp:243] Iteration 337400 (1.23069 iter/s, 162.511s/200 iters), loss = 1.63071
I0129 02:16:56.995395 46007 solver.cpp:262]     Train net output #0: accuracy = 0.601562
I0129 02:16:56.995414 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.8125
I0129 02:16:56.995438 46007 solver.cpp:262]     Train net output #2: loss = 1.63071 (* 1 = 1.63071 loss)
I0129 02:16:56.995450 46007 sgd_solver.cpp:122] Iteration 337400, lr = 1e-06
I0129 02:20:01.295236 46007 solver.cpp:243] Iteration 337600 (1.08523 iter/s, 184.293s/200 iters), loss = 1.64515
I0129 02:20:01.307003 46007 solver.cpp:262]     Train net output #0: accuracy = 0.632812
I0129 02:20:01.307029 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.820312
I0129 02:20:01.307054 46007 solver.cpp:262]     Train net output #2: loss = 1.64515 (* 1 = 1.64515 loss)
I0129 02:20:01.307065 46007 sgd_solver.cpp:122] Iteration 337600, lr = 1e-06
I0129 02:23:02.174729 46007 solver.cpp:243] Iteration 337800 (1.10582 iter/s, 180.861s/200 iters), loss = 1.95978
I0129 02:23:02.174845 46007 solver.cpp:262]     Train net output #0: accuracy = 0.554688
I0129 02:23:02.174859 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.761719
I0129 02:23:02.174880 46007 solver.cpp:262]     Train net output #2: loss = 1.95978 (* 1 = 1.95978 loss)
I0129 02:23:02.174895 46007 sgd_solver.cpp:122] Iteration 337800, lr = 1e-06
I0129 02:26:00.542030 46007 solver.cpp:385] Iteration 338000, Testing net (#0)
I0129 02:26:59.890297 46007 blocking_queue.cpp:49] Waiting for data
I0129 02:29:20.574560 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0129 02:29:20.662286 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46306
I0129 02:29:20.662333 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.70902
I0129 02:29:20.662354 46007 solver.cpp:454]     Test net output #2: loss = 2.44686 (* 1 = 2.44686 loss)
I0129 02:29:20.662364 46007 solver.cpp:474] ================================
I0129 02:29:20.662369 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0129 02:29:20.662375 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0129 02:29:21.342033 46007 solver.cpp:243] Iteration 338000 (0.527492 iter/s, 379.153s/200 iters), loss = 1.66651
I0129 02:29:21.344425 46007 solver.cpp:262]     Train net output #0: accuracy = 0.574219
I0129 02:29:21.344465 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.820312
I0129 02:29:21.344506 46007 solver.cpp:262]     Train net output #2: loss = 1.66651 (* 1 = 1.66651 loss)
I0129 02:29:21.344524 46007 sgd_solver.cpp:122] Iteration 338000, lr = 1e-06
I0129 02:31:56.776804 46007 solver.cpp:243] Iteration 338200 (1.28678 iter/s, 155.426s/200 iters), loss = 1.57604
I0129 02:31:56.789240 46007 solver.cpp:262]     Train net output #0: accuracy = 0.585938
I0129 02:31:56.789264 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.820312
I0129 02:31:56.789305 46007 solver.cpp:262]     Train net output #2: loss = 1.57604 (* 1 = 1.57604 loss)
I0129 02:31:56.789315 46007 sgd_solver.cpp:122] Iteration 338200, lr = 1e-06
I0129 02:35:08.717032 46007 solver.cpp:243] Iteration 338400 (1.0421 iter/s, 191.92s/200 iters), loss = 1.57669
I0129 02:35:08.717137 46007 solver.cpp:262]     Train net output #0: accuracy = 0.625
I0129 02:35:08.717150 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.832031
I0129 02:35:08.717175 46007 solver.cpp:262]     Train net output #2: loss = 1.57669 (* 1 = 1.57669 loss)
I0129 02:35:08.717190 46007 sgd_solver.cpp:122] Iteration 338400, lr = 1e-06
I0129 02:38:10.003032 46007 solver.cpp:243] Iteration 338600 (1.10327 iter/s, 181.279s/200 iters), loss = 1.81601
I0129 02:38:10.014839 46007 solver.cpp:262]     Train net output #0: accuracy = 0.570312
I0129 02:38:10.014863 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.800781
I0129 02:38:10.014889 46007 solver.cpp:262]     Train net output #2: loss = 1.81601 (* 1 = 1.81601 loss)
I0129 02:38:10.014901 46007 sgd_solver.cpp:122] Iteration 338600, lr = 1e-06
I0129 02:41:02.322333 46007 solver.cpp:243] Iteration 338800 (1.16076 iter/s, 172.301s/200 iters), loss = 1.76536
I0129 02:41:02.334089 46007 solver.cpp:262]     Train net output #0: accuracy = 0.574219
I0129 02:41:02.334131 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.796875
I0129 02:41:02.334158 46007 solver.cpp:262]     Train net output #2: loss = 1.76536 (* 1 = 1.76536 loss)
I0129 02:41:02.334170 46007 sgd_solver.cpp:122] Iteration 338800, lr = 1e-06
I0129 02:43:57.369609 46007 solver.cpp:385] Iteration 339000, Testing net (#0)
I0129 02:44:07.841737 46007 blocking_queue.cpp:49] Waiting for data
I0129 02:45:44.971704 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0129 02:45:45.026830 46007 solver.cpp:454]     Test net output #0: accuracy = 0.463121
I0129 02:45:45.026881 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.708379
I0129 02:45:45.026898 46007 solver.cpp:454]     Test net output #2: loss = 2.44328 (* 1 = 2.44328 loss)
I0129 02:45:45.026907 46007 solver.cpp:474] ================================
I0129 02:45:45.026912 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0129 02:45:45.026919 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0129 02:45:45.798893 46007 solver.cpp:243] Iteration 339000 (0.705601 iter/s, 283.446s/200 iters), loss = 1.76212
I0129 02:45:45.801267 46007 solver.cpp:262]     Train net output #0: accuracy = 0.585938
I0129 02:45:45.801295 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.789062
I0129 02:45:45.801323 46007 solver.cpp:262]     Train net output #2: loss = 1.76212 (* 1 = 1.76212 loss)
I0129 02:45:45.801337 46007 sgd_solver.cpp:122] Iteration 339000, lr = 1e-06
I0129 02:48:55.190465 46007 solver.cpp:243] Iteration 339200 (1.0561 iter/s, 189.377s/200 iters), loss = 1.73541
I0129 02:48:55.202309 46007 solver.cpp:262]     Train net output #0: accuracy = 0.621094
I0129 02:48:55.202349 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.804688
I0129 02:48:55.202389 46007 solver.cpp:262]     Train net output #2: loss = 1.73541 (* 1 = 1.73541 loss)
I0129 02:48:55.202400 46007 sgd_solver.cpp:122] Iteration 339200, lr = 1e-06
I0129 02:52:02.132486 46007 solver.cpp:243] Iteration 339400 (1.06996 iter/s, 186.923s/200 iters), loss = 1.68931
I0129 02:52:02.132604 46007 solver.cpp:262]     Train net output #0: accuracy = 0.628906
I0129 02:52:02.132616 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.8125
I0129 02:52:02.132639 46007 solver.cpp:262]     Train net output #2: loss = 1.68931 (* 1 = 1.68931 loss)
I0129 02:52:02.132652 46007 sgd_solver.cpp:122] Iteration 339400, lr = 1e-06
I0129 02:52:18.532282 46007 blocking_queue.cpp:49] Waiting for data
I0129 02:54:55.834733 46007 solver.cpp:243] Iteration 339600 (1.15144 iter/s, 173.696s/200 iters), loss = 1.4762
I0129 02:54:55.834861 46007 solver.cpp:262]     Train net output #0: accuracy = 0.660156
I0129 02:54:55.834874 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.84375
I0129 02:54:55.834897 46007 solver.cpp:262]     Train net output #2: loss = 1.4762 (* 1 = 1.4762 loss)
I0129 02:54:55.834911 46007 sgd_solver.cpp:122] Iteration 339600, lr = 1e-06
I0129 02:57:49.555841 46007 solver.cpp:243] Iteration 339800 (1.15131 iter/s, 173.714s/200 iters), loss = 1.63652
I0129 02:57:49.567667 46007 solver.cpp:262]     Train net output #0: accuracy = 0.613281
I0129 02:57:49.567695 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.808594
I0129 02:57:49.567724 46007 solver.cpp:262]     Train net output #2: loss = 1.63652 (* 1 = 1.63652 loss)
I0129 02:57:49.567737 46007 sgd_solver.cpp:122] Iteration 339800, lr = 1e-06
I0129 03:00:39.778338 46007 solver.cpp:525] Snapshotting to binary proto file snapshot/solver_iter_340000.caffemodel
I0129 03:00:39.778429 46007 net.cpp:929] Serializing 41 layers
I0129 03:00:51.988739 46007 sgd_solver.cpp:311] Snapshotting solver state to binary proto file snapshot/solver_iter_340000.solverstate
I0129 03:00:55.172137 46007 solver.cpp:385] Iteration 340000, Testing net (#0)
I0129 03:02:25.404425 46007 blocking_queue.cpp:49] Waiting for data
I0129 03:02:45.949800 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0129 03:02:46.006155 46007 solver.cpp:454]     Test net output #0: accuracy = 0.4617
I0129 03:02:46.006203 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.707179
I0129 03:02:46.006230 46007 solver.cpp:454]     Test net output #2: loss = 2.45069 (* 1 = 2.45069 loss)
I0129 03:02:46.006240 46007 solver.cpp:474] ================================
I0129 03:02:46.006247 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0129 03:02:46.006253 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0129 03:02:46.717229 46007 solver.cpp:243] Iteration 340000 (0.673083 iter/s, 297.14s/200 iters), loss = 1.732
I0129 03:02:46.719615 46007 solver.cpp:262]     Train net output #0: accuracy = 0.625
I0129 03:02:46.719641 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.820312
I0129 03:02:46.719669 46007 solver.cpp:262]     Train net output #2: loss = 1.732 (* 1 = 1.732 loss)
I0129 03:02:46.719682 46007 sgd_solver.cpp:122] Iteration 340000, lr = 1e-06
I0129 03:03:14.300107 46077 data_layer.cpp:73] Restarting data prefetching from start.
I0129 03:05:44.693631 46007 solver.cpp:243] Iteration 340200 (1.12379 iter/s, 177.969s/200 iters), loss = 1.91888
I0129 03:05:44.693745 46007 solver.cpp:262]     Train net output #0: accuracy = 0.539062
I0129 03:05:44.693758 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.792969
I0129 03:05:44.693784 46007 solver.cpp:262]     Train net output #2: loss = 1.91888 (* 1 = 1.91888 loss)
I0129 03:05:44.693799 46007 sgd_solver.cpp:122] Iteration 340200, lr = 1e-06
I0129 03:08:43.683861 46007 solver.cpp:243] Iteration 340400 (1.11741 iter/s, 178.985s/200 iters), loss = 1.77689
I0129 03:08:43.683960 46007 solver.cpp:262]     Train net output #0: accuracy = 0.570312
I0129 03:08:43.683975 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.808594
I0129 03:08:43.684000 46007 solver.cpp:262]     Train net output #2: loss = 1.77689 (* 1 = 1.77689 loss)
I0129 03:08:43.684012 46007 sgd_solver.cpp:122] Iteration 340400, lr = 1e-06
I0129 03:11:36.853803 46007 solver.cpp:243] Iteration 340600 (1.15497 iter/s, 173.165s/200 iters), loss = 1.58468
I0129 03:11:36.853906 46007 solver.cpp:262]     Train net output #0: accuracy = 0.625
I0129 03:11:36.853921 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.84375
I0129 03:11:36.853945 46007 solver.cpp:262]     Train net output #2: loss = 1.58468 (* 1 = 1.58468 loss)
I0129 03:11:36.853960 46007 sgd_solver.cpp:122] Iteration 340600, lr = 1e-06
I0129 03:14:33.634721 46007 solver.cpp:243] Iteration 340800 (1.13138 iter/s, 176.775s/200 iters), loss = 1.81546
I0129 03:14:33.646548 46007 solver.cpp:262]     Train net output #0: accuracy = 0.601562
I0129 03:14:33.646565 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.773438
I0129 03:14:33.646600 46007 solver.cpp:262]     Train net output #2: loss = 1.81546 (* 1 = 1.81546 loss)
I0129 03:14:33.646611 46007 sgd_solver.cpp:122] Iteration 340800, lr = 1e-06
I0129 03:17:38.543308 46007 solver.cpp:385] Iteration 341000, Testing net (#0)
I0129 03:18:21.664450 46007 blocking_queue.cpp:49] Waiting for data
I0129 03:19:30.819442 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0129 03:19:30.879500 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46426
I0129 03:19:30.879561 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.710239
I0129 03:19:30.879580 46007 solver.cpp:454]     Test net output #2: loss = 2.43786 (* 1 = 2.43786 loss)
I0129 03:19:30.879590 46007 solver.cpp:474] ================================
I0129 03:19:30.879595 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0129 03:19:30.879601 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0129 03:19:31.655532 46007 solver.cpp:243] Iteration 341000 (0.671144 iter/s, 297.999s/200 iters), loss = 1.81352
I0129 03:19:31.657932 46007 solver.cpp:262]     Train net output #0: accuracy = 0.578125
I0129 03:19:31.657977 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.828125
I0129 03:19:31.658033 46007 solver.cpp:262]     Train net output #2: loss = 1.81352 (* 1 = 1.81352 loss)
I0129 03:19:31.658054 46007 sgd_solver.cpp:122] Iteration 341000, lr = 1e-06
I0129 03:22:19.548224 46007 solver.cpp:243] Iteration 341200 (1.1913 iter/s, 167.884s/200 iters), loss = 1.88011
I0129 03:22:19.560034 46007 solver.cpp:262]     Train net output #0: accuracy = 0.605469
I0129 03:22:19.560056 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.765625
I0129 03:22:19.560082 46007 solver.cpp:262]     Train net output #2: loss = 1.88011 (* 1 = 1.88011 loss)
I0129 03:22:19.560092 46007 sgd_solver.cpp:122] Iteration 341200, lr = 1e-06
I0129 03:25:10.196090 46007 solver.cpp:243] Iteration 341400 (1.17213 iter/s, 170.63s/200 iters), loss = 1.8954
I0129 03:25:10.196200 46007 solver.cpp:262]     Train net output #0: accuracy = 0.546875
I0129 03:25:10.196213 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.796875
I0129 03:25:10.196235 46007 solver.cpp:262]     Train net output #2: loss = 1.8954 (* 1 = 1.8954 loss)
I0129 03:25:10.196249 46007 sgd_solver.cpp:122] Iteration 341400, lr = 1e-06
I0129 03:28:00.772541 46007 solver.cpp:243] Iteration 341600 (1.17254 iter/s, 170.57s/200 iters), loss = 1.57944
I0129 03:28:00.784363 46007 solver.cpp:262]     Train net output #0: accuracy = 0.632812
I0129 03:28:00.784381 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.828125
I0129 03:28:00.784423 46007 solver.cpp:262]     Train net output #2: loss = 1.57944 (* 1 = 1.57944 loss)
I0129 03:28:00.784433 46007 sgd_solver.cpp:122] Iteration 341600, lr = 1e-06
I0129 03:31:04.228015 46007 solver.cpp:243] Iteration 341800 (1.09029 iter/s, 183.437s/200 iters), loss = 1.60328
I0129 03:31:04.239768 46007 solver.cpp:262]     Train net output #0: accuracy = 0.601562
I0129 03:31:04.239784 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.84375
I0129 03:31:04.239812 46007 solver.cpp:262]     Train net output #2: loss = 1.60328 (* 1 = 1.60328 loss)
I0129 03:31:04.239822 46007 sgd_solver.cpp:122] Iteration 341800, lr = 1e-06
I0129 03:33:44.703860 46007 solver.cpp:385] Iteration 342000, Testing net (#0)
I0129 03:34:07.396550 46007 blocking_queue.cpp:49] Waiting for data
I0129 03:35:36.699656 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0129 03:35:36.754233 46007 solver.cpp:454]     Test net output #0: accuracy = 0.4665
I0129 03:35:36.754303 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.71256
I0129 03:35:36.754325 46007 solver.cpp:454]     Test net output #2: loss = 2.42732 (* 1 = 2.42732 loss)
I0129 03:35:36.754334 46007 solver.cpp:474] ================================
I0129 03:35:36.754339 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0129 03:35:36.754354 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0129 03:35:37.432505 46007 solver.cpp:243] Iteration 342000 (0.732109 iter/s, 273.183s/200 iters), loss = 1.86182
I0129 03:35:37.434893 46007 solver.cpp:262]     Train net output #0: accuracy = 0.566406
I0129 03:35:37.434918 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.773438
I0129 03:35:37.434954 46007 solver.cpp:262]     Train net output #2: loss = 1.86182 (* 1 = 1.86182 loss)
I0129 03:35:37.434967 46007 sgd_solver.cpp:122] Iteration 342000, lr = 1e-06
I0129 03:38:20.855384 46007 solver.cpp:243] Iteration 342200 (1.22388 iter/s, 163.415s/200 iters), loss = 1.80772
I0129 03:38:20.867177 46007 solver.cpp:262]     Train net output #0: accuracy = 0.582031
I0129 03:38:20.867202 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.804688
I0129 03:38:20.867246 46007 solver.cpp:262]     Train net output #2: loss = 1.80772 (* 1 = 1.80772 loss)
I0129 03:38:20.867260 46007 sgd_solver.cpp:122] Iteration 342200, lr = 1e-06
I0129 03:41:08.104089 46007 solver.cpp:243] Iteration 342400 (1.19595 iter/s, 167.231s/200 iters), loss = 1.63919
I0129 03:41:08.115887 46007 solver.cpp:262]     Train net output #0: accuracy = 0.601562
I0129 03:41:08.115912 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.820312
I0129 03:41:08.115942 46007 solver.cpp:262]     Train net output #2: loss = 1.63919 (* 1 = 1.63919 loss)
I0129 03:41:08.115954 46007 sgd_solver.cpp:122] Iteration 342400, lr = 1e-06
I0129 03:42:51.162372 46007 blocking_queue.cpp:49] Waiting for data
I0129 03:43:58.697662 46007 solver.cpp:243] Iteration 342600 (1.1725 iter/s, 170.576s/200 iters), loss = 1.76286
I0129 03:43:58.697772 46007 solver.cpp:262]     Train net output #0: accuracy = 0.59375
I0129 03:43:58.697784 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.785156
I0129 03:43:58.697805 46007 solver.cpp:262]     Train net output #2: loss = 1.76286 (* 1 = 1.76286 loss)
I0129 03:43:58.697816 46007 sgd_solver.cpp:122] Iteration 342600, lr = 1e-06
I0129 03:47:09.694473 46007 solver.cpp:243] Iteration 342800 (1.04717 iter/s, 190.99s/200 iters), loss = 1.82766
I0129 03:47:09.694576 46007 solver.cpp:262]     Train net output #0: accuracy = 0.539062
I0129 03:47:09.694588 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.8125
I0129 03:47:09.694609 46007 solver.cpp:262]     Train net output #2: loss = 1.82766 (* 1 = 1.82766 loss)
I0129 03:47:09.694620 46007 sgd_solver.cpp:122] Iteration 342800, lr = 1e-06
I0129 03:50:09.561985 46007 solver.cpp:385] Iteration 343000, Testing net (#0)
I0129 03:51:35.416149 46007 blocking_queue.cpp:49] Waiting for data
I0129 03:52:03.079974 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0129 03:52:03.140421 46007 solver.cpp:454]     Test net output #0: accuracy = 0.4595
I0129 03:52:03.140486 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.705979
I0129 03:52:03.140503 46007 solver.cpp:454]     Test net output #2: loss = 2.45821 (* 1 = 2.45821 loss)
I0129 03:52:03.140514 46007 solver.cpp:474] ================================
I0129 03:52:03.140519 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0129 03:52:03.140527 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0129 03:52:03.920207 46007 solver.cpp:243] Iteration 343000 (0.679774 iter/s, 294.215s/200 iters), loss = 1.86691
I0129 03:52:03.922574 46007 solver.cpp:262]     Train net output #0: accuracy = 0.542969
I0129 03:52:03.922596 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.808594
I0129 03:52:03.922626 46007 solver.cpp:262]     Train net output #2: loss = 1.86691 (* 1 = 1.86691 loss)
I0129 03:52:03.922637 46007 sgd_solver.cpp:122] Iteration 343000, lr = 1e-06
I0129 03:54:56.113577 46007 solver.cpp:243] Iteration 343200 (1.16154 iter/s, 172.185s/200 iters), loss = 1.65455
I0129 03:54:56.125367 46007 solver.cpp:262]     Train net output #0: accuracy = 0.609375
I0129 03:54:56.125427 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.824219
I0129 03:54:56.125506 46007 solver.cpp:262]     Train net output #2: loss = 1.65455 (* 1 = 1.65455 loss)
I0129 03:54:56.125541 46007 sgd_solver.cpp:122] Iteration 343200, lr = 1e-06
I0129 03:57:52.805498 46007 solver.cpp:243] Iteration 343400 (1.13203 iter/s, 176.674s/200 iters), loss = 1.71416
I0129 03:57:52.817174 46007 solver.cpp:262]     Train net output #0: accuracy = 0.578125
I0129 03:57:52.817190 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.808594
I0129 03:57:52.817216 46007 solver.cpp:262]     Train net output #2: loss = 1.71416 (* 1 = 1.71416 loss)
I0129 03:57:52.817226 46007 sgd_solver.cpp:122] Iteration 343400, lr = 1e-06
I0129 04:00:49.270956 46007 solver.cpp:243] Iteration 343600 (1.13348 iter/s, 176.448s/200 iters), loss = 1.6585
I0129 04:00:49.271046 46007 solver.cpp:262]     Train net output #0: accuracy = 0.601562
I0129 04:00:49.271061 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.828125
I0129 04:00:49.271082 46007 solver.cpp:262]     Train net output #2: loss = 1.6585 (* 1 = 1.6585 loss)
I0129 04:00:49.271093 46007 sgd_solver.cpp:122] Iteration 343600, lr = 1e-06
I0129 04:03:51.622907 46007 solver.cpp:243] Iteration 343800 (1.09682 iter/s, 182.345s/200 iters), loss = 1.67304
I0129 04:03:51.623028 46007 solver.cpp:262]     Train net output #0: accuracy = 0.582031
I0129 04:03:51.623041 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.839844
I0129 04:03:51.623064 46007 solver.cpp:262]     Train net output #2: loss = 1.67304 (* 1 = 1.67304 loss)
I0129 04:03:51.623080 46007 sgd_solver.cpp:122] Iteration 343800, lr = 1e-06
I0129 04:06:39.020514 46007 solver.cpp:385] Iteration 344000, Testing net (#0)
I0129 04:07:39.147703 46007 blocking_queue.cpp:49] Waiting for data
I0129 04:08:31.074828 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0129 04:08:31.126544 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46034
I0129 04:08:31.126598 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.706439
I0129 04:08:31.126616 46007 solver.cpp:454]     Test net output #2: loss = 2.4577 (* 1 = 2.4577 loss)
I0129 04:08:31.126627 46007 solver.cpp:474] ================================
I0129 04:08:31.126632 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0129 04:08:31.126638 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0129 04:08:31.860749 46007 solver.cpp:243] Iteration 344000 (0.713707 iter/s, 280.227s/200 iters), loss = 1.6165
I0129 04:08:31.863111 46007 solver.cpp:262]     Train net output #0: accuracy = 0.617188
I0129 04:08:31.863137 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.847656
I0129 04:08:31.863162 46007 solver.cpp:262]     Train net output #2: loss = 1.6165 (* 1 = 1.6165 loss)
I0129 04:08:31.863173 46007 sgd_solver.cpp:122] Iteration 344000, lr = 1e-06
I0129 04:11:21.619566 46007 solver.cpp:243] Iteration 344200 (1.17821 iter/s, 169.749s/200 iters), loss = 1.72393
I0129 04:11:21.631302 46007 solver.cpp:262]     Train net output #0: accuracy = 0.589844
I0129 04:11:21.631319 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.839844
I0129 04:11:21.631361 46007 solver.cpp:262]     Train net output #2: loss = 1.72393 (* 1 = 1.72393 loss)
I0129 04:11:21.631372 46007 sgd_solver.cpp:122] Iteration 344200, lr = 1e-06
I0129 04:14:17.642307 46007 solver.cpp:243] Iteration 344400 (1.13635 iter/s, 176.003s/200 iters), loss = 1.90316
I0129 04:14:17.642421 46007 solver.cpp:262]     Train net output #0: accuracy = 0.574219
I0129 04:14:17.642433 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.78125
I0129 04:14:17.642454 46007 solver.cpp:262]     Train net output #2: loss = 1.90316 (* 1 = 1.90316 loss)
I0129 04:14:17.642465 46007 sgd_solver.cpp:122] Iteration 344400, lr = 1e-06
I0129 04:17:13.159664 46007 solver.cpp:243] Iteration 344600 (1.13954 iter/s, 175.509s/200 iters), loss = 1.60956
I0129 04:17:13.171852 46007 solver.cpp:262]     Train net output #0: accuracy = 0.621094
I0129 04:17:13.171869 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.847656
I0129 04:17:13.171892 46007 solver.cpp:262]     Train net output #2: loss = 1.60956 (* 1 = 1.60956 loss)
I0129 04:17:13.171901 46007 sgd_solver.cpp:122] Iteration 344600, lr = 1e-06
I0129 04:20:03.947903 46007 solver.cpp:243] Iteration 344800 (1.17118 iter/s, 170.768s/200 iters), loss = 1.67326
I0129 04:20:03.959676 46007 solver.cpp:262]     Train net output #0: accuracy = 0.574219
I0129 04:20:03.959691 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.832031
I0129 04:20:03.959712 46007 solver.cpp:262]     Train net output #2: loss = 1.67326 (* 1 = 1.67326 loss)
I0129 04:20:03.959722 46007 sgd_solver.cpp:122] Iteration 344800, lr = 1e-06
I0129 04:22:48.428544 46007 solver.cpp:385] Iteration 345000, Testing net (#0)
I0129 04:24:07.814014 46007 blocking_queue.cpp:49] Waiting for data
I0129 04:26:36.567867 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0129 04:26:36.618583 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46056
I0129 04:26:36.618626 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.708199
I0129 04:26:36.618643 46007 solver.cpp:454]     Test net output #2: loss = 2.45297 (* 1 = 2.45297 loss)
I0129 04:26:36.618649 46007 solver.cpp:474] ================================
I0129 04:26:36.618654 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0129 04:26:36.618659 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0129 04:26:37.280520 46007 solver.cpp:243] Iteration 345000 (0.508511 iter/s, 393.305s/200 iters), loss = 1.66961
I0129 04:26:37.282943 46007 solver.cpp:262]     Train net output #0: accuracy = 0.589844
I0129 04:26:37.282965 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.84375
I0129 04:26:37.282989 46007 solver.cpp:262]     Train net output #2: loss = 1.66961 (* 1 = 1.66961 loss)
I0129 04:26:37.283000 46007 sgd_solver.cpp:122] Iteration 345000, lr = 1e-06
I0129 04:27:07.343456 46077 data_layer.cpp:73] Restarting data prefetching from start.
I0129 04:29:28.731863 46007 solver.cpp:243] Iteration 345200 (1.16658 iter/s, 171.441s/200 iters), loss = 1.71904
I0129 04:29:28.731966 46007 solver.cpp:262]     Train net output #0: accuracy = 0.578125
I0129 04:29:28.731978 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.816406
I0129 04:29:28.732002 46007 solver.cpp:262]     Train net output #2: loss = 1.71904 (* 1 = 1.71904 loss)
I0129 04:29:28.732015 46007 sgd_solver.cpp:122] Iteration 345200, lr = 1e-06
I0129 04:32:12.290714 46007 solver.cpp:243] Iteration 345400 (1.22286 iter/s, 163.551s/200 iters), loss = 1.94965
I0129 04:32:12.302518 46007 solver.cpp:262]     Train net output #0: accuracy = 0.523438
I0129 04:32:12.302536 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.765625
I0129 04:32:12.302577 46007 solver.cpp:262]     Train net output #2: loss = 1.94965 (* 1 = 1.94965 loss)
I0129 04:32:12.302587 46007 sgd_solver.cpp:122] Iteration 345400, lr = 1e-06
I0129 04:35:14.000756 46007 solver.cpp:243] Iteration 345600 (1.10078 iter/s, 181.69s/200 iters), loss = 1.71698
I0129 04:35:14.012490 46007 solver.cpp:262]     Train net output #0: accuracy = 0.554688
I0129 04:35:14.012507 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.8125
I0129 04:35:14.012531 46007 solver.cpp:262]     Train net output #2: loss = 1.71698 (* 1 = 1.71698 loss)
I0129 04:35:14.012543 46007 sgd_solver.cpp:122] Iteration 345600, lr = 1e-06
I0129 04:37:53.065676 46007 solver.cpp:243] Iteration 345800 (1.2575 iter/s, 159.046s/200 iters), loss = 1.86755
I0129 04:37:53.077563 46007 solver.cpp:262]     Train net output #0: accuracy = 0.570312
I0129 04:37:53.077589 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.800781
I0129 04:37:53.077627 46007 solver.cpp:262]     Train net output #2: loss = 1.86755 (* 1 = 1.86755 loss)
I0129 04:37:53.077641 46007 sgd_solver.cpp:122] Iteration 345800, lr = 1e-06
I0129 04:40:42.459902 46007 solver.cpp:385] Iteration 346000, Testing net (#0)
I0129 04:41:24.257819 46007 blocking_queue.cpp:49] Waiting for data
I0129 04:44:06.011466 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0129 04:44:06.066447 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46104
I0129 04:44:06.066489 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.70754
I0129 04:44:06.066505 46007 solver.cpp:454]     Test net output #2: loss = 2.45794 (* 1 = 2.45794 loss)
I0129 04:44:06.066515 46007 solver.cpp:474] ================================
I0129 04:44:06.066519 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0129 04:44:06.066525 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0129 04:44:06.775637 46007 solver.cpp:243] Iteration 346000 (0.535212 iter/s, 373.684s/200 iters), loss = 1.74164
I0129 04:44:06.778075 46007 solver.cpp:262]     Train net output #0: accuracy = 0.578125
I0129 04:44:06.778117 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.804688
I0129 04:44:06.778164 46007 solver.cpp:262]     Train net output #2: loss = 1.74164 (* 1 = 1.74164 loss)
I0129 04:44:06.778178 46007 sgd_solver.cpp:122] Iteration 346000, lr = 1e-06
I0129 04:46:41.029069 46007 solver.cpp:243] Iteration 346200 (1.29664 iter/s, 154.245s/200 iters), loss = 1.82939
I0129 04:46:41.040855 46007 solver.cpp:262]     Train net output #0: accuracy = 0.601562
I0129 04:46:41.040870 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.8125
I0129 04:46:41.040892 46007 solver.cpp:262]     Train net output #2: loss = 1.82939 (* 1 = 1.82939 loss)
I0129 04:46:41.040902 46007 sgd_solver.cpp:122] Iteration 346200, lr = 1e-06
I0129 04:49:24.809024 46007 solver.cpp:243] Iteration 346400 (1.22128 iter/s, 163.762s/200 iters), loss = 1.70786
I0129 04:49:24.820804 46007 solver.cpp:262]     Train net output #0: accuracy = 0.59375
I0129 04:49:24.820830 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.816406
I0129 04:49:24.820861 46007 solver.cpp:262]     Train net output #2: loss = 1.70786 (* 1 = 1.70786 loss)
I0129 04:49:24.820873 46007 sgd_solver.cpp:122] Iteration 346400, lr = 1e-06
I0129 04:52:15.421569 46007 solver.cpp:243] Iteration 346600 (1.17237 iter/s, 170.594s/200 iters), loss = 1.76754
I0129 04:52:15.433259 46007 solver.cpp:262]     Train net output #0: accuracy = 0.597656
I0129 04:52:15.433274 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.820312
I0129 04:52:15.433296 46007 solver.cpp:262]     Train net output #2: loss = 1.76754 (* 1 = 1.76754 loss)
I0129 04:52:15.433310 46007 sgd_solver.cpp:122] Iteration 346600, lr = 1e-06
I0129 04:55:01.182034 46007 solver.cpp:243] Iteration 346800 (1.20669 iter/s, 165.743s/200 iters), loss = 1.6556
I0129 04:55:01.182147 46007 solver.cpp:262]     Train net output #0: accuracy = 0.597656
I0129 04:55:01.182159 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.832031
I0129 04:55:01.182183 46007 solver.cpp:262]     Train net output #2: loss = 1.6556 (* 1 = 1.6556 loss)
I0129 04:55:01.182198 46007 sgd_solver.cpp:122] Iteration 346800, lr = 1e-06
I0129 04:57:45.132202 46007 solver.cpp:385] Iteration 347000, Testing net (#0)
I0129 04:58:08.830572 46007 blocking_queue.cpp:49] Waiting for data
I0129 05:01:16.525216 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0129 05:01:16.580742 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46374
I0129 05:01:16.580785 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.710899
I0129 05:01:16.580801 46007 solver.cpp:454]     Test net output #2: loss = 2.44064 (* 1 = 2.44064 loss)
I0129 05:01:16.580811 46007 solver.cpp:474] ================================
I0129 05:01:16.580816 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0129 05:01:16.580821 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0129 05:01:17.326988 46007 solver.cpp:243] Iteration 347000 (0.531729 iter/s, 376.131s/200 iters), loss = 1.66823
I0129 05:01:17.329319 46007 solver.cpp:262]     Train net output #0: accuracy = 0.574219
I0129 05:01:17.329350 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.832031
I0129 05:01:17.329380 46007 solver.cpp:262]     Train net output #2: loss = 1.66823 (* 1 = 1.66823 loss)
I0129 05:01:17.329394 46007 sgd_solver.cpp:122] Iteration 347000, lr = 1e-06
I0129 05:03:46.169266 46007 solver.cpp:243] Iteration 347200 (1.34377 iter/s, 148.835s/200 iters), loss = 1.6844
I0129 05:03:46.169394 46007 solver.cpp:262]     Train net output #0: accuracy = 0.585938
I0129 05:03:46.169406 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.804688
I0129 05:03:46.169426 46007 solver.cpp:262]     Train net output #2: loss = 1.6844 (* 1 = 1.6844 loss)
I0129 05:03:46.169440 46007 sgd_solver.cpp:122] Iteration 347200, lr = 1e-06
I0129 05:06:09.467684 46007 solver.cpp:243] Iteration 347400 (1.39574 iter/s, 143.293s/200 iters), loss = 1.66033
I0129 05:06:09.479522 46007 solver.cpp:262]     Train net output #0: accuracy = 0.621094
I0129 05:06:09.479547 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.835938
I0129 05:06:09.479589 46007 solver.cpp:262]     Train net output #2: loss = 1.66033 (* 1 = 1.66033 loss)
I0129 05:06:09.479600 46007 sgd_solver.cpp:122] Iteration 347400, lr = 1e-06
I0129 05:08:37.526598 46007 solver.cpp:243] Iteration 347600 (1.35097 iter/s, 148.042s/200 iters), loss = 2.07681
I0129 05:08:37.538403 46007 solver.cpp:262]     Train net output #0: accuracy = 0.507812
I0129 05:08:37.538429 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.757812
I0129 05:08:37.538462 46007 solver.cpp:262]     Train net output #2: loss = 2.07681 (* 1 = 2.07681 loss)
I0129 05:08:37.538481 46007 sgd_solver.cpp:122] Iteration 347600, lr = 1e-06
I0129 05:11:11.555092 46007 solver.cpp:243] Iteration 347800 (1.2986 iter/s, 154.011s/200 iters), loss = 1.71141
I0129 05:11:11.566946 46007 solver.cpp:262]     Train net output #0: accuracy = 0.582031
I0129 05:11:11.566962 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.839844
I0129 05:11:11.566987 46007 solver.cpp:262]     Train net output #2: loss = 1.71141 (* 1 = 1.71141 loss)
I0129 05:11:11.566996 46007 sgd_solver.cpp:122] Iteration 347800, lr = 1e-06
I0129 05:13:43.909323 46007 solver.cpp:385] Iteration 348000, Testing net (#0)
I0129 05:13:50.347820 46007 blocking_queue.cpp:49] Waiting for data
I0129 05:16:46.463552 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0129 05:16:46.514482 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46292
I0129 05:16:46.514544 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.709079
I0129 05:16:46.514571 46007 solver.cpp:454]     Test net output #2: loss = 2.44875 (* 1 = 2.44875 loss)
I0129 05:16:46.514582 46007 solver.cpp:474] ================================
I0129 05:16:46.514587 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0129 05:16:46.514595 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0129 05:16:47.191152 46007 solver.cpp:243] Iteration 348000 (0.595925 iter/s, 335.613s/200 iters), loss = 1.48333
I0129 05:16:47.193536 46007 solver.cpp:262]     Train net output #0: accuracy = 0.65625
I0129 05:16:47.193583 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.855469
I0129 05:16:47.193639 46007 solver.cpp:262]     Train net output #2: loss = 1.48333 (* 1 = 1.48333 loss)
I0129 05:16:47.193661 46007 sgd_solver.cpp:122] Iteration 348000, lr = 1e-06
I0129 05:19:15.087293 46007 solver.cpp:243] Iteration 348200 (1.35237 iter/s, 147.888s/200 iters), loss = 1.79735
I0129 05:19:15.099051 46007 solver.cpp:262]     Train net output #0: accuracy = 0.585938
I0129 05:19:15.099069 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.792969
I0129 05:19:15.099092 46007 solver.cpp:262]     Train net output #2: loss = 1.79735 (* 1 = 1.79735 loss)
I0129 05:19:15.099102 46007 sgd_solver.cpp:122] Iteration 348200, lr = 1e-06
I0129 05:21:03.463189 46007 blocking_queue.cpp:49] Waiting for data
I0129 05:21:47.071612 46007 solver.cpp:243] Iteration 348400 (1.31608 iter/s, 151.967s/200 iters), loss = 1.65156
I0129 05:21:47.083420 46007 solver.cpp:262]     Train net output #0: accuracy = 0.589844
I0129 05:21:47.083437 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.820312
I0129 05:21:47.083467 46007 solver.cpp:262]     Train net output #2: loss = 1.65156 (* 1 = 1.65156 loss)
I0129 05:21:47.083479 46007 sgd_solver.cpp:122] Iteration 348400, lr = 1e-06
I0129 05:24:32.573989 46007 solver.cpp:243] Iteration 348600 (1.20857 iter/s, 165.484s/200 iters), loss = 1.57229
I0129 05:24:32.585752 46007 solver.cpp:262]     Train net output #0: accuracy = 0.585938
I0129 05:24:32.585775 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.835938
I0129 05:24:32.585798 46007 solver.cpp:262]     Train net output #2: loss = 1.57229 (* 1 = 1.57229 loss)
I0129 05:24:32.585809 46007 sgd_solver.cpp:122] Iteration 348600, lr = 1e-06
I0129 05:27:20.209796 46007 solver.cpp:243] Iteration 348800 (1.19319 iter/s, 167.618s/200 iters), loss = 1.54934
I0129 05:27:20.221911 46007 solver.cpp:262]     Train net output #0: accuracy = 0.644531
I0129 05:27:20.221937 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.859375
I0129 05:27:20.221968 46007 solver.cpp:262]     Train net output #2: loss = 1.54934 (* 1 = 1.54934 loss)
I0129 05:27:20.221982 46007 sgd_solver.cpp:122] Iteration 348800, lr = 1e-06
I0129 05:30:07.403048 46007 solver.cpp:385] Iteration 349000, Testing net (#0)
I0129 05:32:04.141685 46007 blocking_queue.cpp:49] Waiting for data
I0129 05:32:05.856243 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0129 05:32:05.911816 46007 solver.cpp:454]     Test net output #0: accuracy = 0.46426
I0129 05:32:05.911886 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.708439
I0129 05:32:05.911901 46007 solver.cpp:454]     Test net output #2: loss = 2.44877 (* 1 = 2.44877 loss)
I0129 05:32:05.911909 46007 solver.cpp:474] ================================
I0129 05:32:05.911913 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0129 05:32:05.911919 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0129 05:32:06.617842 46007 solver.cpp:243] Iteration 349000 (0.69836 iter/s, 286.385s/200 iters), loss = 1.67056
I0129 05:32:06.620244 46007 solver.cpp:262]     Train net output #0: accuracy = 0.589844
I0129 05:32:06.620268 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.839844
I0129 05:32:06.620306 46007 solver.cpp:262]     Train net output #2: loss = 1.67056 (* 1 = 1.67056 loss)
I0129 05:32:06.620319 46007 sgd_solver.cpp:122] Iteration 349000, lr = 1e-06
I0129 05:34:52.233533 46007 solver.cpp:243] Iteration 349200 (1.20767 iter/s, 165.608s/200 iters), loss = 1.67832
I0129 05:34:52.233681 46007 solver.cpp:262]     Train net output #0: accuracy = 0.585938
I0129 05:34:52.233708 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.839844
I0129 05:34:52.233737 46007 solver.cpp:262]     Train net output #2: loss = 1.67832 (* 1 = 1.67832 loss)
I0129 05:34:52.233752 46007 sgd_solver.cpp:122] Iteration 349200, lr = 1e-06
I0129 05:37:54.114390 46007 solver.cpp:243] Iteration 349400 (1.09962 iter/s, 181.88s/200 iters), loss = 1.64207
I0129 05:37:54.114498 46007 solver.cpp:262]     Train net output #0: accuracy = 0.546875
I0129 05:37:54.114526 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.855469
I0129 05:37:54.114558 46007 solver.cpp:262]     Train net output #2: loss = 1.64207 (* 1 = 1.64207 loss)
I0129 05:37:54.114576 46007 sgd_solver.cpp:122] Iteration 349400, lr = 1e-06
I0129 05:40:31.534740 46007 solver.cpp:243] Iteration 349600 (1.27049 iter/s, 157.42s/200 iters), loss = 1.56963
I0129 05:40:31.534847 46007 solver.cpp:262]     Train net output #0: accuracy = 0.617188
I0129 05:40:31.534860 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.839844
I0129 05:40:31.534886 46007 solver.cpp:262]     Train net output #2: loss = 1.56963 (* 1 = 1.56963 loss)
I0129 05:40:31.534900 46007 sgd_solver.cpp:122] Iteration 349600, lr = 1e-06
I0129 05:43:30.777441 46007 solver.cpp:243] Iteration 349800 (1.11581 iter/s, 179.242s/200 iters), loss = 1.72705
I0129 05:43:30.777552 46007 solver.cpp:262]     Train net output #0: accuracy = 0.601562
I0129 05:43:30.777566 46007 solver.cpp:262]     Train net output #1: accuracy_5 = 0.820312
I0129 05:43:30.777595 46007 solver.cpp:262]     Train net output #2: loss = 1.72705 (* 1 = 1.72705 loss)
I0129 05:43:30.777611 46007 sgd_solver.cpp:122] Iteration 349800, lr = 1e-06
I0129 05:46:27.390034 46007 solver.cpp:525] Snapshotting to binary proto file snapshot/solver_iter_350000.caffemodel
I0129 05:46:27.390103 46007 net.cpp:929] Serializing 41 layers
I0129 05:46:41.918408 46007 sgd_solver.cpp:311] Snapshotting solver state to binary proto file snapshot/solver_iter_350000.solverstate
I0129 05:46:45.589057 46007 solver.cpp:365] Iteration 350000, loss = 1.66539
I0129 05:46:45.589146 46007 solver.cpp:385] Iteration 350000, Testing net (#0)
I0129 05:48:55.835623 46007 blocking_queue.cpp:49] Waiting for data
I0129 05:48:57.366317 46164 data_layer.cpp:73] Restarting data prefetching from start.
I0129 05:48:57.425094 46007 solver.cpp:454]     Test net output #0: accuracy = 0.45846
I0129 05:48:57.425140 46007 solver.cpp:454]     Test net output #1: accuracy_5 = 0.70512
I0129 05:48:57.425155 46007 solver.cpp:454]     Test net output #2: loss = 2.46549 (* 1 = 2.46549 loss)
I0129 05:48:57.425163 46007 solver.cpp:474] ================================
I0129 05:48:57.425168 46007 solver.cpp:475]     Test net best accuracy1 is: 0.4677
I0129 05:48:57.425173 46007 solver.cpp:477]     Test net best accuracy5 is: 0.71252
I0129 05:48:57.425180 46007 solver.cpp:370] Optimization Done.
I0129 05:48:57.428649 46007 caffe.cpp:250] Optimization Done.
