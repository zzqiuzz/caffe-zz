I0108 22:11:31.145834 14998 upgrade_proto.cpp:1113] snapshot_prefix was a directory and is replaced to snapshot/solver
I0108 22:11:31.146570 14998 caffe.cpp:204] Using GPUs 6
I0108 22:11:31.238108 14998 caffe.cpp:209] GPU 6: GeForce GTX 1080 Ti
I0108 22:11:32.173293 14998 solver.cpp:45] Initializing solver from parameters: 
test_iter: 1000
test_interval: 1000
base_lr: 0.001
display: 200
max_iter: 500000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 10000
snapshot_prefix: "snapshot/solver"
solver_mode: GPU
device_id: 6
net: "train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
I0108 22:11:32.173888 14998 solver.cpp:105] Creating training net from net file: train_test.prototxt
I0108 22:11:32.175523 14998 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0108 22:11:32.175900 14998 net.cpp:51] Initializing net from parameters: 
name: "AlexNet-BN"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/zhengzhe/Data/imagenet_shrt256/ilsvrc12_train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 96
    bias_term: false
    pad: 2
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "pool1"
  top: "pool1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive1"
  type: "BinActive"
  bottom: "pool1"
  top: "binactive1"
}
layer {
  name: "conv2"
  type: "BinaryConvolution"
  bottom: "binactive1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "pool2"
  top: "pool2"
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "pool2"
  top: "pool2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive2"
  type: "BinActive"
  bottom: "pool2"
  top: "binactive2"
}
layer {
  name: "conv3"
  type: "BinaryConvolution"
  bottom: "binactive2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive3"
  type: "BinActive"
  bottom: "conv3"
  top: "binactive3"
}
layer {
  name: "conv4"
  type: "BinaryConvolution"
  bottom: "binactive3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "scale5"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive4"
  type: "BinActive"
  bottom: "conv4"
  top: "binactive4"
}
layer {
  name: "conv5"
  type: "BinaryConvolution"
  bottom: "binactive4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "bn6"
  type: "BatchNorm"
  bottom: "pool5"
  top: "pool5"
}
layer {
  name: "scale6"
  type: "Scale"
  bottom: "pool5"
  top: "pool5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive5"
  type: "BinActive"
  bottom: "pool5"
  top: "binactive5"
}
layer {
  name: "fc6"
  type: "BinaryInnerProduct"
  bottom: "binactive5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4096
    bias_term: false
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "scale7"
  type: "Scale"
  bottom: "fc6"
  top: "fc6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive6"
  type: "BinActive"
  bottom: "fc6"
  top: "binactive6"
}
layer {
  name: "fc7"
  type: "BinaryInnerProduct"
  bottom: "binactive6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4096
    bias_term: false
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn8"
  type: "BatchNorm"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "scale8"
  type: "Scale"
  bottom: "fc7"
  top: "fc7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "accuracy_5"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy_5"
  accuracy_param {
    top_k: 5
  }
}
I0108 22:11:32.176949 14998 layer_factory.hpp:78] Creating layer data
I0108 22:11:32.177254 14998 db_lmdb.cpp:35] Opened lmdb /home/zhengzhe/Data/imagenet_shrt256/ilsvrc12_train_lmdb
I0108 22:11:32.177387 14998 net.cpp:84] Creating Layer data
I0108 22:11:32.177434 14998 net.cpp:380] data -> data
I0108 22:11:32.177650 14998 net.cpp:380] data -> label
I0108 22:11:32.180944 14998 data_layer.cpp:45] output data size: 256,3,224,224
I0108 22:11:32.714380 14998 base_data_layer.cpp:72] Initializing prefetch
I0108 22:11:32.714722 14998 base_data_layer.cpp:75] Prefetch initialized.
I0108 22:11:32.714758 14998 net.cpp:122] Setting up data
I0108 22:11:32.714814 14998 net.cpp:129] Top shape: 256 3 224 224 (38535168)
I0108 22:11:32.714843 14998 net.cpp:129] Top shape: 256 (256)
I0108 22:11:32.714859 14998 net.cpp:137] Memory required for data: 154141696
I0108 22:11:32.714907 14998 layer_factory.hpp:78] Creating layer label_data_1_split
I0108 22:11:32.714987 14998 net.cpp:84] Creating Layer label_data_1_split
I0108 22:11:32.715032 14998 net.cpp:406] label_data_1_split <- label
I0108 22:11:32.715116 14998 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0108 22:11:32.715183 14998 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0108 22:11:32.715224 14998 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0108 22:11:32.715350 14998 net.cpp:122] Setting up label_data_1_split
I0108 22:11:32.715400 14998 net.cpp:129] Top shape: 256 (256)
I0108 22:11:32.715431 14998 net.cpp:129] Top shape: 256 (256)
I0108 22:11:32.715472 14998 net.cpp:129] Top shape: 256 (256)
I0108 22:11:32.715488 14998 net.cpp:137] Memory required for data: 154144768
I0108 22:11:32.715508 14998 layer_factory.hpp:78] Creating layer conv1
I0108 22:11:32.715608 14998 net.cpp:84] Creating Layer conv1
I0108 22:11:32.715638 14998 net.cpp:406] conv1 <- data
I0108 22:11:32.715679 14998 net.cpp:380] conv1 -> conv1
I0108 22:11:34.400485 14998 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 127416
I0108 22:11:34.400827 14998 net.cpp:122] Setting up conv1
I0108 22:11:34.400853 14998 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0108 22:11:34.400864 14998 net.cpp:137] Memory required for data: 451514368
I0108 22:11:34.400954 14998 layer_factory.hpp:78] Creating layer bn1
I0108 22:11:34.400998 14998 net.cpp:84] Creating Layer bn1
I0108 22:11:34.401011 14998 net.cpp:406] bn1 <- conv1
I0108 22:11:34.401041 14998 net.cpp:367] bn1 -> conv1 (in-place)
I0108 22:11:34.402704 14998 net.cpp:122] Setting up bn1
I0108 22:11:34.402720 14998 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0108 22:11:34.402724 14998 net.cpp:137] Memory required for data: 748883968
I0108 22:11:34.402771 14998 layer_factory.hpp:78] Creating layer scale1
I0108 22:11:34.402808 14998 net.cpp:84] Creating Layer scale1
I0108 22:11:34.402817 14998 net.cpp:406] scale1 <- conv1
I0108 22:11:34.402833 14998 net.cpp:367] scale1 -> conv1 (in-place)
I0108 22:11:34.402925 14998 layer_factory.hpp:78] Creating layer scale1
I0108 22:11:34.403142 14998 net.cpp:122] Setting up scale1
I0108 22:11:34.403157 14998 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0108 22:11:34.403161 14998 net.cpp:137] Memory required for data: 1046253568
I0108 22:11:34.403184 14998 layer_factory.hpp:78] Creating layer relu1
I0108 22:11:34.403214 14998 net.cpp:84] Creating Layer relu1
I0108 22:11:34.403223 14998 net.cpp:406] relu1 <- conv1
I0108 22:11:34.403236 14998 net.cpp:367] relu1 -> conv1 (in-place)
I0108 22:11:34.403837 14998 net.cpp:122] Setting up relu1
I0108 22:11:34.403851 14998 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0108 22:11:34.403854 14998 net.cpp:137] Memory required for data: 1343623168
I0108 22:11:34.403861 14998 layer_factory.hpp:78] Creating layer pool1
I0108 22:11:34.403887 14998 net.cpp:84] Creating Layer pool1
I0108 22:11:34.403894 14998 net.cpp:406] pool1 <- conv1
I0108 22:11:34.403911 14998 net.cpp:380] pool1 -> pool1
I0108 22:11:34.403997 14998 net.cpp:122] Setting up pool1
I0108 22:11:34.404011 14998 net.cpp:129] Top shape: 256 96 27 27 (17915904)
I0108 22:11:34.404016 14998 net.cpp:137] Memory required for data: 1415286784
I0108 22:11:34.404021 14998 layer_factory.hpp:78] Creating layer bn2
I0108 22:11:34.404034 14998 net.cpp:84] Creating Layer bn2
I0108 22:11:34.404042 14998 net.cpp:406] bn2 <- pool1
I0108 22:11:34.404058 14998 net.cpp:367] bn2 -> pool1 (in-place)
I0108 22:11:34.405619 14998 net.cpp:122] Setting up bn2
I0108 22:11:34.405635 14998 net.cpp:129] Top shape: 256 96 27 27 (17915904)
I0108 22:11:34.405639 14998 net.cpp:137] Memory required for data: 1486950400
I0108 22:11:34.405673 14998 layer_factory.hpp:78] Creating layer scale2
I0108 22:11:34.405696 14998 net.cpp:84] Creating Layer scale2
I0108 22:11:34.405705 14998 net.cpp:406] scale2 <- pool1
I0108 22:11:34.405724 14998 net.cpp:367] scale2 -> pool1 (in-place)
I0108 22:11:34.405787 14998 layer_factory.hpp:78] Creating layer scale2
I0108 22:11:34.405967 14998 net.cpp:122] Setting up scale2
I0108 22:11:34.405979 14998 net.cpp:129] Top shape: 256 96 27 27 (17915904)
I0108 22:11:34.405982 14998 net.cpp:137] Memory required for data: 1558614016
I0108 22:11:34.405997 14998 layer_factory.hpp:78] Creating layer binactive1
I0108 22:11:34.406016 14998 net.cpp:84] Creating Layer binactive1
I0108 22:11:34.406024 14998 net.cpp:406] binactive1 <- pool1
I0108 22:11:34.406042 14998 net.cpp:380] binactive1 -> binactive1
I0108 22:11:34.406085 14998 net.cpp:122] Setting up binactive1
I0108 22:11:34.406096 14998 net.cpp:129] Top shape: 256 96 27 27 (17915904)
I0108 22:11:34.406100 14998 net.cpp:137] Memory required for data: 1630277632
I0108 22:11:34.406127 14998 layer_factory.hpp:78] Creating layer conv2
I0108 22:11:34.406167 14998 net.cpp:84] Creating Layer conv2
I0108 22:11:34.406177 14998 net.cpp:406] conv2 <- binactive1
I0108 22:11:34.406196 14998 net.cpp:380] conv2 -> conv2
I0108 22:11:34.466025 14998 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 19668
I0108 22:11:34.466071 14998 net.cpp:122] Setting up conv2
I0108 22:11:34.466089 14998 net.cpp:129] Top shape: 256 256 27 27 (47775744)
I0108 22:11:34.466094 14998 net.cpp:137] Memory required for data: 1821380608
I0108 22:11:34.466118 14998 layer_factory.hpp:78] Creating layer pool2
I0108 22:11:34.466157 14998 net.cpp:84] Creating Layer pool2
I0108 22:11:34.466169 14998 net.cpp:406] pool2 <- conv2
I0108 22:11:34.466197 14998 net.cpp:380] pool2 -> pool2
I0108 22:11:34.466267 14998 net.cpp:122] Setting up pool2
I0108 22:11:34.466284 14998 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0108 22:11:34.466287 14998 net.cpp:137] Memory required for data: 1865682944
I0108 22:11:34.466293 14998 layer_factory.hpp:78] Creating layer bn3
I0108 22:11:34.466307 14998 net.cpp:84] Creating Layer bn3
I0108 22:11:34.466313 14998 net.cpp:406] bn3 <- pool2
I0108 22:11:34.466326 14998 net.cpp:367] bn3 -> pool2 (in-place)
I0108 22:11:34.466559 14998 net.cpp:122] Setting up bn3
I0108 22:11:34.466572 14998 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0108 22:11:34.466576 14998 net.cpp:137] Memory required for data: 1909985280
I0108 22:11:34.466606 14998 layer_factory.hpp:78] Creating layer scale3
I0108 22:11:34.466629 14998 net.cpp:84] Creating Layer scale3
I0108 22:11:34.466636 14998 net.cpp:406] scale3 <- pool2
I0108 22:11:34.466651 14998 net.cpp:367] scale3 -> pool2 (in-place)
I0108 22:11:34.466717 14998 layer_factory.hpp:78] Creating layer scale3
I0108 22:11:34.466876 14998 net.cpp:122] Setting up scale3
I0108 22:11:34.466890 14998 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0108 22:11:34.466895 14998 net.cpp:137] Memory required for data: 1954287616
I0108 22:11:34.466922 14998 layer_factory.hpp:78] Creating layer binactive2
I0108 22:11:34.466938 14998 net.cpp:84] Creating Layer binactive2
I0108 22:11:34.466946 14998 net.cpp:406] binactive2 <- pool2
I0108 22:11:34.466959 14998 net.cpp:380] binactive2 -> binactive2
I0108 22:11:34.466996 14998 net.cpp:122] Setting up binactive2
I0108 22:11:34.467007 14998 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0108 22:11:34.467011 14998 net.cpp:137] Memory required for data: 1998589952
I0108 22:11:34.467017 14998 layer_factory.hpp:78] Creating layer conv3
I0108 22:11:34.467049 14998 net.cpp:84] Creating Layer conv3
I0108 22:11:34.467058 14998 net.cpp:406] conv3 <- binactive2
I0108 22:11:34.467077 14998 net.cpp:380] conv3 -> conv3
I0108 22:11:34.550063 14998 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 18874368
I0108 22:11:34.552021 14998 net.cpp:122] Setting up conv3
I0108 22:11:34.552045 14998 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0108 22:11:34.552049 14998 net.cpp:137] Memory required for data: 2065043456
I0108 22:11:34.552079 14998 layer_factory.hpp:78] Creating layer bn4
I0108 22:11:34.552125 14998 net.cpp:84] Creating Layer bn4
I0108 22:11:34.552139 14998 net.cpp:406] bn4 <- conv3
I0108 22:11:34.552166 14998 net.cpp:367] bn4 -> conv3 (in-place)
I0108 22:11:34.552423 14998 net.cpp:122] Setting up bn4
I0108 22:11:34.552434 14998 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0108 22:11:34.552438 14998 net.cpp:137] Memory required for data: 2131496960
I0108 22:11:34.552461 14998 layer_factory.hpp:78] Creating layer scale4
I0108 22:11:34.552485 14998 net.cpp:84] Creating Layer scale4
I0108 22:11:34.552491 14998 net.cpp:406] scale4 <- conv3
I0108 22:11:34.552505 14998 net.cpp:367] scale4 -> conv3 (in-place)
I0108 22:11:34.552568 14998 layer_factory.hpp:78] Creating layer scale4
I0108 22:11:34.552737 14998 net.cpp:122] Setting up scale4
I0108 22:11:34.552749 14998 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0108 22:11:34.552752 14998 net.cpp:137] Memory required for data: 2197950464
I0108 22:11:34.552793 14998 layer_factory.hpp:78] Creating layer binactive3
I0108 22:11:34.552812 14998 net.cpp:84] Creating Layer binactive3
I0108 22:11:34.552819 14998 net.cpp:406] binactive3 <- conv3
I0108 22:11:34.552834 14998 net.cpp:380] binactive3 -> binactive3
I0108 22:11:34.552873 14998 net.cpp:122] Setting up binactive3
I0108 22:11:34.552886 14998 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0108 22:11:34.552888 14998 net.cpp:137] Memory required for data: 2264403968
I0108 22:11:34.552894 14998 layer_factory.hpp:78] Creating layer conv4
I0108 22:11:34.552927 14998 net.cpp:84] Creating Layer conv4
I0108 22:11:34.552935 14998 net.cpp:406] conv4 <- binactive3
I0108 22:11:34.552953 14998 net.cpp:380] conv4 -> conv4
I0108 22:11:34.674500 14998 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 9840
I0108 22:11:34.674547 14998 net.cpp:122] Setting up conv4
I0108 22:11:34.674566 14998 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0108 22:11:34.674569 14998 net.cpp:137] Memory required for data: 2330857472
I0108 22:11:34.674597 14998 layer_factory.hpp:78] Creating layer bn5
I0108 22:11:34.674633 14998 net.cpp:84] Creating Layer bn5
I0108 22:11:34.674646 14998 net.cpp:406] bn5 <- conv4
I0108 22:11:34.674670 14998 net.cpp:367] bn5 -> conv4 (in-place)
I0108 22:11:34.674911 14998 net.cpp:122] Setting up bn5
I0108 22:11:34.674922 14998 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0108 22:11:34.674926 14998 net.cpp:137] Memory required for data: 2397310976
I0108 22:11:34.674947 14998 layer_factory.hpp:78] Creating layer scale5
I0108 22:11:34.674968 14998 net.cpp:84] Creating Layer scale5
I0108 22:11:34.674975 14998 net.cpp:406] scale5 <- conv4
I0108 22:11:34.674989 14998 net.cpp:367] scale5 -> conv4 (in-place)
I0108 22:11:34.675056 14998 layer_factory.hpp:78] Creating layer scale5
I0108 22:11:34.675226 14998 net.cpp:122] Setting up scale5
I0108 22:11:34.675238 14998 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0108 22:11:34.675243 14998 net.cpp:137] Memory required for data: 2463764480
I0108 22:11:34.675258 14998 layer_factory.hpp:78] Creating layer binactive4
I0108 22:11:34.675272 14998 net.cpp:84] Creating Layer binactive4
I0108 22:11:34.675279 14998 net.cpp:406] binactive4 <- conv4
I0108 22:11:34.675294 14998 net.cpp:380] binactive4 -> binactive4
I0108 22:11:34.675333 14998 net.cpp:122] Setting up binactive4
I0108 22:11:34.675352 14998 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0108 22:11:34.675356 14998 net.cpp:137] Memory required for data: 2530217984
I0108 22:11:34.675362 14998 layer_factory.hpp:78] Creating layer conv5
I0108 22:11:34.675395 14998 net.cpp:84] Creating Layer conv5
I0108 22:11:34.675403 14998 net.cpp:406] conv5 <- binactive4
I0108 22:11:34.675422 14998 net.cpp:380] conv5 -> conv5
I0108 22:11:34.757064 14998 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 18874368
I0108 22:11:34.757436 14998 net.cpp:122] Setting up conv5
I0108 22:11:34.757459 14998 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0108 22:11:34.757464 14998 net.cpp:137] Memory required for data: 2574520320
I0108 22:11:34.757493 14998 layer_factory.hpp:78] Creating layer pool5
I0108 22:11:34.757532 14998 net.cpp:84] Creating Layer pool5
I0108 22:11:34.757546 14998 net.cpp:406] pool5 <- conv5
I0108 22:11:34.757572 14998 net.cpp:380] pool5 -> pool5
I0108 22:11:34.757658 14998 net.cpp:122] Setting up pool5
I0108 22:11:34.757673 14998 net.cpp:129] Top shape: 256 256 6 6 (2359296)
I0108 22:11:34.757676 14998 net.cpp:137] Memory required for data: 2583957504
I0108 22:11:34.757683 14998 layer_factory.hpp:78] Creating layer bn6
I0108 22:11:34.757696 14998 net.cpp:84] Creating Layer bn6
I0108 22:11:34.757704 14998 net.cpp:406] bn6 <- pool5
I0108 22:11:34.757725 14998 net.cpp:367] bn6 -> pool5 (in-place)
I0108 22:11:34.757951 14998 net.cpp:122] Setting up bn6
I0108 22:11:34.757961 14998 net.cpp:129] Top shape: 256 256 6 6 (2359296)
I0108 22:11:34.757966 14998 net.cpp:137] Memory required for data: 2593394688
I0108 22:11:34.758002 14998 layer_factory.hpp:78] Creating layer scale6
I0108 22:11:34.758049 14998 net.cpp:84] Creating Layer scale6
I0108 22:11:34.758059 14998 net.cpp:406] scale6 <- pool5
I0108 22:11:34.758074 14998 net.cpp:367] scale6 -> pool5 (in-place)
I0108 22:11:34.758146 14998 layer_factory.hpp:78] Creating layer scale6
I0108 22:11:34.758308 14998 net.cpp:122] Setting up scale6
I0108 22:11:34.758322 14998 net.cpp:129] Top shape: 256 256 6 6 (2359296)
I0108 22:11:34.758327 14998 net.cpp:137] Memory required for data: 2602831872
I0108 22:11:34.758347 14998 layer_factory.hpp:78] Creating layer binactive5
I0108 22:11:34.758363 14998 net.cpp:84] Creating Layer binactive5
I0108 22:11:34.758369 14998 net.cpp:406] binactive5 <- pool5
I0108 22:11:34.758385 14998 net.cpp:380] binactive5 -> binactive5
I0108 22:11:34.758433 14998 net.cpp:122] Setting up binactive5
I0108 22:11:34.758443 14998 net.cpp:129] Top shape: 256 256 6 6 (2359296)
I0108 22:11:34.758446 14998 net.cpp:137] Memory required for data: 2612269056
I0108 22:11:34.758452 14998 layer_factory.hpp:78] Creating layer fc6
I0108 22:11:34.758483 14998 net.cpp:84] Creating Layer fc6
I0108 22:11:34.758492 14998 net.cpp:406] fc6 <- binactive5
I0108 22:11:34.758509 14998 net.cpp:380] fc6 -> fc6
I0108 22:11:38.096129 14998 net.cpp:122] Setting up fc6
I0108 22:11:38.096189 14998 net.cpp:129] Top shape: 256 4096 (1048576)
I0108 22:11:38.096194 14998 net.cpp:137] Memory required for data: 2616463360
I0108 22:11:38.096241 14998 layer_factory.hpp:78] Creating layer bn7
I0108 22:11:38.096297 14998 net.cpp:84] Creating Layer bn7
I0108 22:11:38.096328 14998 net.cpp:406] bn7 <- fc6
I0108 22:11:38.096376 14998 net.cpp:367] bn7 -> fc6 (in-place)
I0108 22:11:38.096632 14998 net.cpp:122] Setting up bn7
I0108 22:11:38.096657 14998 net.cpp:129] Top shape: 256 4096 (1048576)
I0108 22:11:38.096662 14998 net.cpp:137] Memory required for data: 2620657664
I0108 22:11:38.096704 14998 layer_factory.hpp:78] Creating layer scale7
I0108 22:11:38.096730 14998 net.cpp:84] Creating Layer scale7
I0108 22:11:38.096741 14998 net.cpp:406] scale7 <- fc6
I0108 22:11:38.096756 14998 net.cpp:367] scale7 -> fc6 (in-place)
I0108 22:11:38.096851 14998 layer_factory.hpp:78] Creating layer scale7
I0108 22:11:38.097051 14998 net.cpp:122] Setting up scale7
I0108 22:11:38.097064 14998 net.cpp:129] Top shape: 256 4096 (1048576)
I0108 22:11:38.097069 14998 net.cpp:137] Memory required for data: 2624851968
I0108 22:11:38.097097 14998 layer_factory.hpp:78] Creating layer binactive6
I0108 22:11:38.097110 14998 net.cpp:84] Creating Layer binactive6
I0108 22:11:38.097117 14998 net.cpp:406] binactive6 <- fc6
I0108 22:11:38.097139 14998 net.cpp:380] binactive6 -> binactive6
I0108 22:11:38.097180 14998 net.cpp:122] Setting up binactive6
I0108 22:11:38.097193 14998 net.cpp:129] Top shape: 256 4096 (1048576)
I0108 22:11:38.097198 14998 net.cpp:137] Memory required for data: 2629046272
I0108 22:11:38.097203 14998 layer_factory.hpp:78] Creating layer fc7
I0108 22:11:38.097237 14998 net.cpp:84] Creating Layer fc7
I0108 22:11:38.097246 14998 net.cpp:406] fc7 <- binactive6
I0108 22:11:38.097265 14998 net.cpp:380] fc7 -> fc7
I0108 22:11:40.200212 14998 net.cpp:122] Setting up fc7
I0108 22:11:40.200332 14998 net.cpp:129] Top shape: 256 4096 (1048576)
I0108 22:11:40.200361 14998 net.cpp:137] Memory required for data: 2633240576
I0108 22:11:40.200417 14998 layer_factory.hpp:78] Creating layer bn8
I0108 22:11:40.200489 14998 net.cpp:84] Creating Layer bn8
I0108 22:11:40.200525 14998 net.cpp:406] bn8 <- fc7
I0108 22:11:40.200575 14998 net.cpp:367] bn8 -> fc7 (in-place)
I0108 22:11:40.200947 14998 net.cpp:122] Setting up bn8
I0108 22:11:40.200981 14998 net.cpp:129] Top shape: 256 4096 (1048576)
I0108 22:11:40.201004 14998 net.cpp:137] Memory required for data: 2637434880
I0108 22:11:40.201054 14998 layer_factory.hpp:78] Creating layer scale8
I0108 22:11:40.201108 14998 net.cpp:84] Creating Layer scale8
I0108 22:11:40.201138 14998 net.cpp:406] scale8 <- fc7
I0108 22:11:40.201179 14998 net.cpp:367] scale8 -> fc7 (in-place)
I0108 22:11:40.201321 14998 layer_factory.hpp:78] Creating layer scale8
I0108 22:11:40.201608 14998 net.cpp:122] Setting up scale8
I0108 22:11:40.201664 14998 net.cpp:129] Top shape: 256 4096 (1048576)
I0108 22:11:40.201687 14998 net.cpp:137] Memory required for data: 2641629184
I0108 22:11:40.201722 14998 layer_factory.hpp:78] Creating layer relu7
I0108 22:11:40.201761 14998 net.cpp:84] Creating Layer relu7
I0108 22:11:40.201787 14998 net.cpp:406] relu7 <- fc7
I0108 22:11:40.201826 14998 net.cpp:367] relu7 -> fc7 (in-place)
I0108 22:11:40.203145 14998 net.cpp:122] Setting up relu7
I0108 22:11:40.203187 14998 net.cpp:129] Top shape: 256 4096 (1048576)
I0108 22:11:40.203210 14998 net.cpp:137] Memory required for data: 2645823488
I0108 22:11:40.203233 14998 layer_factory.hpp:78] Creating layer fc8
I0108 22:11:40.203291 14998 net.cpp:84] Creating Layer fc8
I0108 22:11:40.203322 14998 net.cpp:406] fc8 <- fc7
I0108 22:11:40.203375 14998 net.cpp:380] fc8 -> fc8
I0108 22:11:40.590618 14998 net.cpp:122] Setting up fc8
I0108 22:11:40.590689 14998 net.cpp:129] Top shape: 256 1000 (256000)
I0108 22:11:40.590694 14998 net.cpp:137] Memory required for data: 2646847488
I0108 22:11:40.590728 14998 layer_factory.hpp:78] Creating layer fc8_fc8_0_split
I0108 22:11:40.590760 14998 net.cpp:84] Creating Layer fc8_fc8_0_split
I0108 22:11:40.590775 14998 net.cpp:406] fc8_fc8_0_split <- fc8
I0108 22:11:40.590798 14998 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0108 22:11:40.590823 14998 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0108 22:11:40.590837 14998 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0108 22:11:40.590903 14998 net.cpp:122] Setting up fc8_fc8_0_split
I0108 22:11:40.590914 14998 net.cpp:129] Top shape: 256 1000 (256000)
I0108 22:11:40.590919 14998 net.cpp:129] Top shape: 256 1000 (256000)
I0108 22:11:40.590924 14998 net.cpp:129] Top shape: 256 1000 (256000)
I0108 22:11:40.590925 14998 net.cpp:137] Memory required for data: 2649919488
I0108 22:11:40.590931 14998 layer_factory.hpp:78] Creating layer loss
I0108 22:11:40.590961 14998 net.cpp:84] Creating Layer loss
I0108 22:11:40.590970 14998 net.cpp:406] loss <- fc8_fc8_0_split_0
I0108 22:11:40.590982 14998 net.cpp:406] loss <- label_data_1_split_0
I0108 22:11:40.591001 14998 net.cpp:380] loss -> loss
I0108 22:11:40.591048 14998 layer_factory.hpp:78] Creating layer loss
I0108 22:11:40.593888 14998 net.cpp:122] Setting up loss
I0108 22:11:40.593904 14998 net.cpp:129] Top shape: (1)
I0108 22:11:40.593909 14998 net.cpp:132]     with loss weight 1
I0108 22:11:40.593945 14998 net.cpp:137] Memory required for data: 2649919492
I0108 22:11:40.593952 14998 layer_factory.hpp:78] Creating layer accuracy
I0108 22:11:40.593971 14998 net.cpp:84] Creating Layer accuracy
I0108 22:11:40.593981 14998 net.cpp:406] accuracy <- fc8_fc8_0_split_1
I0108 22:11:40.594008 14998 net.cpp:406] accuracy <- label_data_1_split_1
I0108 22:11:40.594018 14998 net.cpp:380] accuracy -> accuracy
I0108 22:11:40.594041 14998 net.cpp:122] Setting up accuracy
I0108 22:11:40.594050 14998 net.cpp:129] Top shape: (1)
I0108 22:11:40.594053 14998 net.cpp:137] Memory required for data: 2649919496
I0108 22:11:40.594058 14998 layer_factory.hpp:78] Creating layer accuracy_5
I0108 22:11:40.594070 14998 net.cpp:84] Creating Layer accuracy_5
I0108 22:11:40.594079 14998 net.cpp:406] accuracy_5 <- fc8_fc8_0_split_2
I0108 22:11:40.594105 14998 net.cpp:406] accuracy_5 <- label_data_1_split_2
I0108 22:11:40.594118 14998 net.cpp:380] accuracy_5 -> accuracy_5
I0108 22:11:40.594141 14998 net.cpp:122] Setting up accuracy_5
I0108 22:11:40.594149 14998 net.cpp:129] Top shape: (1)
I0108 22:11:40.594152 14998 net.cpp:137] Memory required for data: 2649919500
I0108 22:11:40.594159 14998 net.cpp:200] accuracy_5 does not need backward computation.
I0108 22:11:40.594166 14998 net.cpp:200] accuracy does not need backward computation.
I0108 22:11:40.594172 14998 net.cpp:198] loss needs backward computation.
I0108 22:11:40.594177 14998 net.cpp:198] fc8_fc8_0_split needs backward computation.
I0108 22:11:40.594180 14998 net.cpp:198] fc8 needs backward computation.
I0108 22:11:40.594184 14998 net.cpp:198] relu7 needs backward computation.
I0108 22:11:40.594211 14998 net.cpp:198] scale8 needs backward computation.
I0108 22:11:40.594215 14998 net.cpp:198] bn8 needs backward computation.
I0108 22:11:40.594218 14998 net.cpp:198] fc7 needs backward computation.
I0108 22:11:40.594223 14998 net.cpp:198] binactive6 needs backward computation.
I0108 22:11:40.594228 14998 net.cpp:198] scale7 needs backward computation.
I0108 22:11:40.594230 14998 net.cpp:198] bn7 needs backward computation.
I0108 22:11:40.594234 14998 net.cpp:198] fc6 needs backward computation.
I0108 22:11:40.594238 14998 net.cpp:198] binactive5 needs backward computation.
I0108 22:11:40.594242 14998 net.cpp:198] scale6 needs backward computation.
I0108 22:11:40.594246 14998 net.cpp:198] bn6 needs backward computation.
I0108 22:11:40.594249 14998 net.cpp:198] pool5 needs backward computation.
I0108 22:11:40.594254 14998 net.cpp:198] conv5 needs backward computation.
I0108 22:11:40.594259 14998 net.cpp:198] binactive4 needs backward computation.
I0108 22:11:40.594264 14998 net.cpp:198] scale5 needs backward computation.
I0108 22:11:40.594267 14998 net.cpp:198] bn5 needs backward computation.
I0108 22:11:40.594270 14998 net.cpp:198] conv4 needs backward computation.
I0108 22:11:40.594275 14998 net.cpp:198] binactive3 needs backward computation.
I0108 22:11:40.594280 14998 net.cpp:198] scale4 needs backward computation.
I0108 22:11:40.594282 14998 net.cpp:198] bn4 needs backward computation.
I0108 22:11:40.594286 14998 net.cpp:198] conv3 needs backward computation.
I0108 22:11:40.594290 14998 net.cpp:198] binactive2 needs backward computation.
I0108 22:11:40.594301 14998 net.cpp:198] scale3 needs backward computation.
I0108 22:11:40.594305 14998 net.cpp:198] bn3 needs backward computation.
I0108 22:11:40.594310 14998 net.cpp:198] pool2 needs backward computation.
I0108 22:11:40.594313 14998 net.cpp:198] conv2 needs backward computation.
I0108 22:11:40.594317 14998 net.cpp:198] binactive1 needs backward computation.
I0108 22:11:40.594321 14998 net.cpp:198] scale2 needs backward computation.
I0108 22:11:40.594324 14998 net.cpp:198] bn2 needs backward computation.
I0108 22:11:40.594334 14998 net.cpp:198] pool1 needs backward computation.
I0108 22:11:40.594346 14998 net.cpp:198] relu1 needs backward computation.
I0108 22:11:40.594349 14998 net.cpp:198] scale1 needs backward computation.
I0108 22:11:40.594369 14998 net.cpp:198] bn1 needs backward computation.
I0108 22:11:40.594377 14998 net.cpp:198] conv1 needs backward computation.
I0108 22:11:40.594388 14998 net.cpp:200] label_data_1_split does not need backward computation.
I0108 22:11:40.594395 14998 net.cpp:200] data does not need backward computation.
I0108 22:11:40.594408 14998 net.cpp:242] This network produces output accuracy
I0108 22:11:40.594415 14998 net.cpp:242] This network produces output accuracy_5
I0108 22:11:40.594420 14998 net.cpp:242] This network produces output loss
I0108 22:11:40.594492 14998 net.cpp:255] Network initialization done.
I0108 22:11:40.595381 14998 solver.cpp:193] Creating test net (#0) specified by net file: train_test.prototxt
I0108 22:11:40.595485 14998 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0108 22:11:40.595685 14998 net.cpp:51] Initializing net from parameters: 
name: "AlexNet-BN"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 224
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/zhengzhe/Data/imagenet_shrt256/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 96
    bias_term: false
    pad: 2
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "pool1"
  top: "pool1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive1"
  type: "BinActive"
  bottom: "pool1"
  top: "binactive1"
}
layer {
  name: "conv2"
  type: "BinaryConvolution"
  bottom: "binactive1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "pool2"
  top: "pool2"
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "pool2"
  top: "pool2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive2"
  type: "BinActive"
  bottom: "pool2"
  top: "binactive2"
}
layer {
  name: "conv3"
  type: "BinaryConvolution"
  bottom: "binactive2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive3"
  type: "BinActive"
  bottom: "conv3"
  top: "binactive3"
}
layer {
  name: "conv4"
  type: "BinaryConvolution"
  bottom: "binactive3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "scale5"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive4"
  type: "BinActive"
  bottom: "conv4"
  top: "binactive4"
}
layer {
  name: "conv5"
  type: "BinaryConvolution"
  bottom: "binactive4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "bn6"
  type: "BatchNorm"
  bottom: "pool5"
  top: "pool5"
}
layer {
  name: "scale6"
  type: "Scale"
  bottom: "pool5"
  top: "pool5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive5"
  type: "BinActive"
  bottom: "pool5"
  top: "binactive5"
}
layer {
  name: "fc6"
  type: "BinaryInnerProduct"
  bottom: "binactive5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4096
    bias_term: false
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "scale7"
  type: "Scale"
  bottom: "fc6"
  top: "fc6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive6"
  type: "BinActive"
  bottom: "fc6"
  top: "binactive6"
}
layer {
  name: "fc7"
  type: "BinaryInnerProduct"
  bottom: "binactive6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4096
    bias_term: false
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn8"
  type: "BatchNorm"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "scale8"
  type: "Scale"
  bottom: "fc7"
  top: "fc7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "accuracy_5"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy_5"
  accuracy_param {
    top_k: 5
  }
}
I0108 22:11:40.596048 14998 layer_factory.hpp:78] Creating layer data
I0108 22:11:40.596134 14998 db_lmdb.cpp:35] Opened lmdb /home/zhengzhe/Data/imagenet_shrt256/ilsvrc12_val_lmdb
I0108 22:11:40.596168 14998 net.cpp:84] Creating Layer data
I0108 22:11:40.596184 14998 net.cpp:380] data -> data
I0108 22:11:40.596231 14998 net.cpp:380] data -> label
I0108 22:11:40.596801 14998 data_layer.cpp:45] output data size: 50,3,224,224
I0108 22:11:40.675067 14998 base_data_layer.cpp:72] Initializing prefetch
I0108 22:11:40.912631 14998 base_data_layer.cpp:75] Prefetch initialized.
I0108 22:11:40.912667 14998 net.cpp:122] Setting up data
I0108 22:11:40.912693 14998 net.cpp:129] Top shape: 50 3 224 224 (7526400)
I0108 22:11:40.912700 14998 net.cpp:129] Top shape: 50 (50)
I0108 22:11:40.912703 14998 net.cpp:137] Memory required for data: 30105800
I0108 22:11:40.912730 14998 layer_factory.hpp:78] Creating layer label_data_1_split
I0108 22:11:40.912781 14998 net.cpp:84] Creating Layer label_data_1_split
I0108 22:11:40.912796 14998 net.cpp:406] label_data_1_split <- label
I0108 22:11:40.912827 14998 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0108 22:11:40.912860 14998 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0108 22:11:40.912875 14998 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0108 22:11:40.913056 14998 net.cpp:122] Setting up label_data_1_split
I0108 22:11:40.913071 14998 net.cpp:129] Top shape: 50 (50)
I0108 22:11:40.913076 14998 net.cpp:129] Top shape: 50 (50)
I0108 22:11:40.913081 14998 net.cpp:129] Top shape: 50 (50)
I0108 22:11:40.913084 14998 net.cpp:137] Memory required for data: 30106400
I0108 22:11:40.913090 14998 layer_factory.hpp:78] Creating layer conv1
I0108 22:11:40.913130 14998 net.cpp:84] Creating Layer conv1
I0108 22:11:40.913139 14998 net.cpp:406] conv1 <- data
I0108 22:11:40.913157 14998 net.cpp:380] conv1 -> conv1
I0108 22:11:40.920897 14998 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 127416
I0108 22:11:40.920995 14998 net.cpp:122] Setting up conv1
I0108 22:11:40.921008 14998 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0108 22:11:40.921013 14998 net.cpp:137] Memory required for data: 88186400
I0108 22:11:40.921043 14998 layer_factory.hpp:78] Creating layer bn1
I0108 22:11:40.921061 14998 net.cpp:84] Creating Layer bn1
I0108 22:11:40.921072 14998 net.cpp:406] bn1 <- conv1
I0108 22:11:40.921084 14998 net.cpp:367] bn1 -> conv1 (in-place)
I0108 22:11:40.921437 14998 net.cpp:122] Setting up bn1
I0108 22:11:40.921450 14998 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0108 22:11:40.921453 14998 net.cpp:137] Memory required for data: 146266400
I0108 22:11:40.921486 14998 layer_factory.hpp:78] Creating layer scale1
I0108 22:11:40.921512 14998 net.cpp:84] Creating Layer scale1
I0108 22:11:40.921519 14998 net.cpp:406] scale1 <- conv1
I0108 22:11:40.921536 14998 net.cpp:367] scale1 -> conv1 (in-place)
I0108 22:11:40.921612 14998 layer_factory.hpp:78] Creating layer scale1
I0108 22:11:40.921867 14998 net.cpp:122] Setting up scale1
I0108 22:11:40.921880 14998 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0108 22:11:40.921883 14998 net.cpp:137] Memory required for data: 204346400
I0108 22:11:40.921933 14998 layer_factory.hpp:78] Creating layer relu1
I0108 22:11:40.921950 14998 net.cpp:84] Creating Layer relu1
I0108 22:11:40.921957 14998 net.cpp:406] relu1 <- conv1
I0108 22:11:40.921972 14998 net.cpp:367] relu1 -> conv1 (in-place)
I0108 22:11:40.922631 14998 net.cpp:122] Setting up relu1
I0108 22:11:40.922659 14998 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0108 22:11:40.922673 14998 net.cpp:137] Memory required for data: 262426400
I0108 22:11:40.922679 14998 layer_factory.hpp:78] Creating layer pool1
I0108 22:11:40.922701 14998 net.cpp:84] Creating Layer pool1
I0108 22:11:40.922710 14998 net.cpp:406] pool1 <- conv1
I0108 22:11:40.922727 14998 net.cpp:380] pool1 -> pool1
I0108 22:11:40.922798 14998 net.cpp:122] Setting up pool1
I0108 22:11:40.922811 14998 net.cpp:129] Top shape: 50 96 27 27 (3499200)
I0108 22:11:40.922816 14998 net.cpp:137] Memory required for data: 276423200
I0108 22:11:40.922821 14998 layer_factory.hpp:78] Creating layer bn2
I0108 22:11:40.922834 14998 net.cpp:84] Creating Layer bn2
I0108 22:11:40.922840 14998 net.cpp:406] bn2 <- pool1
I0108 22:11:40.922857 14998 net.cpp:367] bn2 -> pool1 (in-place)
I0108 22:11:40.923115 14998 net.cpp:122] Setting up bn2
I0108 22:11:40.923125 14998 net.cpp:129] Top shape: 50 96 27 27 (3499200)
I0108 22:11:40.923128 14998 net.cpp:137] Memory required for data: 290420000
I0108 22:11:40.923157 14998 layer_factory.hpp:78] Creating layer scale2
I0108 22:11:40.923179 14998 net.cpp:84] Creating Layer scale2
I0108 22:11:40.923187 14998 net.cpp:406] scale2 <- pool1
I0108 22:11:40.923203 14998 net.cpp:367] scale2 -> pool1 (in-place)
I0108 22:11:40.923276 14998 layer_factory.hpp:78] Creating layer scale2
I0108 22:11:40.923547 14998 net.cpp:122] Setting up scale2
I0108 22:11:40.923574 14998 net.cpp:129] Top shape: 50 96 27 27 (3499200)
I0108 22:11:40.923578 14998 net.cpp:137] Memory required for data: 304416800
I0108 22:11:40.923593 14998 layer_factory.hpp:78] Creating layer binactive1
I0108 22:11:40.923609 14998 net.cpp:84] Creating Layer binactive1
I0108 22:11:40.923615 14998 net.cpp:406] binactive1 <- pool1
I0108 22:11:40.923645 14998 net.cpp:380] binactive1 -> binactive1
I0108 22:11:40.923686 14998 net.cpp:122] Setting up binactive1
I0108 22:11:40.923697 14998 net.cpp:129] Top shape: 50 96 27 27 (3499200)
I0108 22:11:40.923701 14998 net.cpp:137] Memory required for data: 318413600
I0108 22:11:40.923705 14998 layer_factory.hpp:78] Creating layer conv2
I0108 22:11:40.923732 14998 net.cpp:84] Creating Layer conv2
I0108 22:11:40.923741 14998 net.cpp:406] conv2 <- binactive1
I0108 22:11:40.923758 14998 net.cpp:380] conv2 -> conv2
I0108 22:11:40.981945 14998 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 19668
I0108 22:11:40.982005 14998 net.cpp:122] Setting up conv2
I0108 22:11:40.982023 14998 net.cpp:129] Top shape: 50 256 27 27 (9331200)
I0108 22:11:40.982026 14998 net.cpp:137] Memory required for data: 355738400
I0108 22:11:40.982060 14998 layer_factory.hpp:78] Creating layer pool2
I0108 22:11:40.982097 14998 net.cpp:84] Creating Layer pool2
I0108 22:11:40.982110 14998 net.cpp:406] pool2 <- conv2
I0108 22:11:40.982151 14998 net.cpp:380] pool2 -> pool2
I0108 22:11:40.982225 14998 net.cpp:122] Setting up pool2
I0108 22:11:40.982237 14998 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0108 22:11:40.982242 14998 net.cpp:137] Memory required for data: 364391200
I0108 22:11:40.982249 14998 layer_factory.hpp:78] Creating layer bn3
I0108 22:11:40.982262 14998 net.cpp:84] Creating Layer bn3
I0108 22:11:40.982270 14998 net.cpp:406] bn3 <- pool2
I0108 22:11:40.982282 14998 net.cpp:367] bn3 -> pool2 (in-place)
I0108 22:11:40.982571 14998 net.cpp:122] Setting up bn3
I0108 22:11:40.982583 14998 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0108 22:11:40.982586 14998 net.cpp:137] Memory required for data: 373044000
I0108 22:11:40.982607 14998 layer_factory.hpp:78] Creating layer scale3
I0108 22:11:40.982627 14998 net.cpp:84] Creating Layer scale3
I0108 22:11:40.982635 14998 net.cpp:406] scale3 <- pool2
I0108 22:11:40.982683 14998 net.cpp:367] scale3 -> pool2 (in-place)
I0108 22:11:40.982782 14998 layer_factory.hpp:78] Creating layer scale3
I0108 22:11:40.982955 14998 net.cpp:122] Setting up scale3
I0108 22:11:40.982967 14998 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0108 22:11:40.982970 14998 net.cpp:137] Memory required for data: 381696800
I0108 22:11:40.982996 14998 layer_factory.hpp:78] Creating layer binactive2
I0108 22:11:40.983011 14998 net.cpp:84] Creating Layer binactive2
I0108 22:11:40.983019 14998 net.cpp:406] binactive2 <- pool2
I0108 22:11:40.983047 14998 net.cpp:380] binactive2 -> binactive2
I0108 22:11:40.983094 14998 net.cpp:122] Setting up binactive2
I0108 22:11:40.983105 14998 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0108 22:11:40.983109 14998 net.cpp:137] Memory required for data: 390349600
I0108 22:11:40.983114 14998 layer_factory.hpp:78] Creating layer conv3
I0108 22:11:40.983142 14998 net.cpp:84] Creating Layer conv3
I0108 22:11:40.983151 14998 net.cpp:406] conv3 <- binactive2
I0108 22:11:40.983171 14998 net.cpp:380] conv3 -> conv3
I0108 22:11:41.069594 14998 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 18874368
I0108 22:11:41.069985 14998 net.cpp:122] Setting up conv3
I0108 22:11:41.070019 14998 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0108 22:11:41.070022 14998 net.cpp:137] Memory required for data: 403328800
I0108 22:11:41.070042 14998 layer_factory.hpp:78] Creating layer bn4
I0108 22:11:41.070081 14998 net.cpp:84] Creating Layer bn4
I0108 22:11:41.070092 14998 net.cpp:406] bn4 <- conv3
I0108 22:11:41.070122 14998 net.cpp:367] bn4 -> conv3 (in-place)
I0108 22:11:41.070403 14998 net.cpp:122] Setting up bn4
I0108 22:11:41.070415 14998 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0108 22:11:41.070420 14998 net.cpp:137] Memory required for data: 416308000
I0108 22:11:41.070441 14998 layer_factory.hpp:78] Creating layer scale4
I0108 22:11:41.070461 14998 net.cpp:84] Creating Layer scale4
I0108 22:11:41.070469 14998 net.cpp:406] scale4 <- conv3
I0108 22:11:41.070484 14998 net.cpp:367] scale4 -> conv3 (in-place)
I0108 22:11:41.070552 14998 layer_factory.hpp:78] Creating layer scale4
I0108 22:11:41.070756 14998 net.cpp:122] Setting up scale4
I0108 22:11:41.070767 14998 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0108 22:11:41.070771 14998 net.cpp:137] Memory required for data: 429287200
I0108 22:11:41.070799 14998 layer_factory.hpp:78] Creating layer binactive3
I0108 22:11:41.070819 14998 net.cpp:84] Creating Layer binactive3
I0108 22:11:41.070827 14998 net.cpp:406] binactive3 <- conv3
I0108 22:11:41.070843 14998 net.cpp:380] binactive3 -> binactive3
I0108 22:11:41.070904 14998 net.cpp:122] Setting up binactive3
I0108 22:11:41.070914 14998 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0108 22:11:41.070919 14998 net.cpp:137] Memory required for data: 442266400
I0108 22:11:41.070924 14998 layer_factory.hpp:78] Creating layer conv4
I0108 22:11:41.070952 14998 net.cpp:84] Creating Layer conv4
I0108 22:11:41.070961 14998 net.cpp:406] conv4 <- binactive3
I0108 22:11:41.070981 14998 net.cpp:380] conv4 -> conv4
I0108 22:11:41.193356 14998 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 9840
I0108 22:11:41.193408 14998 net.cpp:122] Setting up conv4
I0108 22:11:41.193445 14998 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0108 22:11:41.193449 14998 net.cpp:137] Memory required for data: 455245600
I0108 22:11:41.193475 14998 layer_factory.hpp:78] Creating layer bn5
I0108 22:11:41.193503 14998 net.cpp:84] Creating Layer bn5
I0108 22:11:41.193516 14998 net.cpp:406] bn5 <- conv4
I0108 22:11:41.193538 14998 net.cpp:367] bn5 -> conv4 (in-place)
I0108 22:11:41.193819 14998 net.cpp:122] Setting up bn5
I0108 22:11:41.193830 14998 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0108 22:11:41.193835 14998 net.cpp:137] Memory required for data: 468224800
I0108 22:11:41.193871 14998 layer_factory.hpp:78] Creating layer scale5
I0108 22:11:41.193889 14998 net.cpp:84] Creating Layer scale5
I0108 22:11:41.193897 14998 net.cpp:406] scale5 <- conv4
I0108 22:11:41.193935 14998 net.cpp:367] scale5 -> conv4 (in-place)
I0108 22:11:41.194016 14998 layer_factory.hpp:78] Creating layer scale5
I0108 22:11:41.194198 14998 net.cpp:122] Setting up scale5
I0108 22:11:41.194209 14998 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0108 22:11:41.194213 14998 net.cpp:137] Memory required for data: 481204000
I0108 22:11:41.194228 14998 layer_factory.hpp:78] Creating layer binactive4
I0108 22:11:41.194244 14998 net.cpp:84] Creating Layer binactive4
I0108 22:11:41.194252 14998 net.cpp:406] binactive4 <- conv4
I0108 22:11:41.194267 14998 net.cpp:380] binactive4 -> binactive4
I0108 22:11:41.194310 14998 net.cpp:122] Setting up binactive4
I0108 22:11:41.194325 14998 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0108 22:11:41.194329 14998 net.cpp:137] Memory required for data: 494183200
I0108 22:11:41.194335 14998 layer_factory.hpp:78] Creating layer conv5
I0108 22:11:41.194367 14998 net.cpp:84] Creating Layer conv5
I0108 22:11:41.194377 14998 net.cpp:406] conv5 <- binactive4
I0108 22:11:41.194411 14998 net.cpp:380] conv5 -> conv5
I0108 22:11:41.272318 14998 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 18874368
I0108 22:11:41.272682 14998 net.cpp:122] Setting up conv5
I0108 22:11:41.272732 14998 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0108 22:11:41.272735 14998 net.cpp:137] Memory required for data: 502836000
I0108 22:11:41.272758 14998 layer_factory.hpp:78] Creating layer pool5
I0108 22:11:41.272791 14998 net.cpp:84] Creating Layer pool5
I0108 22:11:41.272825 14998 net.cpp:406] pool5 <- conv5
I0108 22:11:41.272847 14998 net.cpp:380] pool5 -> pool5
I0108 22:11:41.272934 14998 net.cpp:122] Setting up pool5
I0108 22:11:41.272948 14998 net.cpp:129] Top shape: 50 256 6 6 (460800)
I0108 22:11:41.272953 14998 net.cpp:137] Memory required for data: 504679200
I0108 22:11:41.272958 14998 layer_factory.hpp:78] Creating layer bn6
I0108 22:11:41.272974 14998 net.cpp:84] Creating Layer bn6
I0108 22:11:41.272981 14998 net.cpp:406] bn6 <- pool5
I0108 22:11:41.272995 14998 net.cpp:367] bn6 -> pool5 (in-place)
I0108 22:11:41.273322 14998 net.cpp:122] Setting up bn6
I0108 22:11:41.273334 14998 net.cpp:129] Top shape: 50 256 6 6 (460800)
I0108 22:11:41.273351 14998 net.cpp:137] Memory required for data: 506522400
I0108 22:11:41.273401 14998 layer_factory.hpp:78] Creating layer scale6
I0108 22:11:41.273422 14998 net.cpp:84] Creating Layer scale6
I0108 22:11:41.273430 14998 net.cpp:406] scale6 <- pool5
I0108 22:11:41.273444 14998 net.cpp:367] scale6 -> pool5 (in-place)
I0108 22:11:41.273521 14998 layer_factory.hpp:78] Creating layer scale6
I0108 22:11:41.273694 14998 net.cpp:122] Setting up scale6
I0108 22:11:41.273705 14998 net.cpp:129] Top shape: 50 256 6 6 (460800)
I0108 22:11:41.273708 14998 net.cpp:137] Memory required for data: 508365600
I0108 22:11:41.273733 14998 layer_factory.hpp:78] Creating layer binactive5
I0108 22:11:41.273746 14998 net.cpp:84] Creating Layer binactive5
I0108 22:11:41.273753 14998 net.cpp:406] binactive5 <- pool5
I0108 22:11:41.273767 14998 net.cpp:380] binactive5 -> binactive5
I0108 22:11:41.273811 14998 net.cpp:122] Setting up binactive5
I0108 22:11:41.273823 14998 net.cpp:129] Top shape: 50 256 6 6 (460800)
I0108 22:11:41.273826 14998 net.cpp:137] Memory required for data: 510208800
I0108 22:11:41.273831 14998 layer_factory.hpp:78] Creating layer fc6
I0108 22:11:41.273869 14998 net.cpp:84] Creating Layer fc6
I0108 22:11:41.273876 14998 net.cpp:406] fc6 <- binactive5
I0108 22:11:41.273892 14998 net.cpp:380] fc6 -> fc6
I0108 22:11:44.742489 14998 net.cpp:122] Setting up fc6
I0108 22:11:44.742552 14998 net.cpp:129] Top shape: 50 4096 (204800)
I0108 22:11:44.742558 14998 net.cpp:137] Memory required for data: 511028000
I0108 22:11:44.742592 14998 layer_factory.hpp:78] Creating layer bn7
I0108 22:11:44.742630 14998 net.cpp:84] Creating Layer bn7
I0108 22:11:44.742645 14998 net.cpp:406] bn7 <- fc6
I0108 22:11:44.742671 14998 net.cpp:367] bn7 -> fc6 (in-place)
I0108 22:11:44.742955 14998 net.cpp:122] Setting up bn7
I0108 22:11:44.742966 14998 net.cpp:129] Top shape: 50 4096 (204800)
I0108 22:11:44.742990 14998 net.cpp:137] Memory required for data: 511847200
I0108 22:11:44.743013 14998 layer_factory.hpp:78] Creating layer scale7
I0108 22:11:44.743049 14998 net.cpp:84] Creating Layer scale7
I0108 22:11:44.743057 14998 net.cpp:406] scale7 <- fc6
I0108 22:11:44.743072 14998 net.cpp:367] scale7 -> fc6 (in-place)
I0108 22:11:44.743170 14998 layer_factory.hpp:78] Creating layer scale7
I0108 22:11:44.743396 14998 net.cpp:122] Setting up scale7
I0108 22:11:44.743407 14998 net.cpp:129] Top shape: 50 4096 (204800)
I0108 22:11:44.743412 14998 net.cpp:137] Memory required for data: 512666400
I0108 22:11:44.743427 14998 layer_factory.hpp:78] Creating layer binactive6
I0108 22:11:44.743441 14998 net.cpp:84] Creating Layer binactive6
I0108 22:11:44.743448 14998 net.cpp:406] binactive6 <- fc6
I0108 22:11:44.743463 14998 net.cpp:380] binactive6 -> binactive6
I0108 22:11:44.743511 14998 net.cpp:122] Setting up binactive6
I0108 22:11:44.743523 14998 net.cpp:129] Top shape: 50 4096 (204800)
I0108 22:11:44.743526 14998 net.cpp:137] Memory required for data: 513485600
I0108 22:11:44.743531 14998 layer_factory.hpp:78] Creating layer fc7
I0108 22:11:44.743564 14998 net.cpp:84] Creating Layer fc7
I0108 22:11:44.743572 14998 net.cpp:406] fc7 <- binactive6
I0108 22:11:44.743590 14998 net.cpp:380] fc7 -> fc7
I0108 22:11:46.283974 14998 net.cpp:122] Setting up fc7
I0108 22:11:46.284034 14998 net.cpp:129] Top shape: 50 4096 (204800)
I0108 22:11:46.284039 14998 net.cpp:137] Memory required for data: 514304800
I0108 22:11:46.284066 14998 layer_factory.hpp:78] Creating layer bn8
I0108 22:11:46.284116 14998 net.cpp:84] Creating Layer bn8
I0108 22:11:46.284133 14998 net.cpp:406] bn8 <- fc7
I0108 22:11:46.284173 14998 net.cpp:367] bn8 -> fc7 (in-place)
I0108 22:11:46.284492 14998 net.cpp:122] Setting up bn8
I0108 22:11:46.284502 14998 net.cpp:129] Top shape: 50 4096 (204800)
I0108 22:11:46.284505 14998 net.cpp:137] Memory required for data: 515124000
I0108 22:11:46.284525 14998 layer_factory.hpp:78] Creating layer scale8
I0108 22:11:46.284566 14998 net.cpp:84] Creating Layer scale8
I0108 22:11:46.284574 14998 net.cpp:406] scale8 <- fc7
I0108 22:11:46.284588 14998 net.cpp:367] scale8 -> fc7 (in-place)
I0108 22:11:46.284682 14998 layer_factory.hpp:78] Creating layer scale8
I0108 22:11:46.284893 14998 net.cpp:122] Setting up scale8
I0108 22:11:46.284904 14998 net.cpp:129] Top shape: 50 4096 (204800)
I0108 22:11:46.284909 14998 net.cpp:137] Memory required for data: 515943200
I0108 22:11:46.284921 14998 layer_factory.hpp:78] Creating layer relu7
I0108 22:11:46.284955 14998 net.cpp:84] Creating Layer relu7
I0108 22:11:46.284960 14998 net.cpp:406] relu7 <- fc7
I0108 22:11:46.284974 14998 net.cpp:367] relu7 -> fc7 (in-place)
I0108 22:11:46.286557 14998 net.cpp:122] Setting up relu7
I0108 22:11:46.286573 14998 net.cpp:129] Top shape: 50 4096 (204800)
I0108 22:11:46.286592 14998 net.cpp:137] Memory required for data: 516762400
I0108 22:11:46.286599 14998 layer_factory.hpp:78] Creating layer fc8
I0108 22:11:46.286626 14998 net.cpp:84] Creating Layer fc8
I0108 22:11:46.286635 14998 net.cpp:406] fc8 <- fc7
I0108 22:11:46.286656 14998 net.cpp:380] fc8 -> fc8
I0108 22:11:46.673461 14998 net.cpp:122] Setting up fc8
I0108 22:11:46.673511 14998 net.cpp:129] Top shape: 50 1000 (50000)
I0108 22:11:46.673514 14998 net.cpp:137] Memory required for data: 516962400
I0108 22:11:46.673547 14998 layer_factory.hpp:78] Creating layer fc8_fc8_0_split
I0108 22:11:46.673591 14998 net.cpp:84] Creating Layer fc8_fc8_0_split
I0108 22:11:46.673606 14998 net.cpp:406] fc8_fc8_0_split <- fc8
I0108 22:11:46.673633 14998 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0108 22:11:46.673658 14998 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0108 22:11:46.673671 14998 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0108 22:11:46.673753 14998 net.cpp:122] Setting up fc8_fc8_0_split
I0108 22:11:46.673765 14998 net.cpp:129] Top shape: 50 1000 (50000)
I0108 22:11:46.673769 14998 net.cpp:129] Top shape: 50 1000 (50000)
I0108 22:11:46.673774 14998 net.cpp:129] Top shape: 50 1000 (50000)
I0108 22:11:46.673799 14998 net.cpp:137] Memory required for data: 517562400
I0108 22:11:46.673806 14998 layer_factory.hpp:78] Creating layer loss
I0108 22:11:46.673828 14998 net.cpp:84] Creating Layer loss
I0108 22:11:46.673836 14998 net.cpp:406] loss <- fc8_fc8_0_split_0
I0108 22:11:46.673849 14998 net.cpp:406] loss <- label_data_1_split_0
I0108 22:11:46.673862 14998 net.cpp:380] loss -> loss
I0108 22:11:46.673883 14998 layer_factory.hpp:78] Creating layer loss
I0108 22:11:46.674970 14998 net.cpp:122] Setting up loss
I0108 22:11:46.675002 14998 net.cpp:129] Top shape: (1)
I0108 22:11:46.675006 14998 net.cpp:132]     with loss weight 1
I0108 22:11:46.675015 14998 net.cpp:137] Memory required for data: 517562404
I0108 22:11:46.675022 14998 layer_factory.hpp:78] Creating layer accuracy
I0108 22:11:46.675040 14998 net.cpp:84] Creating Layer accuracy
I0108 22:11:46.675047 14998 net.cpp:406] accuracy <- fc8_fc8_0_split_1
I0108 22:11:46.675062 14998 net.cpp:406] accuracy <- label_data_1_split_1
I0108 22:11:46.675073 14998 net.cpp:380] accuracy -> accuracy
I0108 22:11:46.675096 14998 net.cpp:122] Setting up accuracy
I0108 22:11:46.675103 14998 net.cpp:129] Top shape: (1)
I0108 22:11:46.675107 14998 net.cpp:137] Memory required for data: 517562408
I0108 22:11:46.675112 14998 layer_factory.hpp:78] Creating layer accuracy_5
I0108 22:11:46.675132 14998 net.cpp:84] Creating Layer accuracy_5
I0108 22:11:46.675138 14998 net.cpp:406] accuracy_5 <- fc8_fc8_0_split_2
I0108 22:11:46.675148 14998 net.cpp:406] accuracy_5 <- label_data_1_split_2
I0108 22:11:46.675163 14998 net.cpp:380] accuracy_5 -> accuracy_5
I0108 22:11:46.675181 14998 net.cpp:122] Setting up accuracy_5
I0108 22:11:46.675191 14998 net.cpp:129] Top shape: (1)
I0108 22:11:46.675194 14998 net.cpp:137] Memory required for data: 517562412
I0108 22:11:46.675201 14998 net.cpp:200] accuracy_5 does not need backward computation.
I0108 22:11:46.675206 14998 net.cpp:200] accuracy does not need backward computation.
I0108 22:11:46.675211 14998 net.cpp:198] loss needs backward computation.
I0108 22:11:46.675216 14998 net.cpp:198] fc8_fc8_0_split needs backward computation.
I0108 22:11:46.675220 14998 net.cpp:198] fc8 needs backward computation.
I0108 22:11:46.675225 14998 net.cpp:198] relu7 needs backward computation.
I0108 22:11:46.675227 14998 net.cpp:198] scale8 needs backward computation.
I0108 22:11:46.675232 14998 net.cpp:198] bn8 needs backward computation.
I0108 22:11:46.675235 14998 net.cpp:198] fc7 needs backward computation.
I0108 22:11:46.675240 14998 net.cpp:198] binactive6 needs backward computation.
I0108 22:11:46.675243 14998 net.cpp:198] scale7 needs backward computation.
I0108 22:11:46.675247 14998 net.cpp:198] bn7 needs backward computation.
I0108 22:11:46.675251 14998 net.cpp:198] fc6 needs backward computation.
I0108 22:11:46.675256 14998 net.cpp:198] binactive5 needs backward computation.
I0108 22:11:46.675261 14998 net.cpp:198] scale6 needs backward computation.
I0108 22:11:46.675264 14998 net.cpp:198] bn6 needs backward computation.
I0108 22:11:46.675269 14998 net.cpp:198] pool5 needs backward computation.
I0108 22:11:46.675274 14998 net.cpp:198] conv5 needs backward computation.
I0108 22:11:46.675278 14998 net.cpp:198] binactive4 needs backward computation.
I0108 22:11:46.675282 14998 net.cpp:198] scale5 needs backward computation.
I0108 22:11:46.675287 14998 net.cpp:198] bn5 needs backward computation.
I0108 22:11:46.675290 14998 net.cpp:198] conv4 needs backward computation.
I0108 22:11:46.675295 14998 net.cpp:198] binactive3 needs backward computation.
I0108 22:11:46.675299 14998 net.cpp:198] scale4 needs backward computation.
I0108 22:11:46.675303 14998 net.cpp:198] bn4 needs backward computation.
I0108 22:11:46.675308 14998 net.cpp:198] conv3 needs backward computation.
I0108 22:11:46.675312 14998 net.cpp:198] binactive2 needs backward computation.
I0108 22:11:46.675318 14998 net.cpp:198] scale3 needs backward computation.
I0108 22:11:46.675321 14998 net.cpp:198] bn3 needs backward computation.
I0108 22:11:46.675326 14998 net.cpp:198] pool2 needs backward computation.
I0108 22:11:46.675352 14998 net.cpp:198] conv2 needs backward computation.
I0108 22:11:46.675360 14998 net.cpp:198] binactive1 needs backward computation.
I0108 22:11:46.675365 14998 net.cpp:198] scale2 needs backward computation.
I0108 22:11:46.675369 14998 net.cpp:198] bn2 needs backward computation.
I0108 22:11:46.675374 14998 net.cpp:198] pool1 needs backward computation.
I0108 22:11:46.675379 14998 net.cpp:198] relu1 needs backward computation.
I0108 22:11:46.675384 14998 net.cpp:198] scale1 needs backward computation.
I0108 22:11:46.675387 14998 net.cpp:198] bn1 needs backward computation.
I0108 22:11:46.675391 14998 net.cpp:198] conv1 needs backward computation.
I0108 22:11:46.675398 14998 net.cpp:200] label_data_1_split does not need backward computation.
I0108 22:11:46.675405 14998 net.cpp:200] data does not need backward computation.
I0108 22:11:46.675407 14998 net.cpp:242] This network produces output accuracy
I0108 22:11:46.675415 14998 net.cpp:242] This network produces output accuracy_5
I0108 22:11:46.675420 14998 net.cpp:242] This network produces output loss
I0108 22:11:46.675473 14998 net.cpp:255] Network initialization done.
I0108 22:11:46.675649 14998 solver.cpp:57] Solver scaffolding done.
I0108 22:11:46.677971 14998 caffe.cpp:239] Starting Optimization
I0108 22:11:46.678004 14998 solver.cpp:299] Solving AlexNet-BN
I0108 22:11:46.678007 14998 solver.cpp:300] Learning Rate Policy: step
I0108 22:11:46.681670 14998 solver.cpp:384] Iteration 0, Testing net (#0)
I0108 22:11:46.965929 14998 blocking_queue.cpp:49] Waiting for data
I0108 22:14:07.189594 15132 data_layer.cpp:73] Restarting data prefetching from start.
I0108 22:14:07.238409 14998 solver.cpp:452]     Test net output #0: accuracy = 0.00118
I0108 22:14:07.238458 14998 solver.cpp:452]     Test net output #1: accuracy_5 = 0.00546
I0108 22:14:07.238487 14998 solver.cpp:452]     Test net output #2: loss = 87.1709 (* 1 = 87.1709 loss)
I0108 22:14:07.238494 14998 solver.cpp:463] ================================
I0108 22:14:07.238499 14998 solver.cpp:464]     Test net best accuracy1 is: 0.00118
I0108 22:14:07.238505 14998 solver.cpp:466]     Test net best accuracy5 is: 0.00546
I0108 22:14:07.940892 14998 solver.cpp:242] Iteration 0 (2.77435e+20 iter/s, 141.258s/200 iters), loss = 7.4731
I0108 22:14:07.940951 14998 solver.cpp:261]     Train net output #0: accuracy = 0
I0108 22:14:07.940964 14998 solver.cpp:261]     Train net output #1: accuracy_5 = 0.0117188
I0108 22:14:07.940981 14998 solver.cpp:261]     Train net output #2: loss = 7.4731 (* 1 = 7.4731 loss)
I0108 22:14:07.941031 14998 sgd_solver.cpp:122] Iteration 0, lr = 0.001
I0108 22:14:29.364353 14998 blocking_queue.cpp:49] Waiting for data
I0108 22:16:28.019302 14998 solver.cpp:242] Iteration 200 (1.42783 iter/s, 140.073s/200 iters), loss = 7.2829
I0108 22:16:28.031299 14998 solver.cpp:261]     Train net output #0: accuracy = 0
I0108 22:16:28.031319 14998 solver.cpp:261]     Train net output #1: accuracy_5 = 0.0117188
I0108 22:16:28.031359 14998 solver.cpp:261]     Train net output #2: loss = 7.2829 (* 1 = 7.2829 loss)
I0108 22:16:28.031375 14998 sgd_solver.cpp:122] Iteration 200, lr = 0.001
I0108 22:18:48.285248 14998 solver.cpp:242] Iteration 400 (1.42604 iter/s, 140.249s/200 iters), loss = 7.23517
I0108 22:18:48.297032 14998 solver.cpp:261]     Train net output #0: accuracy = 0
I0108 22:18:48.297052 14998 solver.cpp:261]     Train net output #1: accuracy_5 = 0
I0108 22:18:48.297070 14998 solver.cpp:261]     Train net output #2: loss = 7.23517 (* 1 = 7.23517 loss)
I0108 22:18:48.297083 14998 sgd_solver.cpp:122] Iteration 400, lr = 0.001
I0108 22:21:07.898267 14998 solver.cpp:242] Iteration 600 (1.43271 iter/s, 139.595s/200 iters), loss = 7.34059
I0108 22:21:07.909133 14998 solver.cpp:261]     Train net output #0: accuracy = 0
I0108 22:21:07.909155 14998 solver.cpp:261]     Train net output #1: accuracy_5 = 0.00390625
I0108 22:21:07.909183 14998 solver.cpp:261]     Train net output #2: loss = 7.34059 (* 1 = 7.34059 loss)
I0108 22:21:07.909195 14998 sgd_solver.cpp:122] Iteration 600, lr = 0.001
I0108 22:23:35.069239 14998 solver.cpp:242] Iteration 800 (1.35911 iter/s, 147.155s/200 iters), loss = 7.26283
I0108 22:23:35.069350 14998 solver.cpp:261]     Train net output #0: accuracy = 0
I0108 22:23:35.069362 14998 solver.cpp:261]     Train net output #1: accuracy_5 = 0
I0108 22:23:35.069382 14998 solver.cpp:261]     Train net output #2: loss = 7.26283 (* 1 = 7.26283 loss)
I0108 22:23:35.069396 14998 sgd_solver.cpp:122] Iteration 800, lr = 0.001
I0108 22:27:38.303205 14998 solver.cpp:384] Iteration 1000, Testing net (#0)
I0108 22:32:19.677933 14998 blocking_queue.cpp:49] Waiting for data
I0108 22:33:58.214500 15132 data_layer.cpp:73] Restarting data prefetching from start.
I0108 22:33:58.263052 14998 solver.cpp:452]     Test net output #0: accuracy = 0.00104
I0108 22:33:58.263098 14998 solver.cpp:452]     Test net output #1: accuracy_5 = 0.005
I0108 22:33:58.263120 14998 solver.cpp:452]     Test net output #2: loss = 7.77453 (* 1 = 7.77453 loss)
I0108 22:33:58.263128 14998 solver.cpp:463] ================================
I0108 22:33:58.263130 14998 solver.cpp:464]     Test net best accuracy1 is: 0.00118
I0108 22:33:58.263135 14998 solver.cpp:466]     Test net best accuracy5 is: 0.00546
I0108 22:33:58.947412 14998 solver.cpp:242] Iteration 1000 (0.320587 iter/s, 623.855s/200 iters), loss = 7.38484
I0108 22:33:58.949743 14998 solver.cpp:261]     Train net output #0: accuracy = 0.00390625
I0108 22:33:58.949770 14998 solver.cpp:261]     Train net output #1: accuracy_5 = 0.00390625
I0108 22:33:58.949795 14998 solver.cpp:261]     Train net output #2: loss = 7.38484 (* 1 = 7.38484 loss)
I0108 22:33:58.949811 14998 sgd_solver.cpp:122] Iteration 1000, lr = 0.001
I0108 22:36:22.865823 14998 solver.cpp:242] Iteration 1200 (1.38975 iter/s, 143.911s/200 iters), loss = 7.33059
I0108 22:36:22.865957 14998 solver.cpp:261]     Train net output #0: accuracy = 0
I0108 22:36:22.865968 14998 solver.cpp:261]     Train net output #1: accuracy_5 = 0.00390625
I0108 22:36:22.865988 14998 solver.cpp:261]     Train net output #2: loss = 7.33059 (* 1 = 7.33059 loss)
I0108 22:36:22.866020 14998 sgd_solver.cpp:122] Iteration 1200, lr = 0.001
I0108 22:39:04.677949 14998 solver.cpp:242] Iteration 1400 (1.23605 iter/s, 161.806s/200 iters), loss = 7.28974
I0108 22:39:04.689703 14998 solver.cpp:261]     Train net output #0: accuracy = 0
I0108 22:39:04.689733 14998 solver.cpp:261]     Train net output #1: accuracy_5 = 0
I0108 22:39:04.689759 14998 solver.cpp:261]     Train net output #2: loss = 7.28974 (* 1 = 7.28974 loss)
I0108 22:39:04.689774 14998 sgd_solver.cpp:122] Iteration 1400, lr = 0.001
I0108 22:44:15.426750 14998 solver.cpp:242] Iteration 1600 (0.643655 iter/s, 310.725s/200 iters), loss = 7.26507
I0108 22:44:15.426848 14998 solver.cpp:261]     Train net output #0: accuracy = 0
I0108 22:44:15.426864 14998 solver.cpp:261]     Train net output #1: accuracy_5 = 0.0078125
I0108 22:44:15.426897 14998 solver.cpp:261]     Train net output #2: loss = 7.26507 (* 1 = 7.26507 loss)
I0108 22:44:15.426911 14998 sgd_solver.cpp:122] Iteration 1600, lr = 0.001
