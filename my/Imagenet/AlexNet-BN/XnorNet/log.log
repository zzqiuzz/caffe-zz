I0114 15:47:02.704704 10064 upgrade_proto.cpp:1113] snapshot_prefix was a directory and is replaced to snapshot/solver
I0114 15:47:02.705544 10064 caffe.cpp:204] Using GPUs 0
I0114 15:47:03.393326 10064 caffe.cpp:209] GPU 0: GeForce GTX 1080 Ti
I0114 15:47:04.695631 10064 solver.cpp:45] Initializing solver from parameters: 
test_iter: 1000
test_interval: 1000
display: 200
max_iter: 500000
lr_policy: "modified_lr"
momentum: 0.9
snapshot: 10000
snapshot_prefix: "snapshot/solver"
solver_mode: GPU
device_id: 0
net: "train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
momentum2: 0.999
type: "Adam"
modified_lr {
  stepvalue: 125000
  stepvalue: 250000
  stepvalue: 375000
  stepvalue: 500000
  mlr: 0.001
  mlr: 0.0001
  mlr: 1e-05
  mlr: 1e-06
  weight_decay: 1e-05
  weight_decay: 1e-05
  weight_decay: 1e-05
  weight_decay: 1e-05
}
I0114 15:47:04.698762 10064 solver.cpp:105] Creating training net from net file: train_test.prototxt
I0114 15:47:04.699903 10064 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0114 15:47:04.700183 10064 net.cpp:51] Initializing net from parameters: 
name: "AlexNet-BN"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/zhengzhe/Data/imagenet_shrt256/ilsvrc12_train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 96
    bias_term: false
    pad: 2
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "pool1"
  top: "pool1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive1"
  type: "BinActive"
  bottom: "pool1"
  top: "binactive1"
}
layer {
  name: "conv2"
  type: "BinaryConvolution"
  bottom: "binactive1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "pool2"
  top: "pool2"
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "pool2"
  top: "pool2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive2"
  type: "BinActive"
  bottom: "pool2"
  top: "binactive2"
}
layer {
  name: "conv3"
  type: "BinaryConvolution"
  bottom: "binactive2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive3"
  type: "BinActive"
  bottom: "conv3"
  top: "binactive3"
}
layer {
  name: "conv4"
  type: "BinaryConvolution"
  bottom: "binactive3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "scale5"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive4"
  type: "BinActive"
  bottom: "conv4"
  top: "binactive4"
}
layer {
  name: "conv5"
  type: "BinaryConvolution"
  bottom: "binactive4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "bn6"
  type: "BatchNorm"
  bottom: "pool5"
  top: "pool5"
}
layer {
  name: "scale6"
  type: "Scale"
  bottom: "pool5"
  top: "pool5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive5"
  type: "BinActive"
  bottom: "pool5"
  top: "binactive5"
}
layer {
  name: "fc6"
  type: "BinaryInnerProduct"
  bottom: "binactive5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4096
    bias_term: false
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "scale7"
  type: "Scale"
  bottom: "fc6"
  top: "fc6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive6"
  type: "BinActive"
  bottom: "fc6"
  top: "binactive6"
}
layer {
  name: "fc7"
  type: "BinaryInnerProduct"
  bottom: "binactive6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4096
    bias_term: false
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn8"
  type: "BatchNorm"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "scale8"
  type: "Scale"
  bottom: "fc7"
  top: "fc7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "accuracy_5"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy_5"
  accuracy_param {
    top_k: 5
  }
}
I0114 15:47:04.700979 10064 layer_factory.hpp:78] Creating layer data
I0114 15:47:04.701211 10064 db_lmdb.cpp:35] Opened lmdb /home/zhengzhe/Data/imagenet_shrt256/ilsvrc12_train_lmdb
I0114 15:47:04.701294 10064 net.cpp:84] Creating Layer data
I0114 15:47:04.701333 10064 net.cpp:380] data -> data
I0114 15:47:04.701496 10064 net.cpp:380] data -> label
I0114 15:47:04.703812 10064 data_layer.cpp:45] output data size: 256,3,224,224
I0114 15:47:05.324057 10064 base_data_layer.cpp:72] Initializing prefetch
I0114 15:47:05.325665 10064 base_data_layer.cpp:75] Prefetch initialized.
I0114 15:47:05.325816 10064 net.cpp:122] Setting up data
I0114 15:47:05.325953 10064 net.cpp:129] Top shape: 256 3 224 224 (38535168)
I0114 15:47:05.326067 10064 net.cpp:129] Top shape: 256 (256)
I0114 15:47:05.326156 10064 net.cpp:137] Memory required for data: 154141696
I0114 15:47:05.326294 10064 layer_factory.hpp:78] Creating layer label_data_1_split
I0114 15:47:05.326508 10064 net.cpp:84] Creating Layer label_data_1_split
I0114 15:47:05.326627 10064 net.cpp:406] label_data_1_split <- label
I0114 15:47:05.326784 10064 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0114 15:47:05.326943 10064 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0114 15:47:05.327060 10064 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0114 15:47:05.327304 10064 net.cpp:122] Setting up label_data_1_split
I0114 15:47:05.327414 10064 net.cpp:129] Top shape: 256 (256)
I0114 15:47:05.327509 10064 net.cpp:129] Top shape: 256 (256)
I0114 15:47:05.327595 10064 net.cpp:129] Top shape: 256 (256)
I0114 15:47:05.327675 10064 net.cpp:137] Memory required for data: 154144768
I0114 15:47:05.327759 10064 layer_factory.hpp:78] Creating layer conv1
I0114 15:47:05.327929 10064 net.cpp:84] Creating Layer conv1
I0114 15:47:05.328025 10064 net.cpp:406] conv1 <- data
I0114 15:47:05.328137 10064 net.cpp:380] conv1 -> conv1
I0114 15:47:06.921604 10064 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 127416
I0114 15:47:06.922233 10064 net.cpp:122] Setting up conv1
I0114 15:47:06.922299 10064 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0114 15:47:06.922322 10064 net.cpp:137] Memory required for data: 451514368
I0114 15:47:06.922451 10064 layer_factory.hpp:78] Creating layer bn1
I0114 15:47:06.922533 10064 net.cpp:84] Creating Layer bn1
I0114 15:47:06.922570 10064 net.cpp:406] bn1 <- conv1
I0114 15:47:06.922627 10064 net.cpp:367] bn1 -> conv1 (in-place)
I0114 15:47:06.924759 10064 net.cpp:122] Setting up bn1
I0114 15:47:06.926851 10064 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0114 15:47:06.926889 10064 net.cpp:137] Memory required for data: 748883968
I0114 15:47:06.926978 10064 layer_factory.hpp:78] Creating layer scale1
I0114 15:47:06.927120 10064 net.cpp:84] Creating Layer scale1
I0114 15:47:06.927204 10064 net.cpp:406] scale1 <- conv1
I0114 15:47:06.927259 10064 net.cpp:367] scale1 -> conv1 (in-place)
I0114 15:47:06.927441 10064 layer_factory.hpp:78] Creating layer scale1
I0114 15:47:06.927886 10064 net.cpp:122] Setting up scale1
I0114 15:47:06.928220 10064 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0114 15:47:06.928251 10064 net.cpp:137] Memory required for data: 1046253568
I0114 15:47:06.928310 10064 layer_factory.hpp:78] Creating layer relu1
I0114 15:47:06.928406 10064 net.cpp:84] Creating Layer relu1
I0114 15:47:06.928478 10064 net.cpp:406] relu1 <- conv1
I0114 15:47:06.928529 10064 net.cpp:367] relu1 -> conv1 (in-place)
I0114 15:47:06.929209 10064 net.cpp:122] Setting up relu1
I0114 15:47:06.929891 10064 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0114 15:47:06.929930 10064 net.cpp:137] Memory required for data: 1343623168
I0114 15:47:06.929966 10064 layer_factory.hpp:78] Creating layer pool1
I0114 15:47:06.930022 10064 net.cpp:84] Creating Layer pool1
I0114 15:47:06.930084 10064 net.cpp:406] pool1 <- conv1
I0114 15:47:06.930140 10064 net.cpp:380] pool1 -> pool1
I0114 15:47:06.930302 10064 net.cpp:122] Setting up pool1
I0114 15:47:06.930455 10064 net.cpp:129] Top shape: 256 96 27 27 (17915904)
I0114 15:47:06.930498 10064 net.cpp:137] Memory required for data: 1415286784
I0114 15:47:06.930526 10064 layer_factory.hpp:78] Creating layer bn2
I0114 15:47:06.930573 10064 net.cpp:84] Creating Layer bn2
I0114 15:47:06.930619 10064 net.cpp:406] bn2 <- pool1
I0114 15:47:06.930670 10064 net.cpp:367] bn2 -> pool1 (in-place)
I0114 15:47:06.946892 10064 net.cpp:122] Setting up bn2
I0114 15:47:06.947492 10064 net.cpp:129] Top shape: 256 96 27 27 (17915904)
I0114 15:47:06.947543 10064 net.cpp:137] Memory required for data: 1486950400
I0114 15:47:06.947640 10064 layer_factory.hpp:78] Creating layer scale2
I0114 15:47:06.947799 10064 net.cpp:84] Creating Layer scale2
I0114 15:47:06.952379 10064 net.cpp:406] scale2 <- pool1
I0114 15:47:06.952507 10064 net.cpp:367] scale2 -> pool1 (in-place)
I0114 15:47:06.952738 10064 layer_factory.hpp:78] Creating layer scale2
I0114 15:47:06.953202 10064 net.cpp:122] Setting up scale2
I0114 15:47:06.953531 10064 net.cpp:129] Top shape: 256 96 27 27 (17915904)
I0114 15:47:06.953573 10064 net.cpp:137] Memory required for data: 1558614016
I0114 15:47:06.953619 10064 layer_factory.hpp:78] Creating layer binactive1
I0114 15:47:06.953696 10064 net.cpp:84] Creating Layer binactive1
I0114 15:47:06.953778 10064 net.cpp:406] binactive1 <- pool1
I0114 15:47:06.953828 10064 net.cpp:380] binactive1 -> binactive1
I0114 15:47:06.953976 10064 net.cpp:122] Setting up binactive1
I0114 15:47:06.954085 10064 net.cpp:129] Top shape: 256 96 27 27 (17915904)
I0114 15:47:06.954121 10064 net.cpp:137] Memory required for data: 1630277632
I0114 15:47:06.954156 10064 layer_factory.hpp:78] Creating layer conv2
I0114 15:47:06.954233 10064 net.cpp:84] Creating Layer conv2
I0114 15:47:06.954314 10064 net.cpp:406] conv2 <- binactive1
I0114 15:47:06.954375 10064 net.cpp:380] conv2 -> conv2
I0114 15:47:07.080078 10064 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 19668
I0114 15:47:07.080205 10064 net.cpp:122] Setting up conv2
I0114 15:47:07.080251 10064 net.cpp:129] Top shape: 256 256 27 27 (47775744)
I0114 15:47:07.080315 10064 net.cpp:137] Memory required for data: 1821380608
I0114 15:47:07.080405 10064 layer_factory.hpp:78] Creating layer pool2
I0114 15:47:07.080504 10064 net.cpp:84] Creating Layer pool2
I0114 15:47:07.080566 10064 net.cpp:406] pool2 <- conv2
I0114 15:47:07.080646 10064 net.cpp:380] pool2 -> pool2
I0114 15:47:07.080801 10064 net.cpp:122] Setting up pool2
I0114 15:47:07.080866 10064 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0114 15:47:07.080916 10064 net.cpp:137] Memory required for data: 1865682944
I0114 15:47:07.080967 10064 layer_factory.hpp:78] Creating layer bn3
I0114 15:47:07.081032 10064 net.cpp:84] Creating Layer bn3
I0114 15:47:07.081084 10064 net.cpp:406] bn3 <- pool2
I0114 15:47:07.081148 10064 net.cpp:367] bn3 -> pool2 (in-place)
I0114 15:47:07.081537 10064 net.cpp:122] Setting up bn3
I0114 15:47:07.081602 10064 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0114 15:47:07.081652 10064 net.cpp:137] Memory required for data: 1909985280
I0114 15:47:07.081728 10064 layer_factory.hpp:78] Creating layer scale3
I0114 15:47:07.081802 10064 net.cpp:84] Creating Layer scale3
I0114 15:47:07.081856 10064 net.cpp:406] scale3 <- pool2
I0114 15:47:07.081923 10064 net.cpp:367] scale3 -> pool2 (in-place)
I0114 15:47:07.082073 10064 layer_factory.hpp:78] Creating layer scale3
I0114 15:47:07.082378 10064 net.cpp:122] Setting up scale3
I0114 15:47:07.082446 10064 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0114 15:47:07.082496 10064 net.cpp:137] Memory required for data: 1954287616
I0114 15:47:07.082578 10064 layer_factory.hpp:78] Creating layer binactive2
I0114 15:47:07.082648 10064 net.cpp:84] Creating Layer binactive2
I0114 15:47:07.082703 10064 net.cpp:406] binactive2 <- pool2
I0114 15:47:07.082772 10064 net.cpp:380] binactive2 -> binactive2
I0114 15:47:07.082875 10064 net.cpp:122] Setting up binactive2
I0114 15:47:07.082938 10064 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0114 15:47:07.082988 10064 net.cpp:137] Memory required for data: 1998589952
I0114 15:47:07.083039 10064 layer_factory.hpp:78] Creating layer conv3
I0114 15:47:07.083122 10064 net.cpp:84] Creating Layer conv3
I0114 15:47:07.083179 10064 net.cpp:406] conv3 <- binactive2
I0114 15:47:07.083256 10064 net.cpp:380] conv3 -> conv3
I0114 15:47:07.275702 10064 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 18874368
I0114 15:47:07.276170 10064 net.cpp:122] Setting up conv3
I0114 15:47:07.276228 10064 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0114 15:47:07.276253 10064 net.cpp:137] Memory required for data: 2065043456
I0114 15:47:07.276307 10064 layer_factory.hpp:78] Creating layer bn4
I0114 15:47:07.276383 10064 net.cpp:84] Creating Layer bn4
I0114 15:47:07.276422 10064 net.cpp:406] bn4 <- conv3
I0114 15:47:07.276474 10064 net.cpp:367] bn4 -> conv3 (in-place)
I0114 15:47:07.276842 10064 net.cpp:122] Setting up bn4
I0114 15:47:07.276880 10064 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0114 15:47:07.276902 10064 net.cpp:137] Memory required for data: 2131496960
I0114 15:47:07.276952 10064 layer_factory.hpp:78] Creating layer scale4
I0114 15:47:07.277001 10064 net.cpp:84] Creating Layer scale4
I0114 15:47:07.277031 10064 net.cpp:406] scale4 <- conv3
I0114 15:47:07.277074 10064 net.cpp:367] scale4 -> conv3 (in-place)
I0114 15:47:07.277209 10064 layer_factory.hpp:78] Creating layer scale4
I0114 15:47:07.277504 10064 net.cpp:122] Setting up scale4
I0114 15:47:07.277544 10064 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0114 15:47:07.277567 10064 net.cpp:137] Memory required for data: 2197950464
I0114 15:47:07.277604 10064 layer_factory.hpp:78] Creating layer binactive3
I0114 15:47:07.277643 10064 net.cpp:84] Creating Layer binactive3
I0114 15:47:07.277673 10064 net.cpp:406] binactive3 <- conv3
I0114 15:47:07.277714 10064 net.cpp:380] binactive3 -> binactive3
I0114 15:47:07.277794 10064 net.cpp:122] Setting up binactive3
I0114 15:47:07.277830 10064 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0114 15:47:07.277853 10064 net.cpp:137] Memory required for data: 2264403968
I0114 15:47:07.277879 10064 layer_factory.hpp:78] Creating layer conv4
I0114 15:47:07.277941 10064 net.cpp:84] Creating Layer conv4
I0114 15:47:07.277974 10064 net.cpp:406] conv4 <- binactive3
I0114 15:47:07.278023 10064 net.cpp:380] conv4 -> conv4
I0114 15:47:07.477679 10064 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 9840
I0114 15:47:07.477872 10064 net.cpp:122] Setting up conv4
I0114 15:47:07.477946 10064 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0114 15:47:07.477998 10064 net.cpp:137] Memory required for data: 2330857472
I0114 15:47:07.478075 10064 layer_factory.hpp:78] Creating layer bn5
I0114 15:47:07.478161 10064 net.cpp:84] Creating Layer bn5
I0114 15:47:07.478224 10064 net.cpp:406] bn5 <- conv4
I0114 15:47:07.478302 10064 net.cpp:367] bn5 -> conv4 (in-place)
I0114 15:47:07.478701 10064 net.cpp:122] Setting up bn5
I0114 15:47:07.478767 10064 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0114 15:47:07.478818 10064 net.cpp:137] Memory required for data: 2397310976
I0114 15:47:07.478893 10064 layer_factory.hpp:78] Creating layer scale5
I0114 15:47:07.478976 10064 net.cpp:84] Creating Layer scale5
I0114 15:47:07.479035 10064 net.cpp:406] scale5 <- conv4
I0114 15:47:07.479101 10064 net.cpp:367] scale5 -> conv4 (in-place)
I0114 15:47:07.479243 10064 layer_factory.hpp:78] Creating layer scale5
I0114 15:47:07.479549 10064 net.cpp:122] Setting up scale5
I0114 15:47:07.479616 10064 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0114 15:47:07.479667 10064 net.cpp:137] Memory required for data: 2463764480
I0114 15:47:07.479732 10064 layer_factory.hpp:78] Creating layer binactive4
I0114 15:47:07.479799 10064 net.cpp:84] Creating Layer binactive4
I0114 15:47:07.479851 10064 net.cpp:406] binactive4 <- conv4
I0114 15:47:07.479920 10064 net.cpp:380] binactive4 -> binactive4
I0114 15:47:07.480026 10064 net.cpp:122] Setting up binactive4
I0114 15:47:07.480089 10064 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0114 15:47:07.480139 10064 net.cpp:137] Memory required for data: 2530217984
I0114 15:47:07.480188 10064 layer_factory.hpp:78] Creating layer conv5
I0114 15:47:07.480269 10064 net.cpp:84] Creating Layer conv5
I0114 15:47:07.480327 10064 net.cpp:406] conv5 <- binactive4
I0114 15:47:07.480412 10064 net.cpp:380] conv5 -> conv5
I0114 15:47:07.685503 10064 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 18874368
I0114 15:47:07.685848 10064 net.cpp:122] Setting up conv5
I0114 15:47:07.685871 10064 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0114 15:47:07.685878 10064 net.cpp:137] Memory required for data: 2574520320
I0114 15:47:07.685905 10064 layer_factory.hpp:78] Creating layer pool5
I0114 15:47:07.685943 10064 net.cpp:84] Creating Layer pool5
I0114 15:47:07.685986 10064 net.cpp:406] pool5 <- conv5
I0114 15:47:07.686035 10064 net.cpp:380] pool5 -> pool5
I0114 15:47:07.686141 10064 net.cpp:122] Setting up pool5
I0114 15:47:07.686166 10064 net.cpp:129] Top shape: 256 256 6 6 (2359296)
I0114 15:47:07.686189 10064 net.cpp:137] Memory required for data: 2583957504
I0114 15:47:07.686214 10064 layer_factory.hpp:78] Creating layer bn6
I0114 15:47:07.686256 10064 net.cpp:84] Creating Layer bn6
I0114 15:47:07.686270 10064 net.cpp:406] bn6 <- pool5
I0114 15:47:07.686311 10064 net.cpp:367] bn6 -> pool5 (in-place)
I0114 15:47:07.686626 10064 net.cpp:122] Setting up bn6
I0114 15:47:07.686643 10064 net.cpp:129] Top shape: 256 256 6 6 (2359296)
I0114 15:47:07.686671 10064 net.cpp:137] Memory required for data: 2593394688
I0114 15:47:07.686727 10064 layer_factory.hpp:78] Creating layer scale6
I0114 15:47:07.686758 10064 net.cpp:84] Creating Layer scale6
I0114 15:47:07.686772 10064 net.cpp:406] scale6 <- pool5
I0114 15:47:07.686821 10064 net.cpp:367] scale6 -> pool5 (in-place)
I0114 15:47:07.686914 10064 layer_factory.hpp:78] Creating layer scale6
I0114 15:47:07.687108 10064 net.cpp:122] Setting up scale6
I0114 15:47:07.687124 10064 net.cpp:129] Top shape: 256 256 6 6 (2359296)
I0114 15:47:07.687131 10064 net.cpp:137] Memory required for data: 2602831872
I0114 15:47:07.687153 10064 layer_factory.hpp:78] Creating layer binactive5
I0114 15:47:07.687196 10064 net.cpp:84] Creating Layer binactive5
I0114 15:47:07.687209 10064 net.cpp:406] binactive5 <- pool5
I0114 15:47:07.687234 10064 net.cpp:380] binactive5 -> binactive5
I0114 15:47:07.687294 10064 net.cpp:122] Setting up binactive5
I0114 15:47:07.687315 10064 net.cpp:129] Top shape: 256 256 6 6 (2359296)
I0114 15:47:07.687324 10064 net.cpp:137] Memory required for data: 2612269056
I0114 15:47:07.687332 10064 layer_factory.hpp:78] Creating layer fc6
I0114 15:47:07.687399 10064 net.cpp:84] Creating Layer fc6
I0114 15:47:07.687431 10064 net.cpp:406] fc6 <- binactive5
I0114 15:47:07.687479 10064 net.cpp:380] fc6 -> fc6
I0114 15:47:13.167268 10064 net.cpp:122] Setting up fc6
I0114 15:47:13.167336 10064 net.cpp:129] Top shape: 256 4096 (1048576)
I0114 15:47:13.167351 10064 net.cpp:137] Memory required for data: 2616463360
I0114 15:47:13.167398 10064 layer_factory.hpp:78] Creating layer bn7
I0114 15:47:13.167452 10064 net.cpp:84] Creating Layer bn7
I0114 15:47:13.167477 10064 net.cpp:406] bn7 <- fc6
I0114 15:47:13.167511 10064 net.cpp:367] bn7 -> fc6 (in-place)
I0114 15:47:13.167871 10064 net.cpp:122] Setting up bn7
I0114 15:47:13.167887 10064 net.cpp:129] Top shape: 256 4096 (1048576)
I0114 15:47:13.167948 10064 net.cpp:137] Memory required for data: 2620657664
I0114 15:47:13.167997 10064 layer_factory.hpp:78] Creating layer scale7
I0114 15:47:13.168032 10064 net.cpp:84] Creating Layer scale7
I0114 15:47:13.168045 10064 net.cpp:406] scale7 <- fc6
I0114 15:47:13.168066 10064 net.cpp:367] scale7 -> fc6 (in-place)
I0114 15:47:13.168169 10064 layer_factory.hpp:78] Creating layer scale7
I0114 15:47:13.168429 10064 net.cpp:122] Setting up scale7
I0114 15:47:13.168447 10064 net.cpp:129] Top shape: 256 4096 (1048576)
I0114 15:47:13.168453 10064 net.cpp:137] Memory required for data: 2624851968
I0114 15:47:13.168474 10064 layer_factory.hpp:78] Creating layer binactive6
I0114 15:47:13.168493 10064 net.cpp:84] Creating Layer binactive6
I0114 15:47:13.168503 10064 net.cpp:406] binactive6 <- fc6
I0114 15:47:13.168555 10064 net.cpp:380] binactive6 -> binactive6
I0114 15:47:13.168617 10064 net.cpp:122] Setting up binactive6
I0114 15:47:13.168633 10064 net.cpp:129] Top shape: 256 4096 (1048576)
I0114 15:47:13.168639 10064 net.cpp:137] Memory required for data: 2629046272
I0114 15:47:13.168648 10064 layer_factory.hpp:78] Creating layer fc7
I0114 15:47:13.168692 10064 net.cpp:84] Creating Layer fc7
I0114 15:47:13.168704 10064 net.cpp:406] fc7 <- binactive6
I0114 15:47:13.168731 10064 net.cpp:380] fc7 -> fc7
I0114 15:47:16.356995 10064 net.cpp:122] Setting up fc7
I0114 15:47:16.357132 10064 net.cpp:129] Top shape: 256 4096 (1048576)
I0114 15:47:16.357162 10064 net.cpp:137] Memory required for data: 2633240576
I0114 15:47:16.357228 10064 layer_factory.hpp:78] Creating layer bn8
I0114 15:47:16.357308 10064 net.cpp:84] Creating Layer bn8
I0114 15:47:16.357362 10064 net.cpp:406] bn8 <- fc7
I0114 15:47:16.357429 10064 net.cpp:367] bn8 -> fc7 (in-place)
I0114 15:47:16.357918 10064 net.cpp:122] Setting up bn8
I0114 15:47:16.357964 10064 net.cpp:129] Top shape: 256 4096 (1048576)
I0114 15:47:16.357990 10064 net.cpp:137] Memory required for data: 2637434880
I0114 15:47:16.358041 10064 layer_factory.hpp:78] Creating layer scale8
I0114 15:47:16.358109 10064 net.cpp:84] Creating Layer scale8
I0114 15:47:16.358160 10064 net.cpp:406] scale8 <- fc7
I0114 15:47:16.358206 10064 net.cpp:367] scale8 -> fc7 (in-place)
I0114 15:47:16.358336 10064 layer_factory.hpp:78] Creating layer scale8
I0114 15:47:16.358651 10064 net.cpp:122] Setting up scale8
I0114 15:47:16.358692 10064 net.cpp:129] Top shape: 256 4096 (1048576)
I0114 15:47:16.358714 10064 net.cpp:137] Memory required for data: 2641629184
I0114 15:47:16.358752 10064 layer_factory.hpp:78] Creating layer relu7
I0114 15:47:16.358793 10064 net.cpp:84] Creating Layer relu7
I0114 15:47:16.358829 10064 net.cpp:406] relu7 <- fc7
I0114 15:47:16.358876 10064 net.cpp:367] relu7 -> fc7 (in-place)
I0114 15:47:16.360206 10064 net.cpp:122] Setting up relu7
I0114 15:47:16.360253 10064 net.cpp:129] Top shape: 256 4096 (1048576)
I0114 15:47:16.360276 10064 net.cpp:137] Memory required for data: 2645823488
I0114 15:47:16.360298 10064 layer_factory.hpp:78] Creating layer fc8
I0114 15:47:16.360363 10064 net.cpp:84] Creating Layer fc8
I0114 15:47:16.360399 10064 net.cpp:406] fc8 <- fc7
I0114 15:47:16.360456 10064 net.cpp:380] fc8 -> fc8
I0114 15:47:17.194262 10064 net.cpp:122] Setting up fc8
I0114 15:47:17.194381 10064 net.cpp:129] Top shape: 256 1000 (256000)
I0114 15:47:17.194403 10064 net.cpp:137] Memory required for data: 2646847488
I0114 15:47:17.194458 10064 layer_factory.hpp:78] Creating layer fc8_fc8_0_split
I0114 15:47:17.194516 10064 net.cpp:84] Creating Layer fc8_fc8_0_split
I0114 15:47:17.194550 10064 net.cpp:406] fc8_fc8_0_split <- fc8
I0114 15:47:17.194598 10064 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0114 15:47:17.194650 10064 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0114 15:47:17.194692 10064 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0114 15:47:17.194810 10064 net.cpp:122] Setting up fc8_fc8_0_split
I0114 15:47:17.194849 10064 net.cpp:129] Top shape: 256 1000 (256000)
I0114 15:47:17.194874 10064 net.cpp:129] Top shape: 256 1000 (256000)
I0114 15:47:17.194892 10064 net.cpp:129] Top shape: 256 1000 (256000)
I0114 15:47:17.194909 10064 net.cpp:137] Memory required for data: 2649919488
I0114 15:47:17.194931 10064 layer_factory.hpp:78] Creating layer loss
I0114 15:47:17.194999 10064 net.cpp:84] Creating Layer loss
I0114 15:47:17.195027 10064 net.cpp:406] loss <- fc8_fc8_0_split_0
I0114 15:47:17.195058 10064 net.cpp:406] loss <- label_data_1_split_0
I0114 15:47:17.195097 10064 net.cpp:380] loss -> loss
I0114 15:47:17.195148 10064 layer_factory.hpp:78] Creating layer loss
I0114 15:47:17.198832 10064 net.cpp:122] Setting up loss
I0114 15:47:17.198885 10064 net.cpp:129] Top shape: (1)
I0114 15:47:17.198907 10064 net.cpp:132]     with loss weight 1
I0114 15:47:17.198994 10064 net.cpp:137] Memory required for data: 2649919492
I0114 15:47:17.199017 10064 layer_factory.hpp:78] Creating layer accuracy
I0114 15:47:17.199061 10064 net.cpp:84] Creating Layer accuracy
I0114 15:47:17.199090 10064 net.cpp:406] accuracy <- fc8_fc8_0_split_1
I0114 15:47:17.199123 10064 net.cpp:406] accuracy <- label_data_1_split_1
I0114 15:47:17.199162 10064 net.cpp:380] accuracy -> accuracy
I0114 15:47:17.199220 10064 net.cpp:122] Setting up accuracy
I0114 15:47:17.199252 10064 net.cpp:129] Top shape: (1)
I0114 15:47:17.199270 10064 net.cpp:137] Memory required for data: 2649919496
I0114 15:47:17.199290 10064 layer_factory.hpp:78] Creating layer accuracy_5
I0114 15:47:17.199326 10064 net.cpp:84] Creating Layer accuracy_5
I0114 15:47:17.199355 10064 net.cpp:406] accuracy_5 <- fc8_fc8_0_split_2
I0114 15:47:17.199388 10064 net.cpp:406] accuracy_5 <- label_data_1_split_2
I0114 15:47:17.199422 10064 net.cpp:380] accuracy_5 -> accuracy_5
I0114 15:47:17.199470 10064 net.cpp:122] Setting up accuracy_5
I0114 15:47:17.199501 10064 net.cpp:129] Top shape: (1)
I0114 15:47:17.199522 10064 net.cpp:137] Memory required for data: 2649919500
I0114 15:47:17.199546 10064 net.cpp:200] accuracy_5 does not need backward computation.
I0114 15:47:17.199568 10064 net.cpp:200] accuracy does not need backward computation.
I0114 15:47:17.199609 10064 net.cpp:198] loss needs backward computation.
I0114 15:47:17.199631 10064 net.cpp:198] fc8_fc8_0_split needs backward computation.
I0114 15:47:17.199668 10064 net.cpp:198] fc8 needs backward computation.
I0114 15:47:17.199690 10064 net.cpp:198] relu7 needs backward computation.
I0114 15:47:17.199712 10064 net.cpp:198] scale8 needs backward computation.
I0114 15:47:17.199730 10064 net.cpp:198] bn8 needs backward computation.
I0114 15:47:17.199748 10064 net.cpp:198] fc7 needs backward computation.
I0114 15:47:17.199766 10064 net.cpp:198] binactive6 needs backward computation.
I0114 15:47:17.199785 10064 net.cpp:198] scale7 needs backward computation.
I0114 15:47:17.199805 10064 net.cpp:198] bn7 needs backward computation.
I0114 15:47:17.199826 10064 net.cpp:198] fc6 needs backward computation.
I0114 15:47:17.199844 10064 net.cpp:198] binactive5 needs backward computation.
I0114 15:47:17.199863 10064 net.cpp:198] scale6 needs backward computation.
I0114 15:47:17.199882 10064 net.cpp:198] bn6 needs backward computation.
I0114 15:47:17.199900 10064 net.cpp:198] pool5 needs backward computation.
I0114 15:47:17.199921 10064 net.cpp:198] conv5 needs backward computation.
I0114 15:47:17.200039 10064 net.cpp:198] binactive4 needs backward computation.
I0114 15:47:17.200091 10064 net.cpp:198] scale5 needs backward computation.
I0114 15:47:17.200142 10064 net.cpp:198] bn5 needs backward computation.
I0114 15:47:17.200192 10064 net.cpp:198] conv4 needs backward computation.
I0114 15:47:17.200242 10064 net.cpp:198] binactive3 needs backward computation.
I0114 15:47:17.200294 10064 net.cpp:198] scale4 needs backward computation.
I0114 15:47:17.200347 10064 net.cpp:198] bn4 needs backward computation.
I0114 15:47:17.200402 10064 net.cpp:198] conv3 needs backward computation.
I0114 15:47:17.200454 10064 net.cpp:198] binactive2 needs backward computation.
I0114 15:47:17.200506 10064 net.cpp:198] scale3 needs backward computation.
I0114 15:47:17.200558 10064 net.cpp:198] bn3 needs backward computation.
I0114 15:47:17.200608 10064 net.cpp:198] pool2 needs backward computation.
I0114 15:47:17.200659 10064 net.cpp:198] conv2 needs backward computation.
I0114 15:47:17.200709 10064 net.cpp:198] binactive1 needs backward computation.
I0114 15:47:17.200759 10064 net.cpp:198] scale2 needs backward computation.
I0114 15:47:17.200810 10064 net.cpp:198] bn2 needs backward computation.
I0114 15:47:17.200861 10064 net.cpp:198] pool1 needs backward computation.
I0114 15:47:17.200911 10064 net.cpp:198] relu1 needs backward computation.
I0114 15:47:17.200960 10064 net.cpp:198] scale1 needs backward computation.
I0114 15:47:17.201009 10064 net.cpp:198] bn1 needs backward computation.
I0114 15:47:17.201058 10064 net.cpp:198] conv1 needs backward computation.
I0114 15:47:17.201112 10064 net.cpp:200] label_data_1_split does not need backward computation.
I0114 15:47:17.201167 10064 net.cpp:200] data does not need backward computation.
I0114 15:47:17.201221 10064 net.cpp:242] This network produces output accuracy
I0114 15:47:17.201277 10064 net.cpp:242] This network produces output accuracy_5
I0114 15:47:17.201330 10064 net.cpp:242] This network produces output loss
I0114 15:47:17.201468 10064 net.cpp:255] Network initialization done.
I0114 15:47:17.203042 10064 solver.cpp:193] Creating test net (#0) specified by net file: train_test.prototxt
I0114 15:47:17.203274 10064 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0114 15:47:17.203694 10064 net.cpp:51] Initializing net from parameters: 
name: "AlexNet-BN"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 224
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/zhengzhe/Data/imagenet_shrt256/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 96
    bias_term: false
    pad: 2
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "pool1"
  top: "pool1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive1"
  type: "BinActive"
  bottom: "pool1"
  top: "binactive1"
}
layer {
  name: "conv2"
  type: "BinaryConvolution"
  bottom: "binactive1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "pool2"
  top: "pool2"
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "pool2"
  top: "pool2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive2"
  type: "BinActive"
  bottom: "pool2"
  top: "binactive2"
}
layer {
  name: "conv3"
  type: "BinaryConvolution"
  bottom: "binactive2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive3"
  type: "BinActive"
  bottom: "conv3"
  top: "binactive3"
}
layer {
  name: "conv4"
  type: "BinaryConvolution"
  bottom: "binactive3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "scale5"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive4"
  type: "BinActive"
  bottom: "conv4"
  top: "binactive4"
}
layer {
  name: "conv5"
  type: "BinaryConvolution"
  bottom: "binactive4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "bn6"
  type: "BatchNorm"
  bottom: "pool5"
  top: "pool5"
}
layer {
  name: "scale6"
  type: "Scale"
  bottom: "pool5"
  top: "pool5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive5"
  type: "BinActive"
  bottom: "pool5"
  top: "binactive5"
}
layer {
  name: "fc6"
  type: "BinaryInnerProduct"
  bottom: "binactive5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4096
    bias_term: false
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "scale7"
  type: "Scale"
  bottom: "fc6"
  top: "fc6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive6"
  type: "BinActive"
  bottom: "fc6"
  top: "binactive6"
}
layer {
  name: "fc7"
  type: "BinaryInnerProduct"
  bottom: "binactive6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4096
    bias_term: false
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn8"
  type: "BatchNorm"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "scale8"
  type: "Scale"
  bottom: "fc7"
  top: "fc7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "accuracy_5"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy_5"
  accuracy_param {
    top_k: 5
  }
}
I0114 15:47:17.206315 10064 layer_factory.hpp:78] Creating layer data
I0114 15:47:17.206521 10064 db_lmdb.cpp:35] Opened lmdb /home/zhengzhe/Data/imagenet_shrt256/ilsvrc12_val_lmdb
I0114 15:47:17.206615 10064 net.cpp:84] Creating Layer data
I0114 15:47:17.206678 10064 net.cpp:380] data -> data
I0114 15:47:17.206768 10064 net.cpp:380] data -> label
I0114 15:47:17.207561 10064 data_layer.cpp:45] output data size: 50,3,224,224
I0114 15:47:17.337738 10064 base_data_layer.cpp:72] Initializing prefetch
I0114 15:47:17.338114 10064 base_data_layer.cpp:75] Prefetch initialized.
I0114 15:47:17.338147 10064 net.cpp:122] Setting up data
I0114 15:47:17.338193 10064 net.cpp:129] Top shape: 50 3 224 224 (7526400)
I0114 15:47:17.338224 10064 net.cpp:129] Top shape: 50 (50)
I0114 15:47:17.338245 10064 net.cpp:137] Memory required for data: 30105800
I0114 15:47:17.338290 10064 layer_factory.hpp:78] Creating layer label_data_1_split
I0114 15:47:17.338364 10064 net.cpp:84] Creating Layer label_data_1_split
I0114 15:47:17.338402 10064 net.cpp:406] label_data_1_split <- label
I0114 15:47:17.338456 10064 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0114 15:47:17.338524 10064 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0114 15:47:17.338570 10064 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0114 15:47:17.338729 10064 net.cpp:122] Setting up label_data_1_split
I0114 15:47:17.338768 10064 net.cpp:129] Top shape: 50 (50)
I0114 15:47:17.338794 10064 net.cpp:129] Top shape: 50 (50)
I0114 15:47:17.338820 10064 net.cpp:129] Top shape: 50 (50)
I0114 15:47:17.338840 10064 net.cpp:137] Memory required for data: 30106400
I0114 15:47:17.338865 10064 layer_factory.hpp:78] Creating layer conv1
I0114 15:47:17.338930 10064 net.cpp:84] Creating Layer conv1
I0114 15:47:17.338960 10064 net.cpp:406] conv1 <- data
I0114 15:47:17.339007 10064 net.cpp:380] conv1 -> conv1
I0114 15:47:17.347524 10064 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 127416
I0114 15:47:17.347611 10064 net.cpp:122] Setting up conv1
I0114 15:47:17.347645 10064 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0114 15:47:17.347668 10064 net.cpp:137] Memory required for data: 88186400
I0114 15:47:17.347724 10064 layer_factory.hpp:78] Creating layer bn1
I0114 15:47:17.347769 10064 net.cpp:84] Creating Layer bn1
I0114 15:47:17.347797 10064 net.cpp:406] bn1 <- conv1
I0114 15:47:17.347843 10064 net.cpp:367] bn1 -> conv1 (in-place)
I0114 15:47:17.348254 10064 net.cpp:122] Setting up bn1
I0114 15:47:17.348292 10064 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0114 15:47:17.348315 10064 net.cpp:137] Memory required for data: 146266400
I0114 15:47:17.348390 10064 layer_factory.hpp:78] Creating layer scale1
I0114 15:47:17.348446 10064 net.cpp:84] Creating Layer scale1
I0114 15:47:17.348477 10064 net.cpp:406] scale1 <- conv1
I0114 15:47:17.348537 10064 net.cpp:367] scale1 -> conv1 (in-place)
I0114 15:47:17.348671 10064 layer_factory.hpp:78] Creating layer scale1
I0114 15:47:17.349030 10064 net.cpp:122] Setting up scale1
I0114 15:47:17.349069 10064 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0114 15:47:17.349092 10064 net.cpp:137] Memory required for data: 204346400
I0114 15:47:17.349144 10064 layer_factory.hpp:78] Creating layer relu1
I0114 15:47:17.349187 10064 net.cpp:84] Creating Layer relu1
I0114 15:47:17.349215 10064 net.cpp:406] relu1 <- conv1
I0114 15:47:17.349256 10064 net.cpp:367] relu1 -> conv1 (in-place)
I0114 15:47:17.358363 10064 net.cpp:122] Setting up relu1
I0114 15:47:17.359306 10064 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0114 15:47:17.359360 10064 net.cpp:137] Memory required for data: 262426400
I0114 15:47:17.359411 10064 layer_factory.hpp:78] Creating layer pool1
I0114 15:47:17.359506 10064 net.cpp:84] Creating Layer pool1
I0114 15:47:17.359604 10064 net.cpp:406] pool1 <- conv1
I0114 15:47:17.359694 10064 net.cpp:380] pool1 -> pool1
I0114 15:47:17.359910 10064 net.cpp:122] Setting up pool1
I0114 15:47:17.372364 10064 net.cpp:129] Top shape: 50 96 27 27 (3499200)
I0114 15:47:17.372407 10064 net.cpp:137] Memory required for data: 276423200
I0114 15:47:17.372432 10064 layer_factory.hpp:78] Creating layer bn2
I0114 15:47:17.372473 10064 net.cpp:84] Creating Layer bn2
I0114 15:47:17.372503 10064 net.cpp:406] bn2 <- pool1
I0114 15:47:17.372560 10064 net.cpp:367] bn2 -> pool1 (in-place)
I0114 15:47:17.372998 10064 net.cpp:122] Setting up bn2
I0114 15:47:17.373039 10064 net.cpp:129] Top shape: 50 96 27 27 (3499200)
I0114 15:47:17.373062 10064 net.cpp:137] Memory required for data: 290420000
I0114 15:47:17.373136 10064 layer_factory.hpp:78] Creating layer scale2
I0114 15:47:17.373193 10064 net.cpp:84] Creating Layer scale2
I0114 15:47:17.373221 10064 net.cpp:406] scale2 <- pool1
I0114 15:47:17.373263 10064 net.cpp:367] scale2 -> pool1 (in-place)
I0114 15:47:17.373412 10064 layer_factory.hpp:78] Creating layer scale2
I0114 15:47:17.373739 10064 net.cpp:122] Setting up scale2
I0114 15:47:17.373777 10064 net.cpp:129] Top shape: 50 96 27 27 (3499200)
I0114 15:47:17.373800 10064 net.cpp:137] Memory required for data: 304416800
I0114 15:47:17.373837 10064 layer_factory.hpp:78] Creating layer binactive1
I0114 15:47:17.373875 10064 net.cpp:84] Creating Layer binactive1
I0114 15:47:17.373903 10064 net.cpp:406] binactive1 <- pool1
I0114 15:47:17.373945 10064 net.cpp:380] binactive1 -> binactive1
I0114 15:47:17.374034 10064 net.cpp:122] Setting up binactive1
I0114 15:47:17.374070 10064 net.cpp:129] Top shape: 50 96 27 27 (3499200)
I0114 15:47:17.374092 10064 net.cpp:137] Memory required for data: 318413600
I0114 15:47:17.374116 10064 layer_factory.hpp:78] Creating layer conv2
I0114 15:47:17.374176 10064 net.cpp:84] Creating Layer conv2
I0114 15:47:17.374207 10064 net.cpp:406] conv2 <- binactive1
I0114 15:47:17.374259 10064 net.cpp:380] conv2 -> conv2
I0114 15:47:17.494328 10064 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 19668
I0114 15:47:17.494565 10064 net.cpp:122] Setting up conv2
I0114 15:47:17.494724 10064 net.cpp:129] Top shape: 50 256 27 27 (9331200)
I0114 15:47:17.494834 10064 net.cpp:137] Memory required for data: 355738400
I0114 15:47:17.494992 10064 layer_factory.hpp:78] Creating layer pool2
I0114 15:47:17.495148 10064 net.cpp:84] Creating Layer pool2
I0114 15:47:17.495270 10064 net.cpp:406] pool2 <- conv2
I0114 15:47:17.495385 10064 net.cpp:380] pool2 -> pool2
I0114 15:47:17.495622 10064 net.cpp:122] Setting up pool2
I0114 15:47:17.495752 10064 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0114 15:47:17.495882 10064 net.cpp:137] Memory required for data: 364391200
I0114 15:47:17.496006 10064 layer_factory.hpp:78] Creating layer bn3
I0114 15:47:17.496084 10064 net.cpp:84] Creating Layer bn3
I0114 15:47:17.496150 10064 net.cpp:406] bn3 <- pool2
I0114 15:47:17.496233 10064 net.cpp:367] bn3 -> pool2 (in-place)
I0114 15:47:17.496724 10064 net.cpp:122] Setting up bn3
I0114 15:47:17.496870 10064 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0114 15:47:17.496991 10064 net.cpp:137] Memory required for data: 373044000
I0114 15:47:17.497160 10064 layer_factory.hpp:78] Creating layer scale3
I0114 15:47:17.497311 10064 net.cpp:84] Creating Layer scale3
I0114 15:47:17.497406 10064 net.cpp:406] scale3 <- pool2
I0114 15:47:17.497552 10064 net.cpp:367] scale3 -> pool2 (in-place)
I0114 15:47:17.497781 10064 layer_factory.hpp:78] Creating layer scale3
I0114 15:47:17.498152 10064 net.cpp:122] Setting up scale3
I0114 15:47:17.498262 10064 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0114 15:47:17.498373 10064 net.cpp:137] Memory required for data: 381696800
I0114 15:47:17.498518 10064 layer_factory.hpp:78] Creating layer binactive2
I0114 15:47:17.498666 10064 net.cpp:84] Creating Layer binactive2
I0114 15:47:17.498731 10064 net.cpp:406] binactive2 <- pool2
I0114 15:47:17.498811 10064 net.cpp:380] binactive2 -> binactive2
I0114 15:47:17.498986 10064 net.cpp:122] Setting up binactive2
I0114 15:47:17.499123 10064 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0114 15:47:17.499246 10064 net.cpp:137] Memory required for data: 390349600
I0114 15:47:17.499373 10064 layer_factory.hpp:78] Creating layer conv3
I0114 15:47:17.499541 10064 net.cpp:84] Creating Layer conv3
I0114 15:47:17.499675 10064 net.cpp:406] conv3 <- binactive2
I0114 15:47:17.499799 10064 net.cpp:380] conv3 -> conv3
I0114 15:47:17.633074 10064 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 18874368
I0114 15:47:17.633600 10064 net.cpp:122] Setting up conv3
I0114 15:47:17.633690 10064 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0114 15:47:17.633745 10064 net.cpp:137] Memory required for data: 403328800
I0114 15:47:17.633819 10064 layer_factory.hpp:78] Creating layer bn4
I0114 15:47:17.633903 10064 net.cpp:84] Creating Layer bn4
I0114 15:47:17.633961 10064 net.cpp:406] bn4 <- conv3
I0114 15:47:17.634030 10064 net.cpp:367] bn4 -> conv3 (in-place)
I0114 15:47:17.634474 10064 net.cpp:122] Setting up bn4
I0114 15:47:17.634542 10064 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0114 15:47:17.634594 10064 net.cpp:137] Memory required for data: 416308000
I0114 15:47:17.634670 10064 layer_factory.hpp:78] Creating layer scale4
I0114 15:47:17.634745 10064 net.cpp:84] Creating Layer scale4
I0114 15:47:17.647359 10064 net.cpp:406] scale4 <- conv3
I0114 15:47:17.647477 10064 net.cpp:367] scale4 -> conv3 (in-place)
I0114 15:47:17.647675 10064 layer_factory.hpp:78] Creating layer scale4
I0114 15:47:17.648015 10064 net.cpp:122] Setting up scale4
I0114 15:47:17.648085 10064 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0114 15:47:17.648138 10064 net.cpp:137] Memory required for data: 429287200
I0114 15:47:17.648206 10064 layer_factory.hpp:78] Creating layer binactive3
I0114 15:47:17.648274 10064 net.cpp:84] Creating Layer binactive3
I0114 15:47:17.648330 10064 net.cpp:406] binactive3 <- conv3
I0114 15:47:17.648406 10064 net.cpp:380] binactive3 -> binactive3
I0114 15:47:17.648524 10064 net.cpp:122] Setting up binactive3
I0114 15:47:17.648596 10064 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0114 15:47:17.648646 10064 net.cpp:137] Memory required for data: 442266400
I0114 15:47:17.648700 10064 layer_factory.hpp:78] Creating layer conv4
I0114 15:47:17.648785 10064 net.cpp:84] Creating Layer conv4
I0114 15:47:17.648845 10064 net.cpp:406] conv4 <- binactive3
I0114 15:47:17.648918 10064 net.cpp:380] conv4 -> conv4
I0114 15:47:17.851647 10064 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 9840
I0114 15:47:17.851691 10064 net.cpp:122] Setting up conv4
I0114 15:47:17.851707 10064 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0114 15:47:17.851747 10064 net.cpp:137] Memory required for data: 455245600
I0114 15:47:17.851781 10064 layer_factory.hpp:78] Creating layer bn5
I0114 15:47:17.851814 10064 net.cpp:84] Creating Layer bn5
I0114 15:47:17.851830 10064 net.cpp:406] bn5 <- conv4
I0114 15:47:17.851886 10064 net.cpp:367] bn5 -> conv4 (in-place)
I0114 15:47:17.852191 10064 net.cpp:122] Setting up bn5
I0114 15:47:17.852205 10064 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0114 15:47:17.852208 10064 net.cpp:137] Memory required for data: 468224800
I0114 15:47:17.852257 10064 layer_factory.hpp:78] Creating layer scale5
I0114 15:47:17.852289 10064 net.cpp:84] Creating Layer scale5
I0114 15:47:17.852303 10064 net.cpp:406] scale5 <- conv4
I0114 15:47:17.852331 10064 net.cpp:367] scale5 -> conv4 (in-place)
I0114 15:47:17.852443 10064 layer_factory.hpp:78] Creating layer scale5
I0114 15:47:17.852676 10064 net.cpp:122] Setting up scale5
I0114 15:47:17.852691 10064 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0114 15:47:17.852695 10064 net.cpp:137] Memory required for data: 481204000
I0114 15:47:17.852711 10064 layer_factory.hpp:78] Creating layer binactive4
I0114 15:47:17.852727 10064 net.cpp:84] Creating Layer binactive4
I0114 15:47:17.852735 10064 net.cpp:406] binactive4 <- conv4
I0114 15:47:17.852761 10064 net.cpp:380] binactive4 -> binactive4
I0114 15:47:17.852828 10064 net.cpp:122] Setting up binactive4
I0114 15:47:17.852845 10064 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0114 15:47:17.852852 10064 net.cpp:137] Memory required for data: 494183200
I0114 15:47:17.852861 10064 layer_factory.hpp:78] Creating layer conv5
I0114 15:47:17.852924 10064 net.cpp:84] Creating Layer conv5
I0114 15:47:17.852941 10064 net.cpp:406] conv5 <- binactive4
I0114 15:47:17.852972 10064 net.cpp:380] conv5 -> conv5
I0114 15:47:18.100414 10064 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 18874368
I0114 15:47:18.109503 10064 net.cpp:122] Setting up conv5
I0114 15:47:18.109558 10064 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0114 15:47:18.109583 10064 net.cpp:137] Memory required for data: 502836000
I0114 15:47:18.109637 10064 layer_factory.hpp:78] Creating layer pool5
I0114 15:47:18.109707 10064 net.cpp:84] Creating Layer pool5
I0114 15:47:18.109745 10064 net.cpp:406] pool5 <- conv5
I0114 15:47:18.109800 10064 net.cpp:380] pool5 -> pool5
I0114 15:47:18.109951 10064 net.cpp:122] Setting up pool5
I0114 15:47:18.109987 10064 net.cpp:129] Top shape: 50 256 6 6 (460800)
I0114 15:47:18.110007 10064 net.cpp:137] Memory required for data: 504679200
I0114 15:47:18.110026 10064 layer_factory.hpp:78] Creating layer bn6
I0114 15:47:18.110059 10064 net.cpp:84] Creating Layer bn6
I0114 15:47:18.110085 10064 net.cpp:406] bn6 <- pool5
I0114 15:47:18.110119 10064 net.cpp:367] bn6 -> pool5 (in-place)
I0114 15:47:18.110759 10064 net.cpp:122] Setting up bn6
I0114 15:47:18.110823 10064 net.cpp:129] Top shape: 50 256 6 6 (460800)
I0114 15:47:18.110847 10064 net.cpp:137] Memory required for data: 506522400
I0114 15:47:18.110916 10064 layer_factory.hpp:78] Creating layer scale6
I0114 15:47:18.110970 10064 net.cpp:84] Creating Layer scale6
I0114 15:47:18.110998 10064 net.cpp:406] scale6 <- pool5
I0114 15:47:18.111040 10064 net.cpp:367] scale6 -> pool5 (in-place)
I0114 15:47:18.111181 10064 layer_factory.hpp:78] Creating layer scale6
I0114 15:47:18.111474 10064 net.cpp:122] Setting up scale6
I0114 15:47:18.111516 10064 net.cpp:129] Top shape: 50 256 6 6 (460800)
I0114 15:47:18.111541 10064 net.cpp:137] Memory required for data: 508365600
I0114 15:47:18.111578 10064 layer_factory.hpp:78] Creating layer binactive5
I0114 15:47:18.111634 10064 net.cpp:84] Creating Layer binactive5
I0114 15:47:18.111665 10064 net.cpp:406] binactive5 <- pool5
I0114 15:47:18.111707 10064 net.cpp:380] binactive5 -> binactive5
I0114 15:47:18.111816 10064 net.cpp:122] Setting up binactive5
I0114 15:47:18.111878 10064 net.cpp:129] Top shape: 50 256 6 6 (460800)
I0114 15:47:18.111922 10064 net.cpp:137] Memory required for data: 510208800
I0114 15:47:18.111955 10064 layer_factory.hpp:78] Creating layer fc6
I0114 15:47:18.112025 10064 net.cpp:84] Creating Layer fc6
I0114 15:47:18.112114 10064 net.cpp:406] fc6 <- binactive5
I0114 15:47:18.112201 10064 net.cpp:380] fc6 -> fc6
I0114 15:47:23.407948 10064 net.cpp:122] Setting up fc6
I0114 15:47:23.408299 10064 net.cpp:129] Top shape: 50 4096 (204800)
I0114 15:47:23.408411 10064 net.cpp:137] Memory required for data: 511028000
I0114 15:47:23.408583 10064 layer_factory.hpp:78] Creating layer bn7
I0114 15:47:23.408738 10064 net.cpp:84] Creating Layer bn7
I0114 15:47:23.408880 10064 net.cpp:406] bn7 <- fc6
I0114 15:47:23.409009 10064 net.cpp:367] bn7 -> fc6 (in-place)
I0114 15:47:23.410002 10064 net.cpp:122] Setting up bn7
I0114 15:47:23.410218 10064 net.cpp:129] Top shape: 50 4096 (204800)
I0114 15:47:23.410409 10064 net.cpp:137] Memory required for data: 511847200
I0114 15:47:23.410635 10064 layer_factory.hpp:78] Creating layer scale7
I0114 15:47:23.410876 10064 net.cpp:84] Creating Layer scale7
I0114 15:47:23.411073 10064 net.cpp:406] scale7 <- fc6
I0114 15:47:23.411283 10064 net.cpp:367] scale7 -> fc6 (in-place)
I0114 15:47:23.412806 10064 layer_factory.hpp:78] Creating layer scale7
I0114 15:47:23.413278 10064 net.cpp:122] Setting up scale7
I0114 15:47:23.413398 10064 net.cpp:129] Top shape: 50 4096 (204800)
I0114 15:47:23.413492 10064 net.cpp:137] Memory required for data: 512666400
I0114 15:47:23.413614 10064 layer_factory.hpp:78] Creating layer binactive6
I0114 15:47:23.413730 10064 net.cpp:84] Creating Layer binactive6
I0114 15:47:23.413827 10064 net.cpp:406] binactive6 <- fc6
I0114 15:47:23.413969 10064 net.cpp:380] binactive6 -> binactive6
I0114 15:47:23.414139 10064 net.cpp:122] Setting up binactive6
I0114 15:47:23.414252 10064 net.cpp:129] Top shape: 50 4096 (204800)
I0114 15:47:23.414345 10064 net.cpp:137] Memory required for data: 513485600
I0114 15:47:23.414438 10064 layer_factory.hpp:78] Creating layer fc7
I0114 15:47:23.414579 10064 net.cpp:84] Creating Layer fc7
I0114 15:47:23.414680 10064 net.cpp:406] fc7 <- binactive6
I0114 15:47:23.414798 10064 net.cpp:380] fc7 -> fc7
I0114 15:47:26.453558 10064 net.cpp:122] Setting up fc7
I0114 15:47:26.456478 10064 net.cpp:129] Top shape: 50 4096 (204800)
I0114 15:47:26.456550 10064 net.cpp:137] Memory required for data: 514304800
I0114 15:47:26.456632 10064 layer_factory.hpp:78] Creating layer bn8
I0114 15:47:26.456779 10064 net.cpp:84] Creating Layer bn8
I0114 15:47:26.456898 10064 net.cpp:406] bn8 <- fc7
I0114 15:47:26.456992 10064 net.cpp:367] bn8 -> fc7 (in-place)
I0114 15:47:26.457525 10064 net.cpp:122] Setting up bn8
I0114 15:47:26.458036 10064 net.cpp:129] Top shape: 50 4096 (204800)
I0114 15:47:26.458078 10064 net.cpp:137] Memory required for data: 515124000
I0114 15:47:26.458145 10064 layer_factory.hpp:78] Creating layer scale8
I0114 15:47:26.458256 10064 net.cpp:84] Creating Layer scale8
I0114 15:47:26.458335 10064 net.cpp:406] scale8 <- fc7
I0114 15:47:26.458406 10064 net.cpp:367] scale8 -> fc7 (in-place)
I0114 15:47:26.458604 10064 layer_factory.hpp:78] Creating layer scale8
I0114 15:47:26.459082 10064 net.cpp:122] Setting up scale8
I0114 15:47:26.459434 10064 net.cpp:129] Top shape: 50 4096 (204800)
I0114 15:47:26.459480 10064 net.cpp:137] Memory required for data: 515943200
I0114 15:47:26.459535 10064 layer_factory.hpp:78] Creating layer relu7
I0114 15:47:26.459619 10064 net.cpp:84] Creating Layer relu7
I0114 15:47:26.459686 10064 net.cpp:406] relu7 <- fc7
I0114 15:47:26.459746 10064 net.cpp:367] relu7 -> fc7 (in-place)
I0114 15:47:26.468233 10064 net.cpp:122] Setting up relu7
I0114 15:47:26.468281 10064 net.cpp:129] Top shape: 50 4096 (204800)
I0114 15:47:26.468303 10064 net.cpp:137] Memory required for data: 516762400
I0114 15:47:26.468328 10064 layer_factory.hpp:78] Creating layer fc8
I0114 15:47:26.468391 10064 net.cpp:84] Creating Layer fc8
I0114 15:47:26.468423 10064 net.cpp:406] fc8 <- fc7
I0114 15:47:26.468472 10064 net.cpp:380] fc8 -> fc8
I0114 15:47:27.195057 10064 net.cpp:122] Setting up fc8
I0114 15:47:27.195401 10064 net.cpp:129] Top shape: 50 1000 (50000)
I0114 15:47:27.195513 10064 net.cpp:137] Memory required for data: 516962400
I0114 15:47:27.195665 10064 layer_factory.hpp:78] Creating layer fc8_fc8_0_split
I0114 15:47:27.195816 10064 net.cpp:84] Creating Layer fc8_fc8_0_split
I0114 15:47:27.195942 10064 net.cpp:406] fc8_fc8_0_split <- fc8
I0114 15:47:27.196084 10064 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0114 15:47:27.196226 10064 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0114 15:47:27.196372 10064 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0114 15:47:27.196617 10064 net.cpp:122] Setting up fc8_fc8_0_split
I0114 15:47:27.196748 10064 net.cpp:129] Top shape: 50 1000 (50000)
I0114 15:47:27.196847 10064 net.cpp:129] Top shape: 50 1000 (50000)
I0114 15:47:27.196941 10064 net.cpp:129] Top shape: 50 1000 (50000)
I0114 15:47:27.197028 10064 net.cpp:137] Memory required for data: 517562400
I0114 15:47:27.197125 10064 layer_factory.hpp:78] Creating layer loss
I0114 15:47:27.197240 10064 net.cpp:84] Creating Layer loss
I0114 15:47:27.197345 10064 net.cpp:406] loss <- fc8_fc8_0_split_0
I0114 15:47:27.197469 10064 net.cpp:406] loss <- label_data_1_split_0
I0114 15:47:27.197587 10064 net.cpp:380] loss -> loss
I0114 15:47:27.197721 10064 layer_factory.hpp:78] Creating layer loss
I0114 15:47:27.199272 10064 net.cpp:122] Setting up loss
I0114 15:47:27.199401 10064 net.cpp:129] Top shape: (1)
I0114 15:47:27.199496 10064 net.cpp:132]     with loss weight 1
I0114 15:47:27.199609 10064 net.cpp:137] Memory required for data: 517562404
I0114 15:47:27.199705 10064 layer_factory.hpp:78] Creating layer accuracy
I0114 15:47:27.199818 10064 net.cpp:84] Creating Layer accuracy
I0114 15:47:27.199918 10064 net.cpp:406] accuracy <- fc8_fc8_0_split_1
I0114 15:47:27.200026 10064 net.cpp:406] accuracy <- label_data_1_split_1
I0114 15:47:27.200146 10064 net.cpp:380] accuracy -> accuracy
I0114 15:47:27.200278 10064 net.cpp:122] Setting up accuracy
I0114 15:47:27.200388 10064 net.cpp:129] Top shape: (1)
I0114 15:47:27.200479 10064 net.cpp:137] Memory required for data: 517562408
I0114 15:47:27.200574 10064 layer_factory.hpp:78] Creating layer accuracy_5
I0114 15:47:27.200690 10064 net.cpp:84] Creating Layer accuracy_5
I0114 15:47:27.200788 10064 net.cpp:406] accuracy_5 <- fc8_fc8_0_split_2
I0114 15:47:27.200901 10064 net.cpp:406] accuracy_5 <- label_data_1_split_2
I0114 15:47:27.201020 10064 net.cpp:380] accuracy_5 -> accuracy_5
I0114 15:47:27.201150 10064 net.cpp:122] Setting up accuracy_5
I0114 15:47:27.201254 10064 net.cpp:129] Top shape: (1)
I0114 15:47:27.201349 10064 net.cpp:137] Memory required for data: 517562412
I0114 15:47:27.201449 10064 net.cpp:200] accuracy_5 does not need backward computation.
I0114 15:47:27.201555 10064 net.cpp:200] accuracy does not need backward computation.
I0114 15:47:27.201655 10064 net.cpp:198] loss needs backward computation.
I0114 15:47:27.201755 10064 net.cpp:198] fc8_fc8_0_split needs backward computation.
I0114 15:47:27.201854 10064 net.cpp:198] fc8 needs backward computation.
I0114 15:47:27.201951 10064 net.cpp:198] relu7 needs backward computation.
I0114 15:47:27.202049 10064 net.cpp:198] scale8 needs backward computation.
I0114 15:47:27.202142 10064 net.cpp:198] bn8 needs backward computation.
I0114 15:47:27.202235 10064 net.cpp:198] fc7 needs backward computation.
I0114 15:47:27.202332 10064 net.cpp:198] binactive6 needs backward computation.
I0114 15:47:27.202440 10064 net.cpp:198] scale7 needs backward computation.
I0114 15:47:27.202538 10064 net.cpp:198] bn7 needs backward computation.
I0114 15:47:27.202630 10064 net.cpp:198] fc6 needs backward computation.
I0114 15:47:27.202728 10064 net.cpp:198] binactive5 needs backward computation.
I0114 15:47:27.202826 10064 net.cpp:198] scale6 needs backward computation.
I0114 15:47:27.202922 10064 net.cpp:198] bn6 needs backward computation.
I0114 15:47:27.203014 10064 net.cpp:198] pool5 needs backward computation.
I0114 15:47:27.203114 10064 net.cpp:198] conv5 needs backward computation.
I0114 15:47:27.203212 10064 net.cpp:198] binactive4 needs backward computation.
I0114 15:47:27.203312 10064 net.cpp:198] scale5 needs backward computation.
I0114 15:47:27.203416 10064 net.cpp:198] bn5 needs backward computation.
I0114 15:47:27.203513 10064 net.cpp:198] conv4 needs backward computation.
I0114 15:47:27.203610 10064 net.cpp:198] binactive3 needs backward computation.
I0114 15:47:27.203708 10064 net.cpp:198] scale4 needs backward computation.
I0114 15:47:27.203800 10064 net.cpp:198] bn4 needs backward computation.
I0114 15:47:27.203905 10064 net.cpp:198] conv3 needs backward computation.
I0114 15:47:27.203999 10064 net.cpp:198] binactive2 needs backward computation.
I0114 15:47:27.204110 10064 net.cpp:198] scale3 needs backward computation.
I0114 15:47:27.204207 10064 net.cpp:198] bn3 needs backward computation.
I0114 15:47:27.204300 10064 net.cpp:198] pool2 needs backward computation.
I0114 15:47:27.204403 10064 net.cpp:198] conv2 needs backward computation.
I0114 15:47:27.204504 10064 net.cpp:198] binactive1 needs backward computation.
I0114 15:47:27.204600 10064 net.cpp:198] scale2 needs backward computation.
I0114 15:47:27.204696 10064 net.cpp:198] bn2 needs backward computation.
I0114 15:47:27.204792 10064 net.cpp:198] pool1 needs backward computation.
I0114 15:47:27.204891 10064 net.cpp:198] relu1 needs backward computation.
I0114 15:47:27.204983 10064 net.cpp:198] scale1 needs backward computation.
I0114 15:47:27.205078 10064 net.cpp:198] bn1 needs backward computation.
I0114 15:47:27.205173 10064 net.cpp:198] conv1 needs backward computation.
I0114 15:47:27.205271 10064 net.cpp:200] label_data_1_split does not need backward computation.
I0114 15:47:27.205384 10064 net.cpp:200] data does not need backward computation.
I0114 15:47:27.205480 10064 net.cpp:242] This network produces output accuracy
I0114 15:47:27.205586 10064 net.cpp:242] This network produces output accuracy_5
I0114 15:47:27.205687 10064 net.cpp:242] This network produces output loss
I0114 15:47:27.205864 10064 net.cpp:255] Network initialization done.
I0114 15:47:27.206214 10064 solver.cpp:57] Solver scaffolding done.
I0114 15:47:27.211285 10064 caffe.cpp:235] Resuming from snapshot/solver_iter_110000.solverstate
I0114 15:47:51.998586 10064 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: snapshot/solver_iter_110000.caffemodel
I0114 15:47:51.998697 10064 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0114 15:47:51.998729 10064 net.cpp:824] Copying source layer data
I0114 15:47:51.998759 10064 net.cpp:824] Copying source layer label_data_1_split
I0114 15:47:51.998770 10064 net.cpp:824] Copying source layer conv1
I0114 15:47:52.000013 10064 net.cpp:824] Copying source layer bn1
I0114 15:47:52.000448 10064 net.cpp:824] Copying source layer scale1
I0114 15:47:52.000516 10064 net.cpp:824] Copying source layer relu1
I0114 15:47:52.000527 10064 net.cpp:824] Copying source layer pool1
I0114 15:47:52.000537 10064 net.cpp:824] Copying source layer bn2
I0114 15:47:52.000608 10064 net.cpp:824] Copying source layer scale2
I0114 15:47:52.000663 10064 net.cpp:824] Copying source layer binactive1
I0114 15:47:52.000679 10064 net.cpp:824] Copying source layer conv2
I0114 15:47:52.010607 10064 net.cpp:824] Copying source layer pool2
I0114 15:47:52.010627 10064 net.cpp:824] Copying source layer bn3
I0114 15:47:52.010728 10064 net.cpp:824] Copying source layer scale3
I0114 15:47:52.010797 10064 net.cpp:824] Copying source layer binactive2
I0114 15:47:52.010808 10064 net.cpp:824] Copying source layer conv3
I0114 15:47:52.023979 10064 net.cpp:824] Copying source layer bn4
I0114 15:47:52.024204 10064 net.cpp:824] Copying source layer scale4
I0114 15:47:52.024260 10064 net.cpp:824] Copying source layer binactive3
I0114 15:47:52.024274 10064 net.cpp:824] Copying source layer conv4
I0114 15:47:52.043443 10064 net.cpp:824] Copying source layer bn5
I0114 15:47:52.043542 10064 net.cpp:824] Copying source layer scale5
I0114 15:47:52.043593 10064 net.cpp:824] Copying source layer binactive4
I0114 15:47:52.043606 10064 net.cpp:824] Copying source layer conv5
I0114 15:47:52.057610 10064 net.cpp:824] Copying source layer pool5
I0114 15:47:52.057627 10064 net.cpp:824] Copying source layer bn6
I0114 15:47:52.057723 10064 net.cpp:824] Copying source layer scale6
I0114 15:47:52.057785 10064 net.cpp:824] Copying source layer binactive5
I0114 15:47:52.057796 10064 net.cpp:824] Copying source layer fc6
I0114 15:47:52.649013 10064 net.cpp:824] Copying source layer bn7
I0114 15:47:52.649513 10064 net.cpp:824] Copying source layer scale7
I0114 15:47:52.649721 10064 net.cpp:824] Copying source layer binactive6
I0114 15:47:52.649729 10064 net.cpp:824] Copying source layer fc7
I0114 15:47:52.880542 10064 net.cpp:824] Copying source layer bn8
I0114 15:47:52.880975 10064 net.cpp:824] Copying source layer scale8
I0114 15:47:52.881209 10064 net.cpp:824] Copying source layer relu7
I0114 15:47:52.881224 10064 net.cpp:824] Copying source layer fc8
I0114 15:47:52.937382 10064 net.cpp:824] Copying source layer fc8_fc8_0_split
I0114 15:47:52.937453 10064 net.cpp:824] Copying source layer loss
I0114 15:47:52.937463 10064 net.cpp:824] Copying source layer accuracy
I0114 15:47:52.937469 10064 net.cpp:824] Copying source layer accuracy_5
I0114 15:47:52.958158 10064 sgd_solver.cpp:356] SGDSolver: restoring history
I0114 15:47:56.770066 10064 caffe.cpp:239] Starting Optimization
I0114 15:47:56.771307 10064 solver.cpp:299] Solving AlexNet-BN
I0114 15:47:56.771363 10064 solver.cpp:300] Learning Rate Policy: modified_lr
I0114 15:47:56.798648 10064 solver.cpp:384] Iteration 110000, Testing net (#0)
I0114 15:47:57.226408 10064 blocking_queue.cpp:49] Waiting for data
I0114 15:51:51.213223 10299 data_layer.cpp:73] Restarting data prefetching from start.
I0114 15:51:51.264351 10064 solver.cpp:452]     Test net output #0: accuracy = 0.38172
I0114 15:51:51.264420 10064 solver.cpp:452]     Test net output #1: accuracy_5 = 0.62934
I0114 15:51:51.264439 10064 solver.cpp:452]     Test net output #2: loss = 2.96736 (* 1 = 2.96736 loss)
I0114 15:51:51.264494 10064 solver.cpp:466] snapshoting best accuracy model ...
I0114 15:51:51.264521 10064 net.cpp:928] Serializing 41 layers
I0114 15:51:55.828404 10064 solver.cpp:470] snapshoting best accuracy model done.
I0114 15:51:55.841549 10064 solver.cpp:472] ================================
I0114 15:51:55.841573 10064 solver.cpp:473]     Test net best accuracy1 is: 0.38172
I0114 15:51:55.841591 10064 solver.cpp:475]     Test net best accuracy5 is: 0.62934
I0114 15:51:56.687348 10064 solver.cpp:242] Iteration 110000 (458.531 iter/s, 239.896s/200 iters), loss = 2.0743
I0114 15:51:56.687431 10064 solver.cpp:261]     Train net output #0: accuracy = 0.503906
I0114 15:51:56.687445 10064 solver.cpp:261]     Train net output #1: accuracy_5 = 0.78125
I0114 15:51:56.687470 10064 solver.cpp:261]     Train net output #2: loss = 2.0743 (* 1 = 2.0743 loss)
I0114 15:51:56.687501 10064 sgd_solver.cpp:122] Iteration 110000, lr = 0.001
I0114 15:52:04.605494 10064 blocking_queue.cpp:49] Waiting for data
I0114 15:55:17.266430 10064 solver.cpp:242] Iteration 110200 (0.997203 iter/s, 200.561s/200 iters), loss = 1.89319
I0114 15:55:17.266923 10064 solver.cpp:261]     Train net output #0: accuracy = 0.546875
I0114 15:55:17.267076 10064 solver.cpp:261]     Train net output #1: accuracy_5 = 0.773438
I0114 15:55:17.267225 10064 solver.cpp:261]     Train net output #2: loss = 1.89319 (* 1 = 1.89319 loss)
I0114 15:55:17.267489 10064 sgd_solver.cpp:122] Iteration 110200, lr = 0.001
