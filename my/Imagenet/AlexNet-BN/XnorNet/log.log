I0114 16:10:57.168061 24909 upgrade_proto.cpp:1113] snapshot_prefix was a directory and is replaced to snapshot/solver
I0114 16:10:57.168794 24909 caffe.cpp:204] Using GPUs 0
I0114 16:10:57.319655 24909 caffe.cpp:209] GPU 0: GeForce GTX 1080 Ti
I0114 16:10:58.249130 24909 solver.cpp:45] Initializing solver from parameters: 
test_iter: 1000
test_interval: 1000
display: 200
max_iter: 500000
lr_policy: "modified_lr"
momentum: 0.9
snapshot: 10000
snapshot_prefix: "snapshot/solver"
solver_mode: GPU
device_id: 0
net: "train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
momentum2: 0.999
type: "Adam"
modified_lr {
  stepvalue: 125000
  stepvalue: 250000
  stepvalue: 375000
  stepvalue: 500000
  mlr: 0.001
  mlr: 0.0001
  mlr: 1e-05
  mlr: 1e-06
  weight_decay: 1e-05
  weight_decay: 1e-05
  weight_decay: 1e-05
  weight_decay: 1e-05
}
I0114 16:10:58.251058 24909 solver.cpp:105] Creating training net from net file: train_test.prototxt
I0114 16:10:58.252198 24909 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0114 16:10:58.252454 24909 net.cpp:51] Initializing net from parameters: 
name: "AlexNet-BN"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/zhengzhe/Data/imagenet_shrt256/ilsvrc12_train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 96
    bias_term: false
    pad: 2
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "pool1"
  top: "pool1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive1"
  type: "BinActive"
  bottom: "pool1"
  top: "binactive1"
}
layer {
  name: "conv2"
  type: "BinaryConvolution"
  bottom: "binactive1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "pool2"
  top: "pool2"
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "pool2"
  top: "pool2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive2"
  type: "BinActive"
  bottom: "pool2"
  top: "binactive2"
}
layer {
  name: "conv3"
  type: "BinaryConvolution"
  bottom: "binactive2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive3"
  type: "BinActive"
  bottom: "conv3"
  top: "binactive3"
}
layer {
  name: "conv4"
  type: "BinaryConvolution"
  bottom: "binactive3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "scale5"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive4"
  type: "BinActive"
  bottom: "conv4"
  top: "binactive4"
}
layer {
  name: "conv5"
  type: "BinaryConvolution"
  bottom: "binactive4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "bn6"
  type: "BatchNorm"
  bottom: "pool5"
  top: "pool5"
}
layer {
  name: "scale6"
  type: "Scale"
  bottom: "pool5"
  top: "pool5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive5"
  type: "BinActive"
  bottom: "pool5"
  top: "binactive5"
}
layer {
  name: "fc6"
  type: "BinaryInnerProduct"
  bottom: "binactive5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4096
    bias_term: false
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "scale7"
  type: "Scale"
  bottom: "fc6"
  top: "fc6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive6"
  type: "BinActive"
  bottom: "fc6"
  top: "binactive6"
}
layer {
  name: "fc7"
  type: "BinaryInnerProduct"
  bottom: "binactive6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4096
    bias_term: false
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn8"
  type: "BatchNorm"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "scale8"
  type: "Scale"
  bottom: "fc7"
  top: "fc7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "accuracy_5"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy_5"
  accuracy_param {
    top_k: 5
  }
}
I0114 16:10:58.253206 24909 layer_factory.hpp:78] Creating layer data
I0114 16:10:58.253453 24909 db_lmdb.cpp:35] Opened lmdb /home/zhengzhe/Data/imagenet_shrt256/ilsvrc12_train_lmdb
I0114 16:10:58.253542 24909 net.cpp:84] Creating Layer data
I0114 16:10:58.253577 24909 net.cpp:380] data -> data
I0114 16:10:58.253739 24909 net.cpp:380] data -> label
I0114 16:10:58.256247 24909 data_layer.cpp:45] output data size: 256,3,224,224
I0114 16:10:59.163990 24909 base_data_layer.cpp:72] Initializing prefetch
I0114 16:10:59.164739 24909 base_data_layer.cpp:75] Prefetch initialized.
I0114 16:10:59.164865 24909 net.cpp:122] Setting up data
I0114 16:10:59.165002 24909 net.cpp:129] Top shape: 256 3 224 224 (38535168)
I0114 16:10:59.165128 24909 net.cpp:129] Top shape: 256 (256)
I0114 16:10:59.165222 24909 net.cpp:137] Memory required for data: 154141696
I0114 16:10:59.165369 24909 layer_factory.hpp:78] Creating layer label_data_1_split
I0114 16:10:59.165585 24909 net.cpp:84] Creating Layer label_data_1_split
I0114 16:10:59.165705 24909 net.cpp:406] label_data_1_split <- label
I0114 16:10:59.165879 24909 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0114 16:10:59.166044 24909 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0114 16:10:59.166180 24909 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0114 16:10:59.166548 24909 net.cpp:122] Setting up label_data_1_split
I0114 16:10:59.166721 24909 net.cpp:129] Top shape: 256 (256)
I0114 16:10:59.166880 24909 net.cpp:129] Top shape: 256 (256)
I0114 16:10:59.167040 24909 net.cpp:129] Top shape: 256 (256)
I0114 16:10:59.167189 24909 net.cpp:137] Memory required for data: 154144768
I0114 16:10:59.167325 24909 layer_factory.hpp:78] Creating layer conv1
I0114 16:10:59.167596 24909 net.cpp:84] Creating Layer conv1
I0114 16:10:59.167745 24909 net.cpp:406] conv1 <- data
I0114 16:10:59.167902 24909 net.cpp:380] conv1 -> conv1
I0114 16:11:01.032367 24909 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 127416
I0114 16:11:01.032783 24909 net.cpp:122] Setting up conv1
I0114 16:11:01.032822 24909 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0114 16:11:01.032832 24909 net.cpp:137] Memory required for data: 451514368
I0114 16:11:01.032949 24909 layer_factory.hpp:78] Creating layer bn1
I0114 16:11:01.033012 24909 net.cpp:84] Creating Layer bn1
I0114 16:11:01.033033 24909 net.cpp:406] bn1 <- conv1
I0114 16:11:01.033076 24909 net.cpp:367] bn1 -> conv1 (in-place)
I0114 16:11:01.035187 24909 net.cpp:122] Setting up bn1
I0114 16:11:01.035210 24909 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0114 16:11:01.044024 24909 net.cpp:137] Memory required for data: 748883968
I0114 16:11:01.044138 24909 layer_factory.hpp:78] Creating layer scale1
I0114 16:11:01.044299 24909 net.cpp:84] Creating Layer scale1
I0114 16:11:01.044394 24909 net.cpp:406] scale1 <- conv1
I0114 16:11:01.044461 24909 net.cpp:367] scale1 -> conv1 (in-place)
I0114 16:11:01.044649 24909 layer_factory.hpp:78] Creating layer scale1
I0114 16:11:01.045104 24909 net.cpp:122] Setting up scale1
I0114 16:11:01.045442 24909 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0114 16:11:01.045486 24909 net.cpp:137] Memory required for data: 1046253568
I0114 16:11:01.045547 24909 layer_factory.hpp:78] Creating layer relu1
I0114 16:11:01.045650 24909 net.cpp:84] Creating Layer relu1
I0114 16:11:01.045724 24909 net.cpp:406] relu1 <- conv1
I0114 16:11:01.045779 24909 net.cpp:367] relu1 -> conv1 (in-place)
I0114 16:11:01.046545 24909 net.cpp:122] Setting up relu1
I0114 16:11:01.047317 24909 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0114 16:11:01.047356 24909 net.cpp:137] Memory required for data: 1343623168
I0114 16:11:01.047394 24909 layer_factory.hpp:78] Creating layer pool1
I0114 16:11:01.047463 24909 net.cpp:84] Creating Layer pool1
I0114 16:11:01.047538 24909 net.cpp:406] pool1 <- conv1
I0114 16:11:01.047596 24909 net.cpp:380] pool1 -> pool1
I0114 16:11:01.047767 24909 net.cpp:122] Setting up pool1
I0114 16:11:01.047931 24909 net.cpp:129] Top shape: 256 96 27 27 (17915904)
I0114 16:11:01.047973 24909 net.cpp:137] Memory required for data: 1415286784
I0114 16:11:01.048008 24909 layer_factory.hpp:78] Creating layer bn2
I0114 16:11:01.048060 24909 net.cpp:84] Creating Layer bn2
I0114 16:11:01.048115 24909 net.cpp:406] bn2 <- pool1
I0114 16:11:01.048168 24909 net.cpp:367] bn2 -> pool1 (in-place)
I0114 16:11:01.066956 24909 net.cpp:122] Setting up bn2
I0114 16:11:01.070385 24909 net.cpp:129] Top shape: 256 96 27 27 (17915904)
I0114 16:11:01.070456 24909 net.cpp:137] Memory required for data: 1486950400
I0114 16:11:01.070547 24909 layer_factory.hpp:78] Creating layer scale2
I0114 16:11:01.070735 24909 net.cpp:84] Creating Layer scale2
I0114 16:11:01.070861 24909 net.cpp:406] scale2 <- pool1
I0114 16:11:01.070935 24909 net.cpp:367] scale2 -> pool1 (in-place)
I0114 16:11:01.071118 24909 layer_factory.hpp:78] Creating layer scale2
I0114 16:11:01.071600 24909 net.cpp:122] Setting up scale2
I0114 16:11:01.072150 24909 net.cpp:129] Top shape: 256 96 27 27 (17915904)
I0114 16:11:01.072207 24909 net.cpp:137] Memory required for data: 1558614016
I0114 16:11:01.072266 24909 layer_factory.hpp:78] Creating layer binactive1
I0114 16:11:01.072373 24909 net.cpp:84] Creating Layer binactive1
I0114 16:11:01.072484 24909 net.cpp:406] binactive1 <- pool1
I0114 16:11:01.072562 24909 net.cpp:380] binactive1 -> binactive1
I0114 16:11:01.072772 24909 net.cpp:122] Setting up binactive1
I0114 16:11:01.072952 24909 net.cpp:129] Top shape: 256 96 27 27 (17915904)
I0114 16:11:01.073014 24909 net.cpp:137] Memory required for data: 1630277632
I0114 16:11:01.073060 24909 layer_factory.hpp:78] Creating layer conv2
I0114 16:11:01.073158 24909 net.cpp:84] Creating Layer conv2
I0114 16:11:01.073303 24909 net.cpp:406] conv2 <- binactive1
I0114 16:11:01.073385 24909 net.cpp:380] conv2 -> conv2
I0114 16:11:01.293068 24909 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 19668
I0114 16:11:01.293191 24909 net.cpp:122] Setting up conv2
I0114 16:11:01.293237 24909 net.cpp:129] Top shape: 256 256 27 27 (47775744)
I0114 16:11:01.293260 24909 net.cpp:137] Memory required for data: 1821380608
I0114 16:11:01.293316 24909 layer_factory.hpp:78] Creating layer pool2
I0114 16:11:01.293398 24909 net.cpp:84] Creating Layer pool2
I0114 16:11:01.293438 24909 net.cpp:406] pool2 <- conv2
I0114 16:11:01.293496 24909 net.cpp:380] pool2 -> pool2
I0114 16:11:01.293627 24909 net.cpp:122] Setting up pool2
I0114 16:11:01.293666 24909 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0114 16:11:01.293689 24909 net.cpp:137] Memory required for data: 1865682944
I0114 16:11:01.293715 24909 layer_factory.hpp:78] Creating layer bn3
I0114 16:11:01.293753 24909 net.cpp:84] Creating Layer bn3
I0114 16:11:01.293781 24909 net.cpp:406] bn3 <- pool2
I0114 16:11:01.293821 24909 net.cpp:367] bn3 -> pool2 (in-place)
I0114 16:11:01.294173 24909 net.cpp:122] Setting up bn3
I0114 16:11:01.294209 24909 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0114 16:11:01.294229 24909 net.cpp:137] Memory required for data: 1909985280
I0114 16:11:01.294277 24909 layer_factory.hpp:78] Creating layer scale3
I0114 16:11:01.294324 24909 net.cpp:84] Creating Layer scale3
I0114 16:11:01.294359 24909 net.cpp:406] scale3 <- pool2
I0114 16:11:01.294404 24909 net.cpp:367] scale3 -> pool2 (in-place)
I0114 16:11:01.294523 24909 layer_factory.hpp:78] Creating layer scale3
I0114 16:11:01.294775 24909 net.cpp:122] Setting up scale3
I0114 16:11:01.294813 24909 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0114 16:11:01.294836 24909 net.cpp:137] Memory required for data: 1954287616
I0114 16:11:01.294894 24909 layer_factory.hpp:78] Creating layer binactive2
I0114 16:11:01.294935 24909 net.cpp:84] Creating Layer binactive2
I0114 16:11:01.294963 24909 net.cpp:406] binactive2 <- pool2
I0114 16:11:01.295003 24909 net.cpp:380] binactive2 -> binactive2
I0114 16:11:01.295076 24909 net.cpp:122] Setting up binactive2
I0114 16:11:01.295115 24909 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0114 16:11:01.295138 24909 net.cpp:137] Memory required for data: 1998589952
I0114 16:11:01.295164 24909 layer_factory.hpp:78] Creating layer conv3
I0114 16:11:01.295222 24909 net.cpp:84] Creating Layer conv3
I0114 16:11:01.295253 24909 net.cpp:406] conv3 <- binactive2
I0114 16:11:01.295300 24909 net.cpp:380] conv3 -> conv3
I0114 16:11:01.454428 24909 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 18874368
I0114 16:11:01.454785 24909 net.cpp:122] Setting up conv3
I0114 16:11:01.454816 24909 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0114 16:11:01.454823 24909 net.cpp:137] Memory required for data: 2065043456
I0114 16:11:01.454859 24909 layer_factory.hpp:78] Creating layer bn4
I0114 16:11:01.454912 24909 net.cpp:84] Creating Layer bn4
I0114 16:11:01.454931 24909 net.cpp:406] bn4 <- conv3
I0114 16:11:01.454962 24909 net.cpp:367] bn4 -> conv3 (in-place)
I0114 16:11:01.455220 24909 net.cpp:122] Setting up bn4
I0114 16:11:01.455236 24909 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0114 16:11:01.455240 24909 net.cpp:137] Memory required for data: 2131496960
I0114 16:11:01.455265 24909 layer_factory.hpp:78] Creating layer scale4
I0114 16:11:01.455293 24909 net.cpp:84] Creating Layer scale4
I0114 16:11:01.455303 24909 net.cpp:406] scale4 <- conv3
I0114 16:11:01.455323 24909 net.cpp:367] scale4 -> conv3 (in-place)
I0114 16:11:01.455408 24909 layer_factory.hpp:78] Creating layer scale4
I0114 16:11:01.455626 24909 net.cpp:122] Setting up scale4
I0114 16:11:01.455641 24909 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0114 16:11:01.455646 24909 net.cpp:137] Memory required for data: 2197950464
I0114 16:11:01.455664 24909 layer_factory.hpp:78] Creating layer binactive3
I0114 16:11:01.455693 24909 net.cpp:84] Creating Layer binactive3
I0114 16:11:01.455703 24909 net.cpp:406] binactive3 <- conv3
I0114 16:11:01.455720 24909 net.cpp:380] binactive3 -> binactive3
I0114 16:11:01.455766 24909 net.cpp:122] Setting up binactive3
I0114 16:11:01.455780 24909 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0114 16:11:01.455786 24909 net.cpp:137] Memory required for data: 2264403968
I0114 16:11:01.455794 24909 layer_factory.hpp:78] Creating layer conv4
I0114 16:11:01.455832 24909 net.cpp:84] Creating Layer conv4
I0114 16:11:01.455843 24909 net.cpp:406] conv4 <- binactive3
I0114 16:11:01.455866 24909 net.cpp:380] conv4 -> conv4
I0114 16:11:01.810076 24909 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 9840
I0114 16:11:01.810144 24909 net.cpp:122] Setting up conv4
I0114 16:11:01.810170 24909 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0114 16:11:01.810178 24909 net.cpp:137] Memory required for data: 2330857472
I0114 16:11:01.810226 24909 layer_factory.hpp:78] Creating layer bn5
I0114 16:11:01.810276 24909 net.cpp:84] Creating Layer bn5
I0114 16:11:01.810307 24909 net.cpp:406] bn5 <- conv4
I0114 16:11:01.810350 24909 net.cpp:367] bn5 -> conv4 (in-place)
I0114 16:11:01.810685 24909 net.cpp:122] Setting up bn5
I0114 16:11:01.810703 24909 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0114 16:11:01.816742 24909 net.cpp:137] Memory required for data: 2397310976
I0114 16:11:01.816817 24909 layer_factory.hpp:78] Creating layer scale5
I0114 16:11:01.816956 24909 net.cpp:84] Creating Layer scale5
I0114 16:11:01.817050 24909 net.cpp:406] scale5 <- conv4
I0114 16:11:01.817129 24909 net.cpp:367] scale5 -> conv4 (in-place)
I0114 16:11:01.817308 24909 layer_factory.hpp:78] Creating layer scale5
I0114 16:11:01.817770 24909 net.cpp:122] Setting up scale5
I0114 16:11:01.818296 24909 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0114 16:11:01.818358 24909 net.cpp:137] Memory required for data: 2463764480
I0114 16:11:01.818418 24909 layer_factory.hpp:78] Creating layer binactive4
I0114 16:11:01.818521 24909 net.cpp:84] Creating Layer binactive4
I0114 16:11:01.818615 24909 net.cpp:406] binactive4 <- conv4
I0114 16:11:01.818688 24909 net.cpp:380] binactive4 -> binactive4
I0114 16:11:01.818832 24909 net.cpp:122] Setting up binactive4
I0114 16:11:01.818998 24909 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0114 16:11:01.819052 24909 net.cpp:137] Memory required for data: 2530217984
I0114 16:11:01.819093 24909 layer_factory.hpp:78] Creating layer conv5
I0114 16:11:01.819193 24909 net.cpp:84] Creating Layer conv5
I0114 16:11:01.819310 24909 net.cpp:406] conv5 <- binactive4
I0114 16:11:01.819399 24909 net.cpp:380] conv5 -> conv5
I0114 16:11:01.939574 24909 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 18874368
I0114 16:11:01.939908 24909 net.cpp:122] Setting up conv5
I0114 16:11:01.939939 24909 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0114 16:11:01.939944 24909 net.cpp:137] Memory required for data: 2574520320
I0114 16:11:01.939975 24909 layer_factory.hpp:78] Creating layer pool5
I0114 16:11:01.940023 24909 net.cpp:84] Creating Layer pool5
I0114 16:11:01.940040 24909 net.cpp:406] pool5 <- conv5
I0114 16:11:01.940070 24909 net.cpp:380] pool5 -> pool5
I0114 16:11:01.940165 24909 net.cpp:122] Setting up pool5
I0114 16:11:01.940179 24909 net.cpp:129] Top shape: 256 256 6 6 (2359296)
I0114 16:11:01.940184 24909 net.cpp:137] Memory required for data: 2583957504
I0114 16:11:01.940191 24909 layer_factory.hpp:78] Creating layer bn6
I0114 16:11:01.940207 24909 net.cpp:84] Creating Layer bn6
I0114 16:11:01.940214 24909 net.cpp:406] bn6 <- pool5
I0114 16:11:01.940233 24909 net.cpp:367] bn6 -> pool5 (in-place)
I0114 16:11:01.940498 24909 net.cpp:122] Setting up bn6
I0114 16:11:01.940510 24909 net.cpp:129] Top shape: 256 256 6 6 (2359296)
I0114 16:11:01.940536 24909 net.cpp:137] Memory required for data: 2593394688
I0114 16:11:01.940578 24909 layer_factory.hpp:78] Creating layer scale6
I0114 16:11:01.940605 24909 net.cpp:84] Creating Layer scale6
I0114 16:11:01.940614 24909 net.cpp:406] scale6 <- pool5
I0114 16:11:01.940632 24909 net.cpp:367] scale6 -> pool5 (in-place)
I0114 16:11:01.940709 24909 layer_factory.hpp:78] Creating layer scale6
I0114 16:11:01.940886 24909 net.cpp:122] Setting up scale6
I0114 16:11:01.940902 24909 net.cpp:129] Top shape: 256 256 6 6 (2359296)
I0114 16:11:01.940907 24909 net.cpp:137] Memory required for data: 2602831872
I0114 16:11:01.940922 24909 layer_factory.hpp:78] Creating layer binactive5
I0114 16:11:01.940939 24909 net.cpp:84] Creating Layer binactive5
I0114 16:11:01.940948 24909 net.cpp:406] binactive5 <- pool5
I0114 16:11:01.940966 24909 net.cpp:380] binactive5 -> binactive5
I0114 16:11:01.941005 24909 net.cpp:122] Setting up binactive5
I0114 16:11:01.941017 24909 net.cpp:129] Top shape: 256 256 6 6 (2359296)
I0114 16:11:01.941023 24909 net.cpp:137] Memory required for data: 2612269056
I0114 16:11:01.941030 24909 layer_factory.hpp:78] Creating layer fc6
I0114 16:11:01.941071 24909 net.cpp:84] Creating Layer fc6
I0114 16:11:01.941079 24909 net.cpp:406] fc6 <- binactive5
I0114 16:11:01.941100 24909 net.cpp:380] fc6 -> fc6
I0114 16:11:06.630745 24909 net.cpp:122] Setting up fc6
I0114 16:11:06.630884 24909 net.cpp:129] Top shape: 256 4096 (1048576)
I0114 16:11:06.630910 24909 net.cpp:137] Memory required for data: 2616463360
I0114 16:11:06.630975 24909 layer_factory.hpp:78] Creating layer bn7
I0114 16:11:06.631054 24909 net.cpp:84] Creating Layer bn7
I0114 16:11:06.631096 24909 net.cpp:406] bn7 <- fc6
I0114 16:11:06.631150 24909 net.cpp:367] bn7 -> fc6 (in-place)
I0114 16:11:06.631546 24909 net.cpp:122] Setting up bn7
I0114 16:11:06.631582 24909 net.cpp:129] Top shape: 256 4096 (1048576)
I0114 16:11:06.631603 24909 net.cpp:137] Memory required for data: 2620657664
I0114 16:11:06.631649 24909 layer_factory.hpp:78] Creating layer scale7
I0114 16:11:06.631701 24909 net.cpp:84] Creating Layer scale7
I0114 16:11:06.631731 24909 net.cpp:406] scale7 <- fc6
I0114 16:11:06.631772 24909 net.cpp:367] scale7 -> fc6 (in-place)
I0114 16:11:06.631902 24909 layer_factory.hpp:78] Creating layer scale7
I0114 16:11:06.632189 24909 net.cpp:122] Setting up scale7
I0114 16:11:06.632225 24909 net.cpp:129] Top shape: 256 4096 (1048576)
I0114 16:11:06.632246 24909 net.cpp:137] Memory required for data: 2624851968
I0114 16:11:06.632282 24909 layer_factory.hpp:78] Creating layer binactive6
I0114 16:11:06.632321 24909 net.cpp:84] Creating Layer binactive6
I0114 16:11:06.632362 24909 net.cpp:406] binactive6 <- fc6
I0114 16:11:06.632407 24909 net.cpp:380] binactive6 -> binactive6
I0114 16:11:06.632494 24909 net.cpp:122] Setting up binactive6
I0114 16:11:06.632530 24909 net.cpp:129] Top shape: 256 4096 (1048576)
I0114 16:11:06.632550 24909 net.cpp:137] Memory required for data: 2629046272
I0114 16:11:06.632572 24909 layer_factory.hpp:78] Creating layer fc7
I0114 16:11:06.632633 24909 net.cpp:84] Creating Layer fc7
I0114 16:11:06.632663 24909 net.cpp:406] fc7 <- binactive6
I0114 16:11:06.632706 24909 net.cpp:380] fc7 -> fc7
I0114 16:11:08.695865 24909 net.cpp:122] Setting up fc7
I0114 16:11:08.695926 24909 net.cpp:129] Top shape: 256 4096 (1048576)
I0114 16:11:08.695932 24909 net.cpp:137] Memory required for data: 2633240576
I0114 16:11:08.695979 24909 layer_factory.hpp:78] Creating layer bn8
I0114 16:11:08.696029 24909 net.cpp:84] Creating Layer bn8
I0114 16:11:08.696060 24909 net.cpp:406] bn8 <- fc7
I0114 16:11:08.696095 24909 net.cpp:367] bn8 -> fc7 (in-place)
I0114 16:11:08.696415 24909 net.cpp:122] Setting up bn8
I0114 16:11:08.696427 24909 net.cpp:129] Top shape: 256 4096 (1048576)
I0114 16:11:08.696431 24909 net.cpp:137] Memory required for data: 2637434880
I0114 16:11:08.696454 24909 layer_factory.hpp:78] Creating layer scale8
I0114 16:11:08.696478 24909 net.cpp:84] Creating Layer scale8
I0114 16:11:08.696511 24909 net.cpp:406] scale8 <- fc7
I0114 16:11:08.696530 24909 net.cpp:367] scale8 -> fc7 (in-place)
I0114 16:11:08.696624 24909 layer_factory.hpp:78] Creating layer scale8
I0114 16:11:08.696820 24909 net.cpp:122] Setting up scale8
I0114 16:11:08.696832 24909 net.cpp:129] Top shape: 256 4096 (1048576)
I0114 16:11:08.696836 24909 net.cpp:137] Memory required for data: 2641629184
I0114 16:11:08.696851 24909 layer_factory.hpp:78] Creating layer relu7
I0114 16:11:08.696867 24909 net.cpp:84] Creating Layer relu7
I0114 16:11:08.696877 24909 net.cpp:406] relu7 <- fc7
I0114 16:11:08.696890 24909 net.cpp:367] relu7 -> fc7 (in-place)
I0114 16:11:08.697921 24909 net.cpp:122] Setting up relu7
I0114 16:11:08.697939 24909 net.cpp:129] Top shape: 256 4096 (1048576)
I0114 16:11:08.697944 24909 net.cpp:137] Memory required for data: 2645823488
I0114 16:11:08.697952 24909 layer_factory.hpp:78] Creating layer fc8
I0114 16:11:08.697998 24909 net.cpp:84] Creating Layer fc8
I0114 16:11:08.698009 24909 net.cpp:406] fc8 <- fc7
I0114 16:11:08.698030 24909 net.cpp:380] fc8 -> fc8
I0114 16:11:09.071329 24909 net.cpp:122] Setting up fc8
I0114 16:11:09.071372 24909 net.cpp:129] Top shape: 256 1000 (256000)
I0114 16:11:09.071377 24909 net.cpp:137] Memory required for data: 2646847488
I0114 16:11:09.071403 24909 layer_factory.hpp:78] Creating layer fc8_fc8_0_split
I0114 16:11:09.071425 24909 net.cpp:84] Creating Layer fc8_fc8_0_split
I0114 16:11:09.071437 24909 net.cpp:406] fc8_fc8_0_split <- fc8
I0114 16:11:09.071463 24909 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0114 16:11:09.071488 24909 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0114 16:11:09.071506 24909 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0114 16:11:09.071579 24909 net.cpp:122] Setting up fc8_fc8_0_split
I0114 16:11:09.071599 24909 net.cpp:129] Top shape: 256 1000 (256000)
I0114 16:11:09.071604 24909 net.cpp:129] Top shape: 256 1000 (256000)
I0114 16:11:09.071607 24909 net.cpp:129] Top shape: 256 1000 (256000)
I0114 16:11:09.071610 24909 net.cpp:137] Memory required for data: 2649919488
I0114 16:11:09.071616 24909 layer_factory.hpp:78] Creating layer loss
I0114 16:11:09.071655 24909 net.cpp:84] Creating Layer loss
I0114 16:11:09.071665 24909 net.cpp:406] loss <- fc8_fc8_0_split_0
I0114 16:11:09.071678 24909 net.cpp:406] loss <- label_data_1_split_0
I0114 16:11:09.071693 24909 net.cpp:380] loss -> loss
I0114 16:11:09.071722 24909 layer_factory.hpp:78] Creating layer loss
I0114 16:11:09.074695 24909 net.cpp:122] Setting up loss
I0114 16:11:09.074714 24909 net.cpp:129] Top shape: (1)
I0114 16:11:09.074719 24909 net.cpp:132]     with loss weight 1
I0114 16:11:09.074772 24909 net.cpp:137] Memory required for data: 2649919492
I0114 16:11:09.074779 24909 layer_factory.hpp:78] Creating layer accuracy
I0114 16:11:09.074801 24909 net.cpp:84] Creating Layer accuracy
I0114 16:11:09.074812 24909 net.cpp:406] accuracy <- fc8_fc8_0_split_1
I0114 16:11:09.074828 24909 net.cpp:406] accuracy <- label_data_1_split_1
I0114 16:11:09.074851 24909 net.cpp:380] accuracy -> accuracy
I0114 16:11:09.074880 24909 net.cpp:122] Setting up accuracy
I0114 16:11:09.074892 24909 net.cpp:129] Top shape: (1)
I0114 16:11:09.074895 24909 net.cpp:137] Memory required for data: 2649919496
I0114 16:11:09.074901 24909 layer_factory.hpp:78] Creating layer accuracy_5
I0114 16:11:09.074928 24909 net.cpp:84] Creating Layer accuracy_5
I0114 16:11:09.074936 24909 net.cpp:406] accuracy_5 <- fc8_fc8_0_split_2
I0114 16:11:09.074949 24909 net.cpp:406] accuracy_5 <- label_data_1_split_2
I0114 16:11:09.074962 24909 net.cpp:380] accuracy_5 -> accuracy_5
I0114 16:11:09.074996 24909 net.cpp:122] Setting up accuracy_5
I0114 16:11:09.075006 24909 net.cpp:129] Top shape: (1)
I0114 16:11:09.075011 24909 net.cpp:137] Memory required for data: 2649919500
I0114 16:11:09.075017 24909 net.cpp:200] accuracy_5 does not need backward computation.
I0114 16:11:09.075024 24909 net.cpp:200] accuracy does not need backward computation.
I0114 16:11:09.075031 24909 net.cpp:198] loss needs backward computation.
I0114 16:11:09.075037 24909 net.cpp:198] fc8_fc8_0_split needs backward computation.
I0114 16:11:09.075059 24909 net.cpp:198] fc8 needs backward computation.
I0114 16:11:09.075065 24909 net.cpp:198] relu7 needs backward computation.
I0114 16:11:09.075073 24909 net.cpp:198] scale8 needs backward computation.
I0114 16:11:09.075076 24909 net.cpp:198] bn8 needs backward computation.
I0114 16:11:09.075081 24909 net.cpp:198] fc7 needs backward computation.
I0114 16:11:09.075085 24909 net.cpp:198] binactive6 needs backward computation.
I0114 16:11:09.075091 24909 net.cpp:198] scale7 needs backward computation.
I0114 16:11:09.075096 24909 net.cpp:198] bn7 needs backward computation.
I0114 16:11:09.075106 24909 net.cpp:198] fc6 needs backward computation.
I0114 16:11:09.075111 24909 net.cpp:198] binactive5 needs backward computation.
I0114 16:11:09.075115 24909 net.cpp:198] scale6 needs backward computation.
I0114 16:11:09.075120 24909 net.cpp:198] bn6 needs backward computation.
I0114 16:11:09.075124 24909 net.cpp:198] pool5 needs backward computation.
I0114 16:11:09.075131 24909 net.cpp:198] conv5 needs backward computation.
I0114 16:11:09.075136 24909 net.cpp:198] binactive4 needs backward computation.
I0114 16:11:09.075141 24909 net.cpp:198] scale5 needs backward computation.
I0114 16:11:09.075146 24909 net.cpp:198] bn5 needs backward computation.
I0114 16:11:09.075151 24909 net.cpp:198] conv4 needs backward computation.
I0114 16:11:09.075156 24909 net.cpp:198] binactive3 needs backward computation.
I0114 16:11:09.075160 24909 net.cpp:198] scale4 needs backward computation.
I0114 16:11:09.075165 24909 net.cpp:198] bn4 needs backward computation.
I0114 16:11:09.075173 24909 net.cpp:198] conv3 needs backward computation.
I0114 16:11:09.075178 24909 net.cpp:198] binactive2 needs backward computation.
I0114 16:11:09.075183 24909 net.cpp:198] scale3 needs backward computation.
I0114 16:11:09.075192 24909 net.cpp:198] bn3 needs backward computation.
I0114 16:11:09.075197 24909 net.cpp:198] pool2 needs backward computation.
I0114 16:11:09.075202 24909 net.cpp:198] conv2 needs backward computation.
I0114 16:11:09.075206 24909 net.cpp:198] binactive1 needs backward computation.
I0114 16:11:09.075211 24909 net.cpp:198] scale2 needs backward computation.
I0114 16:11:09.075214 24909 net.cpp:198] bn2 needs backward computation.
I0114 16:11:09.075219 24909 net.cpp:198] pool1 needs backward computation.
I0114 16:11:09.075223 24909 net.cpp:198] relu1 needs backward computation.
I0114 16:11:09.075227 24909 net.cpp:198] scale1 needs backward computation.
I0114 16:11:09.075232 24909 net.cpp:198] bn1 needs backward computation.
I0114 16:11:09.075235 24909 net.cpp:198] conv1 needs backward computation.
I0114 16:11:09.075243 24909 net.cpp:200] label_data_1_split does not need backward computation.
I0114 16:11:09.075249 24909 net.cpp:200] data does not need backward computation.
I0114 16:11:09.075258 24909 net.cpp:242] This network produces output accuracy
I0114 16:11:09.075266 24909 net.cpp:242] This network produces output accuracy_5
I0114 16:11:09.075271 24909 net.cpp:242] This network produces output loss
I0114 16:11:09.075328 24909 net.cpp:255] Network initialization done.
I0114 16:11:09.076443 24909 solver.cpp:193] Creating test net (#0) specified by net file: train_test.prototxt
I0114 16:11:09.076550 24909 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0114 16:11:09.076755 24909 net.cpp:51] Initializing net from parameters: 
name: "AlexNet-BN"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 224
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/zhengzhe/Data/imagenet_shrt256/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 96
    bias_term: false
    pad: 2
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "pool1"
  top: "pool1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive1"
  type: "BinActive"
  bottom: "pool1"
  top: "binactive1"
}
layer {
  name: "conv2"
  type: "BinaryConvolution"
  bottom: "binactive1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "pool2"
  top: "pool2"
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "pool2"
  top: "pool2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive2"
  type: "BinActive"
  bottom: "pool2"
  top: "binactive2"
}
layer {
  name: "conv3"
  type: "BinaryConvolution"
  bottom: "binactive2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive3"
  type: "BinActive"
  bottom: "conv3"
  top: "binactive3"
}
layer {
  name: "conv4"
  type: "BinaryConvolution"
  bottom: "binactive3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "scale5"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive4"
  type: "BinActive"
  bottom: "conv4"
  top: "binactive4"
}
layer {
  name: "conv5"
  type: "BinaryConvolution"
  bottom: "binactive4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "bn6"
  type: "BatchNorm"
  bottom: "pool5"
  top: "pool5"
}
layer {
  name: "scale6"
  type: "Scale"
  bottom: "pool5"
  top: "pool5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive5"
  type: "BinActive"
  bottom: "pool5"
  top: "binactive5"
}
layer {
  name: "fc6"
  type: "BinaryInnerProduct"
  bottom: "binactive5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4096
    bias_term: false
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "scale7"
  type: "Scale"
  bottom: "fc6"
  top: "fc6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive6"
  type: "BinActive"
  bottom: "fc6"
  top: "binactive6"
}
layer {
  name: "fc7"
  type: "BinaryInnerProduct"
  bottom: "binactive6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4096
    bias_term: false
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn8"
  type: "BatchNorm"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "scale8"
  type: "Scale"
  bottom: "fc7"
  top: "fc7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "accuracy_5"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy_5"
  accuracy_param {
    top_k: 5
  }
}
I0114 16:11:09.077131 24909 layer_factory.hpp:78] Creating layer data
I0114 16:11:09.077225 24909 db_lmdb.cpp:35] Opened lmdb /home/zhengzhe/Data/imagenet_shrt256/ilsvrc12_val_lmdb
I0114 16:11:09.077265 24909 net.cpp:84] Creating Layer data
I0114 16:11:09.077283 24909 net.cpp:380] data -> data
I0114 16:11:09.077316 24909 net.cpp:380] data -> label
I0114 16:11:09.077879 24909 data_layer.cpp:45] output data size: 50,3,224,224
I0114 16:11:09.153692 24909 base_data_layer.cpp:72] Initializing prefetch
I0114 16:11:09.198091 24909 base_data_layer.cpp:75] Prefetch initialized.
I0114 16:11:09.198179 24909 net.cpp:122] Setting up data
I0114 16:11:09.198230 24909 net.cpp:129] Top shape: 50 3 224 224 (7526400)
I0114 16:11:09.198263 24909 net.cpp:129] Top shape: 50 (50)
I0114 16:11:09.198287 24909 net.cpp:137] Memory required for data: 30105800
I0114 16:11:09.198348 24909 layer_factory.hpp:78] Creating layer label_data_1_split
I0114 16:11:09.198505 24909 net.cpp:84] Creating Layer label_data_1_split
I0114 16:11:09.198549 24909 net.cpp:406] label_data_1_split <- label
I0114 16:11:09.198611 24909 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0114 16:11:09.198688 24909 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0114 16:11:09.198740 24909 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0114 16:11:09.198907 24909 net.cpp:122] Setting up label_data_1_split
I0114 16:11:09.198946 24909 net.cpp:129] Top shape: 50 (50)
I0114 16:11:09.198971 24909 net.cpp:129] Top shape: 50 (50)
I0114 16:11:09.198997 24909 net.cpp:129] Top shape: 50 (50)
I0114 16:11:09.199015 24909 net.cpp:137] Memory required for data: 30106400
I0114 16:11:09.199035 24909 layer_factory.hpp:78] Creating layer conv1
I0114 16:11:09.199103 24909 net.cpp:84] Creating Layer conv1
I0114 16:11:09.199136 24909 net.cpp:406] conv1 <- data
I0114 16:11:09.199183 24909 net.cpp:380] conv1 -> conv1
I0114 16:11:09.207403 24909 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 127416
I0114 16:11:09.207535 24909 net.cpp:122] Setting up conv1
I0114 16:11:09.207600 24909 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0114 16:11:09.207670 24909 net.cpp:137] Memory required for data: 88186400
I0114 16:11:09.207773 24909 layer_factory.hpp:78] Creating layer bn1
I0114 16:11:09.207864 24909 net.cpp:84] Creating Layer bn1
I0114 16:11:09.207942 24909 net.cpp:406] bn1 <- conv1
I0114 16:11:09.208045 24909 net.cpp:367] bn1 -> conv1 (in-place)
I0114 16:11:09.208528 24909 net.cpp:122] Setting up bn1
I0114 16:11:09.208614 24909 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0114 16:11:09.208647 24909 net.cpp:137] Memory required for data: 146266400
I0114 16:11:09.208719 24909 layer_factory.hpp:78] Creating layer scale1
I0114 16:11:09.208786 24909 net.cpp:84] Creating Layer scale1
I0114 16:11:09.208828 24909 net.cpp:406] scale1 <- conv1
I0114 16:11:09.208951 24909 net.cpp:367] scale1 -> conv1 (in-place)
I0114 16:11:09.209106 24909 layer_factory.hpp:78] Creating layer scale1
I0114 16:11:09.209520 24909 net.cpp:122] Setting up scale1
I0114 16:11:09.209605 24909 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0114 16:11:09.209686 24909 net.cpp:137] Memory required for data: 204346400
I0114 16:11:09.209796 24909 layer_factory.hpp:78] Creating layer relu1
I0114 16:11:09.209882 24909 net.cpp:84] Creating Layer relu1
I0114 16:11:09.209946 24909 net.cpp:406] relu1 <- conv1
I0114 16:11:09.210034 24909 net.cpp:367] relu1 -> conv1 (in-place)
I0114 16:11:09.210958 24909 net.cpp:122] Setting up relu1
I0114 16:11:09.211028 24909 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0114 16:11:09.211081 24909 net.cpp:137] Memory required for data: 262426400
I0114 16:11:09.211138 24909 layer_factory.hpp:78] Creating layer pool1
I0114 16:11:09.211244 24909 net.cpp:84] Creating Layer pool1
I0114 16:11:09.211277 24909 net.cpp:406] pool1 <- conv1
I0114 16:11:09.211330 24909 net.cpp:380] pool1 -> pool1
I0114 16:11:09.211493 24909 net.cpp:122] Setting up pool1
I0114 16:11:09.211577 24909 net.cpp:129] Top shape: 50 96 27 27 (3499200)
I0114 16:11:09.211642 24909 net.cpp:137] Memory required for data: 276423200
I0114 16:11:09.211714 24909 layer_factory.hpp:78] Creating layer bn2
I0114 16:11:09.211793 24909 net.cpp:84] Creating Layer bn2
I0114 16:11:09.211863 24909 net.cpp:406] bn2 <- pool1
I0114 16:11:09.211936 24909 net.cpp:367] bn2 -> pool1 (in-place)
I0114 16:11:09.212376 24909 net.cpp:122] Setting up bn2
I0114 16:11:09.212437 24909 net.cpp:129] Top shape: 50 96 27 27 (3499200)
I0114 16:11:09.212505 24909 net.cpp:137] Memory required for data: 290420000
I0114 16:11:09.212622 24909 layer_factory.hpp:78] Creating layer scale2
I0114 16:11:09.212707 24909 net.cpp:84] Creating Layer scale2
I0114 16:11:09.212797 24909 net.cpp:406] scale2 <- pool1
I0114 16:11:09.212895 24909 net.cpp:367] scale2 -> pool1 (in-place)
I0114 16:11:09.213075 24909 layer_factory.hpp:78] Creating layer scale2
I0114 16:11:09.213428 24909 net.cpp:122] Setting up scale2
I0114 16:11:09.213498 24909 net.cpp:129] Top shape: 50 96 27 27 (3499200)
I0114 16:11:09.213546 24909 net.cpp:137] Memory required for data: 304416800
I0114 16:11:09.213629 24909 layer_factory.hpp:78] Creating layer binactive1
I0114 16:11:09.213716 24909 net.cpp:84] Creating Layer binactive1
I0114 16:11:09.213794 24909 net.cpp:406] binactive1 <- pool1
I0114 16:11:09.213883 24909 net.cpp:380] binactive1 -> binactive1
I0114 16:11:09.213981 24909 net.cpp:122] Setting up binactive1
I0114 16:11:09.214025 24909 net.cpp:129] Top shape: 50 96 27 27 (3499200)
I0114 16:11:09.214054 24909 net.cpp:137] Memory required for data: 318413600
I0114 16:11:09.214129 24909 layer_factory.hpp:78] Creating layer conv2
I0114 16:11:09.214231 24909 net.cpp:84] Creating Layer conv2
I0114 16:11:09.214310 24909 net.cpp:406] conv2 <- binactive1
I0114 16:11:09.214419 24909 net.cpp:380] conv2 -> conv2
I0114 16:11:09.297672 24909 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 19668
I0114 16:11:09.297739 24909 net.cpp:122] Setting up conv2
I0114 16:11:09.297781 24909 net.cpp:129] Top shape: 50 256 27 27 (9331200)
I0114 16:11:09.297811 24909 net.cpp:137] Memory required for data: 355738400
I0114 16:11:09.297857 24909 layer_factory.hpp:78] Creating layer pool2
I0114 16:11:09.297917 24909 net.cpp:84] Creating Layer pool2
I0114 16:11:09.297955 24909 net.cpp:406] pool2 <- conv2
I0114 16:11:09.298007 24909 net.cpp:380] pool2 -> pool2
I0114 16:11:09.298140 24909 net.cpp:122] Setting up pool2
I0114 16:11:09.298178 24909 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0114 16:11:09.298207 24909 net.cpp:137] Memory required for data: 364391200
I0114 16:11:09.298240 24909 layer_factory.hpp:78] Creating layer bn3
I0114 16:11:09.298285 24909 net.cpp:84] Creating Layer bn3
I0114 16:11:09.298318 24909 net.cpp:406] bn3 <- pool2
I0114 16:11:09.298360 24909 net.cpp:367] bn3 -> pool2 (in-place)
I0114 16:11:09.298746 24909 net.cpp:122] Setting up bn3
I0114 16:11:09.298770 24909 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0114 16:11:09.298799 24909 net.cpp:137] Memory required for data: 373044000
I0114 16:11:09.298859 24909 layer_factory.hpp:78] Creating layer scale3
I0114 16:11:09.298887 24909 net.cpp:84] Creating Layer scale3
I0114 16:11:09.298903 24909 net.cpp:406] scale3 <- pool2
I0114 16:11:09.298931 24909 net.cpp:367] scale3 -> pool2 (in-place)
I0114 16:11:09.299057 24909 layer_factory.hpp:78] Creating layer scale3
I0114 16:11:09.299317 24909 net.cpp:122] Setting up scale3
I0114 16:11:09.299350 24909 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0114 16:11:09.299381 24909 net.cpp:137] Memory required for data: 381696800
I0114 16:11:09.299441 24909 layer_factory.hpp:78] Creating layer binactive2
I0114 16:11:09.299486 24909 net.cpp:84] Creating Layer binactive2
I0114 16:11:09.299521 24909 net.cpp:406] binactive2 <- pool2
I0114 16:11:09.299568 24909 net.cpp:380] binactive2 -> binactive2
I0114 16:11:09.299654 24909 net.cpp:122] Setting up binactive2
I0114 16:11:09.299692 24909 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0114 16:11:09.299721 24909 net.cpp:137] Memory required for data: 390349600
I0114 16:11:09.299755 24909 layer_factory.hpp:78] Creating layer conv3
I0114 16:11:09.299819 24909 net.cpp:84] Creating Layer conv3
I0114 16:11:09.299855 24909 net.cpp:406] conv3 <- binactive2
I0114 16:11:09.299906 24909 net.cpp:380] conv3 -> conv3
I0114 16:11:09.417649 24909 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 18874368
I0114 16:11:09.417994 24909 net.cpp:122] Setting up conv3
I0114 16:11:09.418022 24909 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0114 16:11:09.418027 24909 net.cpp:137] Memory required for data: 403328800
I0114 16:11:09.418064 24909 layer_factory.hpp:78] Creating layer bn4
I0114 16:11:09.418109 24909 net.cpp:84] Creating Layer bn4
I0114 16:11:09.418124 24909 net.cpp:406] bn4 <- conv3
I0114 16:11:09.418159 24909 net.cpp:367] bn4 -> conv3 (in-place)
I0114 16:11:09.418455 24909 net.cpp:122] Setting up bn4
I0114 16:11:09.418467 24909 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0114 16:11:09.418473 24909 net.cpp:137] Memory required for data: 416308000
I0114 16:11:09.418495 24909 layer_factory.hpp:78] Creating layer scale4
I0114 16:11:09.418519 24909 net.cpp:84] Creating Layer scale4
I0114 16:11:09.418529 24909 net.cpp:406] scale4 <- conv3
I0114 16:11:09.418547 24909 net.cpp:367] scale4 -> conv3 (in-place)
I0114 16:11:09.418628 24909 layer_factory.hpp:78] Creating layer scale4
I0114 16:11:09.418819 24909 net.cpp:122] Setting up scale4
I0114 16:11:09.418833 24909 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0114 16:11:09.418836 24909 net.cpp:137] Memory required for data: 429287200
I0114 16:11:09.418850 24909 layer_factory.hpp:78] Creating layer binactive3
I0114 16:11:09.418866 24909 net.cpp:84] Creating Layer binactive3
I0114 16:11:09.418874 24909 net.cpp:406] binactive3 <- conv3
I0114 16:11:09.418895 24909 net.cpp:380] binactive3 -> binactive3
I0114 16:11:09.418942 24909 net.cpp:122] Setting up binactive3
I0114 16:11:09.418956 24909 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0114 16:11:09.418959 24909 net.cpp:137] Memory required for data: 442266400
I0114 16:11:09.418965 24909 layer_factory.hpp:78] Creating layer conv4
I0114 16:11:09.419001 24909 net.cpp:84] Creating Layer conv4
I0114 16:11:09.419010 24909 net.cpp:406] conv4 <- binactive3
I0114 16:11:09.419031 24909 net.cpp:380] conv4 -> conv4
I0114 16:11:09.540182 24909 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 9840
I0114 16:11:09.540232 24909 net.cpp:122] Setting up conv4
I0114 16:11:09.540257 24909 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0114 16:11:09.540262 24909 net.cpp:137] Memory required for data: 455245600
I0114 16:11:09.540292 24909 layer_factory.hpp:78] Creating layer bn5
I0114 16:11:09.540328 24909 net.cpp:84] Creating Layer bn5
I0114 16:11:09.540349 24909 net.cpp:406] bn5 <- conv4
I0114 16:11:09.540376 24909 net.cpp:367] bn5 -> conv4 (in-place)
I0114 16:11:09.540663 24909 net.cpp:122] Setting up bn5
I0114 16:11:09.540674 24909 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0114 16:11:09.540679 24909 net.cpp:137] Memory required for data: 468224800
I0114 16:11:09.540725 24909 layer_factory.hpp:78] Creating layer scale5
I0114 16:11:09.540750 24909 net.cpp:84] Creating Layer scale5
I0114 16:11:09.540760 24909 net.cpp:406] scale5 <- conv4
I0114 16:11:09.540776 24909 net.cpp:367] scale5 -> conv4 (in-place)
I0114 16:11:09.540858 24909 layer_factory.hpp:78] Creating layer scale5
I0114 16:11:09.541043 24909 net.cpp:122] Setting up scale5
I0114 16:11:09.541055 24909 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0114 16:11:09.541060 24909 net.cpp:137] Memory required for data: 481204000
I0114 16:11:09.541074 24909 layer_factory.hpp:78] Creating layer binactive4
I0114 16:11:09.541088 24909 net.cpp:84] Creating Layer binactive4
I0114 16:11:09.541096 24909 net.cpp:406] binactive4 <- conv4
I0114 16:11:09.541113 24909 net.cpp:380] binactive4 -> binactive4
I0114 16:11:09.541159 24909 net.cpp:122] Setting up binactive4
I0114 16:11:09.541175 24909 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0114 16:11:09.541179 24909 net.cpp:137] Memory required for data: 494183200
I0114 16:11:09.541185 24909 layer_factory.hpp:78] Creating layer conv5
I0114 16:11:09.541216 24909 net.cpp:84] Creating Layer conv5
I0114 16:11:09.541225 24909 net.cpp:406] conv5 <- binactive4
I0114 16:11:09.541244 24909 net.cpp:380] conv5 -> conv5
I0114 16:11:09.624264 24909 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 18874368
I0114 16:11:09.624617 24909 net.cpp:122] Setting up conv5
I0114 16:11:09.624644 24909 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0114 16:11:09.624651 24909 net.cpp:137] Memory required for data: 502836000
I0114 16:11:09.624682 24909 layer_factory.hpp:78] Creating layer pool5
I0114 16:11:09.624727 24909 net.cpp:84] Creating Layer pool5
I0114 16:11:09.624755 24909 net.cpp:406] pool5 <- conv5
I0114 16:11:09.624788 24909 net.cpp:380] pool5 -> pool5
I0114 16:11:09.624883 24909 net.cpp:122] Setting up pool5
I0114 16:11:09.624898 24909 net.cpp:129] Top shape: 50 256 6 6 (460800)
I0114 16:11:09.624903 24909 net.cpp:137] Memory required for data: 504679200
I0114 16:11:09.624909 24909 layer_factory.hpp:78] Creating layer bn6
I0114 16:11:09.624928 24909 net.cpp:84] Creating Layer bn6
I0114 16:11:09.624938 24909 net.cpp:406] bn6 <- pool5
I0114 16:11:09.624953 24909 net.cpp:367] bn6 -> pool5 (in-place)
I0114 16:11:09.625236 24909 net.cpp:122] Setting up bn6
I0114 16:11:09.625252 24909 net.cpp:129] Top shape: 50 256 6 6 (460800)
I0114 16:11:09.625257 24909 net.cpp:137] Memory required for data: 506522400
I0114 16:11:09.625293 24909 layer_factory.hpp:78] Creating layer scale6
I0114 16:11:09.625319 24909 net.cpp:84] Creating Layer scale6
I0114 16:11:09.625327 24909 net.cpp:406] scale6 <- pool5
I0114 16:11:09.625349 24909 net.cpp:367] scale6 -> pool5 (in-place)
I0114 16:11:09.625434 24909 layer_factory.hpp:78] Creating layer scale6
I0114 16:11:09.625622 24909 net.cpp:122] Setting up scale6
I0114 16:11:09.625635 24909 net.cpp:129] Top shape: 50 256 6 6 (460800)
I0114 16:11:09.625639 24909 net.cpp:137] Memory required for data: 508365600
I0114 16:11:09.625653 24909 layer_factory.hpp:78] Creating layer binactive5
I0114 16:11:09.625669 24909 net.cpp:84] Creating Layer binactive5
I0114 16:11:09.625677 24909 net.cpp:406] binactive5 <- pool5
I0114 16:11:09.625694 24909 net.cpp:380] binactive5 -> binactive5
I0114 16:11:09.625741 24909 net.cpp:122] Setting up binactive5
I0114 16:11:09.625753 24909 net.cpp:129] Top shape: 50 256 6 6 (460800)
I0114 16:11:09.625759 24909 net.cpp:137] Memory required for data: 510208800
I0114 16:11:09.625766 24909 layer_factory.hpp:78] Creating layer fc6
I0114 16:11:09.625788 24909 net.cpp:84] Creating Layer fc6
I0114 16:11:09.625797 24909 net.cpp:406] fc6 <- binactive5
I0114 16:11:09.625815 24909 net.cpp:380] fc6 -> fc6
I0114 16:11:14.062898 24909 net.cpp:122] Setting up fc6
I0114 16:11:14.063037 24909 net.cpp:129] Top shape: 50 4096 (204800)
I0114 16:11:14.063063 24909 net.cpp:137] Memory required for data: 511028000
I0114 16:11:14.063148 24909 layer_factory.hpp:78] Creating layer bn7
I0114 16:11:14.063223 24909 net.cpp:84] Creating Layer bn7
I0114 16:11:14.063288 24909 net.cpp:406] bn7 <- fc6
I0114 16:11:14.063354 24909 net.cpp:367] bn7 -> fc6 (in-place)
I0114 16:11:14.063827 24909 net.cpp:122] Setting up bn7
I0114 16:11:14.063864 24909 net.cpp:129] Top shape: 50 4096 (204800)
I0114 16:11:14.063886 24909 net.cpp:137] Memory required for data: 511847200
I0114 16:11:14.063935 24909 layer_factory.hpp:78] Creating layer scale7
I0114 16:11:14.063988 24909 net.cpp:84] Creating Layer scale7
I0114 16:11:14.064018 24909 net.cpp:406] scale7 <- fc6
I0114 16:11:14.064060 24909 net.cpp:367] scale7 -> fc6 (in-place)
I0114 16:11:14.064218 24909 layer_factory.hpp:78] Creating layer scale7
I0114 16:11:14.064543 24909 net.cpp:122] Setting up scale7
I0114 16:11:14.064581 24909 net.cpp:129] Top shape: 50 4096 (204800)
I0114 16:11:14.064604 24909 net.cpp:137] Memory required for data: 512666400
I0114 16:11:14.064643 24909 layer_factory.hpp:78] Creating layer binactive6
I0114 16:11:14.064682 24909 net.cpp:84] Creating Layer binactive6
I0114 16:11:14.064710 24909 net.cpp:406] binactive6 <- fc6
I0114 16:11:14.064754 24909 net.cpp:380] binactive6 -> binactive6
I0114 16:11:14.064851 24909 net.cpp:122] Setting up binactive6
I0114 16:11:14.064888 24909 net.cpp:129] Top shape: 50 4096 (204800)
I0114 16:11:14.064908 24909 net.cpp:137] Memory required for data: 513485600
I0114 16:11:14.064932 24909 layer_factory.hpp:78] Creating layer fc7
I0114 16:11:14.064996 24909 net.cpp:84] Creating Layer fc7
I0114 16:11:14.065027 24909 net.cpp:406] fc7 <- binactive6
I0114 16:11:14.065078 24909 net.cpp:380] fc7 -> fc7
I0114 16:11:15.728157 24909 net.cpp:122] Setting up fc7
I0114 16:11:15.728209 24909 net.cpp:129] Top shape: 50 4096 (204800)
I0114 16:11:15.728214 24909 net.cpp:137] Memory required for data: 514304800
I0114 16:11:15.728251 24909 layer_factory.hpp:78] Creating layer bn8
I0114 16:11:15.728298 24909 net.cpp:84] Creating Layer bn8
I0114 16:11:15.728317 24909 net.cpp:406] bn8 <- fc7
I0114 16:11:15.728353 24909 net.cpp:367] bn8 -> fc7 (in-place)
I0114 16:11:15.728668 24909 net.cpp:122] Setting up bn8
I0114 16:11:15.728680 24909 net.cpp:129] Top shape: 50 4096 (204800)
I0114 16:11:15.728685 24909 net.cpp:137] Memory required for data: 515124000
I0114 16:11:15.728708 24909 layer_factory.hpp:78] Creating layer scale8
I0114 16:11:15.728737 24909 net.cpp:84] Creating Layer scale8
I0114 16:11:15.728747 24909 net.cpp:406] scale8 <- fc7
I0114 16:11:15.728770 24909 net.cpp:367] scale8 -> fc7 (in-place)
I0114 16:11:15.728886 24909 layer_factory.hpp:78] Creating layer scale8
I0114 16:11:15.729104 24909 net.cpp:122] Setting up scale8
I0114 16:11:15.729120 24909 net.cpp:129] Top shape: 50 4096 (204800)
I0114 16:11:15.729125 24909 net.cpp:137] Memory required for data: 515943200
I0114 16:11:15.729148 24909 layer_factory.hpp:78] Creating layer relu7
I0114 16:11:15.729172 24909 net.cpp:84] Creating Layer relu7
I0114 16:11:15.729184 24909 net.cpp:406] relu7 <- fc7
I0114 16:11:15.729207 24909 net.cpp:367] relu7 -> fc7 (in-place)
I0114 16:11:15.730847 24909 net.cpp:122] Setting up relu7
I0114 16:11:15.730864 24909 net.cpp:129] Top shape: 50 4096 (204800)
I0114 16:11:15.730868 24909 net.cpp:137] Memory required for data: 516762400
I0114 16:11:15.730875 24909 layer_factory.hpp:78] Creating layer fc8
I0114 16:11:15.730908 24909 net.cpp:84] Creating Layer fc8
I0114 16:11:15.730918 24909 net.cpp:406] fc8 <- fc7
I0114 16:11:15.730943 24909 net.cpp:380] fc8 -> fc8
I0114 16:11:16.096946 24909 net.cpp:122] Setting up fc8
I0114 16:11:16.096998 24909 net.cpp:129] Top shape: 50 1000 (50000)
I0114 16:11:16.097003 24909 net.cpp:137] Memory required for data: 516962400
I0114 16:11:16.097039 24909 layer_factory.hpp:78] Creating layer fc8_fc8_0_split
I0114 16:11:16.097080 24909 net.cpp:84] Creating Layer fc8_fc8_0_split
I0114 16:11:16.097097 24909 net.cpp:406] fc8_fc8_0_split <- fc8
I0114 16:11:16.097127 24909 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0114 16:11:16.097157 24909 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0114 16:11:16.097173 24909 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0114 16:11:16.097259 24909 net.cpp:122] Setting up fc8_fc8_0_split
I0114 16:11:16.097292 24909 net.cpp:129] Top shape: 50 1000 (50000)
I0114 16:11:16.097302 24909 net.cpp:129] Top shape: 50 1000 (50000)
I0114 16:11:16.097309 24909 net.cpp:129] Top shape: 50 1000 (50000)
I0114 16:11:16.097314 24909 net.cpp:137] Memory required for data: 517562400
I0114 16:11:16.097322 24909 layer_factory.hpp:78] Creating layer loss
I0114 16:11:16.097357 24909 net.cpp:84] Creating Layer loss
I0114 16:11:16.097370 24909 net.cpp:406] loss <- fc8_fc8_0_split_0
I0114 16:11:16.097391 24909 net.cpp:406] loss <- label_data_1_split_0
I0114 16:11:16.097414 24909 net.cpp:380] loss -> loss
I0114 16:11:16.097447 24909 layer_factory.hpp:78] Creating layer loss
I0114 16:11:16.098559 24909 net.cpp:122] Setting up loss
I0114 16:11:16.098578 24909 net.cpp:129] Top shape: (1)
I0114 16:11:16.098584 24909 net.cpp:132]     with loss weight 1
I0114 16:11:16.098604 24909 net.cpp:137] Memory required for data: 517562404
I0114 16:11:16.098613 24909 layer_factory.hpp:78] Creating layer accuracy
I0114 16:11:16.098636 24909 net.cpp:84] Creating Layer accuracy
I0114 16:11:16.098646 24909 net.cpp:406] accuracy <- fc8_fc8_0_split_1
I0114 16:11:16.098666 24909 net.cpp:406] accuracy <- label_data_1_split_1
I0114 16:11:16.098688 24909 net.cpp:380] accuracy -> accuracy
I0114 16:11:16.098717 24909 net.cpp:122] Setting up accuracy
I0114 16:11:16.098727 24909 net.cpp:129] Top shape: (1)
I0114 16:11:16.098731 24909 net.cpp:137] Memory required for data: 517562408
I0114 16:11:16.098737 24909 layer_factory.hpp:78] Creating layer accuracy_5
I0114 16:11:16.098755 24909 net.cpp:84] Creating Layer accuracy_5
I0114 16:11:16.098763 24909 net.cpp:406] accuracy_5 <- fc8_fc8_0_split_2
I0114 16:11:16.098776 24909 net.cpp:406] accuracy_5 <- label_data_1_split_2
I0114 16:11:16.098789 24909 net.cpp:380] accuracy_5 -> accuracy_5
I0114 16:11:16.098811 24909 net.cpp:122] Setting up accuracy_5
I0114 16:11:16.098821 24909 net.cpp:129] Top shape: (1)
I0114 16:11:16.098825 24909 net.cpp:137] Memory required for data: 517562412
I0114 16:11:16.098834 24909 net.cpp:200] accuracy_5 does not need backward computation.
I0114 16:11:16.098842 24909 net.cpp:200] accuracy does not need backward computation.
I0114 16:11:16.098850 24909 net.cpp:198] loss needs backward computation.
I0114 16:11:16.098860 24909 net.cpp:198] fc8_fc8_0_split needs backward computation.
I0114 16:11:16.098868 24909 net.cpp:198] fc8 needs backward computation.
I0114 16:11:16.098896 24909 net.cpp:198] relu7 needs backward computation.
I0114 16:11:16.098904 24909 net.cpp:198] scale8 needs backward computation.
I0114 16:11:16.098908 24909 net.cpp:198] bn8 needs backward computation.
I0114 16:11:16.098912 24909 net.cpp:198] fc7 needs backward computation.
I0114 16:11:16.098917 24909 net.cpp:198] binactive6 needs backward computation.
I0114 16:11:16.098924 24909 net.cpp:198] scale7 needs backward computation.
I0114 16:11:16.098930 24909 net.cpp:198] bn7 needs backward computation.
I0114 16:11:16.098938 24909 net.cpp:198] fc6 needs backward computation.
I0114 16:11:16.098949 24909 net.cpp:198] binactive5 needs backward computation.
I0114 16:11:16.098958 24909 net.cpp:198] scale6 needs backward computation.
I0114 16:11:16.098964 24909 net.cpp:198] bn6 needs backward computation.
I0114 16:11:16.098974 24909 net.cpp:198] pool5 needs backward computation.
I0114 16:11:16.098984 24909 net.cpp:198] conv5 needs backward computation.
I0114 16:11:16.098991 24909 net.cpp:198] binactive4 needs backward computation.
I0114 16:11:16.099000 24909 net.cpp:198] scale5 needs backward computation.
I0114 16:11:16.099010 24909 net.cpp:198] bn5 needs backward computation.
I0114 16:11:16.099020 24909 net.cpp:198] conv4 needs backward computation.
I0114 16:11:16.099025 24909 net.cpp:198] binactive3 needs backward computation.
I0114 16:11:16.099032 24909 net.cpp:198] scale4 needs backward computation.
I0114 16:11:16.099038 24909 net.cpp:198] bn4 needs backward computation.
I0114 16:11:16.099046 24909 net.cpp:198] conv3 needs backward computation.
I0114 16:11:16.099052 24909 net.cpp:198] binactive2 needs backward computation.
I0114 16:11:16.099076 24909 net.cpp:198] scale3 needs backward computation.
I0114 16:11:16.099086 24909 net.cpp:198] bn3 needs backward computation.
I0114 16:11:16.099093 24909 net.cpp:198] pool2 needs backward computation.
I0114 16:11:16.099103 24909 net.cpp:198] conv2 needs backward computation.
I0114 16:11:16.099112 24909 net.cpp:198] binactive1 needs backward computation.
I0114 16:11:16.099117 24909 net.cpp:198] scale2 needs backward computation.
I0114 16:11:16.099123 24909 net.cpp:198] bn2 needs backward computation.
I0114 16:11:16.099128 24909 net.cpp:198] pool1 needs backward computation.
I0114 16:11:16.099135 24909 net.cpp:198] relu1 needs backward computation.
I0114 16:11:16.099141 24909 net.cpp:198] scale1 needs backward computation.
I0114 16:11:16.099148 24909 net.cpp:198] bn1 needs backward computation.
I0114 16:11:16.099156 24909 net.cpp:198] conv1 needs backward computation.
I0114 16:11:16.099167 24909 net.cpp:200] label_data_1_split does not need backward computation.
I0114 16:11:16.099174 24909 net.cpp:200] data does not need backward computation.
I0114 16:11:16.099179 24909 net.cpp:242] This network produces output accuracy
I0114 16:11:16.099187 24909 net.cpp:242] This network produces output accuracy_5
I0114 16:11:16.099195 24909 net.cpp:242] This network produces output loss
I0114 16:11:16.099248 24909 net.cpp:255] Network initialization done.
I0114 16:11:16.099457 24909 solver.cpp:57] Solver scaffolding done.
I0114 16:11:16.102579 24909 caffe.cpp:235] Resuming from snapshot/solver_iter_110000.solverstate
