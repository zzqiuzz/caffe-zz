I0114 16:10:54.156352 24796 upgrade_proto.cpp:1113] snapshot_prefix was a directory and is replaced to snapshot_adam/solver_adam
I0114 16:10:54.158641 24796 caffe.cpp:204] Using GPUs 3
I0114 16:10:54.860126 24796 caffe.cpp:209] GPU 3: GeForce GTX 1080 Ti
I0114 16:10:56.077253 24796 solver.cpp:45] Initializing solver from parameters: 
test_iter: 1000
test_interval: 1000
display: 200
max_iter: 500000
lr_policy: "modified_lr"
momentum: 0.9
snapshot: 10000
snapshot_prefix: "snapshot_adam/solver_adam"
solver_mode: GPU
device_id: 3
net: "train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
momentum2: 0.999
type: "Adam"
modified_lr {
  stepvalue: 120000
  stepvalue: 260000
  stepvalue: 370000
  stepvalue: 500000
  mlr: 0.001
  mlr: 0.0001
  mlr: 1e-05
  mlr: 1e-06
  weight_decay: 0
  weight_decay: 0
  weight_decay: 0
  weight_decay: 0
}
I0114 16:10:56.080986 24796 solver.cpp:105] Creating training net from net file: train_test.prototxt
I0114 16:10:56.082809 24796 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0114 16:10:56.083243 24796 net.cpp:51] Initializing net from parameters: 
name: "AlexNet-BN"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/zhengzhe/Data/imagenet_shrt256/ilsvrc12_train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 96
    bias_term: false
    pad: 2
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "pool1"
  top: "pool1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive1"
  type: "BinActive"
  bottom: "pool1"
  top: "binactive1"
}
layer {
  name: "conv2"
  type: "BinaryConvolution"
  bottom: "binactive1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "pool2"
  top: "pool2"
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "pool2"
  top: "pool2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive2"
  type: "BinActive"
  bottom: "pool2"
  top: "binactive2"
}
layer {
  name: "conv3"
  type: "BinaryConvolution"
  bottom: "binactive2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive3"
  type: "BinActive"
  bottom: "conv3"
  top: "binactive3"
}
layer {
  name: "conv4"
  type: "BinaryConvolution"
  bottom: "binactive3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "scale5"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive4"
  type: "BinActive"
  bottom: "conv4"
  top: "binactive4"
}
layer {
  name: "conv5"
  type: "BinaryConvolution"
  bottom: "binactive4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "bn6"
  type: "BatchNorm"
  bottom: "pool5"
  top: "pool5"
}
layer {
  name: "scale6"
  type: "Scale"
  bottom: "pool5"
  top: "pool5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive5"
  type: "BinActive"
  bottom: "pool5"
  top: "binactive5"
}
layer {
  name: "fc6"
  type: "BinaryInnerProduct"
  bottom: "binactive5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4096
    bias_term: false
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "scale7"
  type: "Scale"
  bottom: "fc6"
  top: "fc6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive6"
  type: "BinActive"
  bottom: "fc6"
  top: "binactive6"
}
layer {
  name: "fc7"
  type: "BinaryInnerProduct"
  bottom: "binactive6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4096
    bias_term: false
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn8"
  type: "BatchNorm"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "scale8"
  type: "Scale"
  bottom: "fc7"
  top: "fc7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "accuracy_5"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy_5"
  accuracy_param {
    top_k: 5
  }
}
I0114 16:10:56.086454 24796 layer_factory.hpp:78] Creating layer data
I0114 16:10:56.086812 24796 db_lmdb.cpp:35] Opened lmdb /home/zhengzhe/Data/imagenet_shrt256/ilsvrc12_train_lmdb
I0114 16:10:56.086982 24796 net.cpp:84] Creating Layer data
I0114 16:10:56.087070 24796 net.cpp:380] data -> data
I0114 16:10:56.087337 24796 net.cpp:380] data -> label
I0114 16:10:56.090569 24796 data_layer.cpp:45] output data size: 256,3,224,224
I0114 16:10:56.798517 24796 base_data_layer.cpp:72] Initializing prefetch
I0114 16:10:56.800174 24796 base_data_layer.cpp:75] Prefetch initialized.
I0114 16:10:56.802757 24796 net.cpp:122] Setting up data
I0114 16:10:56.802870 24796 net.cpp:129] Top shape: 256 3 224 224 (38535168)
I0114 16:10:56.803016 24796 net.cpp:129] Top shape: 256 (256)
I0114 16:10:56.803077 24796 net.cpp:137] Memory required for data: 154141696
I0114 16:10:56.803185 24796 layer_factory.hpp:78] Creating layer label_data_1_split
I0114 16:10:56.803433 24796 net.cpp:84] Creating Layer label_data_1_split
I0114 16:10:56.803767 24796 net.cpp:406] label_data_1_split <- label
I0114 16:10:56.803942 24796 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0114 16:10:56.804211 24796 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0114 16:10:56.804395 24796 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0114 16:10:56.804678 24796 net.cpp:122] Setting up label_data_1_split
I0114 16:10:56.804997 24796 net.cpp:129] Top shape: 256 (256)
I0114 16:10:56.805073 24796 net.cpp:129] Top shape: 256 (256)
I0114 16:10:56.805145 24796 net.cpp:129] Top shape: 256 (256)
I0114 16:10:56.805192 24796 net.cpp:137] Memory required for data: 154144768
I0114 16:10:56.805233 24796 layer_factory.hpp:78] Creating layer conv1
I0114 16:10:56.805384 24796 net.cpp:84] Creating Layer conv1
I0114 16:10:56.805635 24796 net.cpp:406] conv1 <- data
I0114 16:10:56.805719 24796 net.cpp:380] conv1 -> conv1
I0114 16:10:58.581573 24796 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 127416
I0114 16:10:58.585331 24796 net.cpp:122] Setting up conv1
I0114 16:10:58.585844 24796 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0114 16:10:58.585960 24796 net.cpp:137] Memory required for data: 451514368
I0114 16:10:58.586174 24796 layer_factory.hpp:78] Creating layer bn1
I0114 16:10:58.586467 24796 net.cpp:84] Creating Layer bn1
I0114 16:10:58.586627 24796 net.cpp:406] bn1 <- conv1
I0114 16:10:58.586774 24796 net.cpp:367] bn1 -> conv1 (in-place)
I0114 16:10:58.588997 24796 net.cpp:122] Setting up bn1
I0114 16:10:58.591202 24796 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0114 16:10:58.591311 24796 net.cpp:137] Memory required for data: 748883968
I0114 16:10:58.591501 24796 layer_factory.hpp:78] Creating layer scale1
I0114 16:10:58.591753 24796 net.cpp:84] Creating Layer scale1
I0114 16:10:58.591917 24796 net.cpp:406] scale1 <- conv1
I0114 16:10:58.592043 24796 net.cpp:367] scale1 -> conv1 (in-place)
I0114 16:10:58.592355 24796 layer_factory.hpp:78] Creating layer scale1
I0114 16:10:58.593003 24796 net.cpp:122] Setting up scale1
I0114 16:10:58.593487 24796 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0114 16:10:58.593587 24796 net.cpp:137] Memory required for data: 1046253568
I0114 16:10:58.593736 24796 layer_factory.hpp:78] Creating layer relu1
I0114 16:10:58.593907 24796 net.cpp:84] Creating Layer relu1
I0114 16:10:58.594059 24796 net.cpp:406] relu1 <- conv1
I0114 16:10:58.594175 24796 net.cpp:367] relu1 -> conv1 (in-place)
I0114 16:10:58.595131 24796 net.cpp:122] Setting up relu1
I0114 16:10:58.596077 24796 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I0114 16:10:58.596182 24796 net.cpp:137] Memory required for data: 1343623168
I0114 16:10:58.596282 24796 layer_factory.hpp:78] Creating layer pool1
I0114 16:10:58.596446 24796 net.cpp:84] Creating Layer pool1
I0114 16:10:58.596585 24796 net.cpp:406] pool1 <- conv1
I0114 16:10:58.596717 24796 net.cpp:380] pool1 -> pool1
I0114 16:10:58.596990 24796 net.cpp:122] Setting up pool1
I0114 16:10:58.597256 24796 net.cpp:129] Top shape: 256 96 27 27 (17915904)
I0114 16:10:58.597367 24796 net.cpp:137] Memory required for data: 1415286784
I0114 16:10:58.597483 24796 layer_factory.hpp:78] Creating layer bn2
I0114 16:10:58.597595 24796 net.cpp:84] Creating Layer bn2
I0114 16:10:58.597707 24796 net.cpp:406] bn2 <- pool1
I0114 16:10:58.597820 24796 net.cpp:367] bn2 -> pool1 (in-place)
I0114 16:10:58.601702 24796 net.cpp:122] Setting up bn2
I0114 16:10:58.602268 24796 net.cpp:129] Top shape: 256 96 27 27 (17915904)
I0114 16:10:58.602365 24796 net.cpp:137] Memory required for data: 1486950400
I0114 16:10:58.602499 24796 layer_factory.hpp:78] Creating layer scale2
I0114 16:10:58.602644 24796 net.cpp:84] Creating Layer scale2
I0114 16:10:58.602759 24796 net.cpp:406] scale2 <- pool1
I0114 16:10:58.602875 24796 net.cpp:367] scale2 -> pool1 (in-place)
I0114 16:10:58.603086 24796 layer_factory.hpp:78] Creating layer scale2
I0114 16:10:58.603540 24796 net.cpp:122] Setting up scale2
I0114 16:10:58.603894 24796 net.cpp:129] Top shape: 256 96 27 27 (17915904)
I0114 16:10:58.603982 24796 net.cpp:137] Memory required for data: 1558614016
I0114 16:10:58.604090 24796 layer_factory.hpp:78] Creating layer binactive1
I0114 16:10:58.604216 24796 net.cpp:84] Creating Layer binactive1
I0114 16:10:58.604351 24796 net.cpp:406] binactive1 <- pool1
I0114 16:10:58.604463 24796 net.cpp:380] binactive1 -> binactive1
I0114 16:10:58.604678 24796 net.cpp:122] Setting up binactive1
I0114 16:10:58.604849 24796 net.cpp:129] Top shape: 256 96 27 27 (17915904)
I0114 16:10:58.604934 24796 net.cpp:137] Memory required for data: 1630277632
I0114 16:10:58.604976 24796 layer_factory.hpp:78] Creating layer conv2
I0114 16:10:58.605170 24796 net.cpp:84] Creating Layer conv2
I0114 16:10:58.605314 24796 net.cpp:406] conv2 <- binactive1
I0114 16:10:58.605434 24796 net.cpp:380] conv2 -> conv2
I0114 16:10:58.693751 24796 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 19668
I0114 16:10:58.693804 24796 net.cpp:122] Setting up conv2
I0114 16:10:58.693825 24796 net.cpp:129] Top shape: 256 256 27 27 (47775744)
I0114 16:10:58.693831 24796 net.cpp:137] Memory required for data: 1821380608
I0114 16:10:58.693864 24796 layer_factory.hpp:78] Creating layer pool2
I0114 16:10:58.693912 24796 net.cpp:84] Creating Layer pool2
I0114 16:10:58.693928 24796 net.cpp:406] pool2 <- conv2
I0114 16:10:58.693958 24796 net.cpp:380] pool2 -> pool2
I0114 16:10:58.694039 24796 net.cpp:122] Setting up pool2
I0114 16:10:58.694052 24796 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0114 16:10:58.694056 24796 net.cpp:137] Memory required for data: 1865682944
I0114 16:10:58.694062 24796 layer_factory.hpp:78] Creating layer bn3
I0114 16:10:58.694077 24796 net.cpp:84] Creating Layer bn3
I0114 16:10:58.694085 24796 net.cpp:406] bn3 <- pool2
I0114 16:10:58.694099 24796 net.cpp:367] bn3 -> pool2 (in-place)
I0114 16:10:58.694317 24796 net.cpp:122] Setting up bn3
I0114 16:10:58.694327 24796 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0114 16:10:58.694332 24796 net.cpp:137] Memory required for data: 1909985280
I0114 16:10:58.694356 24796 layer_factory.hpp:78] Creating layer scale3
I0114 16:10:58.694383 24796 net.cpp:84] Creating Layer scale3
I0114 16:10:58.694392 24796 net.cpp:406] scale3 <- pool2
I0114 16:10:58.694407 24796 net.cpp:367] scale3 -> pool2 (in-place)
I0114 16:10:58.694506 24796 layer_factory.hpp:78] Creating layer scale3
I0114 16:10:58.694694 24796 net.cpp:122] Setting up scale3
I0114 16:10:58.694706 24796 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0114 16:10:58.694711 24796 net.cpp:137] Memory required for data: 1954287616
I0114 16:10:58.694739 24796 layer_factory.hpp:78] Creating layer binactive2
I0114 16:10:58.694756 24796 net.cpp:84] Creating Layer binactive2
I0114 16:10:58.694763 24796 net.cpp:406] binactive2 <- pool2
I0114 16:10:58.694778 24796 net.cpp:380] binactive2 -> binactive2
I0114 16:10:58.694828 24796 net.cpp:122] Setting up binactive2
I0114 16:10:58.694841 24796 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0114 16:10:58.694846 24796 net.cpp:137] Memory required for data: 1998589952
I0114 16:10:58.694854 24796 layer_factory.hpp:78] Creating layer conv3
I0114 16:10:58.694886 24796 net.cpp:84] Creating Layer conv3
I0114 16:10:58.694895 24796 net.cpp:406] conv3 <- binactive2
I0114 16:10:58.694914 24796 net.cpp:380] conv3 -> conv3
I0114 16:10:58.806207 24796 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 18874368
I0114 16:10:58.806911 24796 net.cpp:122] Setting up conv3
I0114 16:10:58.807044 24796 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0114 16:10:58.807144 24796 net.cpp:137] Memory required for data: 2065043456
I0114 16:10:58.807309 24796 layer_factory.hpp:78] Creating layer bn4
I0114 16:10:58.807482 24796 net.cpp:84] Creating Layer bn4
I0114 16:10:58.807593 24796 net.cpp:406] bn4 <- conv3
I0114 16:10:58.807730 24796 net.cpp:367] bn4 -> conv3 (in-place)
I0114 16:10:58.808187 24796 net.cpp:122] Setting up bn4
I0114 16:10:58.808295 24796 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0114 16:10:58.808390 24796 net.cpp:137] Memory required for data: 2131496960
I0114 16:10:58.808521 24796 layer_factory.hpp:78] Creating layer scale4
I0114 16:10:58.808642 24796 net.cpp:84] Creating Layer scale4
I0114 16:10:58.808753 24796 net.cpp:406] scale4 <- conv3
I0114 16:10:58.808861 24796 net.cpp:367] scale4 -> conv3 (in-place)
I0114 16:10:58.809082 24796 layer_factory.hpp:78] Creating layer scale4
I0114 16:10:58.809468 24796 net.cpp:122] Setting up scale4
I0114 16:10:58.809577 24796 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0114 16:10:58.809669 24796 net.cpp:137] Memory required for data: 2197950464
I0114 16:10:58.809795 24796 layer_factory.hpp:78] Creating layer binactive3
I0114 16:10:58.809907 24796 net.cpp:84] Creating Layer binactive3
I0114 16:10:58.810015 24796 net.cpp:406] binactive3 <- conv3
I0114 16:10:58.810128 24796 net.cpp:380] binactive3 -> binactive3
I0114 16:10:58.810293 24796 net.cpp:122] Setting up binactive3
I0114 16:10:58.810405 24796 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0114 16:10:58.810508 24796 net.cpp:137] Memory required for data: 2264403968
I0114 16:10:58.810605 24796 layer_factory.hpp:78] Creating layer conv4
I0114 16:10:58.810748 24796 net.cpp:84] Creating Layer conv4
I0114 16:10:58.810847 24796 net.cpp:406] conv4 <- binactive3
I0114 16:10:58.810974 24796 net.cpp:380] conv4 -> conv4
I0114 16:10:58.982537 24796 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 9840
I0114 16:10:58.982787 24796 net.cpp:122] Setting up conv4
I0114 16:10:58.982899 24796 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0114 16:10:58.983022 24796 net.cpp:137] Memory required for data: 2330857472
I0114 16:10:58.983144 24796 layer_factory.hpp:78] Creating layer bn5
I0114 16:10:58.983281 24796 net.cpp:84] Creating Layer bn5
I0114 16:10:58.983389 24796 net.cpp:406] bn5 <- conv4
I0114 16:10:58.983507 24796 net.cpp:367] bn5 -> conv4 (in-place)
I0114 16:10:58.983958 24796 net.cpp:122] Setting up bn5
I0114 16:10:58.984064 24796 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0114 16:10:58.984158 24796 net.cpp:137] Memory required for data: 2397310976
I0114 16:10:58.984287 24796 layer_factory.hpp:78] Creating layer scale5
I0114 16:10:58.984413 24796 net.cpp:84] Creating Layer scale5
I0114 16:10:58.984524 24796 net.cpp:406] scale5 <- conv4
I0114 16:10:58.984637 24796 net.cpp:367] scale5 -> conv4 (in-place)
I0114 16:10:58.984834 24796 layer_factory.hpp:78] Creating layer scale5
I0114 16:10:58.985193 24796 net.cpp:122] Setting up scale5
I0114 16:10:58.985301 24796 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0114 16:10:58.985397 24796 net.cpp:137] Memory required for data: 2463764480
I0114 16:10:58.985519 24796 layer_factory.hpp:78] Creating layer binactive4
I0114 16:10:58.985628 24796 net.cpp:84] Creating Layer binactive4
I0114 16:10:58.985735 24796 net.cpp:406] binactive4 <- conv4
I0114 16:10:58.985846 24796 net.cpp:380] binactive4 -> binactive4
I0114 16:10:58.986006 24796 net.cpp:122] Setting up binactive4
I0114 16:10:58.986112 24796 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I0114 16:10:58.986213 24796 net.cpp:137] Memory required for data: 2530217984
I0114 16:10:58.986313 24796 layer_factory.hpp:78] Creating layer conv5
I0114 16:10:58.986461 24796 net.cpp:84] Creating Layer conv5
I0114 16:10:58.986558 24796 net.cpp:406] conv5 <- binactive4
I0114 16:10:58.986687 24796 net.cpp:380] conv5 -> conv5
I0114 16:10:59.101150 24796 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 18874368
I0114 16:10:59.102078 24796 net.cpp:122] Setting up conv5
I0114 16:10:59.102396 24796 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I0114 16:10:59.102504 24796 net.cpp:137] Memory required for data: 2574520320
I0114 16:10:59.102687 24796 layer_factory.hpp:78] Creating layer pool5
I0114 16:10:59.102866 24796 net.cpp:84] Creating Layer pool5
I0114 16:10:59.102977 24796 net.cpp:406] pool5 <- conv5
I0114 16:10:59.103189 24796 net.cpp:380] pool5 -> pool5
I0114 16:10:59.103463 24796 net.cpp:122] Setting up pool5
I0114 16:10:59.103493 24796 net.cpp:129] Top shape: 256 256 6 6 (2359296)
I0114 16:10:59.103502 24796 net.cpp:137] Memory required for data: 2583957504
I0114 16:10:59.103513 24796 layer_factory.hpp:78] Creating layer bn6
I0114 16:10:59.103549 24796 net.cpp:84] Creating Layer bn6
I0114 16:10:59.103559 24796 net.cpp:406] bn6 <- pool5
I0114 16:10:59.103579 24796 net.cpp:367] bn6 -> pool5 (in-place)
I0114 16:10:59.103927 24796 net.cpp:122] Setting up bn6
I0114 16:10:59.103943 24796 net.cpp:129] Top shape: 256 256 6 6 (2359296)
I0114 16:10:59.103977 24796 net.cpp:137] Memory required for data: 2593394688
I0114 16:10:59.104043 24796 layer_factory.hpp:78] Creating layer scale6
I0114 16:10:59.104079 24796 net.cpp:84] Creating Layer scale6
I0114 16:10:59.104089 24796 net.cpp:406] scale6 <- pool5
I0114 16:10:59.104110 24796 net.cpp:367] scale6 -> pool5 (in-place)
I0114 16:10:59.104205 24796 layer_factory.hpp:78] Creating layer scale6
I0114 16:10:59.104445 24796 net.cpp:122] Setting up scale6
I0114 16:10:59.104460 24796 net.cpp:129] Top shape: 256 256 6 6 (2359296)
I0114 16:10:59.104466 24796 net.cpp:137] Memory required for data: 2602831872
I0114 16:10:59.104490 24796 layer_factory.hpp:78] Creating layer binactive5
I0114 16:10:59.104508 24796 net.cpp:84] Creating Layer binactive5
I0114 16:10:59.104517 24796 net.cpp:406] binactive5 <- pool5
I0114 16:10:59.104538 24796 net.cpp:380] binactive5 -> binactive5
I0114 16:10:59.104585 24796 net.cpp:122] Setting up binactive5
I0114 16:10:59.104600 24796 net.cpp:129] Top shape: 256 256 6 6 (2359296)
I0114 16:10:59.104605 24796 net.cpp:137] Memory required for data: 2612269056
I0114 16:10:59.104614 24796 layer_factory.hpp:78] Creating layer fc6
I0114 16:10:59.104657 24796 net.cpp:84] Creating Layer fc6
I0114 16:10:59.104667 24796 net.cpp:406] fc6 <- binactive5
I0114 16:10:59.104692 24796 net.cpp:380] fc6 -> fc6
I0114 16:11:04.878428 24796 net.cpp:122] Setting up fc6
I0114 16:11:04.878490 24796 net.cpp:129] Top shape: 256 4096 (1048576)
I0114 16:11:04.878495 24796 net.cpp:137] Memory required for data: 2616463360
I0114 16:11:04.878540 24796 layer_factory.hpp:78] Creating layer bn7
I0114 16:11:04.878587 24796 net.cpp:84] Creating Layer bn7
I0114 16:11:04.878607 24796 net.cpp:406] bn7 <- fc6
I0114 16:11:04.878635 24796 net.cpp:367] bn7 -> fc6 (in-place)
I0114 16:11:04.878898 24796 net.cpp:122] Setting up bn7
I0114 16:11:04.878909 24796 net.cpp:129] Top shape: 256 4096 (1048576)
I0114 16:11:04.878913 24796 net.cpp:137] Memory required for data: 2620657664
I0114 16:11:04.878934 24796 layer_factory.hpp:78] Creating layer scale7
I0114 16:11:04.878960 24796 net.cpp:84] Creating Layer scale7
I0114 16:11:04.878968 24796 net.cpp:406] scale7 <- fc6
I0114 16:11:04.878983 24796 net.cpp:367] scale7 -> fc6 (in-place)
I0114 16:11:04.879062 24796 layer_factory.hpp:78] Creating layer scale7
I0114 16:11:04.879249 24796 net.cpp:122] Setting up scale7
I0114 16:11:04.879261 24796 net.cpp:129] Top shape: 256 4096 (1048576)
I0114 16:11:04.879266 24796 net.cpp:137] Memory required for data: 2624851968
I0114 16:11:04.879279 24796 layer_factory.hpp:78] Creating layer binactive6
I0114 16:11:04.879295 24796 net.cpp:84] Creating Layer binactive6
I0114 16:11:04.879303 24796 net.cpp:406] binactive6 <- fc6
I0114 16:11:04.879320 24796 net.cpp:380] binactive6 -> binactive6
I0114 16:11:04.879366 24796 net.cpp:122] Setting up binactive6
I0114 16:11:04.879379 24796 net.cpp:129] Top shape: 256 4096 (1048576)
I0114 16:11:04.879382 24796 net.cpp:137] Memory required for data: 2629046272
I0114 16:11:04.879387 24796 layer_factory.hpp:78] Creating layer fc7
I0114 16:11:04.879422 24796 net.cpp:84] Creating Layer fc7
I0114 16:11:04.879431 24796 net.cpp:406] fc7 <- binactive6
I0114 16:11:04.879451 24796 net.cpp:380] fc7 -> fc7
I0114 16:11:07.889689 24796 net.cpp:122] Setting up fc7
I0114 16:11:07.889804 24796 net.cpp:129] Top shape: 256 4096 (1048576)
I0114 16:11:07.889812 24796 net.cpp:137] Memory required for data: 2633240576
I0114 16:11:07.889884 24796 layer_factory.hpp:78] Creating layer bn8
I0114 16:11:07.889962 24796 net.cpp:84] Creating Layer bn8
I0114 16:11:07.890008 24796 net.cpp:406] bn8 <- fc7
I0114 16:11:07.890045 24796 net.cpp:367] bn8 -> fc7 (in-place)
I0114 16:11:07.890410 24796 net.cpp:122] Setting up bn8
I0114 16:11:07.890426 24796 net.cpp:129] Top shape: 256 4096 (1048576)
I0114 16:11:07.890431 24796 net.cpp:137] Memory required for data: 2637434880
I0114 16:11:07.890461 24796 layer_factory.hpp:78] Creating layer scale8
I0114 16:11:07.890501 24796 net.cpp:84] Creating Layer scale8
I0114 16:11:07.890512 24796 net.cpp:406] scale8 <- fc7
I0114 16:11:07.890566 24796 net.cpp:367] scale8 -> fc7 (in-place)
I0114 16:11:07.890679 24796 layer_factory.hpp:78] Creating layer scale8
I0114 16:11:07.890936 24796 net.cpp:122] Setting up scale8
I0114 16:11:07.890954 24796 net.cpp:129] Top shape: 256 4096 (1048576)
I0114 16:11:07.890960 24796 net.cpp:137] Memory required for data: 2641629184
I0114 16:11:07.890980 24796 layer_factory.hpp:78] Creating layer relu7
I0114 16:11:07.891000 24796 net.cpp:84] Creating Layer relu7
I0114 16:11:07.891010 24796 net.cpp:406] relu7 <- fc7
I0114 16:11:07.891029 24796 net.cpp:367] relu7 -> fc7 (in-place)
I0114 16:11:07.893020 24796 net.cpp:122] Setting up relu7
I0114 16:11:07.893040 24796 net.cpp:129] Top shape: 256 4096 (1048576)
I0114 16:11:07.893046 24796 net.cpp:137] Memory required for data: 2645823488
I0114 16:11:07.893056 24796 layer_factory.hpp:78] Creating layer fc8
I0114 16:11:07.893110 24796 net.cpp:84] Creating Layer fc8
I0114 16:11:07.893122 24796 net.cpp:406] fc8 <- fc7
I0114 16:11:07.893152 24796 net.cpp:380] fc8 -> fc8
I0114 16:11:08.521039 24796 net.cpp:122] Setting up fc8
I0114 16:11:08.521108 24796 net.cpp:129] Top shape: 256 1000 (256000)
I0114 16:11:08.521114 24796 net.cpp:137] Memory required for data: 2646847488
I0114 16:11:08.521159 24796 layer_factory.hpp:78] Creating layer fc8_fc8_0_split
I0114 16:11:08.521203 24796 net.cpp:84] Creating Layer fc8_fc8_0_split
I0114 16:11:08.521219 24796 net.cpp:406] fc8_fc8_0_split <- fc8
I0114 16:11:08.521246 24796 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0114 16:11:08.521277 24796 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0114 16:11:08.521296 24796 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0114 16:11:08.521379 24796 net.cpp:122] Setting up fc8_fc8_0_split
I0114 16:11:08.521392 24796 net.cpp:129] Top shape: 256 1000 (256000)
I0114 16:11:08.521399 24796 net.cpp:129] Top shape: 256 1000 (256000)
I0114 16:11:08.521404 24796 net.cpp:129] Top shape: 256 1000 (256000)
I0114 16:11:08.521406 24796 net.cpp:137] Memory required for data: 2649919488
I0114 16:11:08.521412 24796 layer_factory.hpp:78] Creating layer loss
I0114 16:11:08.521443 24796 net.cpp:84] Creating Layer loss
I0114 16:11:08.521452 24796 net.cpp:406] loss <- fc8_fc8_0_split_0
I0114 16:11:08.521466 24796 net.cpp:406] loss <- label_data_1_split_0
I0114 16:11:08.521479 24796 net.cpp:380] loss -> loss
I0114 16:11:08.521512 24796 layer_factory.hpp:78] Creating layer loss
I0114 16:11:08.524647 24796 net.cpp:122] Setting up loss
I0114 16:11:08.524668 24796 net.cpp:129] Top shape: (1)
I0114 16:11:08.524672 24796 net.cpp:132]     with loss weight 1
I0114 16:11:08.524735 24796 net.cpp:137] Memory required for data: 2649919492
I0114 16:11:08.524750 24796 layer_factory.hpp:78] Creating layer accuracy
I0114 16:11:08.524780 24796 net.cpp:84] Creating Layer accuracy
I0114 16:11:08.524788 24796 net.cpp:406] accuracy <- fc8_fc8_0_split_1
I0114 16:11:08.524803 24796 net.cpp:406] accuracy <- label_data_1_split_1
I0114 16:11:08.524817 24796 net.cpp:380] accuracy -> accuracy
I0114 16:11:08.524849 24796 net.cpp:122] Setting up accuracy
I0114 16:11:08.524860 24796 net.cpp:129] Top shape: (1)
I0114 16:11:08.524863 24796 net.cpp:137] Memory required for data: 2649919496
I0114 16:11:08.524869 24796 layer_factory.hpp:78] Creating layer accuracy_5
I0114 16:11:08.524886 24796 net.cpp:84] Creating Layer accuracy_5
I0114 16:11:08.524894 24796 net.cpp:406] accuracy_5 <- fc8_fc8_0_split_2
I0114 16:11:08.524906 24796 net.cpp:406] accuracy_5 <- label_data_1_split_2
I0114 16:11:08.524917 24796 net.cpp:380] accuracy_5 -> accuracy_5
I0114 16:11:08.524941 24796 net.cpp:122] Setting up accuracy_5
I0114 16:11:08.524951 24796 net.cpp:129] Top shape: (1)
I0114 16:11:08.524955 24796 net.cpp:137] Memory required for data: 2649919500
I0114 16:11:08.524963 24796 net.cpp:200] accuracy_5 does not need backward computation.
I0114 16:11:08.524969 24796 net.cpp:200] accuracy does not need backward computation.
I0114 16:11:08.524974 24796 net.cpp:198] loss needs backward computation.
I0114 16:11:08.524979 24796 net.cpp:198] fc8_fc8_0_split needs backward computation.
I0114 16:11:08.525010 24796 net.cpp:198] fc8 needs backward computation.
I0114 16:11:08.525017 24796 net.cpp:198] relu7 needs backward computation.
I0114 16:11:08.525024 24796 net.cpp:198] scale8 needs backward computation.
I0114 16:11:08.525028 24796 net.cpp:198] bn8 needs backward computation.
I0114 16:11:08.525032 24796 net.cpp:198] fc7 needs backward computation.
I0114 16:11:08.525038 24796 net.cpp:198] binactive6 needs backward computation.
I0114 16:11:08.525043 24796 net.cpp:198] scale7 needs backward computation.
I0114 16:11:08.525048 24796 net.cpp:198] bn7 needs backward computation.
I0114 16:11:08.525051 24796 net.cpp:198] fc6 needs backward computation.
I0114 16:11:08.525058 24796 net.cpp:198] binactive5 needs backward computation.
I0114 16:11:08.525064 24796 net.cpp:198] scale6 needs backward computation.
I0114 16:11:08.525070 24796 net.cpp:198] bn6 needs backward computation.
I0114 16:11:08.525074 24796 net.cpp:198] pool5 needs backward computation.
I0114 16:11:08.525079 24796 net.cpp:198] conv5 needs backward computation.
I0114 16:11:08.525084 24796 net.cpp:198] binactive4 needs backward computation.
I0114 16:11:08.525089 24796 net.cpp:198] scale5 needs backward computation.
I0114 16:11:08.525092 24796 net.cpp:198] bn5 needs backward computation.
I0114 16:11:08.525096 24796 net.cpp:198] conv4 needs backward computation.
I0114 16:11:08.525104 24796 net.cpp:198] binactive3 needs backward computation.
I0114 16:11:08.525110 24796 net.cpp:198] scale4 needs backward computation.
I0114 16:11:08.525113 24796 net.cpp:198] bn4 needs backward computation.
I0114 16:11:08.525118 24796 net.cpp:198] conv3 needs backward computation.
I0114 16:11:08.525122 24796 net.cpp:198] binactive2 needs backward computation.
I0114 16:11:08.525130 24796 net.cpp:198] scale3 needs backward computation.
I0114 16:11:08.525135 24796 net.cpp:198] bn3 needs backward computation.
I0114 16:11:08.525140 24796 net.cpp:198] pool2 needs backward computation.
I0114 16:11:08.525146 24796 net.cpp:198] conv2 needs backward computation.
I0114 16:11:08.525149 24796 net.cpp:198] binactive1 needs backward computation.
I0114 16:11:08.525154 24796 net.cpp:198] scale2 needs backward computation.
I0114 16:11:08.525161 24796 net.cpp:198] bn2 needs backward computation.
I0114 16:11:08.525171 24796 net.cpp:198] pool1 needs backward computation.
I0114 16:11:08.525177 24796 net.cpp:198] relu1 needs backward computation.
I0114 16:11:08.525182 24796 net.cpp:198] scale1 needs backward computation.
I0114 16:11:08.525189 24796 net.cpp:198] bn1 needs backward computation.
I0114 16:11:08.525194 24796 net.cpp:198] conv1 needs backward computation.
I0114 16:11:08.525203 24796 net.cpp:200] label_data_1_split does not need backward computation.
I0114 16:11:08.525211 24796 net.cpp:200] data does not need backward computation.
I0114 16:11:08.525224 24796 net.cpp:242] This network produces output accuracy
I0114 16:11:08.525234 24796 net.cpp:242] This network produces output accuracy_5
I0114 16:11:08.525239 24796 net.cpp:242] This network produces output loss
I0114 16:11:08.525303 24796 net.cpp:255] Network initialization done.
I0114 16:11:08.526252 24796 solver.cpp:193] Creating test net (#0) specified by net file: train_test.prototxt
I0114 16:11:08.526382 24796 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0114 16:11:08.526612 24796 net.cpp:51] Initializing net from parameters: 
name: "AlexNet-BN"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 224
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/zhengzhe/Data/imagenet_shrt256/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 96
    bias_term: false
    pad: 2
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "pool1"
  top: "pool1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive1"
  type: "BinActive"
  bottom: "pool1"
  top: "binactive1"
}
layer {
  name: "conv2"
  type: "BinaryConvolution"
  bottom: "binactive1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "pool2"
  top: "pool2"
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "pool2"
  top: "pool2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive2"
  type: "BinActive"
  bottom: "pool2"
  top: "binactive2"
}
layer {
  name: "conv3"
  type: "BinaryConvolution"
  bottom: "binactive2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive3"
  type: "BinActive"
  bottom: "conv3"
  top: "binactive3"
}
layer {
  name: "conv4"
  type: "BinaryConvolution"
  bottom: "binactive3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "scale5"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive4"
  type: "BinActive"
  bottom: "conv4"
  top: "binactive4"
}
layer {
  name: "conv5"
  type: "BinaryConvolution"
  bottom: "binactive4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "bn6"
  type: "BatchNorm"
  bottom: "pool5"
  top: "pool5"
}
layer {
  name: "scale6"
  type: "Scale"
  bottom: "pool5"
  top: "pool5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive5"
  type: "BinActive"
  bottom: "pool5"
  top: "binactive5"
}
layer {
  name: "fc6"
  type: "BinaryInnerProduct"
  bottom: "binactive5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4096
    bias_term: false
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "scale7"
  type: "Scale"
  bottom: "fc6"
  top: "fc6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "binactive6"
  type: "BinActive"
  bottom: "fc6"
  top: "binactive6"
}
layer {
  name: "fc7"
  type: "BinaryInnerProduct"
  bottom: "binactive6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4096
    bias_term: false
    weight_filler {
      type: "msra"
    }
  }
  debug_param {
    xnorno_grad: true
  }
}
layer {
  name: "bn8"
  type: "BatchNorm"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "scale8"
  type: "Scale"
  bottom: "fc7"
  top: "fc7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "accuracy_5"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy_5"
  accuracy_param {
    top_k: 5
  }
}
I0114 16:11:08.526999 24796 layer_factory.hpp:78] Creating layer data
I0114 16:11:08.527102 24796 db_lmdb.cpp:35] Opened lmdb /home/zhengzhe/Data/imagenet_shrt256/ilsvrc12_val_lmdb
I0114 16:11:08.527139 24796 net.cpp:84] Creating Layer data
I0114 16:11:08.527155 24796 net.cpp:380] data -> data
I0114 16:11:08.527189 24796 net.cpp:380] data -> label
I0114 16:11:08.527848 24796 data_layer.cpp:45] output data size: 50,3,224,224
I0114 16:11:08.614595 24796 base_data_layer.cpp:72] Initializing prefetch
I0114 16:11:08.976373 24796 base_data_layer.cpp:75] Prefetch initialized.
I0114 16:11:08.976431 24796 net.cpp:122] Setting up data
I0114 16:11:08.976486 24796 net.cpp:129] Top shape: 50 3 224 224 (7526400)
I0114 16:11:08.976495 24796 net.cpp:129] Top shape: 50 (50)
I0114 16:11:08.976498 24796 net.cpp:137] Memory required for data: 30105800
I0114 16:11:08.976531 24796 layer_factory.hpp:78] Creating layer label_data_1_split
I0114 16:11:08.976596 24796 net.cpp:84] Creating Layer label_data_1_split
I0114 16:11:08.976614 24796 net.cpp:406] label_data_1_split <- label
I0114 16:11:08.976650 24796 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0114 16:11:08.976699 24796 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0114 16:11:08.976716 24796 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0114 16:11:08.977177 24796 net.cpp:122] Setting up label_data_1_split
I0114 16:11:08.977192 24796 net.cpp:129] Top shape: 50 (50)
I0114 16:11:08.977198 24796 net.cpp:129] Top shape: 50 (50)
I0114 16:11:08.977203 24796 net.cpp:129] Top shape: 50 (50)
I0114 16:11:08.977206 24796 net.cpp:137] Memory required for data: 30106400
I0114 16:11:08.977212 24796 layer_factory.hpp:78] Creating layer conv1
I0114 16:11:08.977259 24796 net.cpp:84] Creating Layer conv1
I0114 16:11:08.977269 24796 net.cpp:406] conv1 <- data
I0114 16:11:08.977294 24796 net.cpp:380] conv1 -> conv1
I0114 16:11:08.985532 24796 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 127416
I0114 16:11:08.985589 24796 net.cpp:122] Setting up conv1
I0114 16:11:08.985604 24796 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0114 16:11:08.985607 24796 net.cpp:137] Memory required for data: 88186400
I0114 16:11:08.985643 24796 layer_factory.hpp:78] Creating layer bn1
I0114 16:11:08.985668 24796 net.cpp:84] Creating Layer bn1
I0114 16:11:08.985678 24796 net.cpp:406] bn1 <- conv1
I0114 16:11:08.985693 24796 net.cpp:367] bn1 -> conv1 (in-place)
I0114 16:11:08.986034 24796 net.cpp:122] Setting up bn1
I0114 16:11:08.986047 24796 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0114 16:11:08.986050 24796 net.cpp:137] Memory required for data: 146266400
I0114 16:11:08.986084 24796 layer_factory.hpp:78] Creating layer scale1
I0114 16:11:08.986129 24796 net.cpp:84] Creating Layer scale1
I0114 16:11:08.986138 24796 net.cpp:406] scale1 <- conv1
I0114 16:11:08.986155 24796 net.cpp:367] scale1 -> conv1 (in-place)
I0114 16:11:08.986237 24796 layer_factory.hpp:78] Creating layer scale1
I0114 16:11:08.986488 24796 net.cpp:122] Setting up scale1
I0114 16:11:08.986502 24796 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0114 16:11:08.986505 24796 net.cpp:137] Memory required for data: 204346400
I0114 16:11:08.986529 24796 layer_factory.hpp:78] Creating layer relu1
I0114 16:11:08.986551 24796 net.cpp:84] Creating Layer relu1
I0114 16:11:08.986557 24796 net.cpp:406] relu1 <- conv1
I0114 16:11:08.986574 24796 net.cpp:367] relu1 -> conv1 (in-place)
I0114 16:11:08.987182 24796 net.cpp:122] Setting up relu1
I0114 16:11:08.987195 24796 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0114 16:11:08.987200 24796 net.cpp:137] Memory required for data: 262426400
I0114 16:11:08.987205 24796 layer_factory.hpp:78] Creating layer pool1
I0114 16:11:08.987229 24796 net.cpp:84] Creating Layer pool1
I0114 16:11:08.987236 24796 net.cpp:406] pool1 <- conv1
I0114 16:11:08.987255 24796 net.cpp:380] pool1 -> pool1
I0114 16:11:08.987329 24796 net.cpp:122] Setting up pool1
I0114 16:11:08.987347 24796 net.cpp:129] Top shape: 50 96 27 27 (3499200)
I0114 16:11:08.987352 24796 net.cpp:137] Memory required for data: 276423200
I0114 16:11:08.987357 24796 layer_factory.hpp:78] Creating layer bn2
I0114 16:11:08.987377 24796 net.cpp:84] Creating Layer bn2
I0114 16:11:08.987385 24796 net.cpp:406] bn2 <- pool1
I0114 16:11:08.987398 24796 net.cpp:367] bn2 -> pool1 (in-place)
I0114 16:11:08.987660 24796 net.cpp:122] Setting up bn2
I0114 16:11:08.987671 24796 net.cpp:129] Top shape: 50 96 27 27 (3499200)
I0114 16:11:08.987676 24796 net.cpp:137] Memory required for data: 290420000
I0114 16:11:08.987710 24796 layer_factory.hpp:78] Creating layer scale2
I0114 16:11:08.987733 24796 net.cpp:84] Creating Layer scale2
I0114 16:11:08.987741 24796 net.cpp:406] scale2 <- pool1
I0114 16:11:08.987757 24796 net.cpp:367] scale2 -> pool1 (in-place)
I0114 16:11:08.987829 24796 layer_factory.hpp:78] Creating layer scale2
I0114 16:11:08.988031 24796 net.cpp:122] Setting up scale2
I0114 16:11:08.988044 24796 net.cpp:129] Top shape: 50 96 27 27 (3499200)
I0114 16:11:08.988047 24796 net.cpp:137] Memory required for data: 304416800
I0114 16:11:08.988062 24796 layer_factory.hpp:78] Creating layer binactive1
I0114 16:11:08.988080 24796 net.cpp:84] Creating Layer binactive1
I0114 16:11:08.988088 24796 net.cpp:406] binactive1 <- pool1
I0114 16:11:08.988103 24796 net.cpp:380] binactive1 -> binactive1
I0114 16:11:08.988145 24796 net.cpp:122] Setting up binactive1
I0114 16:11:08.988157 24796 net.cpp:129] Top shape: 50 96 27 27 (3499200)
I0114 16:11:08.988162 24796 net.cpp:137] Memory required for data: 318413600
I0114 16:11:08.988167 24796 layer_factory.hpp:78] Creating layer conv2
I0114 16:11:08.988195 24796 net.cpp:84] Creating Layer conv2
I0114 16:11:08.988204 24796 net.cpp:406] conv2 <- binactive1
I0114 16:11:08.988221 24796 net.cpp:380] conv2 -> conv2
I0114 16:11:09.048167 24796 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 19668
I0114 16:11:09.048200 24796 net.cpp:122] Setting up conv2
I0114 16:11:09.048213 24796 net.cpp:129] Top shape: 50 256 27 27 (9331200)
I0114 16:11:09.048215 24796 net.cpp:137] Memory required for data: 355738400
I0114 16:11:09.048229 24796 layer_factory.hpp:78] Creating layer pool2
I0114 16:11:09.048260 24796 net.cpp:84] Creating Layer pool2
I0114 16:11:09.048270 24796 net.cpp:406] pool2 <- conv2
I0114 16:11:09.048291 24796 net.cpp:380] pool2 -> pool2
I0114 16:11:09.048367 24796 net.cpp:122] Setting up pool2
I0114 16:11:09.048380 24796 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0114 16:11:09.048385 24796 net.cpp:137] Memory required for data: 364391200
I0114 16:11:09.048391 24796 layer_factory.hpp:78] Creating layer bn3
I0114 16:11:09.048408 24796 net.cpp:84] Creating Layer bn3
I0114 16:11:09.048415 24796 net.cpp:406] bn3 <- pool2
I0114 16:11:09.048429 24796 net.cpp:367] bn3 -> pool2 (in-place)
I0114 16:11:09.048727 24796 net.cpp:122] Setting up bn3
I0114 16:11:09.048741 24796 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0114 16:11:09.048746 24796 net.cpp:137] Memory required for data: 373044000
I0114 16:11:09.048789 24796 layer_factory.hpp:78] Creating layer scale3
I0114 16:11:09.048810 24796 net.cpp:84] Creating Layer scale3
I0114 16:11:09.048822 24796 net.cpp:406] scale3 <- pool2
I0114 16:11:09.048841 24796 net.cpp:367] scale3 -> pool2 (in-place)
I0114 16:11:09.048930 24796 layer_factory.hpp:78] Creating layer scale3
I0114 16:11:09.049109 24796 net.cpp:122] Setting up scale3
I0114 16:11:09.049125 24796 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0114 16:11:09.049130 24796 net.cpp:137] Memory required for data: 381696800
I0114 16:11:09.049156 24796 layer_factory.hpp:78] Creating layer binactive2
I0114 16:11:09.049173 24796 net.cpp:84] Creating Layer binactive2
I0114 16:11:09.049182 24796 net.cpp:406] binactive2 <- pool2
I0114 16:11:09.049197 24796 net.cpp:380] binactive2 -> binactive2
I0114 16:11:09.049249 24796 net.cpp:122] Setting up binactive2
I0114 16:11:09.049262 24796 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0114 16:11:09.049265 24796 net.cpp:137] Memory required for data: 390349600
I0114 16:11:09.049270 24796 layer_factory.hpp:78] Creating layer conv3
I0114 16:11:09.049299 24796 net.cpp:84] Creating Layer conv3
I0114 16:11:09.049309 24796 net.cpp:406] conv3 <- binactive2
I0114 16:11:09.049331 24796 net.cpp:380] conv3 -> conv3
I0114 16:11:09.132930 24796 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 18874368
I0114 16:11:09.133266 24796 net.cpp:122] Setting up conv3
I0114 16:11:09.133296 24796 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0114 16:11:09.133301 24796 net.cpp:137] Memory required for data: 403328800
I0114 16:11:09.133337 24796 layer_factory.hpp:78] Creating layer bn4
I0114 16:11:09.133392 24796 net.cpp:84] Creating Layer bn4
I0114 16:11:09.133406 24796 net.cpp:406] bn4 <- conv3
I0114 16:11:09.133436 24796 net.cpp:367] bn4 -> conv3 (in-place)
I0114 16:11:09.133714 24796 net.cpp:122] Setting up bn4
I0114 16:11:09.133725 24796 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0114 16:11:09.133729 24796 net.cpp:137] Memory required for data: 416308000
I0114 16:11:09.133751 24796 layer_factory.hpp:78] Creating layer scale4
I0114 16:11:09.133776 24796 net.cpp:84] Creating Layer scale4
I0114 16:11:09.133783 24796 net.cpp:406] scale4 <- conv3
I0114 16:11:09.133797 24796 net.cpp:367] scale4 -> conv3 (in-place)
I0114 16:11:09.133877 24796 layer_factory.hpp:78] Creating layer scale4
I0114 16:11:09.134063 24796 net.cpp:122] Setting up scale4
I0114 16:11:09.134076 24796 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0114 16:11:09.134079 24796 net.cpp:137] Memory required for data: 429287200
I0114 16:11:09.134095 24796 layer_factory.hpp:78] Creating layer binactive3
I0114 16:11:09.134110 24796 net.cpp:84] Creating Layer binactive3
I0114 16:11:09.134119 24796 net.cpp:406] binactive3 <- conv3
I0114 16:11:09.134133 24796 net.cpp:380] binactive3 -> binactive3
I0114 16:11:09.134186 24796 net.cpp:122] Setting up binactive3
I0114 16:11:09.134197 24796 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0114 16:11:09.134200 24796 net.cpp:137] Memory required for data: 442266400
I0114 16:11:09.134207 24796 layer_factory.hpp:78] Creating layer conv4
I0114 16:11:09.134238 24796 net.cpp:84] Creating Layer conv4
I0114 16:11:09.134246 24796 net.cpp:406] conv4 <- binactive3
I0114 16:11:09.134268 24796 net.cpp:380] conv4 -> conv4
I0114 16:11:09.261725 24796 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 9840
I0114 16:11:09.261770 24796 net.cpp:122] Setting up conv4
I0114 16:11:09.261785 24796 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0114 16:11:09.261792 24796 net.cpp:137] Memory required for data: 455245600
I0114 16:11:09.261827 24796 layer_factory.hpp:78] Creating layer bn5
I0114 16:11:09.261868 24796 net.cpp:84] Creating Layer bn5
I0114 16:11:09.261883 24796 net.cpp:406] bn5 <- conv4
I0114 16:11:09.261912 24796 net.cpp:367] bn5 -> conv4 (in-place)
I0114 16:11:09.262195 24796 net.cpp:122] Setting up bn5
I0114 16:11:09.262207 24796 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0114 16:11:09.262210 24796 net.cpp:137] Memory required for data: 468224800
I0114 16:11:09.262251 24796 layer_factory.hpp:78] Creating layer scale5
I0114 16:11:09.262280 24796 net.cpp:84] Creating Layer scale5
I0114 16:11:09.262289 24796 net.cpp:406] scale5 <- conv4
I0114 16:11:09.262305 24796 net.cpp:367] scale5 -> conv4 (in-place)
I0114 16:11:09.262413 24796 layer_factory.hpp:78] Creating layer scale5
I0114 16:11:09.262603 24796 net.cpp:122] Setting up scale5
I0114 16:11:09.262616 24796 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0114 16:11:09.262619 24796 net.cpp:137] Memory required for data: 481204000
I0114 16:11:09.262634 24796 layer_factory.hpp:78] Creating layer binactive4
I0114 16:11:09.262652 24796 net.cpp:84] Creating Layer binactive4
I0114 16:11:09.262661 24796 net.cpp:406] binactive4 <- conv4
I0114 16:11:09.262676 24796 net.cpp:380] binactive4 -> binactive4
I0114 16:11:09.262723 24796 net.cpp:122] Setting up binactive4
I0114 16:11:09.262734 24796 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0114 16:11:09.262737 24796 net.cpp:137] Memory required for data: 494183200
I0114 16:11:09.262743 24796 layer_factory.hpp:78] Creating layer conv5
I0114 16:11:09.262774 24796 net.cpp:84] Creating Layer conv5
I0114 16:11:09.262782 24796 net.cpp:406] conv5 <- binactive4
I0114 16:11:09.262800 24796 net.cpp:380] conv5 -> conv5
I0114 16:11:09.344276 24796 cudnn_binary_conv_layer.cpp:194] Reallocating workspace storage: 18874368
I0114 16:11:09.344661 24796 net.cpp:122] Setting up conv5
I0114 16:11:09.344686 24796 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0114 16:11:09.344692 24796 net.cpp:137] Memory required for data: 502836000
I0114 16:11:09.344714 24796 layer_factory.hpp:78] Creating layer pool5
I0114 16:11:09.344748 24796 net.cpp:84] Creating Layer pool5
I0114 16:11:09.344758 24796 net.cpp:406] pool5 <- conv5
I0114 16:11:09.344779 24796 net.cpp:380] pool5 -> pool5
I0114 16:11:09.344872 24796 net.cpp:122] Setting up pool5
I0114 16:11:09.344887 24796 net.cpp:129] Top shape: 50 256 6 6 (460800)
I0114 16:11:09.344892 24796 net.cpp:137] Memory required for data: 504679200
I0114 16:11:09.344910 24796 layer_factory.hpp:78] Creating layer bn6
I0114 16:11:09.344928 24796 net.cpp:84] Creating Layer bn6
I0114 16:11:09.344936 24796 net.cpp:406] bn6 <- pool5
I0114 16:11:09.344954 24796 net.cpp:367] bn6 -> pool5 (in-place)
I0114 16:11:09.345232 24796 net.cpp:122] Setting up bn6
I0114 16:11:09.345243 24796 net.cpp:129] Top shape: 50 256 6 6 (460800)
I0114 16:11:09.345248 24796 net.cpp:137] Memory required for data: 506522400
I0114 16:11:09.345286 24796 layer_factory.hpp:78] Creating layer scale6
I0114 16:11:09.345309 24796 net.cpp:84] Creating Layer scale6
I0114 16:11:09.345316 24796 net.cpp:406] scale6 <- pool5
I0114 16:11:09.345331 24796 net.cpp:367] scale6 -> pool5 (in-place)
I0114 16:11:09.345418 24796 layer_factory.hpp:78] Creating layer scale6
I0114 16:11:09.345604 24796 net.cpp:122] Setting up scale6
I0114 16:11:09.345616 24796 net.cpp:129] Top shape: 50 256 6 6 (460800)
I0114 16:11:09.345620 24796 net.cpp:137] Memory required for data: 508365600
I0114 16:11:09.345634 24796 layer_factory.hpp:78] Creating layer binactive5
I0114 16:11:09.345649 24796 net.cpp:84] Creating Layer binactive5
I0114 16:11:09.345657 24796 net.cpp:406] binactive5 <- pool5
I0114 16:11:09.345672 24796 net.cpp:380] binactive5 -> binactive5
I0114 16:11:09.345716 24796 net.cpp:122] Setting up binactive5
I0114 16:11:09.345731 24796 net.cpp:129] Top shape: 50 256 6 6 (460800)
I0114 16:11:09.345736 24796 net.cpp:137] Memory required for data: 510208800
I0114 16:11:09.345741 24796 layer_factory.hpp:78] Creating layer fc6
I0114 16:11:09.345764 24796 net.cpp:84] Creating Layer fc6
I0114 16:11:09.345772 24796 net.cpp:406] fc6 <- binactive5
I0114 16:11:09.345788 24796 net.cpp:380] fc6 -> fc6
I0114 16:11:14.003434 24796 net.cpp:122] Setting up fc6
I0114 16:11:14.003613 24796 net.cpp:129] Top shape: 50 4096 (204800)
I0114 16:11:14.003638 24796 net.cpp:137] Memory required for data: 511028000
I0114 16:11:14.003722 24796 layer_factory.hpp:78] Creating layer bn7
I0114 16:11:14.003826 24796 net.cpp:84] Creating Layer bn7
I0114 16:11:14.003906 24796 net.cpp:406] bn7 <- fc6
I0114 16:11:14.003962 24796 net.cpp:367] bn7 -> fc6 (in-place)
I0114 16:11:14.004420 24796 net.cpp:122] Setting up bn7
I0114 16:11:14.004459 24796 net.cpp:129] Top shape: 50 4096 (204800)
I0114 16:11:14.004479 24796 net.cpp:137] Memory required for data: 511847200
I0114 16:11:14.004526 24796 layer_factory.hpp:78] Creating layer scale7
I0114 16:11:14.004596 24796 net.cpp:84] Creating Layer scale7
I0114 16:11:14.004626 24796 net.cpp:406] scale7 <- fc6
I0114 16:11:14.004664 24796 net.cpp:367] scale7 -> fc6 (in-place)
I0114 16:11:14.004870 24796 layer_factory.hpp:78] Creating layer scale7
I0114 16:11:14.005185 24796 net.cpp:122] Setting up scale7
I0114 16:11:14.005223 24796 net.cpp:129] Top shape: 50 4096 (204800)
I0114 16:11:14.005244 24796 net.cpp:137] Memory required for data: 512666400
I0114 16:11:14.005280 24796 layer_factory.hpp:78] Creating layer binactive6
I0114 16:11:14.005316 24796 net.cpp:84] Creating Layer binactive6
I0114 16:11:14.005347 24796 net.cpp:406] binactive6 <- fc6
I0114 16:11:14.005398 24796 net.cpp:380] binactive6 -> binactive6
I0114 16:11:14.005487 24796 net.cpp:122] Setting up binactive6
I0114 16:11:14.005522 24796 net.cpp:129] Top shape: 50 4096 (204800)
I0114 16:11:14.005542 24796 net.cpp:137] Memory required for data: 513485600
I0114 16:11:14.005564 24796 layer_factory.hpp:78] Creating layer fc7
I0114 16:11:14.005631 24796 net.cpp:84] Creating Layer fc7
I0114 16:11:14.005661 24796 net.cpp:406] fc7 <- binactive6
I0114 16:11:14.005704 24796 net.cpp:380] fc7 -> fc7
I0114 16:11:15.765133 24796 net.cpp:122] Setting up fc7
I0114 16:11:15.765202 24796 net.cpp:129] Top shape: 50 4096 (204800)
I0114 16:11:15.765209 24796 net.cpp:137] Memory required for data: 514304800
I0114 16:11:15.765251 24796 layer_factory.hpp:78] Creating layer bn8
I0114 16:11:15.765336 24796 net.cpp:84] Creating Layer bn8
I0114 16:11:15.765365 24796 net.cpp:406] bn8 <- fc7
I0114 16:11:15.765403 24796 net.cpp:367] bn8 -> fc7 (in-place)
I0114 16:11:15.765868 24796 net.cpp:122] Setting up bn8
I0114 16:11:15.765895 24796 net.cpp:129] Top shape: 50 4096 (204800)
I0114 16:11:15.765900 24796 net.cpp:137] Memory required for data: 515124000
I0114 16:11:15.765928 24796 layer_factory.hpp:78] Creating layer scale8
I0114 16:11:15.765980 24796 net.cpp:84] Creating Layer scale8
I0114 16:11:15.766010 24796 net.cpp:406] scale8 <- fc7
I0114 16:11:15.766046 24796 net.cpp:367] scale8 -> fc7 (in-place)
I0114 16:11:15.766191 24796 layer_factory.hpp:78] Creating layer scale8
I0114 16:11:15.766458 24796 net.cpp:122] Setting up scale8
I0114 16:11:15.766474 24796 net.cpp:129] Top shape: 50 4096 (204800)
I0114 16:11:15.766480 24796 net.cpp:137] Memory required for data: 515943200
I0114 16:11:15.766500 24796 layer_factory.hpp:78] Creating layer relu7
I0114 16:11:15.766523 24796 net.cpp:84] Creating Layer relu7
I0114 16:11:15.766533 24796 net.cpp:406] relu7 <- fc7
I0114 16:11:15.766551 24796 net.cpp:367] relu7 -> fc7 (in-place)
I0114 16:11:15.768308 24796 net.cpp:122] Setting up relu7
I0114 16:11:15.768328 24796 net.cpp:129] Top shape: 50 4096 (204800)
I0114 16:11:15.768333 24796 net.cpp:137] Memory required for data: 516762400
I0114 16:11:15.768349 24796 layer_factory.hpp:78] Creating layer fc8
I0114 16:11:15.768381 24796 net.cpp:84] Creating Layer fc8
I0114 16:11:15.768393 24796 net.cpp:406] fc8 <- fc7
I0114 16:11:15.768424 24796 net.cpp:380] fc8 -> fc8
I0114 16:11:16.174453 24796 net.cpp:122] Setting up fc8
I0114 16:11:16.174582 24796 net.cpp:129] Top shape: 50 1000 (50000)
I0114 16:11:16.174608 24796 net.cpp:137] Memory required for data: 516962400
I0114 16:11:16.174667 24796 layer_factory.hpp:78] Creating layer fc8_fc8_0_split
I0114 16:11:16.174737 24796 net.cpp:84] Creating Layer fc8_fc8_0_split
I0114 16:11:16.174777 24796 net.cpp:406] fc8_fc8_0_split <- fc8
I0114 16:11:16.174830 24796 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0114 16:11:16.174885 24796 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0114 16:11:16.174943 24796 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0114 16:11:16.175084 24796 net.cpp:122] Setting up fc8_fc8_0_split
I0114 16:11:16.175143 24796 net.cpp:129] Top shape: 50 1000 (50000)
I0114 16:11:16.175168 24796 net.cpp:129] Top shape: 50 1000 (50000)
I0114 16:11:16.175189 24796 net.cpp:129] Top shape: 50 1000 (50000)
I0114 16:11:16.175209 24796 net.cpp:137] Memory required for data: 517562400
I0114 16:11:16.175231 24796 layer_factory.hpp:78] Creating layer loss
I0114 16:11:16.175271 24796 net.cpp:84] Creating Layer loss
I0114 16:11:16.175298 24796 net.cpp:406] loss <- fc8_fc8_0_split_0
I0114 16:11:16.175331 24796 net.cpp:406] loss <- label_data_1_split_0
I0114 16:11:16.175388 24796 net.cpp:380] loss -> loss
I0114 16:11:16.175472 24796 layer_factory.hpp:78] Creating layer loss
I0114 16:11:16.177186 24796 net.cpp:122] Setting up loss
I0114 16:11:16.177230 24796 net.cpp:129] Top shape: (1)
I0114 16:11:16.177253 24796 net.cpp:132]     with loss weight 1
I0114 16:11:16.177285 24796 net.cpp:137] Memory required for data: 517562404
I0114 16:11:16.177310 24796 layer_factory.hpp:78] Creating layer accuracy
I0114 16:11:16.177353 24796 net.cpp:84] Creating Layer accuracy
I0114 16:11:16.177382 24796 net.cpp:406] accuracy <- fc8_fc8_0_split_1
I0114 16:11:16.177418 24796 net.cpp:406] accuracy <- label_data_1_split_1
I0114 16:11:16.177456 24796 net.cpp:380] accuracy -> accuracy
I0114 16:11:16.177512 24796 net.cpp:122] Setting up accuracy
I0114 16:11:16.177544 24796 net.cpp:129] Top shape: (1)
I0114 16:11:16.177567 24796 net.cpp:137] Memory required for data: 517562408
I0114 16:11:16.177589 24796 layer_factory.hpp:78] Creating layer accuracy_5
I0114 16:11:16.177626 24796 net.cpp:84] Creating Layer accuracy_5
I0114 16:11:16.177654 24796 net.cpp:406] accuracy_5 <- fc8_fc8_0_split_2
I0114 16:11:16.177686 24796 net.cpp:406] accuracy_5 <- label_data_1_split_2
I0114 16:11:16.177722 24796 net.cpp:380] accuracy_5 -> accuracy_5
I0114 16:11:16.177772 24796 net.cpp:122] Setting up accuracy_5
I0114 16:11:16.177804 24796 net.cpp:129] Top shape: (1)
I0114 16:11:16.177824 24796 net.cpp:137] Memory required for data: 517562412
I0114 16:11:16.177850 24796 net.cpp:200] accuracy_5 does not need backward computation.
I0114 16:11:16.177876 24796 net.cpp:200] accuracy does not need backward computation.
I0114 16:11:16.177901 24796 net.cpp:198] loss needs backward computation.
I0114 16:11:16.177924 24796 net.cpp:198] fc8_fc8_0_split needs backward computation.
I0114 16:11:16.177947 24796 net.cpp:198] fc8 needs backward computation.
I0114 16:11:16.177973 24796 net.cpp:198] relu7 needs backward computation.
I0114 16:11:16.177995 24796 net.cpp:198] scale8 needs backward computation.
I0114 16:11:16.178017 24796 net.cpp:198] bn8 needs backward computation.
I0114 16:11:16.178040 24796 net.cpp:198] fc7 needs backward computation.
I0114 16:11:16.178066 24796 net.cpp:198] binactive6 needs backward computation.
I0114 16:11:16.178088 24796 net.cpp:198] scale7 needs backward computation.
I0114 16:11:16.178112 24796 net.cpp:198] bn7 needs backward computation.
I0114 16:11:16.178133 24796 net.cpp:198] fc6 needs backward computation.
I0114 16:11:16.178158 24796 net.cpp:198] binactive5 needs backward computation.
I0114 16:11:16.178181 24796 net.cpp:198] scale6 needs backward computation.
I0114 16:11:16.178203 24796 net.cpp:198] bn6 needs backward computation.
I0114 16:11:16.178226 24796 net.cpp:198] pool5 needs backward computation.
I0114 16:11:16.178251 24796 net.cpp:198] conv5 needs backward computation.
I0114 16:11:16.178275 24796 net.cpp:198] binactive4 needs backward computation.
I0114 16:11:16.178299 24796 net.cpp:198] scale5 needs backward computation.
I0114 16:11:16.178323 24796 net.cpp:198] bn5 needs backward computation.
I0114 16:11:16.178350 24796 net.cpp:198] conv4 needs backward computation.
I0114 16:11:16.178376 24796 net.cpp:198] binactive3 needs backward computation.
I0114 16:11:16.178401 24796 net.cpp:198] scale4 needs backward computation.
I0114 16:11:16.178423 24796 net.cpp:198] bn4 needs backward computation.
I0114 16:11:16.178454 24796 net.cpp:198] conv3 needs backward computation.
I0114 16:11:16.178478 24796 net.cpp:198] binactive2 needs backward computation.
I0114 16:11:16.178511 24796 net.cpp:198] scale3 needs backward computation.
I0114 16:11:16.178536 24796 net.cpp:198] bn3 needs backward computation.
I0114 16:11:16.178560 24796 net.cpp:198] pool2 needs backward computation.
I0114 16:11:16.178583 24796 net.cpp:198] conv2 needs backward computation.
I0114 16:11:16.178606 24796 net.cpp:198] binactive1 needs backward computation.
I0114 16:11:16.178629 24796 net.cpp:198] scale2 needs backward computation.
I0114 16:11:16.178653 24796 net.cpp:198] bn2 needs backward computation.
I0114 16:11:16.178676 24796 net.cpp:198] pool1 needs backward computation.
I0114 16:11:16.178700 24796 net.cpp:198] relu1 needs backward computation.
I0114 16:11:16.178723 24796 net.cpp:198] scale1 needs backward computation.
I0114 16:11:16.178747 24796 net.cpp:198] bn1 needs backward computation.
I0114 16:11:16.178769 24796 net.cpp:198] conv1 needs backward computation.
I0114 16:11:16.178794 24796 net.cpp:200] label_data_1_split does not need backward computation.
I0114 16:11:16.178820 24796 net.cpp:200] data does not need backward computation.
I0114 16:11:16.178841 24796 net.cpp:242] This network produces output accuracy
I0114 16:11:16.178871 24796 net.cpp:242] This network produces output accuracy_5
I0114 16:11:16.178895 24796 net.cpp:242] This network produces output loss
I0114 16:11:16.178990 24796 net.cpp:255] Network initialization done.
I0114 16:11:16.179255 24796 solver.cpp:57] Solver scaffolding done.
I0114 16:11:16.183660 24796 caffe.cpp:235] Resuming from snapshot/solver_adam_iter_200000.solverstate
